                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   87            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015     A Realidade Aumentada no Ensino de Topologias de Redes:  uma aplicação interativa   Fernanda Maria Rossini Donato1, Rafael Rodrigues da Conceição1, Sayure Salles  Nonnenmacher1, Carla Cristiane Costa2 , Sergio da Costa Nunes1   1Instituto Federal Farroupilha – Campus Júlio de Castilhos – RS - Brasil  Caixa Postal 38 – 98.130-000 – Júlio de Castilhos, RS – Brasil   2Instituto Federal Farroupilha – Reitoria – RS - Brasil  Rua Esmeralda, 430 – 97.110-767 - Santa Maria, RS - Brasil   fernanda.donato1993@gmail.com, rafaell.rrodrigues@gmail.com,  sayuresalles@hotmail.com,sergio.nunes@iffarroupilha.edu.br,   carla.costa@iffarroupilha.edu.br  Abstract. This paper presents the studies conducted by the research group in  Augmented Reality Campus Julio de Castilhos the Federal Institute  Farroupilha. The group consists of three students of the course Bachelor of  Information Systems and the guiding teachers. The studies relate to the  development of learning objects in Augmented Reality (AR ) using 3ds Max  software to create animations and Aumentaty software for viewing on RA . It  is presented throughout this , first the concept of RA , Learning Objects and  then some objects developed by the group ( topologies of computer networks )  . After the development objects used in a class at the Technical Course in  Software in distance education mode Federal Institute Farroupilha .   Resumo. Este trabalho apresenta os estudos desenvolvidos pelo grupo de  pesquisa em Realidade Aumentada do Campus Júlio de Castilhos do Instituto  Federal Farroupilha. O grupo é composto por três alunos do Curso  Bacharelado em Sistemas de Informação e pelos professores orientadores. Os  estudos referem-se ao desenvolvimento de objetos de aprendizagem em  Realidade Aumentada(RA), utilizando o software 3Ds Max para criação das  animações e do software Aumentaty para visualização em RA. Apresenta-se  no decorrer deste, primeiramente os conceitos de RA, Objetos de  Aprendizagem e posteriormente alguns objetos desenvolvidos pelo grupo  (topologias de redes de computadores). Após o desenvolvimento os objetos  utilizados em uma aula no Curso Técnico em Redes de Computadores na  modalidade EAD do Instituto Federal Farroupilha.   1. Introdução   Com o surgimento das novas tecnologias, em particular a Computação Gráfica e a  Realidade Virtual, as técnicas de visualização, manipulação e interação se tornaram  sofisticadas, em um ambiente tridimensional gerado por computador, permitindo uma  melhor compreensão dos fenômenos complexos, ou ao menos de alguns de seus  aspectos (Netto, 2004).    A Realidade Aumentada é um tipo de interface que comporta o uso de diversas  imagens de um ambiente virtual, criando objetos tridimensionais que enriquecem a  visão do usuário. Essas imagens podem ser capturadas através de câmeras de vídeos ou  criadas através de programas de edição de objetos em 3D.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   88            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015      O uso da Realidade Aumentada possibilita criar objetos de aprendizagem para  utilização em várias áreas de pesquisa e estudo. A forma em que os objetos são  apresentados possibilita ao usuário uma melhor compreensão do assunto estudado, pois  a utilização dos objetos tridimensionais reflete ao aluno uma nova visão de  funcionamento do tema abordado.      Os estudos das topologias em redes destinados aos cursos de informática são  essenciais para o aluno compreender o funcionamento completo de uma estrutura de  rede de computadores. Uma estrutura em rede pode conter diversos componentes  conectados entre si, desde computadores de mesas, notebooks, smartphones, tablets e  outros dispositivos móveis que trocam informações constantemente dentro de uma rede.    As topologias de redes são estruturas de ligação para conectar computadores e  componentes dentro de uma rede de trabalho. Criando a possibilidade de que os  usuários da rede possam trocar informações entre si, melhorando o desempenho das  tarefas dentro deste grupo de usuário. O correto entendimento das topologias de redes é  essencial para o estudo dos diversos tipos de redes de computadores e em especial o  estudo da Internet.   2. Trabalhos relacionados   A Realidade Aumentada tem sido utilizada em várias áreas do conhecimento como  ferramenta para auxiliar o processo de ensino-aprendizagem, como, por exemplo, na  Matemática e Física (Forte 2009), Arquitetura e Construção Civil (Rodrigues, Pinto e  Rodrigues, 2010 e Artes (Braga 2011).     Em Kaufmann (2003), é apresentado o Construct3D, um software educativo que  aborda o conteúdo pedagógico relacionado ao ensino de Geometria. O software oferece  um conjunto de itens primitivos para a construção de imagens virtuais pelo usuário  como pontos, linhas, planos, cubos, esferas, cilindros e cones. Além disso, permite ao  usuário realizar operações de interseção, operações booleanas, operações de simetria e  delimitação de medidas.      3. Aprendizagem em EAD utilizando objetos com Realidade Aumentada   Neste capítulo serão apresentados os conceitos e aplicações da Realidade Aumentada  com objetos de aprendizagem em EAD.   3.1. Realidade Aumentada  O crescimento da tecnologia virtual possibilitou um desenvolvimento mais acentuado  para objetos de realidade aumentada, inserindo estes objetos em aplicações de  entretenimento que usamos cotidianamente. Estas aplicações podem ser encontradas em  objetos de aprendizagem, utilizados para o ensino em sala de aula em diversas  disciplinas.    Realidade aumentada é a sobreposição de objetos virtuais gerados por  computador em um ambiente real. A captura acontece através de marcadores  (interpretam o sinal transmitido pela câmera ou dispositivo) expostos em câmeras de  vídeos, webcams ou aparelhos de celulares. A imagem é captada e transmitida ao  marcador que fará a interpretação e exibe no próprio dispositivo o objeto virtual em  sobreposição ao real, como se ambos fossem uma coisa só.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   89            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015      Kirner afirma: A Realidade Virtual (RV) é uma “interface avançada do usuário”  para acessar aplicações executadas no computador, propiciando a visualização,  movimentação e interação do usuário, em tempo real, em ambientes tridimensionais  gerados por computador. O sentido da visão costuma ser preponderante em aplicações  de realidade virtual, mas os outros sentidos, como tato, audição, etc. também podem ser  usados para enriquecer a experiência do usuário.      3.2. Objetos de Aprendizagem  Conforme Weller (2003) um objeto da aprendizagem é uma parte digital do material da  aprendizagem que se dirige a um tópico claramente identificável ou resultado da  aprendizagem obtendo o potencial de reutilização em contextos diferentes. Todavia, o  Ministério da Educação (MEC) orienta que os objetos de aprendizagem devem  objetivar: o aprimoramento da educação presencial e/ou à distância, para incentivar a  pesquisa e a construção de novos conhecimentos para melhoria da qualidade, igualdade  e eficiência dos sistemas públicos de ensino pela incorporação didática das novas  tecnologias de informação e comunicação.                 Os objetos de aprendizagem possuem seis características fundamentais, segundo  Mendes, Souza e Caregnato (2004): Reusabilidade (o grau de facilidade ou de  potencialidade que um componente possui para ser reusado), Adaptabilidade (Adaptarse com facilidade), Granularidade (dividir o sistema em partes pequenas),  Acessibilidade (permite que todos tenham acesso), Durabilidade (como é a vida útil de  um material), Interoperabilidade (à capacidade de diversos sistemas e organizações  trabalharem em conjunto de modo a garantir que pessoas, organizações e sistemas  computacionais interajam para trocar informações de maneira eficaz e eficiente).   .   3.3. Objetos desenvolvidos para EAD  A prática da Educação à Distância (EAD) descreve-se como uma prática educativa, da  qual objetivos, conteúdos e resultados obtidos se identificam com aqueles que  constituem a aprendizagem como projeto e processo humanos, histórica e politicamente  definidos na cultura das diferentes sociedades.    Segundo Coiçaud, (2001), a educação a distância (EaD) surgiu no contexto da  educação como forma de disseminar o conhecimento acadêmico e atender setores mais  amplos da população, suprindo o acúmulo de importantes necessidades educacionais.     As tecnologias da informação aplicadas à EAD proporcionam maior  flexibilidade e acessibilidade à educação, fazendo-as progredir em direção a áreas de  conhecimentos e de métodos de aprendizagem inovadores, modificando conceitos  habituais e futuramente auxiliar na criação dos sistemas educacionais.   4. Objetos de Aprendizagem com Realidade Aumentada   Conforme visto na introdução, a forma em que os objetos são apresentados em realidade  aumentada possibilita ao usuário uma melhor compreensão do assunto estudado.     Baseando-se na perspectiva de suprir as dificuldades em entender o  funcionamento das redes de Internet, o grupo de projeto de ensino em Realidade  Aumentada, do Campus Júlio de Castilhos, decidiu criar alguns objetos de  aprendizagem que auxiliasse no processo de ensino de topologias na disciplina de redes     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   90            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015     de computadores. As topologias escolhidas para a criação dos objetos foram  barramento, estrela, token ring, ponto a ponto, anel, árvore e ainda um exemplo de  multiplexação.     Com a utilização da Realidade Aumentada, observa-se em animação gráfica em  3D o percurso das informações (pacotes) nas topologias.    Para criação dos objetos de aprendizagem utilizamos o software Autodesk 3DS  Max versão 2013. Este é um software de modelagem 3D, animação e renderização, o  qual permite personalizar, colaborar ou criar um conteúdo 3D rapidamente. Não exige  nenhum conhecimento de programação.          Após os objetos de aprendizagem criados neste software, utilizamos para  visualizar, em realidade aumentada, a ferramenta livre Aumentaty Author. Este software  utiliza marcadores para reconhecer o espaço tridimensional através da câmera do  dispositivo. Não exige conhecimento de programação, tornando assim seu uso com  facilidade.      Figura 7. Aumentaty Author   Figura 6. Autodesk 3Ds Max     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   91            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015      A seguir, apresentamos alguns dos objetos criados com base em redes de  computadores.     Na figura 3, está à topologia em barramento. Esta é uma topologia bem comum  possuindo alto poder de extensão, a qual todos os nós estão conectados em uma barra  compartilhada entre todos os processadores, onde este é o componente de hardware  responsável por processar dados e transformar em informação.     Figura 8.Topologia em Barramento    A figura 4 trata-se de uma técnica chamada Multiplexação, a qual permite o  compartilhamento da capacidade de um único meio de transmissão para duas ou mais  transmissões de forma simultânea e independente.      Figura 9. Multiplexação      5. Os Objetos Criados e sua Interatividade   Os objetos criados pelo grupo de estudo foram aplicados em uma turma de 15 alunos do  Curso Técnico em Redes de Computadores na modalidade EAD do Campus Júlio de  Castilhos.     A experiência foi feita em um polo de ensino a distância onde os alunos foram  reunidos para uma aula presencial sobre o conteúdo dos objetos de aprendizagem –  topologias de redes de computadores.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   92            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015      Inicialmente o professor/pesquisador explicou através de exposição dialogada os  conceitos de cada uma das topologias de redes, sem mostrar ou desenhar no quadro  verde nenhum dos tipos.    Após o professor/pesquisador explicou para a turma os conceitos de realidade  aumentada e a maneira de utilizar o software Aumentaty, como exemplo mostrou o  objeto da multiplexação.    A seguir solicitou aos alunos que acessassem o software Aumentaty em cada um  dos computadores e, com a utilização dos marcadores explorassem as topologias  previamente colocadas no software.    Inicialmente verificou-se certa dificuldade de alguns alunos na visualização dos  objetos através do marcador, mas com a ajuda do professor/pesquisador isto logo foi  absorvido.    Após trinta minutos de visualização e interação da turma com os objetos, o  professor/pesquisador solicitou a cada um dos alunos que respondessem o questionário:   1. Quantas topologias você visualizou e interagiu?  2. Quais os nomes das topologias que você interagiu?  3. Desenhe de forma esquemática as topologias barramento, token ring e anel.  4. Em que topologia consegue-se identificar claramente a técnica CSMA/CD?    Na Tabela 1 podemos observar quantitativamente os resultados do experimento:   Tabela 1. Nível de acertos das perguntas do questionário    Acertos % de acertos  Pergunta 1 15 alunos 100  Pergunta 2 13 alunos 86  Pergunta 3 12 alunos 80  Pergunta 4 15 alunos 100    O professor/pesquisador observou durante o experimento, um grande interesse  dos alunos em interagir com os objetos, modificando a posição do marcador e também  através dos botões de rotação do software.      Ao término do experimento os alunos relataram que gostaram muito de  “brincar” com o software e que ficaram animados com a utilização da Realidade  Aumentada em sala de aula. Também colocaram que seria interessante se os professores  utilizassem este tipo de recurso instrutivo em seus materiais didáticos.     6. Conclusões   Acredita-se que este trabalho irá contribuir para a adoção de objetos de aprendizagem  no ensino a distância e também presenciais desenvolvidos em Realidade Aumentada,  pois pode propiciar, através de suas características, um auxílio para a compreensão e  entendimento de objetos e/ou conceitos.    Verificou-se com a aplicação na turma de alunos do Curso de EAD, que os  mesmos obtiveram um bom aproveitamento, conforme mostra a Tabela 1.    Pode-se dizer que os resultados atestam de forma significativa o êxito do  experimento quanto à possibilidade de aprendizado através da interatividade com os     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   93            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015     objetos de aprendizagem. É importante ressaltar que os resultados comprovam que a  utilização da tecnologia para o ensino em EAD é benéfica e traz melhores respostas com  o aluno do que as aulas mais tradicionais.    A interação entre aluno e disciplina é mais positiva com o uso da realidade  aumentada, pois é mais prático ao estudante interagir com as animações e marcadores,  ao invés dos textos explicativos dos livros e as figuras fixas. Uma matéria considerada  teórica, como as topologias em redes, apresenta este benefício positivo com o uso da  realidade virtual. O aluno consegue compreender melhor o uso de determinada  topologia com a animação apresentada no computador.    Cabe salientar que podemos utilizar esta tecnologia também para aplicação em  vídeo aulas, através da filmagem dos objetos expostos com o software Aumentaty,  conforme é possível observarmos nos vídeos disponibilizados pelos autores deste artigo  e anexados nas referências.      O grupo de pesquisa criado no Campus Júlio de Castilhos propõe-se a  desenvolver trabalhos futuros nesta área, procurando colaborar para o processo de  ensino/aprendizagem do Instituto Federal farroupilha.     7. Referências   Coiçaud, Silvia.”A colaboração institucional na educação a distância”. In: LITWIN,  Edith. Educação a distância: temas para o debate de uma nova agenda educativa.  Porto Alegre: Artmed, 2001.   Kirner, Claudio e Siscoutto, Robson (2007) “Realidade Virtual e Aumentada Conceitos,  Projeto e Aplicações”. Livro do Pré-Simpósio IX Symposium on Virtual and  Augmented Reality. Petrópolis – RJ.   MEC – Ministério da Educação. Online: http://portal.mec.gov.br - Acessado em:  08/09/2015.   Mendes, Rozi Mara, Souza, Vanessa Inácio e Caregnato, Sônia Elisa (2004).  “A  propriedade intelectual na elaboração de objetos de aprendizagem”. In: V Encontro  Nacional de Ciência da Informação. Salvador.   Monteiro, Bruno S., Cruz, Henry P., Andrade, Mariel, Gouveia, Thiago, Tavares,  Romero e Anjos, Lucídio F. C. (2006) “Metodologia de desenvolvimento de objetos  de aprendizagem com foco na aprendizagem significativa”. Simpósio Brasileiro de  Informática na Educação – SBIE, XVII (17). Brasília – DF.    Netto, M. L., Del Nero, H. S., Ranieri C. (2004). “ Evolutionary Learning Strategies for  Artificial Life Characters, Recent Advances in Simulated Evolution and Learning”.  Singapore.    Weller, M., Pegler, C. and Mason, R. (2003) “Putting the pieces together: What working  with learning objects means for the educator”.   Youtube. Topologia Estrela. Disponível em:  <https://www.youtube.com/watch?v=PkLZzX95JCU>. Acesso em: 28 Ago. 2015.   Youtube. Topologia em Estrela. Disponível em:  <https://www.youtube.com/watch?v=dizSRjyGD_I>. Acesso em: 28 Ago. 2015.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   94            Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 87-94 Nov/2015     Youtube. Token Ring. Disponível em:  <https://www.youtube.com/watch?v=uowl1OmB62U>. Acesso em: 28 Ago. 2015.   Youtube. Barramento Colisão. Disponível em:  <https://www.youtube.com/watch?v=AE-4GKMp3C4>. Acesso em: 28 Ago. 2015.         
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   13        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015     Ambiental Web: Sistema Especialista para Apoio à  Avaliação de Processos de Licenciamento Ambiental   Luciano Rosa de Almeida, Sidnei Renato Silveira, Guilherme Bernardino Cunha   Universidade Federal de Santa Maria (UFSM) – Centro de Educação Superior Norte  do RS (CESNORS) – Frederico Westphalen – RS – Brasil   lucralm@gmail.com, sidneirenato.silveira@gmail.com  Resumo. O licenciamento ambiental é um dos primeiros passos para a  implantação de empreendimentos e desenvolvimento de atividades que  podem trazer algum impacto potencialmente causador de significativa  degradação do meio ambiente. Devido à complexidade e diversidade de  casos que as leis ambientais brasileiras abrangem, desenvolvemos o  Ambiental Web, um sistema especialista que fornece suporte às decisões de  técnicos e fiscais ambientais para que suas ações estejam amparadas pela  legislação ambiental vigente, no contexto do licenciamento ambiental  florestal.   Palavras-Chave: Licenciamento ambiental, Inteligência Artificial, Sistemas  Especialistas   Abstract. Environmental licensing is one of the first steps for the  implementation of projects and development activities that can bring some  potentially causing impact of significant degradation of the environment.  Because of the complexity and diversity of cases that Brazilian  environmental laws cover, we developed the Ambiental Web, an expert  system that provides support in technical decisions and environmental tax so  that their actions are supported by current environmental legislation in the  context of forest environmental licensing.   Keywords: Licensing environment, Artificial Intelligence, Expert Systems   1. Introdução   O processo de licenciamento ambiental é um procedimento administrativo que mede o  impacto que um empreendimento poderá trazer ao meio ambiente, buscando ao  máximo a redução dos impactos negativos que as atividades utilizadoras de recursos  naturais e potencialmente poluidoras ou aquelas que, sob qualquer forma, possam  causar degradação ambiental. O conhecimento da legislação e de aspectos importantes  das normas legais relacionadas a unidades de conservação é um importante  instrumento para a proteção das espécies de árvores. As leis são muito abrangentes,  alcançando os mais diversos temas ambientais. A literatura em geral trata de temas, na  maioria das vezes, direcionados especificamente a determinadas áreas (MINISTÉRIO  DO MEIO AMBIENTE, 2009).      Neste contexto, desenvolvemos o Ambiental Web, uma ferramenta que  auxiliará na análise prévia e automatizada do processo de corte eventual de árvores,  instituindo na sua base de conhecimento princípios, fixando objetivos e normas  básicas para a proteção do meio ambiente, estabelecidos na lei, de cada localidade,  observando as demais normas estaduais e federais. Acreditamos que, com a aplicação  de técnicas de Inteligência Artificial, por meio da implementação de um protótipo de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   14        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015     Sistema Especialista, seja possível apoiar os técnicos da área ambiental nos processos  que envolvem o licenciamento florestal para corte de árvores, respeitando a legislação  vigente, em especial, na cidade de Frederico Westphalen – RS.   2. Referencial Teórico   A Inteligência pode ser definida como a capacidade de raciocinar, planejar, processar  ideias, compreender linguagem e adquirir conhecimento. O conceito de Inteligência  Artificial (IA) pode ser sintetizado, na capacidade do homem em desenvolver  sistemas computacionais, que são capazes de simular o raciocínio humano, resumindo  ser inteligente (FERNANDES, 2005; LORENZI; SILVEIRA, 2011).    Entre as ferramentas e técnicas existentes na IA, existem os Sistemas  Baseados em Conhecimento (SBC). Os Sistemas Especialistas (foco deste trabalho)  são uma das categorias de SBCs. Definimos SBCs como um programa que se  comporta como um ser humano em um domínio específico do conhecimento. Um  SBC é um programa que utiliza conhecimento representado explicitamente para  resolver problemas, ou seja, são desenvolvidos para serem usados em situações em  que é indispensável uma quantidade considerável de conhecimento e perícia na área  (FERNANDES, 2005; LORENZI, SILVEIRA, 2011; REZENDE, 2003).    O que difere os SBCs dos sistemas convencionais é a capacidade de manipular  o conhecimento armazenado na base de conhecimento e de possuir rotinas de  inferência e questionamentos. O problema proposto deve estar explicitamente  representando nessa base de conhecimento para que o sistema possa auxiliar na busca  de soluções para o mesmo (FERNANDES, 2005).     A finalidade básica de um Sistema Especialista é simular o comportamento de  um especialista em uma determinada área de conhecimento e elaborar respostas como  se fosse um especialista humano (FERNANDES, 2005). Os SEs são caracterizados  como programas computacionais que simulam a capacidade de especialistas humanos  na resolução de problemas em determinadas áreas de conhecimento específicas, por  meio de inferência lógica utilizando fatos e regras. O especialista humano fornece o  conhecimento de como serão inseridas as informações e como devem ser processadas  para determinadas saídas. Os especialistas em IA, com base nessas informações,  implementam o conhecimento em programas, sempre com a supervisão analítica do  especialista (FERNANDES, 2005; LUGER, 2004; REZENDE ,2003).   3.  Estado da Arte   Nesta seção, apresentamos um comparativo entre o Ambiental Web e outros SEs que  tratam de conhecimentos ligados à legislação. Como foram encontrados poucos  trabalhos que abordam a implementação de SEs na área ambiental, estudamos  também, SEs desenvolvidos para a área de Direito, que são os que mais se parecem  com esta proposta, já que tratam de legislação. O quadro 1 apresenta um comparativo  entre o SE proposto e os sistemas estudados nesta seção.    Após a análise dos trabalhos estudados, comparamos e observamos algumas  semelhanças entre os sistemas. Todos utilizam a mesma técnica de IA e apresentam  finalidades distintas, mas o que mais se parece com o sistema proposto é o Previndex,  pois ambos tratam de temas específicos de determinada legislação.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   15        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015       Quadro 1. Comparativo entre os sistemas estudados   Característica   Previndex   (ANSELMO;  SILVEIRA, 2009)   Sistema de suporte à  decisão para   recomendação de uso  e manejo da terra   GIBOSHI (et. al, 2014)   SisDec  (MARTINS   JÚNIOR;  VASCONCELOS  , 2008)     Ambiental Web   Finalidade do  sistema   Consulta em  Direito   Previdenciário   Cálculo de capacidade  de uso do solo   Apoio à decisão  em Direito  Ambiental   Consulta em  legislação  ambiental   Técnica de IA  utilizada   Sistema Baseado  em   Conhecimento:  Sistema   Especialista   Sistema Baseado em  Conhecimento: Sistema   Especialista   Sistema Baseado  em Conhecimento   Sistema Baseado  em   Conhecimento:  Sistema   Especialista  Tipo de aplicação    Web Desktop Desktop Web   Forma de  Representação do   Conhecimento   Regras de  Produção Representação lógica   Representação  lógica   Regras de  Produção   Tecnologias para  Implementação   PHP com banco  de dados MySQL   Visual Basic 5   Prolog   PHP com banco  de dados MySQL   Permite a  Manutenção da   base de  conhecimento   Sim, as regras  podem ser   manipuladas.   Não, apenas executa as  regras pré estabelecidas   Não, apenas  executa as regras  pré-estabelecidas   Sim, as regras  poderão ser   manipuladas.      4. Solução Implementada   O Ambiental Web é um protótipo de SE, visando auxiliar na análise de informações,  proporcionando mais agilidade aos profissionais da área ambiental com especial  interesse na obtenção de licenças ambientais florestais, seja em propriedades  particulares ou em áreas de passeio público. As informações que compõem a base de  conhecimento do SE compreendem as legislações ambientais nas esferas Municipal,  Estadual e Federal, sob o ponto de vista e conhecimento do analista técnico ambiental.    Com a finalidade de facilitar o entendimento da área do conhecimento  envolvida e, consequentemente, encontrar a melhor maneira de representar o  conhecimento em um SE, é fundamental identificar a forma como o especialista do  domínio tratará as informações. Para isso é necessário seguir a linha de raciocínio do  profissional. Sendo assim, por meio de entrevistas realizadas com um especialista da  área de legislação ambiental, verificamos que as regras de produção seriam a forma  mais adequada para o desenvolvimento do Ambiental Web, visto que o especialista  utiliza-se do raciocínio “se...condições... então... conclusões e ações.” para chegar a  um parecer técnico sobre as licenças ambientais.    Na implementação do protótipo aqui apresentado tratamos apenas de um tipo  de requerimento, que é a emissão de Alvará de Licenciamento Florestal para corte  eventual de árvores. Segundo o Departamento de Meio Ambiente da Prefeitura de  Frederico Westphalen-RS, este tipo de requerimento corresponde a mais de 50% da  demanda de pedidos de licença. Para facilitar o entendimento da área do  conhecimento envolvida, contamos com um especialista, Técnico do Departamento de  Meio Ambiente, responsável pela fiscalização, laudos e licenças ambientais na     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   16        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015     Secretaria de Meio Ambiente de Frederico Westphalen-RS, que acompanhou o  desenvolvimento do Ambiental Web. Com o apoio deste especialista, foram criados  fluxogramas que delimitaram o domínio do sistema, permitindo a construção da base  de conhecimento e definição do mecanismo de inferência do SE. A base de  conhecimento foi modelada por meio de um modelo ER (Entidade-Relacionamento).  A Figura 1 apresenta o modelo ER do SE implementado, destacando-se:   • Tabela especies, que armazena as espécies vegetais com nome científico,  nome comum e categoria;   • Tabela categorias, onde são armazenadas as informações fornecidas pelos  técnicos em conformidade com a legislação para identificar as regra na base de  conhecimento;   • Tabela justificativa, que armazena as informações fornecidas pelos técnicos  em conformidade com a legislação, com identificador da regra de corte de  árvore correspondente na base de conhecimento;   • Tabela regras_reps, que armazena as informações fornecidas pelos técnicos em  conformidade com a legislação em relação à reposição das espécies, com  identificador da regra correspondente na base de conhecimento;   • Tabela requerimentos, que armazena as informações da solicitação do pedido  referente ao consulta de licença ambiental, como dados pessoais do  requerente, informações de localização da propriedade;   • Tabela itens_requerimento: tabela relacionada com a tabela requerimentos,  que tem a função de armazenar os itens que compõem o questionário de  requerimento relacionada com a tabela espécies.    O processo de inferência foi implementado no código-fonte do SE, por meio  da consulta às regras definidas na base de conhecimento. O especialista ou o usuário  final, a partir do cadastro dos requerimentos, dispara o processo de inferência. Esse  processo funciona por meio da comparação de todos os dados recebidos no  requerimento, com as regras cadastradas. As regras são compostas de itens prédefinidos pelo especialista que, a partir do seu conhecimento técnico, informa ao  sistema quais espécies de árvores são vulneráveis, quais requisitos são necessários, a  lei e as justificativas que dão suporte ao corte, a quantidade e tipos de espécies de  mudas que devem ser repostas. Como ponto de partida para implementar o processo  de inferência, usamos os fluxogramas (roteiros) elaborados em conjunto com o  especialista. A figura 2 apresenta, de forma gráfica, como funciona o processo de  inferência no Ambiental Web.    Para desenvolver o Ambiental Web utilizamos a linguagem de programação  PHP, o gerenciador de Banco de dados Mysql para armazenar a base de conhecimento  e o framework Bootstrap, que contém diversos componentes visuais desenvolvidos  com CSS (Cascade Style Sheet) e bibliotecas implementadas em JavaScript.  Para  instalar o SE, faz-se necessário um servidor web que suporte as tecnologias citadas.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   17        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015       Figura 1: Modelo ER do Ambiental Web (Fonte: Dos Autores, 2015)     Figura 2: Processo de Inferência do Ambiental Web (Fonte: Dos Autores, 2015)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   18        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015      Para demonstrar as funcionalidades implementadas no Ambiental Web,  escolhemos algumas das telas que apresentam as principais tarefas que podem ser  desenvolvidas com apoio do SE implementado. A Figura 3 apresenta a interface para  que o especialista faça o cadastro de regras de corte e de reposição de árvores.     Figura 3: Cadastro de Regras de Corte e de Regras de Reposição    (Fonte: Dos Autores, 2015)    As regras de corte são justificadas com base legal, destacando em que  hipóteses são admitidas o corte de determinada categoria de árvore. Com relação às  regras de reposição, são definidas quantas mudas deverão ser repostas e se deverão ser  da mesma espécie ou se podem ser de espécies variadas. Após as telas relacionadas à  manutenção da base de conhecimento (categorias, regras de reposição, regras de corte  e espécies), apresentamos a tela a partir da qual é realizado um requerimento, que irá  disparar o processo de inferência do SE. Por meio do formulário apresentado na  Figura 4, o requerente informa os dados pessoais e de localização da propriedade onde  estão as espécies que pretende cortar. Após, é preciso adicionar as espécies de árvores  que serão cortadas.    Para informar as espécies, o usuário deve adicionar as espécies de árvores para  corte, com base no cadastro de espécie que já estão pré-cadastradas no banco de  dados. É preciso informar a espécie, o DAP (diâmetro na altura do peito) e a altura de  cada árvore. O relatório (resultado do processo de inferência - Figura 5) apresenta as  informações de dados pessoais do solicitante, localização da propriedade e a lista de  espécies solicitadas para corte, trazendo as justificativas com as regras de corte e as  regras de reposição, incluindo a quantidade e quais espécies de mudas devem ser  repostas.    Após a implementação do Ambiental Web, foram realizados testes em  situações reais do cotidiano. Para tanto, os técnicos ambientais da Prefeitura de  Frederico Westphalen buscaram resultados de pareceres redigidos de forma manual e  compararam com os resultados do sistema. Para refinar os resultados, os especialistas  puderam modificar regras já existentes na base de conhecimento, além de criar novas  regras, até conseguirem um resultado satisfatório.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   19        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015       Figura 4: Requerimento - Espécies (Fonte: Dos Autores, 2015)   Figura 5: Conclusão do Processo de Inferência (Fonte: Dos Autores, 2015)      5. Considerações Finais   Acreditamos que os objetivos do trabalho foram alcançados, pois realizamos um  estudo sobre as técnicas referentes a sistemas especialistas e legislação ambiental em  específico sobre o corte de árvores. A partir dessas informações e conhecimento do  domínio e auxílio do especialista, modelamos a base de conhecimento e a forma como  definimos o processamento das informações para obter as saídas necessárias, bem  como implementamos e validamos um protótipo do SE proposto, o Ambiental Web.    Entre as dificuldades encontradas, destacamos o pequeno número de SEs  existentes na área ambiental. Como existem poucos exemplos de SEs implementados     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   20        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 13-20 Nov/2015     no domínio proposto tivemos que nos basear em outros domínios que utilizam as  mesmas técnicas para realizar um estudo comparativo.    O Ambiental Web traz, como principal benefício, o acesso a informações de  forma rápida e precisa para que, mesmo que com pouca experiência, técnicos e  profissionais com interesse e conhecimento do domínio, consigam avaliar sem  dificuldades a maior parte das questões com relevância sobre os processos de  licenciamentos florestais.     Como trabalhos futuros propomos a implementação de novos tipos de  requerimentos, com regras específicas a outras atividades, tais como licença ambiental  para instalação de empresas ou licença para atividades rurais. Acreditamos que, ao  disponibilizar um SE permitindo a automatização de tarefas, conseguimos trazer  benefícios como redução do tempo e precisão na tomada de decisões do profissional  da área ambiental, o que contribui para uma prestação de serviço de maior qualidade  ao público, já que o protótipo foi implementado visando o atendimento na Prefeitura  de Frederico Westphalen - RS.    Referências    ANSELMO, M. P. A.; SILVEIRA, S. R. (2009) Previndex:  Sistema Especialista para  a área de Direito Previdenciário. Disponível em:  <http://www.uniritter.edu.br/graduacao/informatica/sistemas/downloads/tcc2k9/TC CII_MarcosPaulo_2009_2.doc>. Trabalho de Conclusão de Curso, Bacharelado  em Sistemas de Informação. Porto Alegre: UniRitter. Acesso em: 20 jun 2014.   FERNANDES, A. M. R. (2005) Inteligência Artificial: noções gerais. Florianópolis:  Visual Books.    GIBOSHI, M. L.; RODRIGUES, L. H. A.; LOMBARDI NETO, F. (2004) Sistema de  suporte à decisão para recomendação de uso e manejo da terra. Disponível em:  <http://www.scielo.br/scielo.php?pid=S141543662006000400012&script=sci_arttext>. Acesso em jun., 2014.   LORENZI, F.; SILVEIRA, S. R. (2011) Desenvolvimento de Sistemas de Informação  Inteligentes. Porto Alegre: UniRitter.   LUGER, G. F. (2004) Inteligência artificial: estruturas e estratégias para a resolução  de problemas complexos. 4. ed. Porto Alegre: Bookman.   MARTINS JUNIOR, P. P.; VASCONCELOS, V. V. (2008). Protótipo de sistema  especialista para auxílio à decisão em direito ambiental: situações de  desmatamentos rurais. Disponível em:  <http://cecemca.rc.unesp.br/ojs/index.php/climatologia/article/view/1789/2206>.  Acesso em: 24 jun. 2009.   MINISTÉRIO DO MEIO AMBIENTE. (2009) Caderno de Licenciamento Ambiental.  Disponível  em:   <http://www.mma.gov.br/estruturas/sqa_pnla/_arquivos/ultimo_caderno_pnc_licen ciamento_caderno_de_licenciamento_ambiental_46.pdf>. Acesso em abr. 2014.   REZENDE, S. O. (Coord.). (2003). Sistemas Inteligentes: fundamentos e aplicações.  Barueri: Manole.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   181        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015     Aplicação da Técnica de Fatoração de Matrizes NãoNegativas à Separação de Fontes Sonoras em Misturas   contendo Elementos Harmônicos e Percussivos   Wellington Fonseca, Zélia Peixoto, Flávia Magalhães, Marcelo Santos   Programa de Pós-Graduação em Engenharia Elétrica  Pontifícia Universidade Católica de Minas Gerais   Belo Horizonte, Minas Gerais – Brasil  wellington.fonseca@sga.pucminas.br,    {assiszmp, flaviamagfreitas}@pucminas.br,   marcelo.borba.ti@hotmail.com   Abstract. This paper deals with the separation of audio signals of which there  is not a priori information. More specifically, the aim is to separate each  instrument in a mixture which includes harmonic and percussive elements.  Among the usual techniques, the method of non-negative matrix factorization  (NMF) was chosen, once the quality of separation provided by this method is  not conditional upon the number of available observations. It was analyzed in  Matlab® environment, using the divergences of Kullback-Leibler and ItakuraSaito. The results showed no significant differences between the methods,  stimulating new researches that include constraints on NMF method, such as  the sparsity and smoothness, among others.  Resumo. Este trabalho trata da separação de sinais de áudio dos quais não se  tem informação a priori, visando separar os instrumentos em uma mistura  composta por elementos harmônicos e percussivos. Dentre as técnicas usuais,  foi escolhido o método de Fatoração de Matrizes Não-Negativas, uma vez que  a qualidade da separação dessa técnica não está condicionada ao número de  observações disponíveis. São apresentados os resultados da implementação  em ambiente Matlab® utilizando as divergências de Kullback-Leibler e  Itakura-Saito. Os resultados não indicaram diferenças significativas entre os  métodos, incentivando novas investigações sobre a incorporação de restrições  ao método NMF, tais como a esparsidade e smoothness, dentre outros.   1. Introdução  Com os recentes avanços da tecnologia digital as quantidades de dados gerados e a  serem tratados pelos sistemas de processamento, em geral, vêm tornando obsoletas as  ferramentas clássicas de análise [Chen et al. 2011] [Berry et al. 2006]. Tarefas  envolvendo a localização de informações e/ou revelações de características intrínsecas  dos sinais demandam, cada vez mais, de técnicas mais eficientes.   Nesse contexto, a técnica de Fatoração de Matrizes Não-Negativas (NMF –  Nonnegative Matriz Factorization) vem se destacando dentre as demais técnicas  disponíveis. A NMF é, basicamente, uma técnica que realiza a decomposição de uma  matriz aproximando-a a uma matriz não-negativa composta por um produto de matrizes  de menor posto, também não-negativas [Guan et al. 2012].    Dentre as áreas nas quais as técnicas NMF podem ser aplicadas, conforme  Krömer et al. (2010),  destacam-se a mineração de dados, análise de texto e detecção de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   182        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015     intrusos em redes de computadores; separação de sinais acústicos e simulação de  multicanais,  5.1 ou 7.1 por exemplo; eliminação de ruídos diversos em equipamentos  biomédicos e redução da dimensão de modelos matemáticos [Krömer et al. 2010] [Lee e  Seung 2001].   Contudo, problemas apresentados pela NMF, como por exemplo, a dificuldade  de agrupamento de padrões espectrais em uma fonte alvo [Kitamura et al. 2013], têm  incentivado modificações da técnica original para um melhor desempenho quanto à  separação de sinais de áudio. Além disso, para alguns instrumentos musicais cujas notas  apresentam, além de ataque percussivo, sustentação harmônica, como guitarra, baixo e  piano, dentre outros, a NMF apresenta dificuldades na representação desta nota como  componentes, uma vez que seus espectros variam no tempo [Tygel, 2009].   O aprimoramento de técnicas de separação de sinais de áudio podem possibilitar  melhorias quanto à remoção de ruídos de crosstalk em gravações com mais de um  microfone, aumento da qualidade no reconhecimento de voz, análises de cenários  musicais, transcrição automática de partituras, restauração e remasterização de obras  antigas [Mahmoud et al. 2009] [Kitamura et al. 2013].   A literatura técnico-científica aborda também a utilização de técnicas  supervisionadas da NMF nas quais, em linhas gerais, cria-se uma base de treinamento  com informações da fonte de interesse, quando se deseja incrementar a qualidade da  separação [Kitamura et al. 2013], embora nem sempre ocorra a disponibilidade do sinal  para treinamento. Além disso, a literatura aborda modificações nas funções de custo, ou  penalizações, visando atender a determinada restrição, como por exemplo, extensão da  NMF para sinais estéreo [Sawada et al. 2012].   Estudos de cunho mais teóricos abordando, dentre outros, diferenças de  resultados, em termos de qualidade e velocidade de convergência, entre métodos  diferentes de otimização, problemas da técnica quanto a convergência e formas de  melhoria dos mesmos, descrição dos algoritmos e descrição das áreas mais comuns de  aplicação podem, também, ser encontrados [Wang e Zhang 2013] [Guan et al. 2012]  [Lin 2007] [Berry et al. 2006].   O presente trabalho tem por objetivo estudar a aplicação da NMF à separação de  misturas contendo fontes sonoras percussivas e harmônicas, caracterizando um conjunto  musical padrão. Os resultados apresentados referem-se a sinais monoaurais, sendo a  extensão a sinais estéreo ou outras formas multi-canais realizadas pelo uso de tensores,  técnica de Fatoração de Tensores Não-Negativos (NTF - Nonnegative Tensor  Factorization) ou modificações adicionais da técnica NMF para a adequação a esse tipo  de sinal, como em [Wang e Zhang 2013] [Sawada et al. 2012].   2. Fundamentos Matemáticos  Fatoração de matrizes é um tópico largamente estudado em áreas como processamento  de sinais e álgebra linear. A ideia de que um elemento, tão simples quanto possível,  possa descrever fenômenos físicos de alto nível de complexidade, tornando-os mais  simples e de fácil entendimento, é um dos motivadores do avanço deste tipo de técnica.  Fatores como a enorme quantidade de dados envolvidos na observação de um problema,  o inter-relacionamento entre variáveis em fenômenos físicos complexos e modelos  matemáticos de problemas físicos restritos a números não negativos são motivadores da  NMF, descrito formalmente como [Chchocki et al. 2009] [Berry et al. 2006] [Lee and  Seung 2001] [Wang and Zhang 2013]:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   183        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015                                                                                                      (1)   onde representa a matriz que contem o espectrograma da mistura a ser  separada, obtido por meio da Transformada de Fourier de Curta Duração (STFT –  Short-Time Fourier Transform), é a chamada matriz de base e representa o  padrão espectral e , a matriz de ativação, representa os coeficientes da  combinação linear que gera cada fonte especificamente. O coeficiente  expressa o  posto das matrizes envolvidas na aproximação e representa o número de fontes contidas  na mistura avaliada. Como se trata de um índice matricial,  e, para que de fato  ocorra uma redução dimensional,  ou  [Lin  2007].           Basicamente, a NMF é uma técnica iterativa, na qual as regras de atualização das   entradas das matrizes  e  são derivadas de funções de custo ou funções objetivo,  frequentemente, a Distância Euclidiana, Divergência de Kullback-Leibler e Divergência  de Itakura-Saito, sendo essa última, a mais utilizada em aplicações de áudio [Sawada et  al. 2012] [Lee and Seung 2001] [Kitamura et al. 2013], todas derivadas da Divergência  de Bregman [Chchocki et al. 2009]. As Equações (2), (3), (4) referem-se à Distância  Euclidiana, e as Divergências de Kullback-Leibler e Itakura-Saito, respectivamente.   Uma vez que se define a função de custo a ser utilizada, algum algoritmo deve  ser utilizado para minimizá-la. As técnicas de otimização são as ferramentas  matemáticas que, quando aplicadas às funções de custo, geram o algoritmo de  atualização das matrizes de base e ativação da NMF, e incluem gradiente descendente,  gradiente projetado, descida coordenada, mínimos quadrados alternados, dentre outros.  A escolha do método de otimização é um compromisso básico entre velocidade e  convergência. O método mais utilizado na NMF é o método do gradiente descendente.  A primeira regra de atualização publicada para a versão original da NMF, na forma de  regra multiplicativa, é obtida aplicando-se o método do gradiente descendente à  Distância Euclidiana, conforme Equações (6) e (7) [Lee and Seung 2001] [Guan et al.  2012] [Berry et al. 2006]. A Equação (5) descreve o método do gradiente descendente.     onde  e  representam os estados futuro e atual da variável , respectivamente, α é  o passo ou peso e , a derivada parcial de f em relação à variável .      As Equações (6) a (11) mostram as regras multiplicativas para a Distância  Euclidiana, e as Divergências de Kullback-Leibler e Itakura-Saito, respectivamente,  derivadas a partir do método do gradiente descendente.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   184        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015                      onde  é uma matriz cujos elementos são todos iguais a 1 e  representa o  produto de Hadamard ou elemento a elemento. As divisões também são definidas  elemento a elemento, tal que as dimensões envolvidas sejam todas compatíveis [Santos  2015].   3. Metodologia Aplicada  Como já dito na Seção 1, tipicamente uma base de testes é composta por músicas  sintetizadas, do tipo MIDI. Entretanto, com o objetivo de testar as técnicas em uma  mistura mais condizente com as músicas comerciais (músicas profissionais gravadas em  estúdio), gravou-se uma música contendo uma guitarra, um baixo e uma bateria, sendo  esta última fonte composta por prato de condução, bumbo e caixa.   Para a gravação dos sinais foi utilizado um microfone para cada fonte, sendo  este microfone caracterizado na tabela 1.   Além disso, como é bastante comum o uso de processadores de efeitos nas  músicas comerciais, a guitarra foi gravada com o efeito de distorção, o que implica na  inserção de mais harmônicos na mistura. Dessa forma, objetiva-se comparar o  desempenho das Divergências de Kullback-Leibler e Itakura-Saito nesse contexto. A  tabela 2 mostra os parâmetros usados na simulação.   Os algoritmos foram implementados em ambiente Matlab®, utilizando um  notebook com processador Intel® 3230m de 2,6GHz e 8GB de memória RAM.      Tabela 1. Especificações do microfone MX150   Característica Especificação Técnica   Tipo Dinâmico     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   185        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015     Polaridade Unidirecional   Faixa de Frequência 56Hz a 14kHz   Sensibilidade 56dB +/- 3dB (0dB = 1V/PA a 1kHz)   Impedância 250 Ohms +/- 30% em 1kHz      Tabela 2. Parâmetros de Simulação  S  T F  T  Tamanho da Janela (Amostras) 1024   Sobreposição (Amostras) 512   NFFT 1024   A lg   Número de Iterações 100   Número de Fontes 5   4. Resultados    Utilizando-se das configurações de simulação descritas na tabela 2, testou-se o resultado  obtido pelo algoritmo implementado baseado nas relações sinal/ruído (SNR). Estas  métricas consideram que a fonte estimada da mistura (sj) é igual à fonte original (salvo)  adicionada às interferências (einter) causadas por outras fontes e erros de quantização ou  artefatos (eartef ) no processo de aquisição/separação. Inclui-se, ainda, uma parcela enoise  referente ao ruído contido na mistura original [Vincent et al. 2006]. A representação  matemática da fonte estimada da mistura é apresentada na Equação (12):     As métricas propostas por [Vincent et al. 2006] são apresentadas a seguir:   • Razão Fonte-Distorção (SDR – Source to Distortio Ratio): Quantifica a  qualidade da separação de uma forma geral, com base na distorção existente entre a  fonte original e a fonte estimada. A Equação (13) apresenta a expressão utilizada  para o cálculo da SDR     • Razão Fonte-Interferência (SIR – Source to Interference Ratio): Mensura a  interferência que a fonte sofreu das demais fontes presentes na mistura, dada pela  expressão (14),     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   186        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015       Figura 1. Mistura Considerada: a - Real; b – Estimada     Figura 2. Erro do Algoritmo     • Razão Fontes-Artefatos (SAR – Source to Artifacts Ratio): Essa razão visa medir  a quantidade de imperfeições geradas nas fases de aquisição/processamento e pode  ser avaliada por meio da Equação (15).     A fig. 1-a mostra a forma de onda da mistura considerada, enquanto a fig. 1-b   mostra a forma de onda da mistura estimada. A fig. 2 mostra a diferença de amplitude  entre a mistura considerada e a mistura estimada, via divergência de Itakura-Saito,  evidenciando a pequena diferença entre as duas.   As figuras 3 e 4-a mostram os espectrogramas da mistura considerada e da  guitarra presente na mistura, respectivamente, enquanto a fig. 4-b mostra o  espectrograma da guitarra separada via algoritmo implementado utilizando a  divergência de Itakura-Saito.   Os resultados obtidos para as Divergências de Kullback-Leibler e Itakura-Saito  são apresentados na tabela 3. Nota-se que, de maneira geral, não é possível afirmar qual  das divergências apresentou melhor resultado para a mistura considerada, uma vez que  houve alternância de acordo com o instrumento considerado. A divergência de  Kullback-Leibler apresentou melhores resultados considerando guitarra, prato de  condução e bumbo enquanto que a divergência de Itakura-Saito separou melhor  considerando baixo e caixa, fontes de menor potência espectral.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   187        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015       Figura 3. Espectrograma da Mistura     Figura 4. Espectrograma da Guitarra: a - Real; b – Estimado   Tabela 3. Resultado da Separação via NMF   5. Conclusão  A técnica de fatoração de Matrizes Não-Negativas, quando utilizada para a separação  cega de fontes (BSS - Blind Source Separation) pode, dependendo da finalidade, ser  considerada bem sucedida. Apesar dos resultados obtidos a partir dos critérios objetivos  apresentarem, na maioria dos testes, valores próximos à 0dB (relação 1 para 1) ou até  mesmo negativos, vale enfatizar que a mistura escolhida para teste trata-se de uma  música próxima a músicas comerciais.   Como trabalhos futuros pretende-se explorar a extensão para sinais estéreo, via  NTF, além da aplicação de restrições aos métodos NMF/NTF, como por exemplo a  esparsidade e smoothness. Assim, trabalha-se com um formato de áudio padrão  (estéreo) e com potencial de melhoria de resultados (através das restrições).   Referências   Berry,M. W., Browne, M., Langville, A. N.., Pauca, V. P., e Plemmons, R. J. (2006).  Algortithms and applications for approximate nonnegative matrix factorization. In  Computational Statistcs and Data Analysis, pages 155-173.    SDR(dB) SIR(dB) SAR(dB)  Fonte KL IS KL IS KL IS   Guitarra 5,918 4,999 19,994 18,393 6,134 5,265  Baixo -19,186 -6,543 -18,043 -4,421 5,280 3,346   Condução 5,944 -0,007 12,898 5,995 7,139 2,142  Bumbo -0,007 -7,030 1,419 -6,092 7,878 7,131  Caixa -8,839 -5,013 -7,543 -1,084 4,970 0,825     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   188        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 181-188 Nov/2015     Chchocki, A., Zdunek, R., Phan, A. H., and Amari, S.-I. (2009). Nonnegative matrix       and tensor factorizations: applications to exploratory multiway data analysis and  blindsource separation. John Wiley & Sons, Ltd, Chichester, Sussex do Oeste,  Inglaterra, 1 edition.   Chen, Y., Bao, H., and He, X. (2011). Non-negative local coordinate factorization for  image representation. pages 569–574.   Guan, N., Tao, D., Luo, Z., and Yuan, B. (2012). Nenmf: An optimal gradiente method  for nonnegative matrix factorization. Signal Processing, IEEE Transactions on,  60(6):2882–2898.   Kitamura, D., Saruwatari, H., Yagi, K., Shikano, K., Takahashi, Y., and Kondo, K.  (2013). Robust music signal separation based on supervised nonnegative matrix  factorization with prevention of basis sharing. In Signal Processing and Information  Technology(ISSPIT), 2013 IEEE International Symposium on, pages 000392– 000397.   Krömer, P., Platos, J., and Snasel, V. (2010). Data mining using nmf and generalized  matrix inverse. In Intelligent Systems Design and Applications (ISDA), 2010 10th  International Conference on, pages 409–414.   Lee, D. D. and Seung, H. S. (2001). Algorithms for non-negative matrix factorization.  In In NIPS, pages 556–562. MIT Press.   Lin, C.-J. (2007). On the convergence of multiplicative update algorithms for  nonnegative matrix factorization. Neural Networks, IEEE Transactions on,  18(6):1589–1596.   Mahmoud, A., Ammar, R., Eladawy, M., and Hussien, M. (2009). Improving the  performance of the instantaneous blind audio source separation algorithms. In Signal  Processing and Information Technology (ISSPIT), 2009 IEEE International  Symposium on, pages 519–526.   Santos, M. B. (2015). Aplicação e análise de desempenho da técnica de fatoração de  matrizes não-negativas para a separação de fontes acústicas percussivas. Master’s  thesis, PPGEE/PUCMG, Minas Gerais, Brasil.   Sawada, H., Kameoka, H., Araki, S., and Ueda, N. (2012). Efficient algorithms for  multichannel extensions of itakura-saito nonnegative matrix factorization. In  Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International  Conference on, pages 261–264.   Tygel, A. F. (2009). Métodos de fatoração de matrizes não-negativas para separação de  sinais musicais. Master’s thesis, COPPE/UFRJ, Rio de Janeiro, Brasil.   Vincent, E., Gribonval, R., and Fevotte, C. (2006). Performance measurement in blind  audio source separation. IEEE Transactions on Audio, Speech, and Language  Processing, 14(4):1462–1469.   Wang, Y.-X. and Zhang, Y.-J. (2013). Nonnegative matrix factorization: A  comprehensive review. Knowledge and Data Engineering, IEEE Transactions on,  25(6):1336–1353.   
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   242        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     Aplicação do Método AHP na Seleção de Software para  Modelagem de Processos de Negócios   Amanda Alves1, Thiago Depoi Stoll1, Rafael Baldiati Parizi1   1Instituto Federal Farroupilha – Campus São Borja (IF Farroupilha)  Rua Otaviano Castilho Mendes, 355 – 97.670-000 – São Borja – RS – Brasil   {amalve.amanda, thiago.stoll}@gmail.com, rafael.parizi@iffarroupilha.edu.br   Abstract. This paper presents a comparison of three BPMN tools through  metrics and predefined criteria , applying them in practice with the AHP –  Analytical method of Process Hierarchy. The article aims to assist in choosing a  tool that leads to improved performance in modelling business processes,  contributing to greater flexibility and cost savings.   Resumo. Este artigo apresenta uma comparação de três ferramentas BPMN,  através de métricas e critérios pré-definidos, aplicando-os na prática com o  método analítico de hierarquia de processos, o AHP. O artigo tem por  finalidade auxiliar na escolha de uma ferramenta que conduza ao melhor  desempenho na modelagem dos processos de negócios, contribuindo com uma  maior agilidade e redução de custos.   Introdução  Um Processo de Negócio trata-se de uma atividade, ou um conjunto de atividades,  realizada por uma empresa (ou qualquer outro tipo de organização) para criar ou adicionar  valor aos clientes. Um processo tem pontos de início e fim bem definidos (entradas e  saídas estabelecidas), cada um dos quais associados com um cliente [Gonçalves 2010].  A Modelagem de Processos de Negócio é essencial para as organizações na medida em  que permite identificar pontos de melhoria e entender melhor o funcionamento da própria  organização. Além disso, facilita a implementação de sistemas de gestão empresarial  (Enterprise Resource Planning – ERP), o que permite uma coleta de dados relevantes de  maneira mais fiel. As noções de modelagem também ajudam a utilizar melhor as  metodologias de planejamento estratégico e, com isso, dada a importância da modelagem,  há uma notação específica para essa atividade, conhecida como BPMN – Business  Process Management Notation [Santos 2004].   Os modelos de processos de negócios construídos com base na BPMN podem ser  considerados complexos, dados os inúmeros elementos envolvidos no fluxo de atividades  de uma organização. Então, para automatizar essa ação, diversas ferramentas podem ser  encontradas na literatura. Elas permitem aos usuários a visualização dos processos de  negócio e do modelo de negócio, bem como simular, automatizar, controlar e medir os  processos. Desta maneira, a escolha da ferramenta para alcançar os objetivos da  modelagem de processos de negócios configura-se como uma tarefa difícil, pois cada  ferramenta possui características próprias, tornando difícil a comparação e definição das  métricas de análise entre as suítes de software.   O objetivo desse artigo é propor uma ordenação de ferramentas que proveem  funcionalidades voltadas a modelagem de processos de negócios com a linguagem     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   243        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     BPMN, por ordem de relevância, para se encontrar àquela que mais se adeque à  necessidade de quem irá modelar. Essa ordenação toma como base métricas de avaliação  de software tornando o cenário em um problema de vários critérios. Nesse sentido, a  análise multicritério é realizada pelo método Analytical Hierarchy Process (AHP),  método multicritério de apoio a tomada de decisões.   Esse artigo está organizado da seguinte forma: a Seção 2 apresenta ferramentas de  modelagem de processos de negócios com base na linguagem BPMN. A Seção 3 mostra  um estudo de caso que explora a aplicação do método AHP para a ordenação das  ferramentas. Na Seção 4 são feitas as considerações finais do trabalho e, finalmente são  elencados os trabalhos que serviram de suporte para a escrita deste artigo.   Ferramentas para Modelagem de Processos de Negócios com BPMN  Grande parte das ferramentas BPMN suportam tarefas humanas alinhadas com tarefas de  sistemas e fluxos de informação. As ferramentas de BPMN monitoram o andamento dos  processos de uma forma rápida e barata, permitindo o controle total dos processos por  meio do acompanhamento detalhado da realização das atividades. A diferença destas  ferramentas está no nível de sofisticação do suporte e nas tarefas humanas que o software  pode executar [van der Aalst et al. 2003].   As Suítes de BPM visam aumentar o desempenho de negócio oferecendo aos  gerentes de negócio uma maneira de controlar de forma eficaz todos os recursos da  organização, sejam eles humanos ou tecnológicos, indispensáveis para a realização de um  processo de negócio. Da mesma forma, o desenvolvimento de um software de BPM  fornece às organizações uma alternativa que é poder rever processos existentes, de  automatizar atividades adicionais, de remover as redundâncias e buscar melhorias nas  ações realizadas.   Uma vez inserido em uma organização, o sistema de BPM auxilia na manutencao  das mudanças rotineiras do processo. De uma maneira simples, BPM é um software que  automatiza, executa e monitora processos de negócio do início até o fim, conectando os  envolvidos e os sistemas.   Como forma de exemplificar ferramentas com foco em modelagem de processos  de negócios com BPMN, a Figura 1 mostra interface gráfica da Ferramenta Bizagi  Modeler.   Figura 1. Interface da Ferramenta BPMN Tibco Business Studio   Estudo de caso: Ordenação das ferramentas BPMN Tibco, Bizagi e Atos  Conforme apresentado na Seção 1, o objetivo deste trabalho é colaborar com a escolha da  ferramenta que permita a modelagem de processos de negócios BPMN que se adeque aos  critérios envolvidos no problema. Como exposto, há ferramentas que permitem realizar a  modelagem e isso leva às organizações a terem de escolher entre uma delas. Nesse  sentido, visando facilitar esta escolha, apresenta-se nessa seção um estudo de caso com  três ferramentas de BPMN, entre elas: (i) Tibco Business Studio; (ii) Bizagi Modeler, e;  (iii) Atos Modeler.   Com a definição das ferramentas a serem ordenadas, obtêm-se um cenário  multicritério, uma vez que a seleção da ferramenta mais adequada deve levar em  consideração várias características de cada um dos softwares. Nesse aspecto, utilizou-se     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   244        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     nesse trabalho o método AHP, que é aplicado em apoio à tomada de decisões em  problemas complexos, ou seja, aqueles que envolvem vários critérios.   O AHP é uma técnica ligada à pesquisa Operacional, que é uma vertente da  matemática aplicada, em caráter interdisciplinar, utilizando-se, além da matemática, da  estatística e da lógica expressa em algoritmos como forma de apoio à tomada de decisões.  Caracteriza-se como uma técnica que propõe o tratamento de problemas de escolha  complexos de forma simples utilizando avaliações hierárquicas de diversos atributos,  possibilitando a realização de análises tanto qualitativas e quantitativas, conforme afirma  [Costa e Moll 2000].   A programação multicritério, por meio do processo AHP, é estruturada para  tomada de decisão em ambientes complexos em que diversas variáveis ou critérios são  considerados para a priorização e seleção de alternativas. O AHP foi desenvolvido na  década de 80 por Thomas L. Saaty [Saaty 1990] e tem sido intensivamente utilizado.  Atualmente, é aplicado para a tomada de decisão em diversos cenários complexos em que  pessoas trabalham em conjunto para tomar decisões e onde percepções humanas,  julgamentos e consequências possuem repercussão ao de longo prazo [Bhushan e Rai  2004].   Para a realização desse trabalho com o uso do método AHP [Saaty 1990], a  primeira etapa é a definição do problema, que como já fora exposto, é a seleção da  ferramenta mais indicada para a modelagem BPMN. A segunda etapa é a representação  do problema de forma hierárquica, a fim de buscar uma melhor compreensão do  problema, através da associação de diversos critérios ao objetivo do problema e a cada  critério diversas alternativas. A Figura 2 apresenta a representação hierárquica realizada  pelo AHP.               Figura 2. Representação do problema de forma hierárquica    Dando sequência à execução do AHP, o próximo passo realizado foi a definição das  métricas que impactam na escolha da ferramenta BPMN. Nesse projeto foram definidas três  características para a seleção de uma ferramenta de BPMN, conforme apresentado na Tabela  1.           Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   245        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     Tabela 1. Critérios extraídos das Ferramentas BPMN   Critério Descrição   C1 Validação Funcionalidade que permite a verificação do modelo construído.   C2 Simulação  Capacidade da ferramenta em permitir a simulação do processo de  negócio.   C3 Portabilidade  Número de sistemas operacionais para os quais a ferramenta está  disponível.     Após a definição dos critérios a serem analisados, o AHP tem como atividade a   definição das importâncias para esses critérios. Nesta etapa, o usuário define a relativa  importância de um critério sobre outro, assim como de uma alternativa sobre outra,  através´ de comparações pareadas. Os valores da Tabela 2 são usados para expressar o  grau de importância entre critérios e alternativas.       Tabela 2. Tabela de importância de Thomas L. Saaty  Grau Importância   1 Mesma importância   3 Fracamente mais importante   5 Moderadamente mais importante   7 Fortemente mais importante   9 Absolutamente mais importante   2..4..6..8 Valores de importância intermediária     Com a definição das importâncias é criada uma matriz quadrada com a relativa  importância dos critérios sobre os demais. Considere, por exemplo, um conjunto de  critérios C = {C1, C2,...,Cn} e uma matriz quadrada M representando a importância de um  critério sobre outro w = {w1,w2,...,wn}. Nesse caso, a matriz de comparações pareadas é  construída da seguinte forma:     (1)   Dessa forma, para o estudo de caso, obteve-se a seguinte matriz de importâncias  com base nas comparações: c1 é moderadamente mais importante do que c2 (c1/c2 = 5), c1 é  entre fortemente e absolutamente mais importante do que c3 (c1/c3 = 8) e c2 é fortemente  mais importante do que c3 (c2/c3 = 7):     (2)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   246        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     Com isso, está exposto que são mais interessantes as ferramentas que possam  validar o modelo, simular o modelo e menos importante é estar disponível para mais de  um sistema operacional.   Através da matriz, calcula-se um vetor contendo os pesos relativos de todos os  critérios da matriz, correspondendo a etapa de síntese. Esse vetor é calculado a partir de  sucessivas elevações da matriz de prioridades ao quadrado, onde a cada iteração a soma  das linhas é calculada e normalizada, até que a diferença entre a soma de dois cálculos  consecutivos seja menor que um valor estipulado previamente. Geralmente são suficientes  entre duas e quatro iterações para que o método encontre a solução.   Continuando o estudo de caso, um vetor pode ser extraído da matriz M com a sua  elevação ao quadrado, soma de suas linhas e por fim a normalização, como apresentado  abaixo (valores são apresentados na versão de número real):        (3)    (4)      total soma vetor = 89.2071         (5)     (6)         (7)      Total normalizado = 1.0000   A indicação do método AHP é que após algumas iterações os valores não tenham  alterações, mantendo-se quase que constantes. Para o estudo de caso, após 3 iterações  necessárias ao processo, o vetor obtido é o seguinte:                          (8)    A realização de mais iterações não altera o vetor de forma significativa (fazendo  uso de 4 casas decimais), tornando novas iterações desnecessárias ao processo. Ao final  deste processo, analisando os valores do vetor, obtém-se uma função matemática que  expressa a importância dos critérios. Através da função matemática obtida, é possível  saber qual a ferramenta que melhor atende aos critérios estabelecidos. A função  matemática obtida é a seguinte:    f(vc) = vc1 × 0.7125+ vc2 × 0.2330+ vc3 × 0.0544. (9)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   247        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     Onde vc1, vc2 e vc3 foram substituídos por valores quantitativos, nesse caso, as  métricas extraídas de cada ferramenta, como mostra a Tabela 3. Nesse caso, foram  assumidos os valores booleanos para os critérios simulação e validação, sendo 1 quando a  funcionalidade é prevista pela ferramenta e 0 quando não é prevista. Para o critério  portabilidade, é apontado o número de Sistemas Operacionais (quantidade) para os quais  a ferramenta pode ser instalada.    Tabela 3. Tabela com a relação de valores Ferramenta x Critério   Validação (C1) Simulação (C2) Portabilidade (C3)   Atos 0 0 1   Tibco 1 1 2   Bizagi 1 1 1     Substituindo os valores dos critérios das ferramentas, expostos na Tabela 3 na   fórmula dada em (9), obteve-se como resultado os valores apresentados na Tabela 4.    Tabela 4. Tabela com a relação de valores Ferramenta x Critério  Ferramenta Valor Resultante Posição na ordenação   Atos 0.0544 3   Bizagi 1 2   Tibco 1.0544 1     Resultados   Após a definição dos critérios, avaliou-se as ferramentas escolhidas, para a atribuição dos  valores, como fora exposto na Tabela 3. Dessa maneira, pôde-se levantar os seguintes  resultados: O software Atos Modeler não possui validação e nem simulação, tendo  portabilidade para apenas um sistema operacional. A ferramenta Bizagi Modeler possui  os processos de validação e simulação e tem portabilidade para um sistema operacional.  Por fim, pode-se analisar que, a ferramenta Tibco Business Studio executa os processos  de validação e simulação, além de possuir portabilidade para dois sistemas operacionais.    Com o resultado, percebe-se que para os critérios definidos, o software Tibco  Business Studio é a que melhor atende necessidades, sendo a que obteve o maior valor  entre as três ferramentas comparadas.   Considerações Finais   Nesse trabalho foram apresentados conceitos relativos a modelagem de processos de  negócios com a linguagem BPMN e, a partir disso, foram identificados critérios de  avaliação de qualidade para ferramentas de software que permitam esta modelagem. Além  disso, apresentou-se a aplicação de um método matemático para a análise par a par  visando ordenar essas ferramentas para então encontrar a que mais se adequa a  necessidade da organização. Esse processo foi explorado por meio de um estudo de caso  que trouxe de forma exemplificada a seleção da melhor ferramenta para os critérios e  importâncias estabelecidos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   248        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 242-248 Nov/2015     Através do estudo de caso realizado com o método AHP, verificou-se que o  método realmente possibilita a obtenção de uma ordem de sistemas de software,  permitindo aos responsáveis pela modelagem dos processos de negócios o uso da melhor  ferramenta e com isso, tenham facilidade na realização desta atividade. Como visto,  através dos resultados apresentados, o AHP mostrou-se eficaz, colaborando efetivamente  para tomada de decisões em sistemas complexos.   Referências  Bhushan, N. and Rai, K. (2004). Strategic Decision Making: Applying the Analytic Hierarchy   Process. Springer-Verlag London.   Costa, H. G. and Moll, R. N. (2000). Emprego do método de análise hierárquica (ahp) na  seleção de variedades para o plantio de cana-de-açúcar. Laboratório de Engenharia de  produção Universidade Estadual Norte Fluminense˜ .   Gonçalves, J. E. L. (2010). As empresas são grandes coleções de processos. ERA – Revista de  Administração de Empresas.   Saaty, T. (1990). How to make a decision: the analytical hierarchy process. In European  Journal of Operation Research.   Santos, A. C. E. (2004). Mensurando a criação de valor na gestão pública. ERA – Revista de  Administração de Empresas˜ .   van der Aalst, W., ter Hofstede, A., and Weske, M. (2003). Business process management: A  survey. In van der Aalst, W. and Weske, M., editors, Business Process Management,  volume 2678 of Lecture Notes in Computer Science, pages 1–12. Springer Berlin  Heidelberg.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   189        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015     Aprova IF: desenvolvimento de um aplicativo para  acompanhamento de notas   Wagner S. Marques, Jaline Gonçalves Mombach   Instituto Federal de Educação, Ciência e Tecnologia Farroupilha -  Campus Alegrete  RS-377 Km 27 - Passo Novo - CEP 97555-000 - Alegrete/RS   {wagner_marques@live.com,jaline.mombach@iffarroupilha.edu.br}     Abstract. Some educational institutions use weighted system to calculate the  final average of students. In this context, it is important to provide means to  facilitate students tracking their academic performance. Therefore, this work  proposes the development of a mobile application for tracking notes in  technical and higher education courses in a specific educational institution. It  is adopted as a working methodology in the Participatory Design, exploring  prototyping on paper and cooperative evaluation. The results indicate that the  solution is feasible and acceptable to approximately 75% of surveyed users.   Resumo. Algumas instituições de ensino usam sistema ponderado para  cálculo da média final dos alunos. Neste contexto, é importante prover meios  que facilitem aos discentes o acompanhamento de seu rendimento escolar.  Logo, este trabalho propõe o desenvolvimento de um aplicativo móvel para  controle de notas em cursos técnicos e superiores de uma instituição de ensino  específica. Adota-se como metodologia de trabalho o Design Participativo,  explorando prototipagem em papel e avaliação cooperativa. Os resultados  indicam que a solução é viável e aceita por aproximadamente 75% dos  usuários entrevistados.      1. Introdução  O uso de dispositivos móveis está em constante crescimento, fazendo parte do cotidiano  das pessoas. Pesquisas indicam que 84% da população brasileira, com 16 anos de idade  ou mais, usam telefones celulares (NIELSEN COMPANY, 2013). Alunos estão  aderindo ao uso destes equipamentos também para fins de estudo. Segundo Portinari  (2015), aplicativos preparatórios para o vestibular já possuem 1,3 milhões de usuários  estudantes. Neste contexto, Pereira e Silva (2014) declaram que dispositivos móveis,  quando usados de maneira correta, podem ser favoráveis às escolas. O uso de  aplicativos na rotina escolar pode facilitar a realização de pesquisas, edição de registros  escolares, compartilhamento de informações com colegas de classe e professores, entre  outras atividades.    No Instituto Federal Farroupilha, a maioria dos cursos técnicos integrados inclui  quinze ou mais disciplinas anuais8, além das disciplinas semestrais de cursos  subsequentes e superiores (IFFARROUPILHA, 2014). No cursos integrados, o primeiro                                                    8  Cursos Técnicos em Agropecuária, Informática, Administração, Eventos, Edificações, Móveis,   Química, entre outros (IFFARROUPILHA, 2014)        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   190        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015     e segundo semestre correspondem a 40% e 60% da nota anual, respectivamente.  Independente da modalidade (integrado, subsequente ou superior), os alunos que não  alcançam a média de aprovação (7,0), precisam realizar exame. A nota do exame  recupera 40% da nota anual e a média de aprovação passa a ser considerada 5,0 após o  exame.   A pesquisa de demanda deste trabalho indica que 48% dos alunos entrevistados  declararam possuírem dúvidas para cálculo de suas notas na maioria das vezes e 28%  relatam sempre possuírem dúvidas. Dessa forma, este artigo apresenta o  desenvolvimento de um aplicativo para controle de notas escolares no Instituto Federal  Farroupilha, considerando armazenamento de notas e cálculo de média nas modalidades  integrado, subsequente e superior.   Este artigo está organizado como segue. Na Seção 2, descreve-se alguns  aplicativos existentes para cálculo de notas escolares, estudados como trabalhos  relacionados. Na Seção 3, apresenta-se a abordagem de trabalho adotada, baseada no  Design Participativo. Na Seção 4, expõe-se as etapas de desenvolvimento da solução.  Finalmente, na Seção 5, relata-se os resultados obtidos e as considerações finais sobre o  projeto.      2. Trabalhos Relacionados     O IF Notas (JAD MOBILE, 2014) é uma aplicação para o sistema operacional Android,  disponibilizado de forma gratuita na PlayStore9. Conforme descrição no repositório, o  aplicativo foi desenvolvido para o Instituto Federal de Ciência e Tecnologia do Ceará  com objetivo de disponibilizar informações gerais sobre a Instituição e possibilitar o  controle de notas obtidas, bem como as médias finais. A aplicação exige número de  matrícula e senha para ser usada, ou seja, o acesso é restrito a alunos da Instituição.    O aplicativo Boletim Escolar (KOCAR TEAM, 2013) tem propósito semelhante  ao IF Notas. É disponibilizado gratuitamente na Playstore, para o sistema Android.  Conforme descrição do repositório, a aplicação propõe seu uso por pais, alunos ou  professores, para inserção de disciplinas e notas, e acompanhamento das médias finais  obtidas conforme notas inseridas. Porém, o cálculo é realizado por média simples, ou  seja, não pode ser aplicado ao caso específico da Instituição estudada neste trabalho,  que adota média ponderada a cada semestre.       3. Abordagem adotada     O desenvolvimento da aplicação explorou conceitos e técnicas do Design Participativo,  como aplicação de questionários a usuários e avaliação cooperativa.    O Design Participativo é considerado uma prática ou metodologia escandinava  ao design, surgida na década de 70. É uma abordagem ao desenvolvimento de  tecnologia que propõe a participação ativa de usuários em vários momentos do ciclo de  desenvolvimento de um produto tecnológico (MELO, 2007). Segundo Camargo e  Fazani (2012), quando o Design Participativo é aplicado no desenvolvimento de um                                                   9  repositório oficial de aplicativos Android (GOOGLE, 2015)       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   191        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015     software, pode-se afirmar que o sistema será mais facilmente aceito pelos usuários  finais, pois envolve pessoas que utilizarão o sistema posteriormente.   A Avaliação Cooperativa é uma técnica adotada para se obter retorno dos  usuários em testes de protótipos com facilidade e baixo custo. A equipe de avaliação é  formada pelo usuário final e o desenvolvedor, que planeja atividades distintas para que  o usuário realize no protótipo e descreva a experiência de uso, dificuldades e sugestões  de melhoria. (MELO; BARANAUSKAS, 2006).    4. Etapas de Desenvolvimento     O projeto de desenvolvimento do aplicativo é baseado no Design Participativo,  conforme ilustra a Figura 1. Inicialmente, realizou-se pesquisa de demanda junto aos  alunos da instituição, com o objetivo de detectar se havia dificuldade dos discentes em  calcular e controlar suas notas na Instituição. A interface foi projetada junto aos  usuários e logo passou-se a codificar o aplicativo. A cada protótipo, houve testes com os  usuários e correções, até se obter versão aceitável.     Figura 1: Ciclo de desenvolvimento do aplicativo Aprova IF     4.1. Análise de Demanda     Aplicou-se um questionário on-line à comunidade do Campus Alegrete,  docentes e alunos de diversas modalidades e cursos, a fim de verificar a demanda para  desenvolvimento da aplicação. As questões aplicadas trataram sobre qual a dificuldade  dos entrevistados em calcular suas notas finais, considerando pesos diferentes dos  semestres e até mesmo o grau de dificuldade no cálculo de nota necessária para  aprovação por média e exame final. Também foram questionados se possuíam,  smartphones e, caso possuíssem, qual o sistema operacional do dispositivo. Houve  participação de  15 usuários, sendo 10 alunos e 5 docentes. Aproximadamente 72% dos  entrevistados indicaram dificuldades nos cálculos de médias finais, ao término do  período letivo do seu curso. O grau de dificuldade  dos entrevistados em relação ao  cálculo de notas para exame final, em casos de reprovação por média, cerca de 80%,  alegou ter dificuldade em calcular notas necessárias no referido exame. O sistema  operacional  mais usado entre os entrevistados, é o sistema móvel Android, estando  presente em 73% dos smartphones.   Ao serem questionados sobre a possibilidade de uso de um aplicativo de celular  que permitisse registrar as avaliações e informasse automaticamente a média da  disciplina e também quanto faltaria para aprovação por média e em exames, 61% dos  entrevistados responderam que sim, usariam sempre o aplicativo, 33% usariam somente  algumas vezes e 6% nunca usariam. O gráfico de respostas é ilustrado na Figura 2.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   192        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015                                   Figura 2: Gráfico que ilustra a demanda do aplicativo     Com os resultados obtidos, concluiu-se que havia demanda para o aplicativo  entre o público-alvo e iniciou-se a atividade de prototipação de interface, junto aos  usuários.      4.2. Prototipagem em Papel   A prototipagem em papel é uma técnica que consiste na criação de protótipos do  sistema, utilizando materiais de baixo custo e de fácil acesso, como papéis, tesouras,  cola, lápis de cor e demais materiais do gênero.   Com o objetivo de propor participação aos prováveis usuários e descobrir suas  necessidades, a atividade de prototipagem em papel foi desempenhada com uma turma  de 20 alunos. A turma foi dividida em grupos de 3 a 5 pessoas e confeccionaram os  possíveis protótipos da aplicação móvel, como mostra a Figura 3. Após, o  desenvolvedor reuniu os protótipos propostos e desenhou a interface gráfica da  aplicação baseada nas sugestões dos usuários.     Figura 3: Registro da técnica com usuários     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   193        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015     As funcionalidades apontadas pelos usuários como necessárias ao aplicativo,  foram: inclusão de disciplinas, configurando se são semestrais ou anuais; inclusão de  avaliações com notas e respectivos pesos (visto que os professores tratam as avaliações  com pesos distintos); edição das disciplinas; edição das notas (às vezes os professores  alteram o peso final de alguma avaliação); indicação da média parcial obtida em cada  disciplina; indicação da nota necessária para aprovação; indicação de nota necessária  para aprovação em exame, quando necessário; cálculo de nota necessária para exame,  somente inserindo a média final, sem histórico de notas; exclusão dos dados inseridos a  cada semestre e/ou ano letivo.      4.3. Codificação e Testes com Usuários    Para o desenvolvimento da aplicação, foi utilizado o pacote oficial de desenvolvimento,  Android Developer Tools Bundle (GOOGLE, 2014). As linguagens empregadas foram  Java para Android e SQLite.   Conforme mencionado, adotou-se a técnica de avaliação cooperativa para  realização de testes entre usuários e o desenvolvedor. Assim, disponibilizou-se um  protótipo do sistema e algumas tarefas para realização pelos usuários. As tarefas  propostas foram:   1. Criar uma disciplina com duração de um semestre e inserir duas avaliações com  notas e pesos aleatórios;   2. Criar uma disciplina com duração de dois semestres e inserir duas avaliações em  cada semestre;   3. Consultar a média atual de uma disciplina;  4. Consultar a nota necessária para aprovação em exame final de um aluno do   curso integrado;  5. Consultar a nota necessária para aprovação em exame final de um aluno do   curso superior;  6. Excluir uma das disciplinas.    Houve participação de 10 usuários nos testes. Após realização das tarefas,  registrou-se vários comentários dos usuários, que auxiliaram na detecção das tarefas em  que apresentaram dificuldades de realização. Alguns comentários e sugestões feitas  pelos usuários, indicaram dificuldades no cadastramento de disciplinas e também  sugeriram que o sistema informasse as médias  parciais das notas obtidas, bem como a  média necessária no próximo semestre e nota necessária no semestre atual, para ser  aprovado. Também foi registrado pedido de desenvolvimento de nova tela de cadastro  de disciplina.   A partir das indicações dos usuários, foram feitas correções no aplicativo, até se  obter versão aceitável.    5. Resultados e Discussões     A versão final da aplicação desenvolvida, realiza todas as funcionalidades sugeridas  pelos usuários, permite o cadastro e consulta de disciplinas e notas, além de possibilitar  consultas de notas necessárias em exames finais. As disciplinas podem ser inseridas  com duração de um semestre para cursos semestrais e de dois semestres em caso de  disciplinas anuais, permitindo desta forma, o cálculo de médias parciais e finais das     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   194        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015     disciplinas de acordo com a modalidade do curso (Integrado, Subsequente e Superior),  suprindo as necessidades do aluno independente de seu curso. As telas são exibidas na  Figura 4.      Figura 4: Funcionalidades do aplicativo     Os trabalhos futuros indicam o registro e disponibilização do aplicativo para os   alunos da Instituição.   Referências          CAMARGO, L. S. A. C; FAZANI, A. J. F. Explorando o design participativo como  prática de desenvolvimento de sistemas de informação. Disponível em:  <http://www.revistas.usp.br/incid/article/view/64103>. Acesso em: 10 de Jun. de  2014.   FREITAS, l. C; HAURA, F. K; SOUZA, L; LARA, L. M. M; MOREIRA, J. C.  Importância da pesquisa de demanda em eventos. Disponível em:  <http://sites.uepg.br/conex/anais/artigos/542-1563-2-DR-mod.pdf>. Acesso em: 20  de jul. de 2015.   IFFARROUPILHA. Projetos Políticos Pedagógicos. Disponível em  <http://www.iffarroupilha.edu.br/site/conteudo.php?cat=254&sub=5896>. Acesso  em: 20 de setembro de 2015.   KOCAR TEAM. Boletim Escolar. Disponívem em:  <https://play.google.com/store/apps/details?id=com.boletimescolar&hl=pt_BR>.  Acesso em 25 de set. de 2014.   JAD MOBILE. IF Notas. Disponívem em:  <https://play.google.com/store/apps/details?id=br.fhs.ifnotas&hl=pt_BR>. Acesso  em 25 de set. de 2014.   LOPES, M. B. T; CARNEIRO, A. G. A importância do teste de software em TI.  Disponível em:  <http://www.univicosa.com.br/arquivos_internos/artigos/ImportanciadoProcessodeT estedeSoftwareemTI.pdf>. Acesso em: 10 de ago. de 2015.   MELO, A; BARANAUSKAS, M. A. C. Uma Opção Inclusiva à Avaliação Cooperativa  de Interfaces de Usuário. Disponivel em:  <http://lab.bc.unicamp.br:8080/lab/producao/arq0048.pdf>  Acesso em: 20 de jul.  2015.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   195        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 189-195 Nov/2015        MELO, A. M. Design inclusivo de sistemas de informação na web. Disponível em:   <http://libdigi.unicamp.br/document/?code=vtls000438900>. Acesso em: 20 de Jul. de  2014.   NIELSEN COMPANY. O Consumidor Móvel: Um Panorama Global. Disponível em  <http://www.nielsen.com/content/dam/corporate/Brasil/reports/2013/EstudoConsumidor-Mobile-Jun13.pdf>. Acesso em 20 de setembro de 2015.   PEREIRA, C. R; SILVA, S. R. O consumo de smartphones entre jovens no ambiente  escolar. Disponível em: <http://alcarsul2014.sites.ufsc.br/wpcontent/uploads/2014/10/gthistoriadamidiadigital_camila_pereira-1.pdf>. Acesso  em: 01 de ago. de 2015.   PORTINARI, Natália. Estudantes usam aplicativos como preparação para vestibular e  Enem. Disponível em: <http://www1.folha.uol.com.br/educacao/2015/08/1666217estudantes-usam-aplicativos-como-preparacao-para-vestibular-e-enem.shtml>.  Acesso em: 11 de ago. de 2015.   SOARES, R. S; PEREIRA, M. P; MARTINS, J. A. M. Recolha, preservação e  contextualização de objetos digitais para dispositivos móveis com Android.  Disponível em:  <http://www.scielo.gpeari.mctes.pt/scielo.php?script=sci_arttext&pid=S164698952012000100007&lang=pt>. Acesso em: 21 de Jul. de 2014.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   116        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015     Estratégia de Navegação Tolerante a Falha de Motores em  Quadrirrotores com Controle PID    Raif C. Gomes1, George André Pereira Thé1   1Departamento de Engenharia de Teleinformática– Universidade Federal do Ceará  (UFC)   Caixa Postal 6007 – 60455-970 – Fortaleza – CE – Brazil  raif.carneiro@gmail.com, george.the@ufc.br     Abstract. The growing interest on service robotics with the use and exploitation of  unmanned aerial vehicles has revealed important issues related to safety and fail  prevention during navigation. In this context, the present paper investigates the  dynamics of an unmanned aerial vehicle of quadrotor type using PID controllers  before a scenario of total failure in two opposite engines and analyses the existing  relation between an equipment design issue and its navigation condition after such  a failure. As a contribution, it is proposed and discussed from simulations a  strategy to mitigate the mentioned failure by landing the quadrotor in a smoothly  fashion. Experiments on a real device are in course and are expected to be shown  at the conference.    Resumo. O crescente interesse em robótica de serviço com o uso e exploração de  veículos aéreos não-tripulados tem revelado importantes questões relacionadas à  segurança e à prevenção de falhas durante a navegação. Neste contexto, o  presente artigo investiga a dinâmica de veículos aéreos não-tripulados do tipo  quadrirrotor usando controladores PID diante de um cenário de falha total em  dois motores, e analisa a relação existente entre o desenho do equipamento e sua  condição de navegação após a falha. Como contribuição, propõe-se e se discute, a  partir de simulações, uma estratégia para mitigar a falha mencionada mediante o  pouso suave do quadrirrotor. Experimentos em um dispositivo real estão em curso  e serão discutidos no encontro.     1. Introdução   O progresso recente da indústria de microeletrônica com a oferta de sensores  microeletromecânicos (MEMS), bem como aquela de produtos químicos, com a  disponibilização de baterias eficientes tem levado a uma significativa difusão de robôs  em diferentes contextos, para além do chão de fábrica. Isso deu razão à robótica de  serviço, que já em 2012 era definida pela Federação Internacional de Robótica como o  campo do conhecimento que compreende os robôs capazes de realizar tarefas para  homens ou máquinas, excluídas as aplicações de automação. Neste contexto, na última  década os veículos aéreos não-tripulados (VANT) atraíram bastante atenção pelo seu  potencial uso em missões militares, bem como pelo largo espectro de aplicações  comerciais em que podem ser usados.    Até o momento, o uso e exploração de VANT em ambientes públicos requer  regulação, talvez porque haja questões relevantes e ainda abertas, as quais normalmente  devem ser levadas em conta quando do projeto de produtos de engenharia; um exemplo     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   117        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015     é a seguração de pessoas diante de falhas desses equipamentos. De fato, o crescente  interesse em robótica de serviço tem pressionado o projeto de sistemas críticos de  segurança [G.Lippielo and Serra 2014], especialmente rumo à realização de  controladores de navegação tolerantes a falha.    Esta questão é um tópico recorrente na literatura recente. Enquanto parte da  comunidade científica está interessada na perda parcial de eficiência dos motores  [Ranjbaran and Khorasani 2010], outros artigos recentes consideraram a quebra  completa de 1, 2 ou mesmo 3 motores do VANT. Este é o caso discutido [Mueller and  D’Andrea 2014], em que a estabilização de voo é investigada teórica e  experimentalmente. Em [A.Lanzon and Longhi 2014], os autores se concentram  novamente na estabilização de voo, mas desta vez para o caso de perda de 1 motor  apenas.    Muitos destes trabalhos lidam com o projeto de um controlador capaz de garantir  condições seguras de navegação após o surgimento de uma falha. Essencialmente, o  aparecimento de uma quebra marca a transição entre uma configuração em cascata de  controladores PID (a ser discutida) e o uso daquilo que doravante será chamado  controlador crítico (que provê segurança a falha).    Uma leitura mais atenta da bibliografia recente revela que a estratégia PID é  frequentemente desprezada como uma escolha possível para o controlador crítico. Em  nossa compreensão, contudo, isto merece uma discussão, uma vez que o PID é, de  longe, a mais usada abordagem de controle em malha fechada, e não impõe dificuldades  para realização em hardware.    Uma segunda questão que é considerada aqui é a influência do desenho geométrico  do VANT em sua condição de navegação. A partir de simulações dinâmicas no domínio  do tempo, discutiremos como o coeficiente de arrasto afeta a estabilização de um  quadrirrotor com falha em dois de seus motores.    Este trabalho está organizado como a seguir: seção II descreve as equações  dinâmicas básicas do movimento de um quadrirrotor, enquanto na seção III, por sua vez,  traz resultados de simulação de uma tarefa de posicionamento, a qual é baseada na  aproximação de pequena variação dos ângulos de orientação. Seção IV traz a discussão  da quebra de dois motores e a proposição de uma técnica de segurança a falha.  Finalmente, na seção V as conclusões são apresentadas.    2. Dinâmica de um Quadrirrotor   Em uma configuração muito comum, um quadrirrotor é uma estrutura cruzada de hastes  contendo asas rotativas acionadas por 4 motores nas extremidades.    Controlando a velocidade e o sentido de rotação de cada motor, o veículo pode  rotacionar sobre as três direções espaciais, dando origem a três ângulos característicos:  guinada ( ψ  ), arfagem ( ϕ ) e rolagem ( θ ). O controle dos ângulos de arfagem e de  rolagem levam à translação do veículo, ao passo que o controle da guinada está  relacionado ao movimento circular (em torno do eixo z), como apresentado na Figura 1.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   118        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015       Figura 1: Sistema de coordenadas. Fonte: [Santana and Borges 2009].     De acordo com [Jirinec 2011], a dinâmica de um quadrirrotor pode ser obtida a partir   das equações da mecânica clássica para os momentos linear e angular, e se expressa  como segue:      Onde, 1) x , y , z  são as coordenadas de posição; 2) ϕ  , θ  e ψ  são os ângulos de   atitude; 3) g  representa a aceleração da gravidade; 4) b  o coeficiente de empuxo; 5) l   o comprimento das hastes; 6) u1 .. . u4  as velocidade dos atuadores, I x , I y , I z  inércia  rotacional, d  coeficiente de arrasto das hélices e finalmente, 7) m  massa do veículo.    Equacoes (1)-(3) mostram que os deslocamentos vertical (ao longo do eixo z) e o  horizontal (no plano xy) de um quadrirrotor é uma função dos ângulos de guinada,  arfagem e rolagem. Os sinais de controle u1 .. . u4  que aparecem no conjunto de  equações(4) acima representam torque e, como tal, têm uma relação direta com a  geometria do equipamento, bem como com a velocidade dos motores, conforme  equações (5)-(6) a seguir. Ressalte-se que esta formulação segue a de [Al-Omari 2013].         3. Validação do Controle   Com o propósito de ilustrar a arquitetura de controle proposta, consideramos a situação  hipotética de uma navegação iniciando em (x=0, y=0, z=0), e terminando em  (x=1,y=1,z=1). Os resultados da simulação para este teste estão mostrados na Figura 2.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   119        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015         Figura 2: Resposta dinâmica do quadricóptero após o passo unitário de posicionamento   em três coordenadas espaciais.    É importante mencionar que nesta análise foi aplicada uma aproximação de pequena   variação para os ângulos de orientação. Esta assunção permite desacoplar as equações  (1)-(4), as quais passam a ser reescritas conforme:        Embora esta assunção seja crucial para o controle do quadrirrotor, ela limita a   validade das equações dinâmicas a ambientes estruturados. Em outras palavras, o  modelo falha quando o ambiente sofre com fortes ventos, situação na qual considerar  nula a variação do ângulo de orientação deixa de ser razoável.    4. Estudo de Sub-excitação   4.1. Desempenho do PID sob Falha de Motor   Com o objetivo de investigar como o controle PID se comporta sob falha de motor,  simulamos o cenário de quebra de 2 motores não-adjacentes. Eis o procedimento: 1) o  VANT em pleno funcionamento foi inicialmente posicionado em (x=0,y=0,z=0); 2) a  seguir, ele atinge a coordenada z=1 metro acima do solo; 3) depois disso, 2 motores  não-adjacentes são levados a velocidade de rotação nula; 4) finalmente, as séries  temporais das variáveis de posição e orientação do veículo são armazenadas desde o  início do ensaio, até muito tempo após a quebra. Esta metodologia foi inspirada na  recente contribuição de [Mueller and D’Andrea 2014]. Os resultados deste teste estão na  Figura 3.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   120        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015       Figura 3: Resposta dinâmica do quadrirrotor após a perda de 2 motores.     Pela Figura 3 pode-se ver que há uma divergência numérica no controle de posição   ao longo dos eixos x e y, mas que ainda se consegue controle vertical. Isto pode ser  associado ao surgimento de um movimento de rotação em torno do eixo-z, o que faz  com que a dinâmica dos ângulos de orientação esteja acoplada. Para ver isto, note que,  para um quadrirrotor estabilizado e em pleno funcionamento, u 4= 0  . Mais ainda,  perceba como a segunda parte da equação (6) influencia na última parte da equação (4)  quando Ω2= Ω4= 0 . Tal acoplamento é a razão pela qual a abordagem PID  monovariável usada falha e, uma vez que ẋ  e ẏ  agora dependerão de θ e ϕ na  equação (1-2), um controle multivariável é recomendável.    Embora vários artigos discutam a estabilização de voo mesmo com perda de 1 ou 2  motores, a solução geralmente aparece às custas do projeto de um controle robusto,  como o regulador linear quadrático (LQR) de [Mueller and D’Andrea 2014] e  [A.Lanzon and Longhi 2014]. O estudo desta estratégia é deixada para trabalho futuro,  visto que nosso interesse atual é entender se o PID pode ser adotado como controlador  crítico.    4.2. Influência da geometria   Uma inspeção na Figura 3d revela que o quadrirrotor gira sobre o eixo z quando uma  falha de dois motores ocorre. Uma vez que agora as equações dinâmicas estão  acopladas, o aumento na magnitude de ψ leva a um aumento monotônico de posição  nas coordenadas do eixo x e y. Mais ainda, aparece uma incerteza na altura do veículo  (veja Figura 3c). Uma questão natural que se pode fazer a este ponto é como mitigar  este fenômeno. É possível manter a velocidade de rotação em torno do eixo z em níveis  aceitáveis, de modo que a assunção de pequena variação dos ângulos ainda seja  aplicável? É possível reduzir a flutuação observada na posição vertical?    Bem, a segunda questão estudada neste artigo é a influência da geometria do VANT  nas suas condições de navegação sob falha. De acordo com [Maxemow 2009], a força  de arrasto é relacionada à forma, à velocidade e às propriedades do material que compõe  o objeto de interesse. Para movimento rotacional, tal qual aquele de um quadrirrotor, o  arrasto aerodinâmico representa um torque de resistência, o qual é, de acordo com  [Mueller and D’Andrea 2014], dependente da velocidade rotacional. Esta   proporcionalidade é expressa como − γ⋅ψ  I z  , em que  γ  é um coeficiente de arrasto em     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   121        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015     N.m.s. Este termo pode ser adicionado à última parcela da equação (4), que agora  assume a forma:         Uma inspeção na Equação 9 revela que, quanto menor for γ  , mais rapidamente o   veículo gira em torno de seu eixo-z. A solução das equações dinâmicas revela que, neste  cenário de coeficiente de arrasto reduzido, a incerteza na posição vertical também  diminui. Portanto, o caminho para garantir precisão no posicionamento vertical é buscar  uma conveniente estrutura para o VANT que apresente baixo arrasto aerodinâmico. Nos  resultados apresentados na Figura 4, o limite inferior de 0. 03  N.m.s representa o caso  limite abaixo do qual aparecem problemas numéricos na resolução da dinâmica.     Figura 4: Influência do coeficiente de arrasto na posição vertical.     Para responder parcialmente às perguntas iniciais, consideramos duas geometrias   diferentes para as hastes, uma de seção circular, e outra de seção transversal quadrada.  Aplicando a fórmula do arrasto aerodinâmico, encontra-se que as hastes cilíndricas  apresentam menor força de arrasto. Para fazer uma comparação, considere uma  velocidade de rotação de -3 rad/s e uma haste de 0.03m x 0.03m x 0.6m com perfil  retangular, bem como uma outra de perfil cilíndrico, com mesmo comprimento (0.6m) e  tendo diâmetro de seção transversal igual a 0.03m. Neste caso, a forma cilíndrica  oferece um arrasto 1.3 vezes superior.    Esta discussão evidencia que quadrirrotores com hastes em formato cilíndrico  apresentam menos incerteza no posicionamento vertical quando há falha nos motores.    4.3. Técnica de Fail-safe   Ciente do fato que o posicionamento no plano xy não é mais possível (o veículo divaga,  conforme simulações), e para evitar avarias e acidentes, é recomendável que o  quadrirrotor pouse. Destacamos que quanto mais rápido ele pousar, menor será o  deslocamento sofrido no plano xy após a quebra. Para atender estas exigências,  propomos um algoritmo capaz de detectar a falha e chavear para um controlador crítico,  como descrito a seguir:    1) a estratégia de fail-safe é disparada sempre que a velocidade rotacional em torno  do eixo-z passar de -2 rad/s; 2) o set-point dos ângulos de rolagem e arfagem é ajustado  para zero; 3) o set-point para controle de altitude é dinamicamente alterado de acordo  com uma função de decaimento exponencial.    Na estratégia acima, o passo 2 é necessário para prevenir a ocorrência de flipping, o  que tornaria impossível a tarefa de pousar o veículo. Por outro lado, o passo 3 é  necessário para garantir pouso conveniente na vizinhança da região onde a falha     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   122        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015     inicialmente ocorre, de modo que a velocidade de aproximação à terra seja quase nula.   O algoritmo acima foi simulado e os resultados são apresentados nas Figuras 5 e 6. O   veículo estava inicialmente em funcionamento e, então, no instante t= 3 0 0 s efetuamos  o desligamento de 2 motores, levando Ω2= Ω4= 0  a zero nas equações (5)-(6). A partir  da Figura 5, vemos o quadrirrotor inicialmente em z= 1  m e, após o pico de velocidade  vertical devido ao disparo do cenário de falha, ele é desacelerado, lentamente  alcançando o solo após 4segundos.         Figura 5: Simulação dinâmica de pouso quando usado o fail-safe descrito.     Como mencionado anteriormente, a rapidez de tal decaimento exponencial é   essencial para limitar o desvio horizontal quando o veículo começa a divagar. Para  investigar esta questão, na Figura 6 é traçado o comportamento do desvio horizontal  como função da rapidez da trajetória de decaimento exponencial. A região de interesse é  a parte inferior esquerda do gráfico, que significa, na prática, um pouso completamente  vertical.      Figura 6: Influência da taxa de decaimento da trajetória exponencial no desvio da   posição horizontal.      5. Conclusão   Neste artigo levantamos a questão do controle da estabilização de voo em VANT com  falha de excitação. Explicamos que a estratégia PID é ineficiente para garantir  navegação segura após a ocorrência de falha dupla de motores, mas pode ser utilizada  em conjunto com uma técnica de fail-safe. Um algoritmo deste tipo foi proposto e usado  para investigar o desempenho do voo do veículo quando ele é usado e mostrar como ele  divaga quando é omitido. Este cenário de falha foi adicionalmente investigado a partir  da seção transversal das hastes do veículo. A este respeito, mostramos que há uma  incerteza na altitude e que esta incerteza se reduz conforme o arrasto aerodinâmico     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   123        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 116-123 Nov/2015     atinge baixos valores, o que é favorecido pela adoção de hastes de perfil cilíndrico. No  que diz respeito ao desempenho da técnica de fail-safe, por sua vez, nossa abordagem  consiste em forçar uma trajetória tipo exponencial para o controle de posição vertical, e  os resultados sugerem que a taxa de decaimento da trajetória deve ser feita rápida o  suficiente para garantir um pouso seguro e quase vertical após a falha, com velocidade  de aproximação do solo quase nula. Como trabalho futuro, estamos embarcando o  algoritmo proposto em um VANT e resultados da prova de conceito serão apressentados  em caso de aceitação do artigo.    6. Agradecimentos   Os autores agradecem a CAPES pelo suporte financeiro e a Fundação NUTEC, pelo  apoio administrativo.    Referências   A. Lanzon, A. F. and Longhi, S. (2014). Flight control of a quadrotor vehicle  subsequent to a rotor failure. Journal of Guidance, Control, and Dynamics,  37(2):580–591.    Al-Omari, M. A. R. (2013). Integrated simulation platform for indoor quadrotor  applications. In Proceedings of the 9th International Symposium on Mechatronics  and its Applications (ISMA13), pages 1–6.    G. Lippielo, F. R. and Serra, D. (2014). Emergency landing for a quadrotor in case of a  propeller failure: A backstepping approach. In Proceedings of the IEEE/RSJ  International Conference on Intelligent Robots and Systems, pages 4782–4788.  IEEE.    Jirinec, T. (2011). Stabilization and control of unmanned quadcopter. Master’s thesis,  Master of Science in Space Engineering-Czech Technical University, Prague.    Maxemow, S. (2009). That’s a drag: The effects of drag forces. Undergraduate Journal  of Mathematical Modeling.    Mueller, M. W. and D’Andrea, R. (2014). Stability and control of a quadrocopter  despite the complete loss of one, two, or three propellers. In Proceedings of the IEEE  International Conference on Robotics and Automation (ICRA 2014), pages 45–52.  IEEE.    Ranjbaran, M. and Khorasani, K. (2010). Fault recovery of an under-actuated quadrotor  aerial vehicle. In Proceedings of the 49th IEEE Conference on Decision and Control,  pages 4385–4392. IEEE.    Santana, P. H. Q. A. and Borges, G. A. (2009). Modelagem e controle de quadrirotores.  In Proceedings of the Simpósio Brasileiro de Automação Inteligente (SBAI 2009),  pages 1–6.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   204        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     Evolução Espaço-Temporal de Disseminação de Epidemias  Baseado no Modelo Malthus-Verhulst com Autômato Celular   Wellington A. V. Fonseca, Maury M. Gouvêa Jr.   Programa de Pós-Graduação em Engenharia Elétrica  Pontifícia Universidade Católica de Minas Gerais   Belo Horizonte, Minas Gerais – Brasil  wellington.fonseca@sga.pucminas.br, maury@pucminas.br   Abstract. The study of natural phenomena can be a complex task, especially  due to their mathematical model. The study of epidemic dynamic is given  special attention by researchers due to social and economic reasons. This  work presents a model witch describes an epidemic time-spatial evolution  based on cellular automaton. The model uses local iterations and the MalthusVerhulst model of population dynamics. With the proposed model, it will be  possible to create different dissemination scenarios in order to evaluate  epidemics, permitting to create more powerful preventive policies.   Resumo. O estudo de fenômenos naturais pode ser uma tarefa complexa,  principalmente em razão do modelo matemático que os descrevem. O estudo  da dinâmica de epidemias tem ganhado destaque entre pesquisadores por  motivos sociais e econômicos. O presente trabalho apresenta um modelo que  descreve a evolução espaço-temporal de epidemias baseado em autômato  celular. O modelo utiliza iterações locais e o modelo de Malthus-Verhulst de  dinâmica de populações. Com o modelo proposto, torna-se possível criar  diferentes cenários de disseminação para a avaliação de epidemias,  permitindo a criação de políticas de prevenção mais efetivas.   6. Introdução  A modelagem matemática é uma forma comum de se representar sistemas presentes no  nosso cotidiano, podendo descrever dos mais simples aos mais complexos. O estudo da  dinâmica dos mesmos tipicamente é realizado através de simulações de modelos  computacionais. Dessa forma, permite-se um estudo mais rápido e eficaz, mais seguro e  com a utilização de menos recursos e, por consequência, a validação dos modelos  propostos [Gouvêa Jr. e Silva 2013].   O chamado Autômato Celular [Wolfram 1983] é um modelo que proporciona  relativa simplificação de sistemas complexos, evitando-se a utilização de Sistemas de  Equações Diferenciais, por exemplo. Nesta abordagem, assume-se uma grade composta  de células com propriedades individuais e as interações entre as mesmas se dá através  de regras de transição, sendo estas as responsáveis pelo comportamento local que  culmina na dinâmica da grade, como um todo [Gouvêa Jr. e Silva 2013]. Aplicações  típicas dos Autômatos Celulares (AC) se dão em áreas como dinâmica de nuvens,  engenharia de tráfego, disseminação de epidemias, criptografia, dentre outras [Rennard  2002].   O presente trabalho tem como objetivo propor um modelo para simular a  disseminação de epidemias levando-se em conta a influência da vizinhança e a evolução  temporal da população em análise. Para tal, utiliza-se o modelo AC para a interação     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   205        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     entre os indivíduos da grade, simulando a dinâmica da epidemia, e o modelo de Malthus  referente ao crescimento populacional. Utiliza-se, portanto, uma grade bidimensional  com vizinhança de Von Neumann, na qual cada célula tem ou não um indivíduo  presente. Cada célula da grade abriga, ou não, um indivíduo, sendo que este apresenta  apenas os estados S (Susceptível) e I (Infectado) do modelo SIR (ou modelo epidêmico).   7. Referencial Teórico  Nesta seção, apresentam-se os conceitos básicos deste trabalho, como os fundamentos  dos principais temas utilizados na pesquisa: autômatos celulares e o modelo de  crescimento populacional. A primeira subseção apresenta conceitos introdutórios de um  autômato celular. A segunda subseção explica o modelo clássico de Malthus-Verhulst,  responsável pela evolução temporal de determinada população.   7.1. Autômato Celular   Trata-se de um tipo de sistema discreto em formato de grade, sendo esta última dividida  em elementos chamados células. Cada célula presente em um AC pode assumir  determinado número de estados e sua interação com as demais células da grade  determinam a dinâmica da grade como um todo. As células presentes na vizinhança  podem ou não alterar o estado de determinada célula, sendo a alteração determinada  através das chamadas regras de transição. As regras de transição de um AC são funções  determinísticas responsáveis por gerar o estado de determinada célula em instantes de  tempos futuros. Em outras palavras, fornecem o estado Si(k+1) da i-ésima célula no  instante de tempo k+1 como uma função dos estados das células pertencentes à  vizinhança Ni [Wolfram 1983] [Gouvêa Jr e Silva 2013].   Um AC pode ser usado para representar diversos modelos de sistemas reais. De  acordo com a característica do problema envolvido, o AC utilizado apresenta dimensões  distintas. Por exemplo, no caso da avaliação da temperatura em uma barra, pode-se  utilizar um AC unidimensional, como representado na Figura 1-a. Uma superfície,  tipicamente, utiliza AC bidimensional, Figura 1-b, assim como será utilizado no  presente trabalho. Para o caso em que se deseja avaliar a variação da umidade, por  exemplo, em uma sala, utiliza-se um AC tridimensional, Figura 1-c.     Figura 1: Dimensões Típicas de um AC   A vizinhança de um AC é dada por uma célula central e as demais ao seu redor,  podendo-se considerar todas, ou somente as imediatamente acima e abaixo, e à direita e  esquerda da célula central; respectivamente chamadas vizinhança de Moore e  vizinhança de Von Neumann. A Figura 2 ilustra as vizinhanças de um AC.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   206        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015       Figure 2: Vizinhanças típicas em um AC   Os autômatos celulares têm aplicações em simulações de sistemas reais,  tipicamente [Rennard 2002]: No estudo do comportamento de bactérias, vírus e gases,  espalhamento de incêndios, desenvolvimento de populações, sistemas econômicos e  crescimento de vegetais; Geração de figuras aleatórias, filtro de imagens e distorção;  Geração de melodias, sons e ruídos digitais; Substituição de equações diferenciais;  Geração de números aleatórios e na criptografia; e simulação de partículas e geração de  texturas.   7.2. Modelo de Crescimento Logístico  O modelo de crescimento populacional proposto por Thomas Malthus define um  crescimento proporcional ao tamanho da população, N, como segue:                                                                                                                             (1)   Na Equação (1), r representa a taxa de crescimento, i.e., a diferença entre as  taxas de natalidade e de mortalidade. A solução dessa equação diferencial define N(t),  tamanho da população N em um determinado período de tempo t, como uma função  exponencial. Esse modelo é válido para um período de tempo, mas não por um longo  período, pois nenhuma população cresce indefinidamente em razão das restrições  ambientais, como as climáticas, e de recursos naturais, como a escassez de alimentos.   Com o objetivo de limitar o crescimento populacional em razão das restrições  supracitadas, Pierre Verhulst introduziu a equação de crescimento logístico, conferindo  ao modelo de Malthus maior fidedignidade [Tavoni e Oliveira 2013]. O modelo de  Verhulst é descrito como segue:                                                                                                       (2)   Onde Nsat é o parâmetro que define a saturação da população. Na sua versão  discreta, aproximada pelo método de Euler, o modelo de crescimento populacional de  Verhulst dá a dinâmica da população N em função do instante de tempo k, e pode ser  descrito como segue:                                                                                                   (3)   sendo Nsat o tamanho da população quando t → ∞.      8. Modelo de Disseminação de Epidemias Proposto     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   207        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     Para permitir a simulação da disseminação de uma epidemia em um período de tempo  superior ao ciclo reprodutivo de uma população, pode ser importante considerar a  evolução natural desta população. Assim, deve-se considerar o modelo de crescimento  populacional da população em estudo.   O modelo neste artigo é baseado no modelo de crescimento logístico proposto  por Verhulst [Tavoni e Oliveira 2013] e por uma regra de disseminação de epidemias  por contaminação direta entre vizinhos. Na grade do AC, cada célula possui um  indivíduo ou está vazia. A contaminação é probabilística, em função do número de  vizinhos contaminados.   A população inicial é disposta aletoriamente na grade do AC e seu crescimento  ocorre em função do modelo de crescimento de Verhulst perturbado pelo número de  mortes decorrente da epidemia em estudo. Para a representação da população, cada um  dos N indivíduos pode apresentar dois estados diferentes: susceptível ou infectado. A  cada iteração, um indivíduo pode evoluir de susceptível para infectado, e deste último  para morte, desaparecendo da célula, ou se recuperar, voltando a ser susceptível, como  mostra a Figura 3. De susceptível, S, o indivíduo pode infectar-se em função de uma  variável aleatória com distribuição normal N(β, σ) definida por uma média γ e desvio  padrão σ, onde β é a probabilidade de o individuo se tornar infectado. De infectado, I, o  indivíduo pode ir a óbito, célula vazia, segundo uma variável aleatória com distribuição  normal N(γ, σ) ou se recuperar com distribuição normal N(1 – γ, σ), tornando-se  susceptível novamente, sendo γ a probabilidade de morte e a probabilidade de  recuperação, 1 – γ.     Figure 3: Diagrama do modelo de contaminação proposto   Propõe-se também uma variação da média em função do número de vizinhos,  NΛ, da célula avaliada. Assim, quanto maior o número de vizinhos infectados, maior  será a probabilidade de contaminação. A probabilidade média de contaminação é, pois,  uma função do número de vizinhos, expressa como segue:                                                                                                                 (4)                                                                                                                 sendo  = 0,2 . Como o tempo de disseminação de epidemias é normalmente menor  que o de crescimento populacional, para cada iteração do modelo de Malthus-Verhulst  ocorre n iterações do modelo epidêmico.   9. Resultados de Simulação  Com a finalidade de analisar a dinâmica do modelo proposto, foram feitas simulações,  em ambiente Matlab, em uma grade 10x10. Alguns parâmetros do sistema foram  variados para que seus impactos sobre o comportamento do modelo fossem analisados.  Para cada simulação, foram realizadas 300 iterações. Os parâmetros utilizados foram o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   208        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     crescimento populacional, r = 10%, β = {0,2; 0,6}, γ = {0,1; 0,5}, N(0) = {20; 40} % e  Nsat = 50% da grade ocupada. A Tabela 1 mostra como foram ajustados os parâmetros  do modelo entre as simulações. A taxa de contaminação ou morte igual a 0% significa  que foi utilizado o modelo original Malthus-Verhulst sem o modelo de disseminação de  epidemias proposto.   Tabela 1: Parametrização das Simulações   Sim. Taxa de  Contaminação   Taxa de  Mortalidade   Pop.  Inicial     (i)   0  20%  60%      10%     20%        (ii)     20%  0   10%  50%     40%      Na simulação (i), o objetivo foi avaliar diferentes taxas de contaminação do  modelo proposto em relação a uma taxa de mortalidade baixa para uma população  pequena em relação ao tamanho da matriz. Assim, pode-se observar o impacto da  epidemia em relação a um cenário favorável, i.e., uma epidemia com baixa taxa de  mortalidade disseminada em uma população pequena. A Figura 4 mostra a evolução da  população na simulação (i). A legenda apresentada da Figura 4(a) rotula, também para  as Figuras 4(b)-(c), as curvas de Malthus-Verhulst, em azul contínuo, do modelo  proposto com β = 0,2, em verde tracejado, e do modelo proposto com β = 0,6, em  vermelho traço-pontilhado.   O modelo original Malthus-Verhulst teve o comportamento esperado, isto é,  com uma taxa de crescimento positiva, a população, N(k), cresce monotonamente até o  valor de saturação definido, Nsat = 50% da grade ocupada. No caso β = 0,2, curva verde  tracejada, a população também cresce, mas com menor intensidade até o valor de  saturação. Ao atingir Nsat, na iteração 150, aproximadamente, N(k) segue oscilando em  razão da perturbação gerada pelas ocorrências de morte causadas pela epidemia. Essa  curva sugere que N(k) continuaria crescendo, assim como no modelo Malthus-Verhulst,  caso não houvesse as limitações propostas no modelo de Verhulst. As baixas taxas de  contaminação e mortalidade, β = 0,2 e γ = 0,1, não são suficientes para evitar o  crescimento da população, apenas o perturba. A população inicial pequena, 20% de  ocupação na matriz, não influenciou a dinâmica da epidemia, caso contrário, o número  de mortes aumentaria com o crescimento da população.   As curvas do número de infectados e mortes das Figuras 4(b)-(c) podem ser  relacionadas entre si, pois ao aumentar o número de infectados, o número de mortes  tende a aumentar. Nas Figuras 4(b)-(c), observa-se picos de crescimentos de infectados  e mortes. Isso ocorre porque o número de infectados tende a aumentar até um limite em  que os indivíduos atingem uma concentração máxima, i.e., um indivíduo possuirá 4  vizinhos. Nesse momento, o número de mortes em decorrência da epidemia tende a  aumentar em decorrência do aumento da probabilidade de contaminação (função do  número de vizinhos). Na comparação entre as populações com diferentes β, há um  número maior de infectados e mortes na população com maior taxa de contaminação.  Assim, as curvas de número de infectados e mortes da população com essa taxa de  contaminação maior, vermelha traço-pontilhada, apresenta maior número de picos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   209        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     Na simulação (ii), o objetivo foi avaliar diferentes taxas de mortalidade do  modelo proposto em relação a uma taxa de mortalidade baixa para uma população de  tamanho médio em relação à dimensão da matriz. Nesse caso, analisa-se o impacto da  epidemia em relação a um cenário menos favorável em relação ao experimento (i). A  Figura 5 mostra a evolução dos parâmetros da população na simulação (ii). Assim como  na Figura 4, a legenda apresentada da Figura 5(a) rotula as curvas também para as  Figuras 5(b)-(c).    A Figura 5(a) mostra a evolução da população para as três condições impostas  pela simulação (ii). Como a população inicial, N(0), foi próxima do valor de saturação,  Nsat, o número de indivíduos no modelo Malthus-Verhulst saturou rapidamente. No caso  γ = 0,1, as baixas taxas de mortalidade e contaminação, β = 0,2, não foram suficientes  para impedir o crescimento da população.     Figure 4: Evolução de uma população na simulação (i): (a) modelo original   Malthus-Verhulst; (b) modelo proposto com β = 0,2; (c) modelo proposto com β  = 0,6     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   210        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015       Figure 5: Evolução de uma população na simulação (ii): (a) modelo original   Malthus-Verhulst; (b) modelo proposto com γ = 0,1; (c) modelo proposto com γ  = 0,5   A oscilação após a saturação foi maior que na simulação (i) com as mesmas  taxas de contaminação e mortalidade. Essa situação pode ser atribuída à maior  população inicial que pode ter constituído um número maior de agrupamentos –  aumentando a taxa de contaminação em razão do número maior de vizinhos. No caso γ  = 0,5, a população declinou, assim como na simulação (i), pois, apesar de uma taxa de  contaminação mais baixa, a taxa de mortalidade foi elevada.   A Figura 5(b) mostra o número de infectados na simulação (ii). Observa-se que  o número médio de infectados no caso γ = 0,1 é maior que no caso γ = 0,5, apesar de em  ambos os casos a taxa de contaminação utilizada ter sido a mesma, β = 0,2. Essa  situação pode ser atribuída à maior taxa de mortalidade do segundo caso, γ = 0,5, que  convertia a morte um número maior de infectados que no primeiro caso, γ = 0,1. Essa  conclusão pode ser reforçada na Figura 5(c), que mostra um número médio de mortes  maior no caso γ = 0,5, curva vermelha traço-pontilhada.   10. Conclusão  Este trabalho apresentou um modelo de dinâmica de epidemias integrado ao modelo de  crescimento populacional Malthus-Verhulst utilizando autômato celular. No modelo  proposto, cada célula do AC pode conter ou não um indivíduo, classificado como  susceptível ou infectado de acordo com taxas de contaminação e mortalidade da  epidemia em estudo. No modelo proposto, o crescimento da população é baseado no  modelo Malthus-Verhulst, que é perturbado pelas regras de transição de estado.   Foram realizadas simulações com o objetivo de analisar a dinâmica do modelo  proposto. Dois tipos de simulações foram realizadas, (i) fixando a taxa de mortalidade e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   211        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 204-211 Nov/2015     variando a taxa de contaminação; e (ii) fixando a taxa de contaminação e variando a  taxa de mortalidade. No experimento (i), estudou-se um cenário mais favorável, pois  usou-se uma população inicial e taxa de mortalidade da epidemia baixas. No  experimento (ii), o cenário foi menos favorável, pois a população inicial foi maior,  formando um número maior de agrupamento de indivíduos, e uma das taxa de  mortalidade foi elevada (50%).   Os estudos mostraram que taxas elevadas de contaminação ou mortalidade do  modelo proposto tendem a declinar o número de indivíduos de uma população. Em  populações maiores, o impacto do modelo se torna maior, pois a probabilidade de  contaminação aumenta quando um indivíduo possui mais vizinhos contaminados.  Assim, como populações maiores possuem mais agrupamentos, mais indivíduos serão  contaminados.   Em trabalhos futuros, pretende-se comparar o modelo proposto com epidemias  já estudadas na literatura e, assim, validar este estudo inicial. Dessa forma, será possível  utilizar o modelo proposto em planejamento de políticas públicas de saúde, analisando o  impacto de epidemias sobre populações humanas ou de bactérias e sobre os recursos  públicos necessários para contê-la.   Agradecimentos   Os autores agradecem à Capes, pelo suporte financeiro na forma de bolsa de pesquisa, e  à Pontifícia Universidade Católica de Minas Gerais que forneceram suporte para  realização deste trabalho.   Referências   Silva, A. K. C. ; Gouvêa JR., M. M. “Dinâmica de Epidemias Baseada no Modelo SIR  com Autômato Celular”. In: Franca Arenare Jeunon, Wolney Lobato, Sérgio de  Morais Hanriot. (Org.). Iniciação Científica: destaques 2013. 1ed.Belo Horizonte:  Editora PUC Minas, 2014, v. 1, p. 161-173.   Wolfram, S. “Cellular Automata”. Los Alamos Science, 1983.  Rennard, J.P. “Implementation of logical functions in the game of life”. In: Adamatzky   A (ed) Collision-based computing. Springer, London, pp 491–512  Tavoni, Robinson; Oliveira, Renata Zotin G. “Os modelos de crescimento populacional   de Malthus e Verhulst - Uma motivação para o ensino de logaritmos e exponenciais”.   Kermack, W. O.; Mckendrick, A. G. “A contribuition to the mathematical theory of  epidemics”. Proceedings of the Royal Society of London. Series A, Containing  Papers of a Mathematical and Physical Character, v. 115, n. 772, 700-721, 1927.   Alvarenga, Lucymara de Resende. “Modelagem de epidemias através de modelos  baseados em indivíduos”. 2008. 130f. Dissertação (Mestrado em Engenharia  Elétrica) - Programa de Pós-graduação em Engenharia Elétrica, Universidade Federal  de Minas Gerais, Belo Horizonte.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   228        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     Extração da Métrica WMC a partir de Código Java   Luana V. Martinez, Maurício S. R. Arrieira, Carlos M. Betemps   Engenharia de Computação – Universidade Federal do Pampa (UNIPAMPA)   Campus Bagé – RS – Brasil  {luanavmartinez, mauriciorealan, carlos.betemps}@gmail.com   Abstract. Software metrics are measures of software system properties that  allow a quantitative evaluation of a software element under analysis. Aiming  to describe the software metrics concepts, this work addresses the related  techniques, mainly the object oriented metrics. Also, it proposes an approach  for the WMC metric extraction, and presents a software prototype that  performs such extraction.   Resumo. As métricas de software consistem em medidas das propriedades de  um sistema de software, permitindo uma avaliação quantitativa de um  elemento de software sob análise. Buscando descrever pontualmente os  conceitos relacionados às métricas de software, esta pesquisa visa abordar as  técnicas referentes ao tema, com ênfase nas Métricas Orientadas a Objetos, e  apresenta uma abordagem para a extração da métrica WMC e um protótipo  de software com capacidade de realizar tal extração.   1. Introdução  Atualmente o software é considerado um dos maiores influenciadores do orçamento das  organizações. A grande maioria delas reconhece a importância de controlar os gastos  com software, analisando o desempenho dos resultados obtidos com o desenvolvimento  e a manutenção dos mesmos. Desta maneira, é necessário fazer uso de medidas e de  modelos apresentados na Engenharia de Software [Cordeiro 2008].  Para obter-se um software de qualidade é necessário realizar medidas nesse software,  também conhecidas como métricas de software. Uma métrica é qualquer tipo de  medição que se refira a um sistema de software, processo, ou documentação relacionada  [Sommerville 2003]. As métricas de software são expressas de forma quantitativa, ou  seja, em números, sem elas os dados obtidos seriam apenas dados subjetivos. Segundo  Guarizzo [2008], com a medição feita é possível estimar custos e prazos para o  desenvolvimento do projeto e entrega do produto final.   O crescimento constante da demanda de desenvolvimento de software motivou  um estudo e análise das métricas de software. Assim, modelos e ferramentas capazes de  realizar a medição das estruturas de um software se tornam cada vez mais  imprescindíveis. Dessa maneira, o objetivo fundamental deste trabalho é apresentar uma  técnica capaz de extrair a métrica de software WMC (Weighted Methods per Class –  Métodos Ponderados por Classe). Sendo assim, será apresentada uma análise  introdutória sobre as métricas de software, com foco nas métricas orientadas a objetos, e  a apresentação de uma abordagem para a extração da métrica WMC de códigos Java.   O restante deste trabalho está organizado da seguinte forma: na seção 2 o  referencial teórico do trabalho é apresentado. Em seguida, a seção 3 apresenta a  metodologia de desenvolvimento deste trabalho. Na seção 4 é mostrada a abordagem  proposta para a extração da métrica WMC. A seção 5 apresenta o protótipo de software  desenvolvido. Por fim, as conclusões e trabalhos futuros são apresentados na seção 6.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   229        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     2. Fundamentação Teórica  Para embasar este estudo faz-se necessário um levantamento teórico de aspectos  relevantes ao tema, os quais são apresentados nesta seção, iniciando com as Métricas de  Software, seguida de Métricas de Software Orientadas a Objetos e as Métricas CK  [Chidamber e Kemerer 1994], além dos conceitos relacionados aos métodos para  extração de métricas.  2.1. Métricas de Software  De acordo com Balzer et al. [2005], métricas de software são medidas quantitativas do  grau em que um sistema de software, um componente, ou processo possuem um  determinado atributo. Elas permitem a identificação de áreas problemáticas, a ilustração  de tendências e, assim, ajudam a melhorar a qualidade dos produtos de software, bem  como ajudam a aumentar a eficiência do processo de desenvolvimento. No contexto de  compreensão de programa e análise de software muitas métricas de software têm sido  estudadas. Exemplos de métricas de software podem ser o número de linhas de código e  o número de atributos públicos em uma classe.   Guarizzo [2008] apresenta algumas vantagens e desvantagens relacionadas ao  uso de métricas de software, conforme apresenta a Figura 1. Conforme o autor, a  desvantagem no uso de métricas está relacionada à confiabilidade dos resultados obtidos  na extração das mesmas.     Figura 11. Vantagens x Desvantagens no Uso de Métricas de Software   2.2. Métricas Orientadas a Objetos  Cada vez mais as métricas orientadas a objetos têm sido usadas para avaliar a qualidade  do software, assim indica Harrison et al. [1998].  Para se tornar válida, uma métrica  precisa provar que mede exatamente o que propôs medir.    O conjunto de métricas CK [Chidamber e Kemerer 1994] foca nas propriedades  da estrutura base de projetos OO - a classe - e buscam medir características de tamanho,  acoplamento, coesão e herança nas classes de um projeto de software.  2.3. Métricas de Chidamber e Kemerer  As métricas CK são métricas orientadas a classe [Chidamber e Kemerer 1994]. São  compostas por métricas que permitem a análise quantitativa dos artefatos de software  construídos utilizando o paradigma da orientação a objetos. O objetivo dessas métricas é  salientar as classes que possivelmente contém maior número de defeitos, com o  propósito de direcionar os esforços de teste.   Oliveira [2012] apresenta que Chidamber e Kemerer propuseram um dos  conjuntos mais amplamente conhecidos de métricas de software orientado a objetos.  Neste conjunto estão as métricas:   • Métodos ponderados por classe (Weighted Methods per Class – WMC);   • Profundidade da Árvore de Herança (Depth of the Inheritance Tree – DIT);     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   230        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     • Número de filhas (os) (Number Of Children – NOC);   • Acoplamento entre Classes de Objeto (Coupling Between Objects – CBO); e   • Falta de Coesão em Métodos (Lack of Cohesion in Methods – LCOM).  2.4. Métrica WMC (Weighted Methods per Class)  A métrica WMC – Métodos Ponderados por Classe – é uma preditora de quanto tempo  e esforço são necessários para desenvolver e manter uma classe. Esse método atribui  pesos aos métodos de uma classe e, dessa maneira, é medida a complexidade individual  de cada classe [Sommerville 2003]. Se todos os métodos de uma classe apresentarem a  mesma complexidade (1, por exemplo), então WMC será somente o número de métodos  definidos em cada classe [Pfleeger 2004]. Operações herdadas de uma superclasse são  desconsideradas.   É possível medir os métodos de acordo com o número de linhas de código do  método, complexidade ciclomática, número de parâmetros, entre outros. Assim, o  número de métodos e a sua complexidade relacionada indicam o tempo e o esforço  requerido para a programação e a manutenção da classe.  2.5. Métodos para Extração de Métricas  A grande quantidade de métricas, coletas manuais e poucos recursos de visualização são  fatores que acabam por desmotivar o uso destas para o monitoramento do código. Além  disso, a compreensão do significado de valores obtidos por meio de métricas não é uma  tarefa trivial, demandando um grande esforço de interpretação necessário para a tomada  de decisão efetiva sobre o projeto de software.   Assim, destaca-se a importância de ferramentas que auxiliem o processo de  medição, compreensão e visualização do software. Atualmente existem algumas  ferramentas que automatizam a extração de métricas do código fonte, com objetivo de  coletar as informações sobre o produto a partir da análise estática do código. Estas são  definidas como ferramentas Extratoras [Del Esposte 2014].   3. Metodologia  Como o objetivo geral deste trabalho é realizar um estudo das métricas de software,  com foco na métrica WMC, foi adotada uma sequência de passos metodológicos para  que, com uma busca e análise do referencial teórico e estudo especifico sobre métricas  de software, fosse possível desenvolver uma abordagem e respectiva aplicação que  fossem capazes de extrair a métrica WMC de código fonte escrito em Java. Na Figura 2  está demonstrada a sequência metodológica adotada para este trabalho.     Figura 2. Sequência de Passos da Metodológica Utilizada no Trabalho     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   231        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015      Em um primeiro momento, foi realizado o levantamento de referências  existentes sobre o tema abordado utilizando mecanismos de busca na internet,  bibliotecas digitais (como a IEEExplore10) e livros da área de engenharia de software.  Posteriormente, foi feita a análise deste referencial. Em seguida foram estudadas as  métricas de software existentes. O próximo passo foi separar dentre essas métricas  encontradas as métricas orientadas a objetos e, consequentemente, a métrica Métodos  Ponderadas por Classe (WMC). Tendo conhecimento sobre a métrica WMC, a mesma  foi escolhida como objeto principal de estudo e experimentação neste trabalho. Em  momento posterior foi desenvolvida uma abordagem para extração de tal métrica. Por  fim, foi realizado o desenvolvimento de um programa em Java, utilizando o editor de  código fonte Notepad++, com funcionalidade de extração da métrica WMC, conforme  definida na abordagem.   4. Abordagem de Extração da Métrica WMC  A linguagem de programação Java foi usada como referência neste projeto, pois seu  modelo de constituição classes-métodos possibilita uma avaliação eficaz da métrica  WMC. A abordagem para extração da métrica WMC apresentada neste trabalho tem por  princípio inicial realizar uma análise sobre o código fonte (escrito em Java).   Assim, para a avaliação da métrica, o primeiro passo da abordagem é identificar  cada palavra do texto do código fonte, com intuito de ter uma referência para os  símbolos e possíveis palavras reservadas da respectiva linguagem de programação.   Em um segundo momento se realiza uma comparação entre todas as palavras do  texto do código fonte com palavras reservadas que podem integrar a assinatura de um  método. No caso da linguagem Java a comparação é feita com palavras reservadas da  linguagem, seguindo a estrutura de um método Java. A Figura 3 apresenta o modelo de  estruturação de um método, baseado no descrito por Gosling e seus colegas no livro  Java Language Specification [Gosling et al. 2014], e alguns exemplos de assinatura de  métodos. Neste modelo, antes do nome do método, a assinatura pode ser composta por:  modificadores seguidos de um tipo de retorno ou somente por um tipo de retorno.       Figura 3. Modelo de Assinatura de um Método Java.    Quando uma comparação retorna um resultado positivo passa-se para mais uma  comparação, isto porque alguns métodos apresentam mais de uma destas palavras  reservadas em sua assinatura (caso dos modificadores). Para finalizar o passo de  comparação e definir que um novo método foi encontrado, busca-se a palavra que está                                                    10 http://ieeexplore.ieee.org/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   232        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     entre a palavra referente ao tipo de retorno e o símbolo de parênteses - este é, então, o  nome do método.   Uma vez que a maneira de encontrar os métodos da classe já está definida, o  próximo passo para a extração da métrica está em analisar a complexidade dos métodos.  Neste trabalho a complexidade dos métodos de uma classe será ponderada pelo número  de linhas do método.   Depois que todos os métodos da classe já possuem um número de linhas  conhecido é realizada a atribuição do peso para cada método. A ponderação para cada  método consiste em uma progressão que acrescenta uma unidade ao peso do método a  cada cinco linhas, isto é, se um método possuir entre uma e cinco linhas ele vai possuir  o peso "1", se ele possuir entre seis e dez linhas ele vai receber peso "2", se ele tiver  entre onze e quinze linhas peso "3" e assim sucessivamente.   Por fim, depois que todos os métodos da classe já foram encontrados e  ponderados ocorre, enfim, o cálculo da métrica WMC, onde o valor da mesma será o  resultado do somatório dos pesos de cada método dividido pelo número de métodos que  a classe possui.   A Figura 4 demonstra o processo para extração da métrica. Cada um dos passos  da técnica está exposto e também é apresentado que, após o passo "3", já foram  identificados o número de métodos da classe e o nome de cada método, fatores esses  importantes no estágio 6 do processo.       Figura 4. Modelo de Extração para métrica WMC.   5. Protótipo de Software Implementado  Para auxiliar na análise sobre o tema, foi construído um software utilizando a linguagem  de programação Java, que extrai a métrica de software WMC, seguindo como premissa  o modelo de extração estabelecido na Seção 4. O código desta implementação está  dividido em classes, são ao todo nove classes que constituem a implementação. As     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   233        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     ferramentas utilizadas para realizar a implementação do programa foram o Notepad++ e  NetBeans IDE 7.4, além do JDK. A implementação possui quatro classes que realizam  as operações de processamento, seleção e carregamento de arquivos e também as  classes que montam as interfaces gráficas.   Inicialmente, o software realiza a leitura dos códigos Java indicados pelo  usuário. Esses arquivos são analisados e todas as suas linhas são decompostas em  palavras. Uma vez que todas as palavras do arquivo possuem uma referencia única, o  software começa uma análise em busca das referências que contenham o nome da classe  e dos métodos de cada um dos arquivos lidos. Em um segundo momento, já com o  conhecimento das classes e respectivos métodos, o protótipo realiza a contagem do  número de linhas que cada método possui. Para cada método é atribuído um peso,  conforme o critério estabelecido pela abordagem - número de linhas que o mesmo  possui e progressão dos pesos a cada cinco linhas.   Após a análise dos códigos Java, uma estrutura em forma de árvore para análise  simplificada é montada pelo software. Esta árvore apresenta uma constituição na qual  cada uma das classes representa um ramo principal. Em cada um desses ramos existem  os nós adjacentes correspondentes a cada um dos métodos da respectiva classe, e dentro  de cada método seus respectivos números de linhas e peso ponderado. Por fim, o  software realiza o cálculo da métrica WMC, conforme apresentado na seção 4.   As Figuras 5 e 6 demonstram o funcionamento do software implementado,  ressaltando a estrutura de árvore utilizada (Figura 5) e os dados referentes à extração da  métrica (Figura 6).     Figura 5. Estrutura em árvore utilizada na aplicação.     Figura 6. Exemplo de dados extraídos pela aplicação.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   234        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 228-234 Nov/2015     6. Conclusões e Trabalhos Futuros  Ao finalizar esta pesquisa, percebe-se que a abordagem para a extração da métrica  WMC formulada neste trabalho pode servir como base para a implementação de  aplicações que executem a extração da métrica WMC, como o protótipo implementado  neste trabalho. O estudo de diferentes métricas de software indica a importância de tal  conhecimento para uma melhor avaliação técnica do significado dos valores de métricas  extraídos a partir de código fonte, como os valores da métrica WMC, que indicam a  complexidade de uma determinada classe. O uso do número de linhas de um método,  especificamente a atribuição do peso de um método com base no número de linhas,  permite que um valor específico seja atribuído por quem está realizando as medidas,  podendo ser ajustado e customizado conforme a iniciativa de desenvolvimento.   Por fim, a generalização do modelo apresentado de forma que possa ser utilizado  em outras linguagens de programação, bastando indicar aspectos da sintaxe da  linguagem, e, também, a definição de abordagens que tratem da extração de outras  métricas, como as demais métricas CK, serão objetos de estudo em trabalhos futuros.   Referências   Balzer, Michael, Oliver Deussen, and Claus Lewerentz. "Voronoi treemaps for the  visualization of software metrics." Proceedings of the 2005 ACM symposium on  Software visualization. ACM, 2005.   Chidamber, A. R.; Kemerer, C. F. 1994, A Metrics Suite for Object-Oriendes Design,  IEEE Trans. Software Engineering, vol SE-20, n 6, June, pp. 476-493.   Cordeiro-GPS, Marco Aurélio. “Métricas de Software”, 2008. Bate Byte. URL:  Disponível em:  <http://www.batebyte.pr.gov.br/modules/conteudo/conteudo.php?conteudo=88>.  Acesso em: 23/10/2015.   Del Esposte, Arthur de Moura. Tomada de decisões orientadas a métricas de software:  observações de métricas de produto e vulnerabilidades de software via DW e  Plataforma de monitoramente de código-fonte. Monografia. Universidade de  Brasília, 2014. Disponível em:  <https://fga.unb.br/articles/0000/5535/TCC1_Arthur_e_Carlos.pdf>. Acesso em:  23/10/2015.   Gosling, James, et al. The Java Language Specification. Pearson Education, 2014.   Guarizzo, Karina. Métricas de Software. Monografia de Graduação, Faculdade de  Jaguariúna, Jaguariúna, SP, 2008.   Harrison, R., Counsell , SJ, e Nithi , RV, " An evaluation of the MOOD set of objectoriented software metrics," IEEE Transactions on Software Engenharia , vol. 24, pp.  491-496, Junho de 1998.   Pfleeger, Shari Lawrence. Engenharia de software: teoria e prática. 2ª Edição, Pearson -  Prentice Hall, 2004.   Sommerville, Ian. Engenharia de Software. Vol 6. São Paulo: Addison Wesley, 2003.   Oliveira, J. F. de. Métricas para Avaliação do Grau de Quantificação de Sistemas  Orientados por Aspectos. Dissertação. Pontífica Universidade Católica de Minas  Gerais – Programa de Pós-Graduação em Informática. Belo Horizonte, 2010    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   173        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     FredSaúde: Sistema de Mapeamento de Saúde do Município  de Frederico Westphalen   Angélica Caetane Pelizza, Cristiano Bertolini   Departamento de Tecnologia da Informação – Centro de Educação Superior Norte –  Universidade Federal de Santa Maria – UFSM    Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS – Brasil  angelicapelizza@hotmail.com, cristiano.bertolini@ufsm.br   Abstract. This paper aims to analyze heath-care open government databases  from the city of Frederico Westphalen – RS. In this way, we present an  application based on Google Maps API where all the heath-care  establishments are listed according to a Brazilian database of all health-care  establishments. The main contribution of this paper is a visualization system  based on the location of different heath-care establishments and all  information about them like health-care plans, services, etc.   Resumo. Este artigo tem como objetivo analisar bases de dados  governamentais abertas na área da saúde do município de Frederico  Westphalen – RS. Desta forma, apresenta uma aplicação utilizando da API do  Google Maps onde estão disponíveis todos os locais de atendimento  disponíveis para a população da cidade de acordo com os dados do Cadastro  Nacional de Estabelecimentos da Saúde. A principal contribuição é o sistema  de visualização das informações e localização de estabelecimentos da área da  saúde distribuindo-as em um mapa com marcadores personalizados e  trazendo todas as informações disponíveis sobre cada um dos  estabelecimentos como convênios, tipo de atendimento, etc.   1. Introdução  Os dados abertos governamentais ainda são pouco explorados, tendo em vista o imenso  acervo de informações disponíveis. Atualmente, existe a possibilidade de construção de  novos projetos a partir manipulação dos dados e a possibilidade de reorganizá-los de  forma interativa e de fácil acesso, visando gerar benefícios para a sociedade. Para Diniz,  [Diniz, 2010] “não há valor na disponibilização de dados governamentais abertos se a  sociedade não tem interesse em reutilizá-los”.   Segundo a fundação do Conhecimento Aberto (Open Knowledge Foundation –  OKF), “dados são abertos quando qualquer pessoa pode livremente usá-los, reutilizá-los  e redistribuí-los, estando sujeito, no máximo, a exigência de creditar a sua autoria e  compartilhar pela mesma licença”. Assim, a disponibilidade de dados governamentais  possibilita a criação de novos aplicativos e informações, onde se pode obter diversas  novas possibilidades de interação entre o governo e sociedade.   Há uma diversidade de serviços que fazem uso de dados abertos para mostrar  temas de interesse público, além de facilitar o cotidiano dos cidadãos. Dentre os  diversos exemplos, uma das iniciativas relacionadas à transparência governamental é o  portal Política Aberta. O Política Aberta utiliza dados do Portal da Transparência e do  Tribunal Superior Eleitoral para apresentar a relação dos maiores doadores de campanha  com os mais contratados pelo Governo federal, ambos do ano de 2012. Com a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   174        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     finalidade de tornar mais transparentes as influências internas e externas [Oliveira,  2013].   Neste contexto, este artigo propõe o desenvolvimento de uma aplicação web  utilizando os dados disponibilizados pelo Cadastro Nacional de Estabelecimentos de  Saúde contendo os diversos serviços de saúde e locais de atendimento da cidade de  Frederico Westphalen – RS.    O objetivo é inserir estes dados disponíveis em um mapa, integrando os dados a  utilização da API do Google Maps, para indicar a localização de cada um dos serviços  disponíveis no município para a população visando facilitar a localização dos pontos e  serviços que um usuário deseja, sem que seja necessária a consulta em várias páginas e  tabelas. E também visualizando o local no mapa, para que assim utilize se disponível,  um atendimento mais próximo.    Este artigo está organizado como da seguinte forma: a Seção 2 apresenta a  definição de Dados Abertos Governamentais e exemplos de utilização dos dados. A  Seção 3 apresenta um estudo de caso. Por fim são apresentadas as conclusões e  referencias bibliográficas.    2. Dados Governamentais Abertos  Segundo a Open Definition, dado aberto é um dado que pode ser livremente utilizado,  reutilizado e redistribuído por qualquer um. O que permite que, a partir disso se tenha  inovação em diversas áreas, possibilitando diferentes maneiras de utilizá-lo.    Pollock, [Pollock, 2007] afirma que “o melhor uso a ser feito do seu dado será  pensado por outra pessoa”. Com a abertura dos dados governamentais têm-se diversas  formas de relacionamento de dados que contribuem para a transparência governamental,  assim como o combate a corrupção e diversas outras formas de relacionamento com  uma diversidade de resultados disponíveis a sociedade.   Os dados governamentais abertos quando disponibilizados seguem alguns oito  princípios dos dados governamentais abertos estabelecidos pelo grupo OpenGovData,  [Open Government Data Principles, 2007] determinam que os dados devem ser:    1. Completos: todos os dados públicos estão disponíveis. Dado público é o dado  que não está sujeito a limitações válidas de privacidade, segurança ou controle  de acesso.   2. Primários: os dados são apresentados tais como coletados na fonte, com o  maior nível possível de granularidade e sem agregação ou modificação.   3. Atuais: os dados são disponibilizados tão rapidamente quanto necessário à  preservação do seu valor.    4. Acessíveis: os dados são disponibilizados para o maior alcance possível de  usuários e para o maior conjunto possível de finalidades.    5. Compreensíveis por máquinas: os dados são razoavelmente estruturados de  modo a possibilitar processamento automatizado.    6. Não discriminatórios: os dados são disponíveis para todos, sem exigência de  requerimento ou cadastro.   7. Não proprietários: os dados são disponíveis em formato sobre o qual nenhuma  entidade detenha controle exclusivo.    8. Livres de licenças: os dados não estão sujeitos a nenhuma restrição de direito  autoral, patente, propriedade intelectual ou segredo industrial. Restrições  sensatas relacionadas à privacidade, segurança e privilégios de acesso são  permitidas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   175        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015      Com a disponibilidade dos dados surge a produção de novos serviços, opções de  consulta e compartilhamento nas mais diversas áreas. Podem ser citadas várias  iniciativas que usam dados abertos e agregam valor aos cidadãos.   Uma dessas iniciativas analisa as bases de dados abertas sobre acidentes de  trabalho disponíveis pelo governo brasileiro, apresentando um demonstrativo com os  principais índices de acidentes de trabalho no país. Visto que os dados publicados no  Portal Brasileiro de Dados Abertos são fornecidos em forma de arquivo de texto ou  formato XML, o que dificulta a interpretação (visualização) dos dados.    Como citado, Traina [Traina et. al., 2007] enfatiza que os seres humanos não são  eficientes para “interpretar” grandes volumes de dados em forma numérica ou textual,  especialmente em espaços de altas dimensões, mas têm uma percepção muito boa  quando esses dados são apresentados de forma gráfica. Assim, com a finalidade de  melhorar a visualização dos dados e poder comparar facilmente os índices de acidentes  referentes às mais diversas localidades, têm-se o desenvolvimento de uma aplicação que  possibilite a visualização e comparação dos dados através de gráficos de barras e o  mapa de calor no Brasil [Vittali et. al, 2015].   Outra iniciativa destaca a problemática de doenças epidêmicas, com ênfase nos  casos de malária, e cita a difícil visualização por causa da desorganização do grande  volume de dados do DATASUS, resultando na difícil interpretação e leitura manual,  tendo os dados espalhados por sessenta arquivos sem padrão entre as tabelas. Com a  problemática desenvolveu-se uma aplicação web com as informações disponíveis da  incidência da malária no Brasil, pretendendo facilitar a visualização dos dados  disponíveis em forma de gráficos customizáveis através filtros.    As informações disponíveis na aplicação são dos casos de malária registrados  no Brasil dos anos de 2008 a 2013. Possuindo em sua base de dados inúmeros registros  de notificações, além de o seu conteúdo ter a possibilidade de ser acessado de modo  responsivo disponível em qualquer dispositivo móvel. Com a criação da aplicação os  cidadãos e profissionais da área da saúde podem buscar dados e estatísticas sobre a  malária facilmente [Prettz et. al, 2014].    Nota-se que a utilização e o interesse de manipulação de Dados Abertos possui  diferentes enfoques, gerando interesse nas mais diversas áreas com o intuito da  usabilidade. As maratonas de programação têm contribuído para a mobilização e o  desenvolvimento de diversos aplicativos neste contexto.    Como exemplo, cita-se a Hackaton – Maratona Hacker que é um concurso de  aplicativos voltados à utilização dos dados legislativos e parlamentares que reúne  programadores, designers e outros profissionais ligados ao desenvolvimento de  software. O objetivo geral é promover o desenvolvimento de projetos para aumentar a  transparência na divulgação de informações publicas por meio de tecnologias digitais  [Câmara dos Deputados, 2013].     O aplicativo Siga Seu Vereador foi campeão na Maratona de Programação  Hackaton da Câmara municipal de São Paulo, e sua finalidade é criar uma plataforma de  linha do tempo que mostra as ações que os atuais vereadores realizaram. Além disso, os  usuários podem seguir um ou mais vereadores de seu interesse, concordar ou discordar  de alguma ação do vereador bem como comentar os assuntos votados pelo vereador,  cadastrando-se rapidamente com a rede social de sua preferência, dentre as disponíveis.    Os dados utilizados foram disponibilizados pela própria câmara durante a  maratona de programação. O propósito é que os habitantes possam acompanhar  facilmente o trabalho desenvolvido por seus vereadores [Portal brasileiro dos Dados  Abertos, 2011].     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   176        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     3. Estudo de Caso  A área da saúde dispõe de diversos dados abertos em todas as áreas. Pelo grande volume  de dados eles costumam ser apresentados e dispostos em formas de tabelas ou ainda  precisam ser manipulados e nem sempre são tão claros, o que traz dificuldades para  quem busca uma informação simples.   O Cadastro Nacional de Estabelecimentos de Saúde – CNES, que é uma  inscrição determinada pelo Ministério da Saúde para todos os estabelecimentos, sendo  eles públicos ou privados, que prestam algum tipo de assistência à saúde. Cada serviço  de saúde envia os dados do seu estabelecimento ao Ministério e recebe um código que  comprova a regularidade do local de atendimento. As informações são referentes aos  aspectos da área física, recursos humanos, equipamentos e serviços ambulatoriais e  hospitalares.   Os dados dos estabelecimentos cadastrados estão disponíveis para a população  em geral. Estas informações servem de base para o conhecimento da realidade da rede  assistencial existente, como as condições de infraestrutura, o funcionamento e também a  localidade, seja em esfera federal, estadual ou municipal. Os dados são apresentados em  diversas tabelas que podem ser localizadas, em geral, por estado e município. No  entanto, a apresentação desses dados pelo CNES se da de forma rudimentar e de difícil  localização dos estabelecimentos de saúde.   Desta forma, para buscar uma informação básica, o usuário precisa abrir várias  tabelas para encontrar a localização dos estabelecimentos de saúde, o qual é  disponibilizado em um mapa, onde para cada endereço é preciso abrir uma nova aba de  navegação. Com isso, uma das finalidades do sistema FredSaúde é deixar as  informações básicas mais acessíveis e com fácil visualização aos usuários, criando um  Mapa de Estabelecimentos de Saúde, com um filtro para cada um dos estabelecimentos  citados acima, sendo diferenciados por cores, visando à facilidade da localização para  tal necessidade do usuário.   O CNES oferece diversas guias com relatórios, serviços, consultas, entre outros.  A consulta realizada foi em relação aos atendimentos prestados, utilizando como estado:  Rio Grande do Sul e o município: Frederico Westphalen. Ao todo foram listados cento e  oito estabelecimentos, agrupados por atendimentos prestados. Sendo: Centro de  Atenção Psicossocial, Centro de Saúde/Unidade Básica, Clinica/Centro de  Especialidade, Consultório Isolado, Hospital Geral, Posto de Saúde, Secretaria de Saúde  e Unidade de Apoio Diagnose e Terapia.   A Tabela 1 apresenta um resumo dos estabelecimentos de saúde disponíveis na  cidade de Frederico Westphalen – RS, e a quantidade de estabelecimentos.      Tabela 1: Resumo dos estabelecimentos da área da saúde do município de  Frederico Westphalen – RS.   Nome do Estabelecimento Quantidade   Centro de Atenção Psicossocial 1   Centro de Saúde/Unidade Básica 5  Clínica/Centro de Especialidade 4   Consultório Isolado 74   Hospital Geral 2  Posto de Saúde 5     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   177        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     Secretaria de Saúde 2   Unidade de Apoio Diagnose e Terapia  19     Para a construção do mapa utilizou-se a Google Maps API. O serviço permite a  qualquer um incorporar um mapa do Google em uma página web ou aplicativo usando  Javascript; bem como a manipulação desse mapa e a inclusão de conteúdos ou  marcações [Google Maps API]. A seguir, são apresentadas as principais funcionalidades  da aplicação FredSaúde que encontra-se disponível apenas na versão desktop. Pode ser  acessada através do endereço: http://200.132.38.214/si/apps/fredsaude/.    A Figura 1 mostra todos os locais de saúde que estão disponíveis na tabela de  Atendimentos do CNES na cidade de Frederico Westphalen. As informações foram  organizadas e dispostas no mesmo padrão em que organizadas nas tabelas disponíveis  no site. O mapa apresenta também uma legenda interativa que ao clicar em uma das  seções apenas o marcador dos estabelecimentos daquela categoria aparecerá no mapa.        Figura 1: Interface da página inicial do mapa.      A Figura 2 apresenta uma possível interação com a legenda. A seção ativa é a  dos Postos de Saúde, onde, no mapa são exibidos com marcador amarelo os locais onde  se encontram os postos de saúde da cidade de Frederico Westphalen.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   178        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015       Figura 2: Interação com a legenda.       A Figura 3 apresenta as informações de um dos marcadores da seção Postos de  Saúde. Todos os marcadores possuem informações como localização e serviços  oferecidos. Como exibido, por exemplo, o Posto de Saúde Aparecida possui  Atendimento Ambulatorial. O Plano de Saúde, neste caso é apenas um: SUS. E o tipo de  atendimento é de demanda espontânea ou referenciada. Desta forma, a população tem  acesso fácil e rápido as informações sobre todos os estabelecimentos da área da saúde  da cidade de Frederico Westphalen.         Figura 3: Interação com o marcador.      Observa-se que a aplicação FredSaúde oferece uma visualização simples e  rápida e pode ser facilmente estendida para todos os municípios brasileiros.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   179        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     4. Conclusão   Este trabalho apresentou um mapa indicando todos os locais de saúde da cidade de  Frederico Westphalen, RS, baseado no Cadastro Nacional de Estabelecimentos de  Saúde. A partir dos dados disponíveis, e com o uso do Google Maps API foram  adicionados os locais de cada estabelecimento no mapa com a diferenciação por cores e  o uso de uma legenda interativa para fazer a busca de um local de saúde com base na  categoria desejada, visando facilitar o acesso e a visualização das informações.   A utilização de dados abertos e informações integradas com outras ferramentas,  como por exemplo, a Google Maps API, facilitam o dia a dia e beneficiam a sociedade e  prestadores de serviço em geral, como nos mostram os resultados das aplicações e  projetos citados ao longo deste trabalho.   Ao acessar o Mapa da Saúde o usuário possuirá as informações com mais  facilidade e clareza, sem que seja necessário o acesso ao site e as diversas tabelas. Bem  como o acesso de apenas uma das localizações por vez. Podendo também visualizar  mais informações e obter todas as categorias que deseja, não só para o atendimento, mas  também para um conhecimento do endereço do local, ou até mesmo a existência de tal  serviço/atendimento na cidade.   Também pretende-se generalizar o aplicativo para todas as cidades do Brasil. O  que exige um tempo maior para a obtenção e organização de cada uma das informações  do site do governo e atualização da base de dados implementada. Bem como as  coordenadas no Google Maps que precisam ser buscadas a partir de cada um dos  endereços que o CNES dispõe.    Para trabalhos futuros citam-se: a adição de novas informações tal como os  equipamentos disponíveis (estrutura), especificidade de atendimento do local, entre  outros, para consulta nos marcadores visando que o usuário tenha mais conhecimento a  respeito do estabelecimento que deseja atendimento.    Acrescentar novos filtros de busca, para que o usuário busque o que deseja com  mais facilidade, como uma categoria de busca por Planos de Saúde, com filtros que  mostrem ao usuário estabelecimentos vinculados ao SUS, a Planos de Saúde  Particulares, etc. Tendo também a possibilidade de explorar ainda mais a ferramenta  Google Maps API e a partir da localização do usuário, para visualizar com mais  facilidade o estabelecimento mais próximo e obter rotas para chegar até o local.    Outra possibilidade é a que o usuário interaja com o mapa, podendo acessá-lo  facilmente através de um cadastro rápido pelas redes sociais como o Facebook, o  Twitter, etc. e possa classificar o atendimento e a estrutura do local. E assim outras  pessoas que desejam consultar aquele local poderão ver as opiniões e estatísticas de  quem os já consultaram.   Referencias    Oliveira, G. (2013), “Política Aberta”, http://www.politicaaberta.org/, acesso em 05 de  agosto de 2015.   Portal Brasileiro dos Dados Abertos, “Aplicativos e Serviços que utilizam Dados  Abertos”, http://dados.gov.br/wp/index.php/aplicativos/#tabs-11, acesso em 05 de  agosto de 2015.   Prettz, J.; Prado, K.; Almeida, L.; Frizon, M.; Murari, M. e Bertolini, C. (2015), “Um  sistema para visualização e monitoramento dos casos de malária no Brasil”, In:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   180        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 173-180 Nov/2015     Computer on the Beach, 2015, Florianópolis – SC, 2015.  http://www6.univali.br/seer/index.php/acotb/article/view/7048   Vitalli, R.; Zacarias, I.; Prediger, D.; Moerschbacher, J. e Bertolini, C. (2015). “Análise  comparativa dos acidentes de trabalho no Brasil a partir de dados abertos”. In:  Computer In the Beach 2015, Florianópolis - SC, 2015.  http://www6.univali.br/seer/index.php/acotb/article/viewFile/7038/3965   Diniz, V. (2010). “Como conseguir dados governamentais abertos”. In: Congresso  Consad de Gestão Pública, III, Brasília, 2010.  https://i3gov.planejamento.gov.br/como_conseguir_dados_governamentais_abertos.p df   Pollock, R. (2007). “Open Data and Componentization at Xtech”,  http://assets.okfn.org/files/talks/xtech_2007/, acesso em 09 de agosto de 2015.   Manual dos Dados Abertos: Governo (2011),  http://www.w3c.br/pub/Materiais/PublicacoesW3C/Manual_Dados_Abertos_WEB.p df, acesso em 09 de agosto de 2015.   Portal Brasileiro dos Dados Abertos (2011), “Aplicativos que utilizam Dados Abertos”,  http://dados.gov.br/wp/index.php/aplicativos/, acesso em 12 de agosto de 2015.   8 Princípios de Dados Governamentais Abertos (2007), “Open Government Data  Principles”, https://public.resource.org/8_principles.html ,acesso em 13 de agosto de  2015.   Câmara dos Deputados (2013) “Educação Para a Democracia, Hackathon”,  http://www2.camara.leg.br/responsabilidade-social/edulegislativa/educacaolegislativa-1/educacao-para-a-democracia-1/hackathon/2013/historico, acesso em 13  de agosto de 2015.   Tribunal de Contas da União, “5 motivos para a abertura de dados na Administração  Pública”, http://portal3.tcu.gov.br/portal/pls/portal/docs/2689107.PDF, acesso em 15  de agosto de 2015.   Cadastro Nacional de Estabelecimentos de Saúde – CNES, http://cnes.datasus.gov.br/,  acesso em 20 de agosto de 2015.   Google Maps API, “Google Code”, http://code.google.com/apis/maps/, acesso em 10 de  setembro de 2015.   Traina, A.; Traina, C.; Botelho, E.; Barione, M. e Bueno, R. (2007). “Visualização de  Dados em Sistemas de Bases de Dados Relacionais”,  http://www.lbd.dcc.ufmg.br/colecoes/sbbd/2001/007.pdf, acesso em  25 de setembro  de 2015.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   220        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     Identificação da História de Compressão em sinais de Áudio  nos Formatos WAV e MP3 utilizando o classificador Máquina   de Vetor de Suporte   Rodrigo Cenachi Araujo¹, Flávia Magalhães Ferreira¹ e Zélia Myriam Peixoto¹   ¹ Programa de Pós Graduação em Engenharia Elétrica - PUC Minas   Belo Horizonte, Minas Gerais, 30535-901, Brasil    rodca1986@gmail.com, {flaviamagfreitas,assiszmp}@pucminas.br  Abstract. Music on the Internet is available on MP3 audio compression format  in high bit-rate. The double compression of MP3, achieved by decompressing  and recompressing audio to a different compression ratio, is a typical  manipulation of audio for malicious purposes. In this context, this research  will approach the evaluation and identification of audio whose quality differs  from the CD standard and evaluation of audio quality without any prior  knowledge of the original audio. To summarize, this work aims to analyze and  improve the existent methods of history compression on WAV and compressed  MP3 format. Additionally, it was possible to achieve a detection rate of 99,9%  on the test compressed versus uncompressed audio.          Resumo. Músicas na Internet são disponibilizadas no formato de compressão  de áudio MP3, em altas taxas de bits. A dupla compressão do MP3, a partir  da descompressão e recompressão do áudio com diferentes taxas, é uma  manipulação típica nos sinais digitais de áudio para propósitos ilícitos. Neste  contexto, este trabalho tratará da avaliação e identificação da qualidade de  áudio não correspondente ao áudio de CD e avaliação da qualidade de áudio  sem nenhum conhecimento prévio do áudio original. Em resumo, o trabalho  visa à análise e melhoria dos métodos já existentes da história de compressão  nos formatos WAV e comprimido MP3. Obteve-se uma taxa de detecção de até  99,9% no teste áudio comprimido versus não comprimido.    1. Introdução   Algoritmos de compressão de áudio geram sinais de áudio com alta fidelidade e taxa de  bits reduzida, para aplicações em armazenamento, transmissão em tempo real pela  internet e radiodifusão [Thiagarajan e Spanias 2011].   Atualmente, há lojas de música online que fazem venda pela Internet.  Frequentemente, essas músicas encontram-se no formato MPEG-1 Audio Layer 3  (MP3), em altas taxas de bits. Nesse caso, o custo de aquisição da música varia de  acordo com a taxa de bits [Yang et. Al 2009] [Liu et. Al 2010].    Nos últimos anos, a pesquisa em multimídia forense começou a considerar  conteúdos de áudio para investigar sua origem e autenticidade. Em particular,  similarmente ao estudo de campo forense de imagem, a análise de artefatos devido à  dupla compressão vem recebendo grande destaque [Bianchi et. Al 2014]. A dupla  compressão do MP3, obtida pela descompressão e recompressão com diferentes taxas  de bits, é uma manipulação típica do áudio para propósitos maliciosos [Qiao et. Al  2013]. Paralelamente, sinais de áudio também são muitas vezes armazenados em     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   221        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     formato WAV, sem nenhum conhecimento de operações de compressão anteriores [Luo  et. Al 2014].   Esta pesquisa baseia-se, fundamentalmente, na estimação da qualidade do áudio,  por meio da identificação da história de compressão do áudio. Em termos mais  específicos, a empregabilidade e importância desse estudo refere-se à identificação de  CDs com qualidade de áudio falsa e avaliação da qualidade do áudio sem nenhum  conhecimento prévio do áudio [Luo et. Al 2014]. Nesse trabalho foi realizado a extração  dos coeficientes MDCT e MFCC no áudio em formato WAV e utilizado o classificador  SVM para a realização dos testes finais. A Seção 2 exemplifica com maiores detalhes  essas técnicas.    2. Referencial teórico   2.1 Compressão de Dados   A compressão de dados é classificada em duas categorias principais: sem perdas  (lossless) e com perdas (lossy). A compressão sem perdas produz a cópia exata do  arquivo original depois de realizada a descompressão enquanto na com perdas o  resultado pode ser praticamente indistinguível do original ou somente audível [Jacaba  2001].   Comprimir imagens e áudio através do formato sem perdas não é tão eficiente,  uma vez que a informação nesse tipo de dados é redundante, o que justifica o emprego  da compressão com perdas. Na aplicação de imagens, tem-se como exemplo o formato  JPEG e, em áudio, a codificação MP3, WMA (Windows Media Audio) e AAC  (Advanced Audio Coding). O formato MP3 é baseado, principalmente, na psicoacústica  que considera o comportamento da percepção do ouvido humano [Jacaba 2001].   2.2  O MP3  Algoritmos MPEG-1/2 envolvem três camadas distintas para a compressão. A camada 1  forma o algoritmo de compressão mais básico (codificação de sub-bandas simples)  enquanto as camadas 2 (banco de filtros com baixo atraso) e 3 (banco de filtros híbrido)  são melhorias que usam alguns elementos da camada 1. Cada sucessiva camada melhora  o desempenho de compressão, mas ao custo de uma complexidade maior do codificador  e decodificador [Britanak 2011].   Essencialmente, a camada 3 do algoritmo MPEG-1/2, conhecido como padrão  MP3, tornou-se a tecnologia chave para realizar a decodificação de áudio para várias  plataformas: distribuição de música pela Internet, players de MP3 portáteis e sistemas  multimídia. [Britanak 2011].   A arquitetura do codificador MP3, opera com frames que consistem de 1152  amostras de áudio. Cada frame é dividido em 2 subframes de 576 amostras, chamados  grãos (granules) [Thiagarajan e Spanias 2011] [Jacaba 2001].   2.3  O Banco de Filtros Híbrido e a MDCT   O banco de filtros inclui segmentação adaptativa (bloco longo ou curto) e consiste de  filtros de sub-banda seguidos pela MDCT (Modified Discrete Cosine Transform). O  banco de filtros e a MDCT realizam a análise tempo-frequência com resolução  adaptativa (dependente da análise psicoacústica humana), consistindo de filtros de 32     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   222        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     canais com largura de banda fixa, seguidos pela MDCT [Thiagarajan e Spanias 2011]  [Jacaba 2001].   A saída do banco de filtros é processada usando a MDCT. Os dados são  segmentados e processados com blocos de sobreposição de 50%. Na camada 3, existem  dois tamanhos possíveis de blocos para a MDCT chamados, bloco curto (12 amostras) e  bloco longo (36 amostras) [Thiagarajan e Spanias 2011] [Britanak 2011].   A MDCT é uma transformada com sobreposição que possui como saídas metade  dos valores referentes ao número de entradas. Ela é baseada na Transformada Discreta  de Cossenos (DCT – Discrete Cosine Transform) tipo IV, com 50% de sobreposição  entre as janelas adjacentes de tempo. Desta forma, a transformada MDCT se estende  através de dois blocos no tempo, eliminando os artefatos entre blocos. Apesar da  sobreposição de 50%, a MDCT é amostrada criticamente e somente M amostras são  geradas a cada 2M amostras do bloco de entrada. Portanto são produzidos 18  componentes de frequência a cada 36 amostras no domínio do tempo, obtendo assim no  formato MP3 um frame com 576 coeficientes de frequência [MDCT/IMDCT 2014]  [Thiagarajan e Spanias 2011] [Jacaba 2001].   É possível observar, na Equação 1, a expressão matemática da MDCT X(k) de  um sinal de entrada x(n), no domínio do tempo, onde h(n) é a resposta ao impulso da  janela (longa ou curta) e M número de sub-bandas.             (1)   Os módulos MDCT empregam blocos curtos (melhor resolução de tempo) para  transientes rápidos e blocos longos (melhor resolução de frequência) para sinais com  variação lenta. Para evitar transições rápidas, janelas intermediárias, longa pra curta e  curta pra longa, são fornecidas pelo padrão [Thiagarajan e Spanias 2011].   Em resumo, para obter os coeficientes MDCT do arquivo WAV a ser analisado  os seguintes passos são realizados:   (1) Divisão em frames de 1152 amostras com 50% de sobreposição.  (2) Para cada frame, as amostras de áudio são separadas em 32 sub-bandas pelo   banco de filtros de análise, adiante a janela MDCT divide cada uma das 32 subbandas em 18 sub-bandas (janela longa) ou 6 sub-bandas (janela curta). Portanto  18 coeficientes podem ser obtidos. É importante destacar que 3 janelas curtas  serão combinadas juntas.   (3) Finalmente, um total de 576 (32x18=576) coeficientes MDCT para cada frame  pode ser obtido.   As operações abordadas anteriormente são exatamente as mesmas no  processamento da compressão MP3 antes da quantização dos coeficientes e da  codificação [MP3Standard]. Na Figura 1, é possível observar exatamente esse ponto de  extração dos coeficientes MDCT.      Figura 1 – Diagrama do esquema de compressão do formato MP3.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   223        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015      A extração desses coeficientes MDCT é utilizado como parte do trabalho que  fará a realização do estudo da história de compressão do arquivo de áudio.   2.4  Mel-Frequency Cepstral Coefficient (MFCC)   O coeficiente cepstral na escala de frequência Mel (MFCC – Mel Frequency Cepstral  Coefficient) é uma DCT de espectro modificado, no qual a frequência e amplitude são  escaladas de forma logarítmica. A distorção de frequência é realizada de acordo com as  bandas críticas da audição humana [Terasawa 2009].    Um banco de filtros de 32 canais, com espaço e largura de banda que assemelha  aproximadamente ao sistema crítico de bandas auditivo faz a distorção da frequência  linear [Terasawa 2009].    Aplica-se ao sinal de áudio, o banco de filtros com resposta em frequência  triangular. Então a energia total em cada canal de frequência, Fi, é integrada para obter a  saída do banco de filtros, no qual i é o número do canal no banco de filtros, Hi(f) é a  resposta do filtro do canal i, e S(f) é o valor absoluto da transformada de Fourier do  sinal. Observa-se esses termos na Equação 2 [Terasawa 2009] [Prahallad 2015].     (2)   O vetor de coeficientes MFCC, denominado Ci na Equação 4, é calculado  tomando a transformada discreta de cossenos (DCT) da saída do banco de filtros na  escala logarítmica, como mostra a Equação 3 [Terasawa 2009] [Prahallad 2015].      (3)       (4)   Para essa pesquisa, o vetor MFCC é utilizado como composição de atributos  para a construção de vetores com informações sobre a história de compressão do  arquivo de áudio. Utilizou-se a biblioteca [VoiceBox] para a extração dos coeficientes  MFCC do arquivo de áudio.   2.5  Aprendizado de Máquina (Machine Learning)  Na área de extração de coeficientes MDCT e MFCC de áudios é comum o uso dos  classificadores Linear Discriminant Analysis, Dynamic Evolving Neural-Fuzzy e  Support Vector Machine (Máquina de Vetor de Suporte). Justifica-se o uso do SVM por  ter opções de kernel bem distintos e flexíveis, ser comumente utilizado e obter precisão  condizente com os melhores classificadores do estado da arte [Ben-Hur et. Al 2010].         O SVM caracteriza-se como uma técnica de classificação binária que realiza a  separação ótima entre duas classes distintas por meio de um hiperplano de separação  [Vapnik 1995]. O algoritmo trabalha com dados linearmente separáveis. No entanto,  existe a possibilidade de adaptação para conjuntos não lineares através das funções  kernel não lineares. Por meio da função kernel RBF (Radial Basis function), é possível  resolver problemas não linearmente separáveis, através da projeção do problema para  um espaço de alta dimensão [Oliveira Junior 2010]. Segundo Hsu et. Al (2010),  usuários do classificador SVM não necessitam conhecer toda a teoria por traz do  algoritmo, mas sim algumas premissas básicas para realizar o procedimento da  classificação.   Neste trabalho utilizou-se para a classificação do áudio, o kernel RBF. No  emprego da classificação em várias classes (multi-class classification) foi utilizado a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   224        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     aproximação one-against-one. A biblioteca SVM de Chang e Lin (2011) foi usada em  todos os modelos de classificações.   3. Trabalhos Relacionados   Em Luo et. Al (2014) é investigado como identificar um arquivo de áudio  descomprimido que foi comprimido anteriormente pelos esquemas de compressão MP3,  WMA e AAC. O artigo Luo et. Al (2014) assemelha-se muito aos objetivos da pesquisa  presente, utiliza-se da técnica de aprendizado de máquina SVM e é um dos trabalhos  mais completos em relação à área de pesquisa. Pode-se enfatizar como diferença que o  presente trabalho está focado nos formatos WAV original e MP3 e possui como  destaque principal fazer a detecção de arquivos MP3 com taxa de bits de valor mais  alto.    Outros trabalhos relacionados são Yang et. Al (2009), Liu et. Al (2010), Bianchi  et. Al (2014) e Qiao et. Al (2013), que fazem a análise do áudio utilizando somente os  coeficientes MDCT e aplicam técnicas estatísticas distintas. O trabalho de Yang et. Al  (2009) utiliza como fator determinante um threshold dos coeficientes MDCT de baixo  valor e não faz uso de classificadores. Em Liu et. Al (2010) é utilizado o valor absoluto  dos coeficientes MDCT em cada banda de frequência e aplicado o SVM. Já em Bianchi  et. Al (2014) é calculado a distância chi-square de histogramas de coeficientes MDCT e  não faz uso de aprendizado de máquina. Em Qiao et. Al (2013) utiliza-se como  parâmetro a distribuição de valores discretos dos coeficientes MDCT e realizado a  comparação dos resultados em dois classificadores: DENFIS (Dynamic Evolving  Neural-Fuzzy) e SVM.   4. Implementação e Validação   A extração dos coeficientes do áudio é realizada nesse trabalho sempre em um áudio em  formato WAV. Na Figura 2, ilustra-se que mesmo para a análise de um arquivo MP3  deve-se descomprimi-lo para o formato WAV.     Figura 2 – Diagrama do método de análise do arquivo de áudio.   Para realizar a extração dos atributos MDCT do arquivo de áudio WAV, foi  utilizado o codificador MP3 LAME [LAME MP3 Encoder] com os parâmetros padrões.    Conforme proposto por Luo et. Al (2014), após obter esses coeficientes o padrão  estatístico especificado na Figura 3 foi realizado. Em resumo foi obtido um frame (576  coeficientes) que representa o valor médio absoluto de todos frames. Esse frame foi  dividido em 24 caixas não sobrepostas e realizado o valor médio de cada pedaço.  Obteve-se assim, (24 = 576 / 24) caixas sendo que as últimas 4 caixas foram descartadas  pois são iguais a zero. Outra informação armazenada foi o valor médio de coeficientes  MDCT iguais a zero por frame.   Para realizar esse trabalho e validá-lo foram coletados 2000 arquivos WAV  aleatórios de CDs de áudio originais. A base de arquivos de áudio criada inclui 53  gêneros musicais diferentes distribuídos igualmente entre si. Os arquivos WAV foram  convertidos para o formato mono e cada arquivo possui tempo total igual a 5 segundos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   225        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     A divisão da base ficou na proporção 50% (1000 arquivos para treinamento e 1000 para  teste).     Figura 3 – Ilustração da extração do padrão estatístico aplicado aos  coeficientes MDCT. Fonte: Adaptado de Luo et. Al (2014).   Após a criação da base foram realizadas as conversões para o formato de áudio  MP3 em estéreo nas taxas de bits (32, 64, 96, 128, 192 e 256 kbps) e realizada a  descompressão para WAV em formato mono.   Para cada arquivo de áudio WAV foi criado um vetor com 75 coeficientes (1 +  20 + 54 = 75). O valor 1, representa o número médio de coeficientes MDCT iguais a  zero por frame. O 20 é representado pelas vinte caixas obtidas no frame de valor médio  absoluto. O valor 54 representa os 18 coeficientes MFCC originais e suas respectivas  primeira e segunda derivadas (18+18+18=54).    5. Resultados Computacionais   Na Figura 4 do lado esquerdo, é possível observar o gráfico boxplot com os resultados  do valor médio de coeficientes MDCT iguais a zero por frame para o arquivo WAV  original e os MP3 comprimidos nas taxas (32, 64, 96, 128, 192 e 256k). Pode-se  perceber, que essa medição ajuda a diferenciar se um arquivo de áudio é um WAV  original sem compressão, ou se sofreu compressão no formato MP3. Uma vez que essa  detecção não é 100% confiável, os demais coeficientes MDCT e MFCC são necessários  para realizar uma classificação com alta precisão.    No lado direito da Figura 4, observa-se o gráfico do vetor MDCT com os  coeficientes de suas 20 caixas para um arquivo de áudio de gênero rock, conforme  mencionado na seção 4. São demonstrados no gráfico os formatos WAV original, e  MP3 32k, 64k e 128k. Essa diferença dos coeficientes MDCT em cada formato, será  uma das bases para o classificador SVM diferenciar cada classe de áudio.    Na tabela 1, obtém-se a porcentagem de detecção obtida na identificação de  arquivos de áudio WAV não comprimidos versus arquivos MP3 descomprimidos em  uma taxa de bits fixa e aleatória. Pode-se observar que as taxas de detecção foram  excelentes, chegando ao valor de até 99,9%.   Tabela 1 – Porcentagem de detecção obtida na identificação de arquivos de  áudio WAV não comprimidos versus arquivos MP3 descomprimidos.     32k 64k 96k 128k 192k 256k Aleatório     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   226        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     MP3 99,9 99,9 99,85 99,85 99,55 99,1 99,65     Figura 4 – Boxplot do valor médio de coeficientes MDCT iguais a zero por  frame e gráfico do vetor MDCT de um arquivo de áudio com suas 20 caixas.    A tabela 2 apresenta em porcentagem como resultado, a matriz de confusão na  identificação do áudio original e do áudio MP3 em diferentes taxas de bits. É possível  observar que em taxas de bits maiores, obtém-se taxas menores de detecção. Justifica-se  essa ocorrência, devido ao fato de que quanto maior a taxa de bits, menor o número de  artefatos e mais difícil fazer detecção dessa classe.   Tabela 2 – Matriz de confusão em porcentagem da identificação do áudio MP3  em diferentes taxas de bits.      Original 32k 64k 96k 128k 192k 256k  Original 98,30 0,00 0,00 0,00 0,10 0,10 1,50   32k 0,00 99,90 0,10 0,00 0,00 0,00 0,00  64k 0,00 0,30 99,30 0,10 0,10 0,00 0,20  96k 0,00 0,10 0,90 94,90 3,80 0,20 0,10   128k 0,00 0,10 0,50 8,40 82,00 7,00 2,00  192k 0,00 0,00 0,30 0,80 8,90 72,40 17,60  256k 0,20 0,10 0,50 0,60 2,10 18,70 77,80   6. Conclusão   Nesse trabalho foi proposta a identificação da história de compressão do arquivo de  áudio em formato WAV, além de potenciais aplicações dessa pesquisa. O método  utilizado, estatísticas dos coeficientes MFCC e MDCT aplicados em um classificador  SVM, é semelhante ao proposto em [Luo et. Al 2014]. As contribuições principais dessa  pesquisa constitui a realização da detecção do áudio MP3 em taxas de bits maiores  (192k e 256k) e a aplicação da técnica em uma base de dados de áudio com gama de  variação maior (53 gêneros musicais).   Pode-se constatar que no teste áudio comprimido versus não comprimido obtémse uma taxa de detecção acima de 99% mesmo para um áudio MP3 comprimido em  altas taxas de bits. No teste da identificação se o áudio pertence à classe original ou em  qual taxa de bits ele foi comprimido, obtém-se taxas de detecção acima de 72,4% em  todos os casos. Como trabalho futuro, deseja-se aplicar ou criar um método de escolha  de coeficientes MDCT e MFCC, que possa selecionar melhor esses coeficientes, a fim  de obter taxas de detecção acima de 90% em todas as taxas de compressão do formato  MP3.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   227        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 220-227 Nov/2015     Referências Bibliográficas  Thiagarajan, J. , Spanias, A. Analysis of the MPEG-1 Layer III (MP3) Algorithm Using   MATLAB, vol.3, pp.1-129 , Morgan & Claypool Publishers, November 2011   Yang, R., Shi Y., and Huang, J. Defeating fake-quality MP3. In Proceedings of the 11th  ACM workshop on Multimedia and security ACM, New York, NY, 2009   Liu, Q., Sung, A., Qiao, M., Detection of Double MP3 Compression, Cognitive  Computation, Dec 2010   Bianchi T., Rosa A., Fontani M., Rocciolo G., and Piva A. Detection and classification  of double compressed MP3 audio tracks. EURASIP, 2014.   Qiao M.; Sung, A.H.; Liu Q., Improved detection of MP3 double compression using  content-independent features, ICSPCC, 2013 IEEE, Aug. 2013   Luo, Da; Luo Weiqi; Yang Rui and Huang Jiwu. Identifying Compression History of  Wave Audio and Its Applications. ACM Trans. Multimedia Comput. 2014   Jacaba, Joebert S., Audio compression using Modified Discrete Cosine Transform: the  MP3 coding standard, Research paper, University of the Philippines Diliman, Oct  2001   Britanak, Vladimir, A survey of efficient MDCT implementations in MP3 audio coding  standard: Retrospective and state-of-the-art, ISSN 0165-1684, April 2011   MDCT/IMDCT- Properties and Applications, Discrete Transforms and their  Applications, Department of Electrical Engineering, the University of Texas, 2014   MP3Standard. Information technology - coding of moving pictures and associated audio  for digital storage media up to about 1.5 mbit/s.   Terasawa Hiroko, A hybrid model for timbre perception: quantitative representations of  sound color and density, a Dissertation submitted to the Department of Music,  Stanford University, December 2009   Prahallad Kishore, Speech Technology: A Practical Introduction Topic: Spectrogram,  Cepstrum and Mel-Frequency Analysis, Carnegie Mellon University & International  Institute of Information Technology Hyderabad, 2015   Voicebox. http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html   Ben-Hur, A., and Weston, J. A user’s guide to support vector machines data mining  techniques for the life sciences. Methods in molecular biology (Clifton, N.J.), 2010   Vapnik, V.N. The Nature of Statistical Learning Theory. 2. ed. New York: SpringerVerlag, 332p, 1995    Oliveira Junior, G. M. Máquinas de Vetores Suporte: Estudo e Análise de Parâmetros  para Otimização de Resultado. Universidade Federal de Pernambuco, 2010.   Hsu, C.W.; Chang, C.C; Lin, C.J. A Practical Guide to Support Vector Classification,  National Taiwan University (Technical report), 2010.   Chang C.-C. and Lin C.-J. LIBSVM: A library for support vector machines.  ACMTrans. Intell. Syst. Technol. 2, 27:1–27:27, 2011.   Lame MP3 Encoder. Disponível em http://sourceforge.net/projects/lame/    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   55        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     Implementação de uma nuvem de armazenamento privada  usando Owncloud e Raspberry PI   Marco Antoni1, Gláucio Ricardo Vivian2, Evandro Preuss1   1Universidade Federal de Santa Maria (UFSM) – Frederico Westphalen   2Instituto Federal Farroupilha – Campus Frederico Westphalen  marco.antoni910@gmail.com,   glaucio.vivian@iffarroupilha.edu.br,evandro@cafw.ufsm.br  Abstract. Cloud computing is somehow still a new concept. Various services  we use every day are no longer on our computer, so this service was  transferred to some cloud of the Internet. There are several types of cloud  services and storage of them. When a user hovers use public cloud services,  the free versions it has limited access to these services as disk space. By  implementing owncloud and create a private cloud storage, the user is  replaced by the full capacity of the hard drive to store your data being an  interesting alternative to backups and access to files from anywhere.   Resumo. A computação em nuvem de certa forma ainda é um conceito  recente. Vários serviços que utilizamos diariamente já não estão mais no  nosso computador, logo esse serviço foi transferido para alguma nuvem da  Internet. Há vários tipos de serviços na nuvem sendo o armazenamento um  deles. Quando um usuário passa utilizar os serviços da nuvem pública, nas  versões gratuitas ele tem acesso limitado a estes serviços como espaço em  disco. Ao implementar o Owncloud e criar uma nuvem privada de  armazenamento, o usuário passa a ter toda a capacidade do disco rígido para  armazenar seus dados sendo uma alternativa interessante para backups e  acesso aos arquivos de qualquer lugar.    1. Introdução   Cloud Computing é uma modalidade de computação recente, que vem se tornando  popular desde meados de 2007. Essa modalidade de computação permite que o usuário  acesse uma grande quantidade de informação e serviços que não estão armazenados  localmente no seu dispositivo. Segundo [Vouk 2010] a Cloud Computing é considerada  o próximo passo na evolução natural dos sistemas computacionais. Para usá-la é preciso  apenas estar conectado a uma rede de comunicação, no caso a Internet, para usufruir de  todos os recursos    Segundo [Taurion 2009], o termo cloud computing surgiu em 2006 durante uma  palestra do Google sobre a forma de gerenciamento dos datacenters da empresa. A  nuvem1 representa a abstração de uma infraestrutura que fica totalmente escondida do  usuário, sendo que o acesso aos serviços da nuvem ocorre através de uma interface  [Andriole and Khorasani 2010].    O principal objetivo é entregar todas as funcionalidades dos serviços que até  então eram inviáveis, reduzindo os custos necessários com a aquisição e manutenção de                                                    1 Nota: A literatura também costuma apresentar o termo “nuvem” como sendo a internet.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   56        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     datacenter: servidores, refrigeramento, link de acesso a Internet, energia entre outros  [Staten 2009]. A partir deste momento, todos os dados do usuário são movidos para a  nuvem eliminando a necessidade de armazenamento e processamento local destes  dados, garantindo assim uma maior mobilidade.     Este artigo apresenta uma implementação de uma nuvem de armazenamento  privada usando Owncloud e Raspberry PI. Na seção 2 são apresentados os modelos de  serviço para Cloud Computing e na seção 3 a classificação das nuvens. A seção 4  destaca a importância e vantagens de se utilizar uma nuvem de armazenamento privada  e na seção 5 o software Owncloud. A seção 6 apresenta a implementação e na seção 7 as  conclusões e trabalhos futuros.   2. Modelos de serviço   A computação em nuvem introduz o conceito de serviços, podendo ser eles:  armazenamento, hardware e software [Andriole and Khorasani 2010]. Outra  característica existente na cloud computing é a demanda, onde o usuário pode adquirir  recursos conforme haja necessidade. Um simples exemplo que está sendo muito  utilizado atualmente são os serviços de armazenamento como Dropox, Drive e  OneDrive onde os arquivos do usuário são salvos em um local que não seja seu  dispositivo[Srinivasan et al. 2015].     É importante salientar que para permitir a aquisição de recursos sob demanda é  necessário que as operações relacionadas com a aquisição do serviço (solicitação e  pagamento) sejam realizadas de maneira automática, permitindo que o usuário tenha  acesso ao recurso da maneira mais rápida possível [Buyya et al. 2010].    Os principais modelos de serviço são Software as a Service, Platform as a  Service e Infrastructure as a Service.   2.1. Software as a Service (Saas)   Da perspectiva do usuário esse modelo de serviço é certamente o mais utilizado pelo  usuário final. Os aplicativos, por serem entregues através da Internet, acabam evitando  que o usuário tenha a tarefa de instalar e fazer atualizações regulares do  aplicativo[Sultan 2010]. Nessa modalidade existem desde os sistemas mais completos,  como os Enterprise Resource Planning (ERP), o NetSuite,  além de soluções pagas do  Google. Em relação ao usuário final, há várias outras alternativas tais como: Office 365  da Microsoft e soluções do Google (Agenda, Gmail, Docs), Netflix, Spotify dentre  outros.   2.2. Platform as a Service (PaaS)    Neste modelo de serviço é fornecido ao usuário (desenvolvedor) a capacidade de  disponibilizar suas aplicações na Internet. Vale lembrar que cada aplicação existente  necessita de um hardware, sistema operacional, banco de dados, middleware e servidor  web. Para que todos esses serviços funcionem sem causar conflitos entre si, é necessário  que haja uma equipe de especialistas nas diversas áreas como o administrador de redes e  DBA que são responsáveis por manter esses serviços funcionando corretamente[Sultan  2010].     Desse modo, o usuário não tem nenhum controle sobre o funcionamento dessa  estrutura. Através dessa camada intermediária, o desenvolvedor tem acesso a um  ambiente onde não há necessidade que ele tenha conhecimentos sobre a instalação e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   57        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     configuração desses serviços permitindo fazer o deploy das aplicações com maior  facilidade. Neste ambiente ele escolhe os serviços que vai utilizar por exemplo: PHP,  Java Server Pages, Pyhton, Mysql, Apache, Nginx, etc[Mell and Grance 2009].   2.3. Infrastructure as a Service (IaaS)    Essa modalidade consiste em oferecer a entrega de uma infraestrutura completa de  hardware[Sultan 2010]. Desse modo o usuário recebe o acesso a uma interface de  gerenciamento onde ele é capaz de criar servidores e escolher o sistema operacional  desejado (com base nos templates existentes). Nesse modelo de serviço o hardware tem  algumas limitações. Por ser uma camada de mais baixo nível, ela provê a estrutura  necessária para as camadas superiores.    Algumas empresas que fornecem esse tipo de serviço são a Amazon, Digital  Ocean, Google Cloud Platform e Microsoft Azure. Uma estrutura desse tipo com  processador de um núcleo, 512 megabytes de memória, armazenamento de 20 gigabytes  e 1 terabyte de transferência tem custo de cinco dólares mensais na Digital Ocean.  Ainda é possível contratar o serviço por hora de uso, neste caso o mesmo plano custaria  0,007 centavos de dólar por hora [Digital Ocean 2015].     Para compreender melhor estes conceitos, pode-se classificar o papel do usuário  (ator) de acordo com o serviço por ele utilizado. A Figura 1 destaca esses papéis, onde o  provedor é o responsável por implantar, gerenciar e monitorar toda a estrutura da  nuvem, fornecendo os três tipos de serviços. O desenvolvedor utiliza os serviços de IaaS  e PaaS, sendo que o PaaS é usado para fornecer o SaaS ao usuário final. A interação  entre os serviços pode ser descrita da seguinte forma: IaaS fornece os recursos  computacionais para o PaaS, que por sua vez fornece tecnologias e ferramentas para as  aplicações (SaaS).      Figura 1: Papeis na computação em nuvem   3. Classificação das nuvens    Todos os modelos de serviços citados acima estão dentro de alguma das  milhares de redes existentes no mundo.  Embora o objetivo da cloud computing seja  prover o acesso a recursos, a classificação das nuvens refere-se a quem tem o controle e  gerenciamento delas. Uma nuvem pode ser:     a) Pública: A infraestrutura existente pertence alguma organização que tem o objetivo  de fornecer acesso aos usuários não sendo necessários que estes façam parte dessa     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   58        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     organização. Geralmente os clientes tem limitações nos recursos que podem ser usados  sendo necessário pagar para obter acesso completo desses recursos [Mell and Grance  2009] [Marston et al. 2011]. A maior desvantagem existente é a distância do usuário  limitando a velocidade de acesso ao seu plano de acesso a Internet.   b) Privada: A infraestrutura existente é propriedade da organização ou usuário em  questão. É importante ressaltar que o número de usuários que acessam essa nuvem é  limitado, estando restrita aos membros da organização ou um pequeno grupo de  usuários quando essa nuvem for residencial [Mell and Grance 2009] [Marston et al.  2011]. Por ser de propriedade privada, o dono decide como o gerenciamento vai ser  feito, podendo até mesmo aplicar um maior grau de confidencialidade no  armazenamento das informações.    c) Híbrida: Como o próprio nome sugere, é uma combinação da nuvem pública e  privada. Neste caso as informações não críticas são armazenadas na nuvem pública  enquanto as informações confidenciais ficam na rede privada [Mell and Grance 2009]  [Marston et al. 2011]. As nuvens híbridas também podem ser consideradas uma forma  de backup para os clientes.   4. Owncloud   O Owncloud é uma aplicação web escrita usando a linguagem PHP. Sua primeira versão  foi lançada em 2012 com o propósito de fazer sincronização de arquivos entre vários  dispositivos. Tal característica é útil quando se quer compartilhar arquivos com outros  usuários e/ou até mesmo fazer backups dos dados. As principais vantagens de se utilizar  essa ferramenta são: gratuita e código fonte é open source, permitindo que o usuário  altere o código conforme sua necessidade e possibilita a criação de uma nuvem de  armazenamento privada sendo uma alternativa as nuvens públicas[Owncloud 2015].     Ele é dividido em duas partes: i) Cliente: é a parte responsável por decidir  quando os dados devem ser enviados e fazer o download dos arquivos atualizados do  servidor. O cliente está disponível para as versões desktop (Linux, Mac e Windows) e  mobile (Android, BlackBerry e IOS). Ainda é possível acessar os arquivos diretamente  do browser através de uma interface web. ii) Servidor: é o ponto de armazenamento  centralizado dos dados sendo responsável por enviar os novos arquivos para todos os  clientes relacionados aquela conta de usuário. Por ser uma aplicação escrita em PHP, é  necessário ter o interpretador PHP instalado no servidor. Além disso é necessário ter um  gerenciador de banco de dados para armazenamento dos metadados dos arquivos  (atualmente) e um servidor web onde a instância do Owncloud estará disponível.     A escalabilidade do Owncloud é um fator relevante quando se fala em  computação na nuvem. Há relatos de organizações que usam o Owncloud que chegam a  atender 500 mil usuários e trabalham com vários terabytes de dados [Owncloud 2015],  porém para atingir essa escalabilidade são necessárias configurações adicionais que não  estão definidas na instalação padrão.   5. Motivação e problemas   A utilização de uma nuvem privada, pública ou híbrida, depende de qual seja a  necessidade da organização em questão. Atualmente, apesar de existirem milhares de  nuvens para armazenamento de dados, elas tem um espaço de armazenamento limitado  (Dropox 2GB, Google Drive 15 GB), sendo esse espaço muito menor que um disco  rígido [Hildmann and Kao 2014]. Além disso, muitas vezes é preciso contar com uma     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   59        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     boa conexão com a Internet. Quando se fala no armazenamento de dados de instituições  públicas, como é o caso dos governos e universidades que trabalham com dados  sigilosos, o problema é ainda maior, pois desde abril de 2014 existe a Lei 12.965 que  impede que esses dados sejam armazenados fora do país, impedindo que sejam usados  serviços como Dropbox, Google, Microsoft, etc.     [Siqueira 2010] afirma que a implantação de uma nuvem privada é destinada a  organizações ou até para usuários domésticos, pois permitem compartilhar dados  através de uma rede local ou Internet e permite que o administrador aplique as técnicas  de criptografia, visando garantir a maior confidencialidade dos dados. A capacidade de  armazenamento é maior, pois a limitação é o disco rígido do servidor. Devido ao  servidor estar mais próximo do usuário, a tendência é que a velocidade de acesso seja  maior, pois muitas vezes o usuário vai acessar os serviços através da mesma rede em  que o servidor está.     Quando se pensa em soluções domésticas ou de pequeno porte de  armazenamento, estamos nos referindo a dispositivos conhecidos por Network Attached  Storage (NAS). Uma solução de armazenamento dessas custa a partir de 600 reais sem  os discos rígidos, todavia é possível criar um dispositivo de armazenamento de menor  custo usando um hardware de menor capacidade como o Raspberry PI, que é um  pequeno computador que mede aproximadamente 9 x 6 x 2 cm. Apesar do tamanho  reduzido, ele vem equipado com 1 GB de memória RAM, processador ARMv7 quadcore de 900 Mhz, armazenamento de 16 GB (cartão micro SD), suas expansões se dão  através das quatro portas USB, uma porta ethernet e uma HDMI [Raspberry 2015].     Os principais motivos que levaram a escolha desse hardware é o baixo consumo  de energia sendo um fator relevante pois o servidor sempre vai estar ligado além das  suas dimensões reduzidas que permite que ele seja guardado em qualquer lugar.   6. Experimentos e Testes    O sistema operacional usado no Raspberry PI foi o Ubuntu 14.04 compilado  para processadores ARM. As dependências para a instalação do Owncloud são: i)  Servidor web, neste caso foi usado o software Ngnix, devido a ele ser um dos que  apresenta melhor desempenho na atualidade. ii) Interpretador PHP e as bibliotecas  cURL e GD. iii) Banco de dados, foi usado o MySQL devido a ele ser um dos SGBDs  mais atualizados atualmente e pela sua escalabilidade.    Ao usar o servidor web Apache, a instalação ocorre sem nenhum problema, mas  ao usar o Nginx são necessárias algumas configurações adicionais para o diretório do  Ownclod. Essas configurações são feitas através da criação de um alias apontando para  os arquivos do Owncloud. A Figura 2 traz as configurações usadas nessa  implementação.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   60        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015       Figure 2: Alias do Owncloud no Nginx       Antes iniciar a instalação é necessário ter uma base de dados e um usuário  definidos que será usado pelo Owncloud. A instalação ocorre através de um assistente  web disponível no primeiro acesso sendo necessário apenas completar as informações  (parâmetros da conexão com o banco de dados e definição da senha de administrador).  A Figura 3 mostra a interface web e a Figura 4 mostra o cliente do servidor do  Owncloud já em produção.        Figure 3: Servidor Owncloud em produção - acesso via web        Figura 4: Cliente do Owncloud em funcionamento        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   61        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015      O objetivo dessa implementação foi criar uma nuvem de pequeno porte sendo  destinada a um pequeno número de usuários com baixo custo financeiro, por isso  hardware utilizado tem capacidade reduzida sendo o único gasto da implementação uma  vez que todos os softwares usados são gratuitos.     Ao usar um servidor NAS em uma versão “acessível” ao usuário doméstico da  D-Link o processador é dual-core de 1 Ghz com apenas 256 MB de memória RAM e  128 MB de armazenamento custando em torno de 600 reais. Em grandes organizações o  hardware usado é de capacidade superior e são usadas outras técnicas como o RAID  para garantir que não ocorram perda dos dados em caso de falhas no disco rígido ou  para que haja melhora no desempenho.     Nessa solução não foi usado nenhuma técnica contra a prevenção de perda dos  dados em caso de falhas no disco rígido, do mesmo modo em que uma solução NAS  não conta com RAID por padrão. Em ambos os casos é necessário comprar mais discos.  A segurança contra a perda dos dados do usuário é que o Owncloud é ele ser uma  ferramenta de sincronização, ou seja, esses dados sempre estarão armazenados em mais  de um dispositivo na rede. Na figura 5 pode-se visualizar o gráfico do uso da CPU no  Raspberry PI durante a sincronização de alguns arquivos entre três dispositivos. Durante  esse tempo, o computador A enviou um arquivo de 3 GB e o computador B baixou  todos os arquivos do servidor totalizando 5 GB de download e o celular C enviou 10  MB de imagens. Esses gráficos foram gerados através da ferramenta Cacti que usa as  informações coletadas através do Simple Network Management Protocol (SNMP) sendo  que os gráficos são atualizados a cada cinco minutos.        Figura 5: Gráfico de uso de CPU do Raspbery PI   7. Resultados e Trabalhos Futuros   Conforme a revisão bibliográfica indica, a cloud computing é uma tendência crescente  no mundo atual, sendo necessário que os usuários se adaptem a essa nova modalidade  de serviço. Os serviços de nuvem pública fornecem recursos limitados ao usuário sendo  necessário que se pague para obter maior capacidade. A principal limitação desses  serviços são os recursos limitados nas versões gratuitas e a distância entre o cliente e  datacenter, sendo necessário ter uma grande largura de banda nos serviços de  armazenamento.      Atualmente existe uma gama muito grande de softwares livres. Graças a essas  soluções é possível realizar a implementação de uma nuvem de armazenamento com  Owncloud, Nginx e MySQL. A combinação dessas ferramentas com o uso do Raspberry  PI mostrou-se uma excelente alternativa na construção de uma nuvem privada de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   62        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 55-62 Nov/2015     pequeno porte sendo uma excelente alternativa em relação as soluções de  armazenamento de storage proprietárias, muitas vezes tendo até um desempenho  superior.   Referências   Andriole, Katherine P., and Ramin Khorasani. "Cloud computing: What is it and could  it be useful?" Journal of the American College of Radiology 7.4 (2010): 252-254.   A Vouk, Mladen. "Cloud computing–issues, research and implementations." CIT.  Journal of Computing and Information Technology 16.4 (2008): 235-246.   Buyya, Rajkumar, James Broberg, and Andrzej M. Goscinski, eds. Cloud computing:  principles and paradigms. Vol. 87. John Wiley & Sons, 2010.   de Siqueira, Mozart Lemos, Emerson Oliveira Machado, and Centro Universitário  Lasalle. "Levantamento sobre Computação em Nuvens." 2010.   DigitalOcean. Simple Pricing: All plans are standard with solid state drives (SSD).  Disponível em: https://www.digitalocean.com/pricing/. Acesso em: 20 ago 2015.   Hildmann, Thomas, and Odej Kao. "Deploying and extending on-premise cloud storage  based on ownCloud." Distributed Computing Systems Workshops (ICDCSW), 2014  IEEE 34th International Conference on. IEEE, 2014.   Marston, Sean, et al. "Cloud computing—The business perspective." Decision Support  Systems 51.1 (2011): 176-189.   Mell, Peter, and Tim Grance. "The NIST definition of cloud computing." National  Institute of Standards and Technology 53.6 (2009): 50.   Owncloud. Access your data from all your devices, on an open platform you can extend  and modify. Disponível em: https://owncloud.org/. Acesso 22 ago 2015.   RaspberryPI. FAQS. Disponível em: https://www.raspberrypi.org/help/faqs/. Acesso 23  ago 2015.   Srinivasan, Aishwarya, Md Abdul Quadir, and V. Vijayakumar. "Era of Cloud  Computing: A New Insight to Hybrid Cloud." Procedia Computer Science 50 (2015):  42-51.   Staten, James. "Hollow out the moose: reducing cost with strategic rightsourcing."  Forrester Research, Inc 209 (2009).   Sultan, Nabil. "Cloud computing for education: A new dawn?" International Journal of  Information Management 30.2 (2010): 109-116.   Taurion, Cezar. "Cloud Computing: Computação em Nuvem: Transformando o mundo  da tecnologia da informação." Rio de Janeiro: Brasport 2.2 (2009): 2-2.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   63        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     LogicBlocks: Uma Ferramenta para o Ensino de Lógica de  Programação   Rogério Paulo Marcon Júnior, Bruno Batista Boniati   Graduação Tecnológica em Sistemas para Internet. Universidade Federal de Santa  Maria   Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS – Brasil  {rogeriom49,brunoboniati}@gmail.com   Abstract. It is not today that the programming logic teaching in various  computer courses is considered challenging for the teacher as well as a  barrier for students. The increased demand for technology professionals,  particularly in the areas of computer programming has attracted students to  computer courses, however, the need for understanding abstract concepts and  the difficulty of putting them into practice using conventional teaching  techniques are considered some of the high evasion of the reasons for such  courses. It is understood that the programming teaching requires  differentiated teaching methodologies in an attempt to break down learning  barriers imposed by the difficulty of retaining the concentration and develop  logical thinking in students. In order to try to create differential and attractive  to enhance student learning, educators are turning to alternative methods in  the classroom, especially the use of games and / or simulators that allow  realized through challenges, different situations found in programming area..   Resumo. Não é de hoje que o ensino de lógica de programação nos diferentes  cursos de computação é considerado desafiante para o professor bem como  uma barreira para os alunos. A falta de profissionais na área de software é  bastante evidente e ainda assim os cursos de tecnologia em geral enfrentam  altos índices de evasão. Entende-se que o ensino de programação requer  metodologias e ferramentas diferenciadas na tentativa de quebrar as  barreiras de aprendizado impostas pela dificuldade de reter a concentração e  desenvolver o raciocínio lógico nos alunos. De forma a tentar criar  diferenciais e atrativos para potencializar a aprendizagem dos alunos, os  educadores estão aderindo a metodologias alternativas dentro de sala de  aula, em especial a utilização de jogos e/ou simuladores que possibilitam  concretizar por meio de desafios, diversas situações encontradas na área de  programação. Este trabalho apresenta a ferramenta LogicBlocks, um website  desenvolvido para propor e resolver desafios de lógica de programação  através de blocos lógicos de encaixe utilizando a API Blockly.   1. Introdução   O aumento da demanda de profissionais de tecnologia, em especial nas áreas de  programação de computadores tem atraído cada vez mais alunos para cursos de  computação/informática no Brasil (Brasil, 2013). Da mesma forma, tem-se observado  altas taxas de evasão nos referidos cursos no mesmo período (Giraffa; Mora, 2013).  Diante deste cenário, evidencia-se que o ensino de programação requer metodologias  diferenciadas, especialmente no diz respeito ao desenvolvimento do raciocínio lógico,  tão importante para a organização do pensamento. Cada vez mais se percebe a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   64        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     necessidade de adoção de métodos de ensino diferenciados, que possam quebrar  algumas barreiras de aprendizado e que possam atrair/reter a atenção e concentração dos  alunos.     A motivação inicial deste trabalho é de desenvolver uma ferramenta que  possibilite a adoção de um método diferenciado para auxílio ao aprendizado de lógica  de programação e que seja baseado em web, podendo ser acessado em diferentes  plataformas. Além disso, o trabalho busca inspiração no projeto de pesquisa intitulado  “O uso de dinâmicas de grupo como instrumento de aprendizagem experimental em  cursos da área de computação”, desenvolvido pelo curso de Tecnologia em Sistemas  para Internet da UFSM em 2014 e que objetivava encontrar e catalogar metodologias  diferenciadas que são utilizadas por professores de computação dentro de suas aulas  (Petri; Marcon, 2014). Por meio deste projeto foi possível observar que metodologias  alternativas vêm sendo utilizadas com frequência dentro de ambientes acadêmicos e se  compartilhadas podem potencializar o aprendizado.    A partir de então, buscou-se desenvolver uma ferramenta web intuitiva de acesso  facilitado que pudesse atrair o aprendiz de programação e que tivesse potencial de ser  utilizada dentro de ambientes acadêmicos de cursos de computação (de diferentes  níveis). A ferramenta deve permitir aos professores criarem seus próprios exercícios da  forma que considerarem mais adequados e apresentar uma área de desenvolvimento  para que alunos possam praticar a lógica por trás da programação utilizando-se de  blocos de encaixe ao invés de código. Entende-se que a utilização dos blocos pode  diminuir duas barreiras: os erros de sintaxe que por vezes desestimulam o aluno  aprendiz e também a necessidade codificação, que inexiste com a utilização de blocos  lógicos, habilitando a ferramenta para ser utilizada em dispositivos móveis, tão comuns  hoje em dia.    Este trabalho é resultado dos estudos de um Trabalho de Conclusão de Curso  (Marcon; Boniati, 2015) e está organizado da seguinte forma: a seção 2 apresenta  algumas reflexões acerca do ensino de programação bem como algumas ferramentas  que podem ser utilizadas para este fim. Na seção 3 são apresentados alguns trabalhos  relacionados a essa temática. As seções 4 e 5 apresentam respectivamente a API  Blockly e o desenvolvimento da ferramenta LogicBlocks. Ao final são apresentados  alguns resultados obtidos até então.   2. O Ensino de Programação   O ensino de programação é considerado por muitos como um dos pilares que sustentam  a base do conhecimento dos cursos de computação. Sendo também considerado como  um dos componentes curriculares mais importantes oferecidos pelos mesmos (Pereira  Jr. et al., 2005). Devido a ser um tópico de grande importância dentro dos cursos de  computação, alguns pesquisadores, professores e alunos dedicam seus tempos e  pesquisas tentando desenvolver metodologias para potencializar e melhorar a forma de  ensinar programação e assuntos afins, como por exemplo: lógica, algoritmos e  linguagem de programação.   2.1. O Método Tradicional e as Metodologias Alternativas   O método tradicional da programação, que já se perpetua há bastante tempo, se constitui  em um exemplo inicial do desenvolvimento de um algoritmo que escreva na tela “Hello  World” e que a partir deste primeiro contato vai desafiando os alunos a buscarem “o que  mais posso fazer além de escrever na tela”. Exercícios matemáticos também são muito     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   65        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     utilizados no início do aprendizado de programação, tais exercícios se utilizam  informações que são digitadas pelo usuário (entradas) e que a partir destas utilizam-se  de algum processamento para produzir valores que são mostrados na tela (saídas).  Fontes e Da Silva (2008) alertam que este tipo de exercício torna-se ineficiente pelo fato  de não estimularem a pratica das habilidades cognitivas, ou seja, que se utilize de  constatações e percepções do aluno na tentativa de construir o conhecimento.    O ensino tradicional de computação evidencia duas situações: estudantes  habituados a serem indivíduos passivos dentro do ambiente escolar e  estudantes/professores limitados pela situação geográfica e tempo. Tem se observado  também uma forte dependência do aluno em relação ao professor/facilitador no sentido  de lhe indicar os motivos para seu código não estar funcionado (em geral os problemas  referem-se à questões sintáticas de uso de linguagens de programação).     É preciso emancipar o aluno de forma que o mesmo possa “aprender a aprender”  e validar suas próprias invenções (Wang; Prado, 2015). Neste sentido, entende-se que é  necessário o desenvolvimento de metodologias alternativas que estimulem o  aprendizado de programação e desenvolvam habilidades cognitivas de forma natural. A  seguir serão apresentadas algumas delas.  2.2. Ferramentas e Iniciativas para o Ensino de Programação   Nesta seção serão citadas ferramentas e iniciativas desenvolvidas por pesquisadores e  grandes empresas com o intuito de auxiliarem novos integrantes dos cursos de  computação a praticarem sua lógica e estimular o interesse pela programação.  2.2.1. APP Inventor   MIT APP Inventor é uma aplicação destinada ao desenvolvimento de aplicativos para  smartphones que não faz a utilização de programação tradicional, como substituição, faz  o uso de programação baseada em blocos. Sendo assim, permite que novos  programadores realizem o desenvolvimento de aplicações apenas fazendo uso de sua  lógica. Teve como participantes o professor Hal Albelson do MIT e alguns engenheiros  do Google. Objetiva a criação de uma ferramenta open source que torne a criação de  aplicativos acessível e que possa atingir um grande número de usuários (APP Inventor,  2015).    A ferramenta é composta por duas partes: a parte de Design, responsável pela  criação do layout da aplicação através do método de drag and drop, ou seja, arrastar  componentes de um menu para uma área (canvas) de design. A outra parte é  responsável pela inclusão das ações representadas por blocos, nesta parte o  desenvolvedor efetuará a inclusão da lógica do aplicativo em desenvolvimento através  de inserção de blocos de encaixe os quais possuem uma funcionalidade pré-definida.  2.2.2. Blockly Games   Blockly games é um conjunto de jogos desenvolvidos utilizando a API Blockly com o  propósito de incentivar e auxiliar usuários interessados em exercitar sua lógica, podendo  ser encontrado na Blockly Games2. É especialmente desenvolvido para introduzir  crianças ao mundo da programação e constitui-se com o um conjunto de desafios que  estimulam o raciocínio e o pensamento lógico/matemático.     Dentro deste conjunto de jogos, pode-se destacar o jogo Turtle, o qual tem como  função introduzir estruturas de repetição aos novos programadores através da habilidade                                                    2 https://blockly-games.appspot.com/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   66        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     de desenhar formas geométricas utilizando os blocos que representam ações que serão  efetuadas pelos personagens disponíveis. A ferramenta é composta por uma área  responsável pela apresentação do personagem que fará o desenho das formas  geométricas através de comandos gerados pelo usuário. Em outra área encontram-se os  blocos que representam as instruções a serem dadas para o personagem.  2.2.3. Hour of Code   Hour of Code é uma ferramenta criada pelo site Code.org, com o intuito de incentivar o  ensino de programação dentro de ambientes de ensino básico. Para que isso seja  possível, a aplicação apresenta diferentes tipos de jogos baseados em lógica e blocos,  tendo como forma de chamar a atenção, a utilização de personagens infantis conhecidos  como participantes dos problemas a serem resolvidos (Hour Of Code, 2015). Assim  como as demais ferramentas, os jogos propostos pela ferramenta Hour of Code utilizase de uma área responsável pela apresentação do comportamento que o código criado  produz e outra onde a logica é desenvolvida utilizando-se os blocos de encaixe.   3. Blockly API   Blockly é framework baseado em tecnologias Web e desenvolvido pelo Google. Tal  ferramenta permite a utilização de um editor visual para que o usuário/programador  especifique sua lógica de programação por meio da conexão de blocos e ao final consiga  simular a execução de seu programa (Blockly API, 2015). O framework também  permite que desenvolvedores integrem o editor nas interfaces de suas aplicações web  para criar novas ferramentas.    A partir da conexão dos blocos de encaixe com funcionalidades pré-definidas, o usuário  pode escrever um pequeno roteiro de um programa e posteriormente executá-lo ou  transformá-lo no respectivo código (atualmente são suportadas as linguagens de  programação PHP, Python, Dart e JavaScript). Com o Blockly é mais difícil cometer um  erro de sintaxe ou mesmo ambiguidades devido ao uso inadequado de parênteses.  Adicionalmente, pessoas que nunca tiveram contato com programação podem achar  uma tela branca com um cursor piscando amedrontadora, porém utilizando Blockly elas  podem navegar por menus e ir conectando blocos de forma intuitiva e experimentar a  partir de exemplos como as coisas funcionam.   4. Trabalhos Relacionados   Nesta seção será apresentado uma revisão de literatura contendo trabalhos  desenvolvidos que tem o intuito de apresentar um método que possa auxiliar integrantes  dos cursos de computação a exercitarem a sua lógica.  4.1. Desenvolvimento de um Plugin para o Moodle Voltado ao Ensino de Programação  Utilizando a API Davit   Desenvolvido como trabalho de graduação pela aluna Karina Wierchok da UFSM, este  trabalho tem como propósito desenvolver um plugin para a plataforma de e-lerning  Moodle que auxilie no aprendizado de programação utilizando-se de um pseudo-código  (baseado em JavaScript) e um conjunto de desafios em formato de labirinto (o  personagem precisa coletar itens em mundo virtual utilizando-se de comandos simples).    Utilizando tecnologias web, o propósito do trabalho é desenvolver uma  ferramenta que possa ser utilizada em qualquer ambiente fazendo o uso da API Davit.  Através do uso desta API, o aluno pode programar as ações do personagem utilizando  os comandos disponibilizados pela mesma. Possui também o objetivo de apresentar uma     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   67        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     nova ferramenta aos professores, dando assim a capacidade da criação de atividades de  uma maneira própria [Wierchok; Boniati, 2014].  4.2. MOJO: Uma Ferramenta para Integrar Juízes Online ao Moodle no Apoio ao  Ensino e Aprendizagem de Programação   Desenvolvido pelos integrantes do PPgCC da UERN, é uma ferramenta de auxílio ao  aprendizado de programação que possui integração com o ambiente Moodle com o  propósito de automatizar a elaboração, submissão e correção de atividades de  programação utilizando Juízes Online, que são sistemas responsáveis por receber  códigos enviados por um indivíduo e efetuar a correção e execução do mesmo.    A ferramenta disponibiliza uma lista com diversas questões organizadas aos  professores que desejarem utilizá-la apresentando todos os dados importantes que são  contidos na questão. Já na visão do aluno, a ferramenta apresentará no Moodle se há  alguma questão disponível, se houver, o aluno realizará a codificação das instruções e  enviará para a correção. A questão enviada será passada para os Juizes Online, que se  encarregam de efetuar a correção e retorná-la ao aluno (Chaves et al., 2015).   5. LogicBlocks   Após um período de pesquisas e testes, desenvolveu-se uma ferramenta baseada na API  Blockly o qual foi chamada LogicBlocks3. Tal ferramenta tem como intuito auxiliar  integrantes dos cursos de computação a praticarem a sua lógica para programação  através da prática de exercícios e desafios de lógica.    A ferramenta funciona através de um sistema de cadastro, ou seja, os estudantes  ou professores que optarem poderão criar um login dentro do sistema para acessarem as  áreas restritas. Dentro destas áreas, por parte do estudante, pode-se encontrar uma seção  destinada a listagem de exercícios previamente cadastrados por diferentes professores.  Também se pode utilizar uma funcionalidade de busca para encontrar exercícios mais  específicos.    Já na área destinada ao professor pode-se encontrar uma seção destinada ao  cadastro de novos exercícios. Para ser cadastrado um exercício precisa ter um título,  enunciado e uma categoria (sequencial, decisão, repetição, etc.). O professor também  pode visualizar todos os exercícios já cadastrados por ele mesmo, tendo a capacidade de  editá-lo ou excluí-los no momento que desejar.    Na figura 1 pode-se identificar a área disponibilizada pela ferramenta para o  desenvolvimento da lógica do exercício escolhido pelo usuário. Dentro desta área  podemos identificar o título do exercício, o enunciado contendo as instruções, um menu  à esquerda contendo todos os blocos utilizáveis dentro da ferramenta. Dentro da  imagem pode-se identificar também a área que será responsável pela apresentação do  código gerado e execução do mesmo.                                                     3 http://inf.fw.iffarroupilha.edu.br/logicblocks/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   68        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015       Figura 1. Área de desenvolvimento do algoritmo e apresentação de código   6. Resultados   Após a fase de desenvolvimento, o sistema foi testado junto aos alunos do Curso  Técnico em Informática (integrado ao ensino médio) e também do Curso de Graduação  Tecnológica em Sistema para Internet, ambos do Instituto Federal Farroupilha, campus  Frederico Westphalen. Nos dois casos os estudantes eram calouros e estavam fazendo  seu primeiro contato com a programação.    Como forma de teste, os alunos participantes foram instruídos a resolverem  alguns problemas cadastrados dentro do sistema pelo professor regente e enviar os  resultados obtidos como atividade avaliativa. Inicialmente os alunos foram apresentados  à ferramenta e lhes foram disponibilizados dois desafios4 já resolvidos. Posteriormente  lhes foram apresentados dois novos desafios: “Área do Trapézio” e “Peso Ideal”. No  primeiro caso, trata-se de um exercício sequencial de linearização de uma expressão  aritmética, 22 alunos do Curso Técnico Integrado e 15 alunos do Curso de Graduação  realizaram a entrega. No segundo caso tem-se um algoritmo que envolve também uma  estrutura de decisão, foram registradas 16 entregas no Curso Técnico e 11 entregas no  Curso de Graduação. Os testes foram realizados no período de 8 a 21 de julho de 2015 e  contou com o cadastro de 62 alunos no sistema. Ressalta-se também que a ferramenta  permite a utilização como visitante, sem limitação de funcionalidades, apenas  restringindo a busca por exercícios.    Ao final do experimento, os alunos foram convidados a realizar uma avaliação  acerca da ferramenta. Para este questionário utilizou-se um documento da plataforma  Google Docs contendo 7 perguntas sem identificação do participante. Ao todo, 35  pessoas sentiram-se motivadas a participar. A análise dos dados aponta que 74% dos  usuários participantes são iniciantes dentro dos cursos, sendo que 60% são do ensino  médio. Ao final, 62% dos alunos que participaram dos testes apontaram que  conseguiram compreender a ferramenta de forma intuitiva e 62% disseram que ainda  não conheciam a API Blockly. Ao serem questionados se a utilização de uma  ferramenta gráfica potencializaria seu aprendizado, 93% dos alunos concordaram.  Quando questionados sobre qual o fator decisivo para favorecer o aprendizado de  programação, 64% dos participantes identificou que a prática de programação é o item                                                   4 http://inf.fw.iffarroupilha.edu.br/logicblocks/desafio/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   69        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     mais importante, destaca-se também que 9% consideram a escolha de linguagem de  programação adequada e o uso de uma ferramenta de simulação e 18% apontam que o  incentivo do professor é o item mais favorável ao aprendizado de programação.   7. Conclusões   Por meio deste trabalho objetivou-se apresentar uma iniciativa baseada em web para  habilitar o uso de metodologias diferenciadas no ensino de lógica de programação. Para  tal, utilizou-se da API Blockly o qual se mostrou uma poderosa ferramenta para  desenvolvimento de aplicações que possam auxiliar o ensino de lógica de programação.  Foram identificadas duas vantagens importantes com o uso de tal API: a eliminação dos  erros de sintaxe (que habilitam o aprendiz de programação a se preocupar apenas com a  lógica do programa) e a utilização de blocos gráficos, os quais representam o  comportamento das instruções da linguagem de programação e que facilitam a  compreensão inicial do comportamento dos programas de computador (que é tão  abstrato em um primeiro contato)    Tomando como base pesquisas realizadas durante o período de desenvolvimento  e escrita deste texto, pode-se identificar que o ensino de programação dentro das  universidades é de fato um problema a ser resolvido. Constatou-se uma grande  variedade de trabalhos e iniciativas que tentam desenvolver ferramentas ou  metodologias que possam tornar o ensino/aprendizado de programação menos difícil e  mais atrativo.    Utilizando como base o período de experimentação e validação da ferramenta  apresentada, podemos identificar um feedback positivo por base dos participantes,  podendo assim identificar o quão útil pode ser a ferramenta que estimule e auxilie  acadêmicos dos cursos de computação a praticarem sua lógica de uma maneira  alternativa sem medo de cometer “erros”. Também pode-se identificar algumas falhas  nas explicações apresentadas na ferramenta que deverão ser corrigidas futuramente para  melhor entendimento da mesma. São trabalhos futuros a integração de tal ferramenta  junto a um sistema de e-learning (ex. Moodle) bem como o desenvolvimento de  funcionalidades que permitam salvar e recuperar a resolução do exercício e a validação  de seu funcionamento a partir de um conjunto de entradas e saídas pré-definidas e  validadas.   Referências   APP Inventor (2015) “MIT App Inventor”, http://appinventor.mit.edu/, Junho/2015.   Blockly API (2015) “Blockly - Library for Building Visual Programming Editors”,   https://developers.google.com/blockly/, Junho/2015.   Brasil (2013) “Rel. Téc. Contendo Estudo Sobre a Atual Relação Oferta/Demanda de  Cursos de Graduação no Brasil”, Ministério da Educação, Brasília/DF.   Chaves, J. O. M.; et al. (2015) “MOJO: Uma Ferramenta para Integrar Juízes Online ao  Moodle no Apoio ao Ensino e Aprendizagem de Programação”. Holos (Online), v. 5,  p. 246-251, Natal/RN.    Fontes, C. R.; Da Silva F. W. O (2008) “O Ensino da Disciplina Linguagem de  Programação em Escolas Técnicas”. Ciências & Cognição (UFRJ), v. 13, p. 84-98.   Giraffa, L. M. M.; Mora, M. C. (2013) “Evasão na Disciplina de Algoritmo e  Programação: Um Estudo a Partir dos Fatores Intervenientes na Perspectiva do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   70        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 63-70 Nov/2015     Aluno”. Tercera Conferencia sobre el Abandono en la Educación Superior (III  CLABES), México.   Hour Of Code (2015) “Join the largest learning event in history”,  http://hourofcode.com/pt/, Junho/2015.   Marcon, R. P.; Boniati, B. (2015) “Logicblocks – Uma Ferramenta de Auxílio ao  Aprendizado de programação”. Trabalho de Graduação - Universidade Federal de  Santa Maria. Frederico Westphalen/RS    Pereira JR, J. C. R.; et al. (2005) “Ensino de Algoritmos e Programação: Uma  Experiência no Nível Médio”. Anais do XXV Congresso da Sociedade Brasileira de  Computação e XIII Workshop sobre Educação em Computação, São Leopoldo/RS.   Petri, G.; Marcon, R. P. (2014) “Jogos Educacionais no Ensino de Metodologias Ágeis:  uma revisão da literatura”. IV Encontro Anual de Tecnologia da Informação (IV  EATI). Frederico Westphalen/RS.   Wang, M. A.; Prado, E. P. V. (2015) “Revisão Sistemática sobre Alfabetização  Computacional”. XI Simpósio Brasileiro de Sistemas de Informação (SBSI),  Goiânia/GO.   Wierchork, K.; Boniati, B. (2014) “Desenvolvendo de um Plugin para MOODLE  Voltado ao Ensino de Programação Utilizando a API Davit”. IV Encontro Anual de  Tecnologia da Informação (IV EATI). Frederico Westphalen/RS.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   102        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015     MB Engine: Game Engine para a Construção de Jogos em  HTML 5   Maik Basso1, Carine Piovesan Lopes1,    Fábio José Parreira2, Sidnei Renato Silveira2   1Curso de Bacharelado em Sistemas de Informação – 2Departamento de Tecnologia da  Informação - Universidade Federal de Santa Maria (UFSM) – Centro de Educação   Superior Norte RS (CESNORS) – Frederico Westphalen – RS – Brasil  maik@maikbasso.com.br, carinepiovesan@gmail.com,   fabiojparreira@gmail.com, sidneirenato.silveira@gmail.com  Resumo. Este artigo apresenta o desenvolvimento de uma Game Engine  (motor de jogos digitais) utilizando as tecnologias Javascript e HTML 5 com o  intuito de facilitar a construção de jogos baseados em um contexto 2D (duas  dimensões). A engine proposta neste artigo dispõe de recursos para a criação  de interfaces, tais como elementos gráficos e sonoros, organizando o conteúdo  e apresentando uma lógica simples para a criação de jogos digitais.   Palavras chaves: Jogos Digitais, Tecnologias Web, Game Engine.   Abstract. This paper presents the development of a Game Engine (digital  game engine) using JavaScript and HTML 5 technologies in order to facilitate  the construction of games based on a 2D context (two dimensions). The engine  proposed in this paper has the resources to create interfaces such as graphics  and sound elements, organizing content and featuring a simple logic to create  digital games.   Keywords: Digital Games, Web Technologies, Game Engine.   1. Introdução  Este artigo apresenta o desenvolvimento de um protótipo de game engine, com o  objetivo de facilitar a construção de jogos digitais baseados em duas dimensões (2D),  fornecendo uma lógica simples para a criação das interfaces e lógicas de jogo.   A motivação para a construção da “MB Engine” (nome proposto para a engine)  surgiu a partir do momento em que um dos autores deste trabalho necessitou  desenvolver um jogo educacional digital como trabalho de conclusão do curso (TGSI –  Trabalho de Graduação em Sistemas de Informação) de Bacharelado em Sistemas de  Informação na UFSM/Frederico Westphalen. A MB Engine está sendo construída com a  utilização de tecnologias web, tais como HTML (HyperText Markup Language) na sua  quinta versão – HTML 5, CSS (Cascading Style Sheets) versão 3 e a linguagem de  programação Javascript. O conceito e a funcionalidade de cada uma destas tecnologias  serão explorados no decorrer deste artigo.   Neste contexto, o presente artigo encontra-se dividido da seguinte forma: a seção  2 apresenta um breve referencial teórico envolvendo as áreas de estudo relacionadas ao  desenvolvimento do protótipo de engine. A seção 3 apresenta alguns trabalhos  relacionados, onde são descritos e comparados trabalhos que envolvem o  desenvolvimento de motores de jogos. A seção 4 apresenta o processo de  desenvolvimento da MB Engine, sendo analisadas as tecnologias e ferramentas usadas  para a implantação do protótipo. Encerrando o artigo são apresentadas as considerações     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   103        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015     finais, destacando os resultados obtidos até o presente momento, bem como as  referências utilizadas.     2. Referencial Teórico  Esta seção apresenta um referencial teórico sobre as áreas envolvidas no  desenvolvimento deste trabalho, destacando conceitos referentes a jogos digitais, a  conceituação de game engine e sua aplicação no desenvolvimento de jogos digitais.    2.1. Jogos Digitais   Um jogo digital é uma atividade lúdica, formada por ações e decisões que resultam em  uma condição final, que representa ganhar ou perder o jogo. Tais ações e decisões são  limitadas por um conjunto de regras e por um universo que, no contexto dos jogos  digitais, são regidos por um programa de computador. O universo contextualiza as ações  e decisões do jogador, fornecendo a ambientação adequada à narrativa do jogo,  enquanto as regras definem o que pode e o que não pode ser realizado, bem como as  consequências das ações e decisões do jogador. Além disso, as regras fornecem desafios  a fim de dificultar ou impedir o jogador de alcançar os objetivos estabelecidos  (SCHUYTEMA, 2008).    Segundo Battaiola (2000), um jogo digital é composto, basicamente, por três  partes: enredo, motor e interface interativa. O enredo define o tema, a trama, os  objetivos do jogo e a sequência com a qual os acontecimentos surgem. O motor do jogo  (engine) é o mecanismo que controla a reação do ambiente às ações e decisões do  jogador, efetuando as alterações de estado neste ambiente. Por fim, a interface interativa  permite a comunicação entre o jogador e o motor do jogo, fornecendo um caminho de  entrada para as ações do jogador e um caminho de saída para as respostas audiovisuais  referentes às mudanças do estado do ambiente.    Conforme Juul (2001), o fato de mundos fictícios existirem é a principal  característica que distingue os jogos digitais dos não-digitais, ressaltando que a  existência de mundos fictícios deve-se à existência de um mundo lúdico único onde o  jogo se desenvolve. Nos jogos não-digitais acaba surgindo um mundo fictício, mas esse  fica limitado ao imaginário de cada participante e não é compartilhado e delimitado  como nos jogos digitais.   2.2. Game Engine  A engine ou motor de jogo é responsável por simular a parte física do mundo real dentro  do ambiente do jogo. O nível de complexidade da engine define também o nível de  realidade que a mesma proporciona ao usuário (BRITO, 2011).   Os motores podem ser considerados como bibliotecas de desenvolvimento,  responsáveis pelo gerenciamento de diversos componentes do jogo tais como imagens,  entrada de dados e outras funções (EBERLY, 2001).    O objetivo de um motor de jogos é agrupar funções fundamentais para o  desenvolvimento de jogos, que podem se estender da interação com os periféricos de  entrada até a renderização5 dos cenários e personagens. Assim, várias aplicações podem  ser desenvolvidas utilizando como base de código este componente central. Isto  certamente reduz o tempo total de produção, à medida que concentra a equipe de  trabalho em atividades de mais alto nível. Por mais genéricos que sejam, entretanto, os                                                    5 Renderizar é o ato de construir as imagens com utilização de contextos no canvas (MDN, 2015)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   104        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015     motores costumam ser projetados tendo em vista uma classe particular de jogos, como  2D ou 3D (OLIVEIRA, 2013).   3. Estado da Arte  Existem diversos estudos focados no desenvolvimento de game engines para auxiliar e  acelerar o trabalho dos desenvolvedores de jogos. As game engines atuais estão cada  vez mais completas e com recursos surpreendentes, incluindo aspectos físicos, visuais e  sonoros, sem contar o suporte multiplataforma e responsividade, entre outros recursos.   Um exemplo de game engine de código aberto que trabalha com um contexto 2D  é o melonJS. Esta engine possui um formato de mapa popular, permitindo projetar  facilmente níveis usando um editor de mapas, proporcionando ao desenvolvedor mais  tempo para implementar as características do jogo a ser desenvolvido. A construção de  jogos nesta engine baseia-se na utilização recursos modernos e sem dependências de  outras bibliotecas. Esta engine conta é compatível com diversos navegadores web do  mercado, incluindo os de plataforma mobile (MELONJS.ORG, 2015).   Outro projeto de código aberto, disponível na Internet, é o EaselJS que, segundo  a comunidade que mantém o projeto, é uma biblioteca de alta performance para o  desenvolvimento de conteúdo 2D interativo em HTML5. Esta engine faz parte do  pacote CreateJS e fornece uma lista de exibição rica em recursos que permitem  manipular e animar gráficos. A engine também fornece um modelo interativo para  manipulação do mouse e também para a utilização de telas de toque. Como a maioria  das engines, esta engine não possui nenhuma dependência externa. Ela se destaca por  ser uma engine Javascript que proporciona suporte não somente à criação de jogos, mas  também anúncios publicitários, arte generativa e visualização de dados, entre outras  possibilidades (CREATEJS.COM, 2015).   O projeto Phaser por sua vez, é um dos projetos de game engine mais bem  conceituados e completos do mercado atual. Além de ser baseado em software livre, é  mantido por uma comunidade que disponibiliza atualizações constantes. O projeto  suporta todos os recursos necessários para a criação de jogos incluindo animações, précarregamento de arquivos, sons, métodos de entrada entre outros. Além disso, a equipe  que mantém o projeto Phaser disponibiliza alguns produtos e serviços, tais como livros  e cursos de apoio ao aprendizado de desenvolvimento de games. Outro ponto relevante  atualmente é a compatibilidade com a maioria dos navegadores web do mercado  (PHOTONSTORM, 2015).   Observando os recursos disponibilizados pelas engines apresentadas neste  artigo, destaca-se que a MB Engine é um projeto que tende a se estender conforme as  necessidades que vão surgindo, visando contemplar diferentes aspectos que já estão em  funcionamento em outras engines. Mesmo tendo um número de recursos reduzido, a MB  Engine se destaca pelo fato de ser uma game engine que dispõe de estrutura multicanvas e pelo fato de ser uma engine responsiva, essas duas propriedades não foram  identificadas nas engines analisadas. Serão descritas na próxima sessão deste artigo as  duas propriedades existentes na MB Engine.   4. Solução Implementada  A MB Engine foi desenvolvida com o intuito de auxiliar no desenvolvimento de jogos  digitais baseados em um contexto 2D (bi-dimensional). O projeto foi desenvolvido com  a utilização de tecnologias web tais como HTML5, CSS3 e Javascript. A presente  engine dispõe de recursos ainda considerados básicos para a construção de jogos,  porém, funciona de forma simples e intuitiva, auxiliando na construção das estruturas do  jogo e também na sua lógica.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   105        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015      O processo de desenvolvimento da engine está sendo realizado de forma paralela  ao desenvolvimento do protótipo de um jogo educacional digital, que está sendo  desenvolvido como TGSI na UFSM/Frederico Westphalen (BASSO et. al., 2015). Desta  forma, sempre que um novo recurso é necessário no protótipo do TGSI, este recurso é  adicionado à MB Engine.   4.1. Tecnologias Empregadas  Como mencionado anteriormente, a game engine está sendo desenvolvida utilizando  tecnologias web de última geração. O HTML5 contém diversos recursos essenciais que  possibilitam a construção de jogos digitais. O canvas, um dos recursos do HTML5,  considerado por Meyer (2011) um dos mais poderosos da linguagem, também é  aplicado na game engine.   O canvas possibilita a construção de imagens por meio de um contexto de duas  dimensões (2D). Estas imagens, denominadas frames, podem ser modificadas  dinamicamente sendo controladas por tempo ou eventos ocorridos no elemento. O  elemento canvas permite que scripts6 modifiquem a tela bitmap7 formando animações.  O fator determinante é a resolução, ou seja, as medidas de altura e largura que definem  o tamanho do bitmap do canvas. A utilização do elemento ainda é altamente  recomendada para a renderização de gráficos do jogo, ou outras imagens visuais em  tempo real (MEYER, 2011; SHANKAR, 2012).   O HTML5 auxilia na definição da estrutura do jogo ou projeto. Sendo assim,  tem-se a necessidade de utilização de outras duas linguagens fundamentais em projetos  web, o CSS para compor os estilos dos elementos do jogo e a linguagem Javascript,  para a produção dos scripts que comporão a lógica de jogo, controle de tempo e espaço,  validação das respostas, entre outros aspectos. É importante ressaltar que, como o  elemento canvas não permite a utilização direta de folhas de estilos em cascata (CSS)  em seus elementos internos, esta será feita por meio da utilização de Javascript  (SHANKAR, 2012).   O Javascript é uma linguagem de programação leve, interpretada pelos browsers  (navegadores web). Por meio desta linguagem podem ser manipulados quaisquer  elementos de um documento HTML, definindo estilos, mudando suas propriedades,  definindo ações, entre outros aspectos (FLANAGAN, 2004).    4.2. Estrutura e Funcionamento da Engine  A engine desenvolvida apresenta uma estrutura simples, composta de métodos, funções  e eventos implementados em Javascript. Basicamente um jogo construído com a MB  Engine possui quatro arquivos: o primeiro arquivo é o “index.html”, ele é o arquivo  HTML onde são feitas as chamadas de todos os arquivos Javascript de forma  assíncrona, ou seja, os arquivos são carregados em paralelo para acelerar o processo de  onload da página.   Os outros três arquivos são arquivos Javascript organizados da seguinte  maneira: o primeiro contém a função “function Arquivos(){}”. Neste arquivo devem-se  adicionar vetores contendo os links/referências aos arquivos multimídia que a engine  deve carregar para a construção do jogo. O segundo arquivo contém a lógica do jogo, tal                                                    6 Script é um código composto por uma sequência de passos durante a execução de um programa  (MSDN, 2015a)  7 Um bitmap é uma matriz de bits que especifica a cor de cada pixel em uma matriz retangular de pixels.  O número de bits dedicados a um pixel individual determina o número de cores que podem ser atribuídos  a esse pixel (MSDN, 2015b)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   106        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015     como sua estrutura. Neste arquivo são criadas as interfaces do jogo seguindo o  pressuposto de que cada função seja considerada uma interface. Dentro destas funções  principais deve-se ter dois métodos obrigatórios que são o “renderizar();” e o  “destruir();”, sendo que o primeiro é responsável por montar e apresentar a interface ao  usuário e, o segundo, por remover a interface da tela. A tela principal de um jogo  desenvolvido com a MB Engine deve ser nomeada de “Principal();”. A partir desta tela  principal todas as outras telas são chamadas, construindo-se a lógica do jogo.   O último arquivo é o da MB Engine que, por sua vez, funciona da seguinte  forma: quando o evento “onload” da página HTML for disparado, a MB Engine cria um  novo contexto de jogo, chamando a tela que faz o carregamento de todos os arquivos  multimídia contidos no script descrito acima. Posteriormente, a tela Principal é criada e  o método Renderizar é disparado. Após isso o jogo se dá por iniciado. A Figura 1  apresenta o funcionamento da MB Engine.   A MB Engine também possui funções matemáticas baseadas no cálculo da regra  de três para que seja possível aplicar o conceito de responsividade, adaptando os jogos  aos diversos tamanhos de displays disponíveis no mercado. O conceito de  responsividade está ligado ao ato de adaptar o layout a qualquer  dispositivo,  tela  e   resolução,  com  objetivo  de garantir  a  boa  experiência  do  usuário,  possibilitando   navegação  e  leitura  confortáveis sem comprometer o conteúdo (SILVA, 2014).   Outra parte muito importante da estrutura da engine é a disponibilização de  esqueletos de elementos gráficos e sonoros para o jogo. Por exemplo, pode-se criar um  retângulo na tela instanciando um objeto contido na classe “var retangulo = new  ElementosGraficos().retangulo;”; então seu método renderizar pode ser chamado  “retangulo.renderizar();”. A mesma lógica de utilização da engine pode ser aplicada aos  sons do jogo.       Figura 1. Funcionamento da MB Engine. Fonte: dos autores.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   107        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015      Neste contexto, o importante a ressaltar é que a MB Engine é multi-canvas, ou  seja, a cada elemento gráfico criado, um novo canvas é criado, dando liberdade e  independência na construção das interfaces, sendo que os elementos da interface podem  ser manipulados separadamente.   5. Considerações Finais  O desenvolvimento da engine está ocorrendo de forma paralela ao desenvolvimento de  um jogo educacional digital (BASSO et. al., 2015), no qual as funcionalidades da  engine estão sendo colocadas em prática, o que possibilita que aprimoramentos sejam  feitos constantemente. A Figura 2 apresenta a tela inicial do jogo Aprendendo com o  Zag (BASSO et. al., 2015), desenvolvido a partir da MB Engine.       Figura 2. Tela Inicial do Jogo Aprendendo com o Zag Fonte: dos autores.      Algumas dificuldades estão presentes no projeto. Uma delas é a falta de suporte  a algumas funcionalidades do HTML5 por parte de alguns dispositivos móveis, o que  impossibilita a execução da engine em dispositivos móveis com versão de Android  anterior a 5.0.  Por outro lado, a engine apresenta um conceito ágil e flexível,  proporcionando liberdade ao desenvolvedor, para construir sua estória de jogo de forma  simples e intuitiva, em um curto prazo de tempo.   O próximo passo a ser realizado referente à implementação da engine envolve a  análise e implementação das recomendações de acessibilidade, para que a mesma fique  disponível à utilização para o maior número possível de usuários independente de suas  limitações e habilidades.   Referências   BATTAIOLA, A. L. (2000). Jogos por computador: Histórico, relevância tecnológica e  mercadológica, tendências e técnicas de implementação. Anais do XIX Jornada de  Atualização em Informática. Curitiba: SBC 2000.   BASSO, M.; KLISZCZ, S.; PARREIRA, F. J.; SILVEIRA, S. R. (2015).  Desenvolvimento de um Jogo Educacional Digital para Auxílio à Alfabetização     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   108        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 102-108 Nov/2015     utilizando Redes Neurais. UFSM: Frederico Westphalen, 2015. TGSI – Trabalho de  Graduação em Sistemas de Informação.   BRITO, (2011). Blender 3D: jogos e animações interativas. São Paulo: Novatec.   CREATEJS.COM (2015). CreateJS. Disponível em: <http://createjs.com>. Acesso sem  setembro de 2015.   EBERLY, D. H. (2001). 3D game engine design: a practical approach to real-time  computer graphics. São Francisco: Morgan Kaufmann.   FLANAGAN, David. JavaScript: o guia definitivo. 4. ed. Porto Alegre: Bookman,  2004.   JUUL, J. (2001). Half-Real: Video Games between Real Rules and Fictional Worlds. 1º  ed. Cambridge: The MIT Press.   MDN Mozilla Developer Network (2015). Utilização Básica do Canvas. Disponível em:  <https://developer.mozilla.org/ptBR/docs/Web/Guide/HTML/Canvas_tutorial/Utilizacao_basica>. Acesso em  setembro de 2015.   MELONJS.ORG. (2015) melonJS: a lightweight HTML5 game engine. Disponível em:  <http://melonjs.org>. Acesso em setembro de 2015.   MEYER, J. (2011). O Guia Essencial do HTML5: Usando jogos para aprender HML5 e  Javascript. Rio de Janeiro: Ciência Moderna.   MSDN Microsoft Developer Network (2015a). JavaScript: princípios básicos.  Disponível em: <https://msdn.microsoft.com/ptbr/library/6974wx4d%28v=vs.94%29.aspx>. Acesso em setembro de 2015.   MSDN Microsoft Developer Network (2015b). Tipos de Bitmaps. Disponível em:  <https://msdn.microsoft.com/pt-br/library/at62haz6%28v=VS.110%29.aspx>.  Acesso em setembro de 2015.   OLIVEIRA, E. R. (2013). O Uso de Engines para o Desenvolvimento de Jogos  Eletrônicos. Monografia de conclusão de curso apresentada à Universidade Estadual  do Sudoeste da Bahia – UESB. Vitória da Conquista, 2013.   PHOTONSTORM (2015). Phaser: desktop and mobile HTML5 game framework.  Disponível em: <http://phaser.io/>. Acesso em setembro de 2015.   SCHUYTEMA, P. (2008). Design de games: uma abordagem prática. São Paulo:  Cengage Learning.   SHANKAR, A. R. (2012). Pro HTML5 Games (Expert's Voice in Web Development).  E-book: Apress, Disponível em: <http://www.apress.com/9781430247104>. Acesso  em 17 de maio de 2015.   SILVA, Arthur De Almeida Pereira Da; Design Responsivo: Técnicas, Frameworks e  Ferramentas. Universidade Federal Do Rio De Janeiro. Centro de Ciências Exatas e  Tecnologias. Escola de informática Aplicada. Rio de Janeiro, 2014. Disponível em:  <http://bsi.uniriotec.br/tcc/201412Almeida.pdf>. Acesso em 10 setembro de 2015.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   71        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     Mineracão de padrões entre doenças relacionadas ao  saneamento ambiental inadequado   Rafael P. Scholant1, Sandro da Silva Camargo2   1Especialização em gestão estratégica de tecnologia da informação – Instituto de   Desenvolvimento do Alto Uruguai (IDEAU) Av. Santa Tecla, 4200 – Bagé – RS – Brasil   2Orientador – Universidade Federal do Pampa (UNIPAMPA), Campus Bagé.  Rua Travessa 45, 1650, gabinete 3139 – Bagé – RS – Brasil     rafael.scholant@gmail.com, sandro.camargo@unipampa.edu.br     Abstract. This study aims to gain insight into the technical data mining and  use practices on cases of diseases related to inadequate sanitation. In the  first stage, and will address briefly some data mining techniques and  subsequently the technique that should be used to obtain the expected results  will be set. The time horizon selected for this work will be a period of  seventeen based on data obtained from the Brazilian portal of open data,  which are provided by the fe- deral government. Finally, the knowledge  gained throughout this work, which involves the interaction between two  areas of expertise - health and data mining- will be summarized at the end  of the work the results of data mining exercise.     Resumo. Este trabalho tem por objetivo obter conhecimento sobre as  técnicas de mineração de dados e a sua utilização pratica sobre os casos  de doenças relacionadas ao saneamento ambiental inadequado. Em uma  primeira etapa, e de forma breve serão abordadas algumas técnicas de  mineração de dados e, posteriormente, será definida a técnica que deverá ser  utilizada para a obtenção dos resultados esperados. O horizonte temporal  selecionado para este trabalhoseráde um perı́odo de dezessete anos tendo  por base dados obtidos junto aoportal brasileiro de dados abertos, que  são fornecidos pelo governo federal. Por fim, os conhecimentos obtidos ao  longo deste trabalho, que pressupõe a interação entre duas áreas de  conhecimento - saúde e mineração de dados -, serão sintetizados ao final  do trabalho os resultados do exercı́cio de mineração de dados.     1. Introdução   Não restam dúvidas que o Brasil tem avançado muito ao longo dos últimos anos,  passando por transições governamentais de uma forma madura, contudo, para um paı́s  que realmente quer ser protagonista, o Brasil ainda precisa avançar muito em certos  aspectos básicos, e a questão do saneamento ambiental talvez seja uma das principais  barreiras a serem superadas.   Em 2009, a organização mundial de saúde (OMS) apontou a falta de  saneamento ambiental como o decimo primeiro fator de risco para mortes no mundo  [OMS 2009].   Neste contexto, em 28 de julho de 2010, a organização das nações unidas     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   72        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     (ONU) reconheceu o acesso ao saneamento básico como um direito de todo ser  humano, sendo um fator primordial para a prevenção de problemas de saúde.   O saneamento ambiental no Brasil encontra-se muito abaixo do esperado,  principalmente no que se refere aos serviços relacionados à coleta e tratamento de  esgotos [Neri 2011].   O presente artigo tem por objetivo analisar os dados sobre doenças relacionadas  ao saneamento ambiental inadequado, obtidos junto ao portal de dados disponibilizado  pelo governo federal, para que se possa criar situações e estatı́sticas sobre os mesmos,  desvendando assim como o saneamento ambiental vem evoluindo durante os últimos  anos.     2. Mineração de dados  Diariamente as organizações acumulam um grande volume de dados em seus  softwares operacionais. Os dados que são obtidos através destes softwares são dados  brutos, que não expressam nada da forma na qual são salvos, demonstram somente o  que aconteceu naquele exato momento. Para que estes dados possam ser realmente uteis  para os gestores, estes devem ser tratados e analisados, neste ponto que surge a  necessidade da mineração de dados [O’brien 2011].   A mineração de dados é uma técnica que tem por objetivo explorar grandes  con- juntos de dados, para que possa se estabelecer relações, associações e padrões  que seriam de difı́cil visualização [Laudon and Laudon 2011]. Para que possa ser  feita esta exploração, são utilizados algoritmos de aprendizagem ou de classificação  baseados em redes neurais e estatı́sticas. Os resultados gerados geralmente são  expressos em forma de regras, hipóteses, arvores de decisão e grafos.   No entanto, a união de três principais recursos é o que torna a mineração de  dados possı́vel, o banco de dados no qual serão obtidos os dados para serem  analisados,a estatı́stica que seráutilizada para descobrir o quanto cada dado  éimportante para ainformação final e por ultimo mas não menos importante a  inteligencia artificial que fará combinações entre os dados e as estatı́sticas para a  descoberta de padrões, conforme esquematizado na Figura 1.   2.1. Tarefas e técnicas de mineração de dados  É importante saber diferenciar o que é uma tarefa e o que é uma técnica de  mineração  de dados. A tarefa consiste na especificação das informações que deverão ser obtidos  dos dados, que tipo de regularidades ou categorias de padrões terão relevância para a  pesquisa. Já a técnica de mineração consiste na especificação de métodos que possam  garantir que os padrões poderão gerar alguma informação com relevância. A  integração entre estes elementos é esquematizada na Figura 2.   Dentre as principais técnicas utilizadas em mineração de dados, exitem  técnicas estatı́sticas e de aprendizado de máquina. A seguir, será feita uma breve  descrição das principais técnicas de mineração.   • Associação: São ocorrências ligadas a um único evento, por exemplo: um  estudo sobre modelos de compras em supermercados pode se descobrir que,  quando houver uma compra de pão, o mesmo comprador em 70% das vezes  também compra        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   73        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015          Figura 1. Principais recursos que consistem a minerao de dados       manteiga, porem quando há uma promoção a manteiga é comprada em 90%  das n vezes. Com estas informações, os gestores da organização têm decisões  mais fáceis de se tomar, pois os mesmos podem ver mais sobre o assunto.   • Classificação: Reconhece modelos que podem descrever o grupo ao qual um  item em especifico pertence por meio de um exame dos itens que já foram  anteriormente classificados e também pela interferência de um conjunto  especifico de regras. Como por exemplo empresas operadoras de cartões de  credito, que podem descobrir regularidades entre clientes e assim poderá prever  quando estes poderão abandona-la e assim oferecer vantagens para que isto não  aconteça.   • Sequencias: Na técnica de mineração por padrões sequenciais os eventos  estão ligados ao longo do tempo. Assim podendo descobrir que quando uma  pessoa compra um carro dentro de um perı́odo de tempo curto a mesma,  efetuara compra de pneus e também de um rádio para o seu automóvel.   • Aglomeração (clustering): A técnica de mineração por aglomeração funciona  de forma semelhante a classificação, porem quando ainda não estiverem sido  definidos os grupos. O algoritmo de aglomeração terá o trabalho de descobrir  diferentes grupos dentro de uma grande quantidade de dados, como por  exemplo encontrar grupos dentre usuários de cartões de credito com base na  demografia e em inves- timentos pessoais.     2.2. Localizando padrões  Existem várias medidas objetivas para que se possa avaliar o grau de interesse que  um padrão pode apresentar para o usuário. Estas medidas são baseadas na estrutura do  padrão descoberto em estatı́sticas apropriadas. Por exemplo, uma medida objetiva  para avaliaro interesse de uma regra de associação é o suporte, representando a  porcentagem dastransações em um banco de dados de transações onde a regra se  verifica.     3. Obtendo e preparando os dados     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   74        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     Os dados utilizados no presente estudo, foram obtidos juntamente ao portal brasileiro  de dados abertos, que é mantido pelo governo federal [Brasil 2015].          Figura 2. Interação entre os elementos da mineração de dados.       A população do estudo na presente pesquisa totalizou 7165 casos de  internação hospitalar referente a doenças relacionadas ao saneamento ambiental  inadequado a cada 100 mil habitantes [Brasil 2014]. As variáveis que foram utilizadas,  são os números totais de internações por categoria de doença e ano de referência.  Estes elementos podem ser observados através da Figura 3.   Doenças relacionadas ao saneamento ambiental inadequado (DRSAI) são  doenças que podem estar associadas ao abastecimento de água deficiente, esgotamento  sanitário inadequado, contaminação por resı́duos sólidos ou condições precárias de  moradia [Brasil 2014].   O perı́odo de tempo foi escolhido a partir de 1993, que foi quando o sistema  único de saúde (SUS) passou a registrar as internações hospitalares de forma mais  sistemática, até 2010, quando foram disponibilizados para o público através do portal  brasileiro de dados abertos, que é mantido pelo governo federal.   A partir da obtenção dos dados, foi feito um pré-processamento das  informações contidas neles e foram categorizados, isto é, definidas classes para  determinados atributos ou variáveis em algumas informações como, doenças de  transmissão feco-oral, doenças transmitidas por inseto vetor, entre outras. Esta  preparação foi necessária para que as informações resultantes da análise sejam de  melhor utilização.     4. Métodos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   75        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     A escolha da técnica de mineração de dados foi feita após o pré-processamento dos dados,  quando notou-se uma grande necessidade de se aglomerar os dados em grupos, para que  assim possa ser feita uma melhor analise das informações.  Assim então escolhendo a  técnica de Aglomeração (clustering).             Figura 3. Gráfico de totais de internações.     Para a realização deste estudo, optou-se pelo uso do algoritmo K-Means  do WEKA (Waikato Environment for Knowledge Analysis), que permite a descoberta  destes padrões na forma de clusters.   Trabalhou-se com o programa WEKA, para a obtenção dos clusters, em  virtude da sua adequação ao estudo e por três importantes razões:   • É uma ferramenta amistosa ao uso por profissionais de saúde, muitas vezes  nãoafeitos à informática.   • Por ser software livre, pode ser utilizado sem custo e com grande facilidade  nas secretarias de saúde.    Analise de clusters é o processo de aglomerar um conjunto de dados em   classes de objetos similares. Um cluster é uma coleção de objetivo que são similares  uns aos outros (de acordo com algum critério de similaridade pré-fixado) e diferentes  a objetos pertencentes a outros clusters. Analise de clusters é uma tarefa de aprendizado  não super- visionado, pelo fato de que os clusters representam classes que não puderam  ser definidas no inı́cio do processo de aprendizagem, como é o caso das tarefas de  classificação, onde o banco de dados de treinamento é composto de tuplas classificadas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   76        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     Na etapa seguinte do processo, que consistia na mineração de dados  propriamente dita, foram extraı́das regras que permitem relacionar as diversas variáveis  sob estudo.     5. Aplicação do modelo escolhido    Para que pudesse ser obtido informações mais consistentes, foram feitas diversas  analises dos dados, simulando universos com 2, 3, 4 e 5 clusters.   Os resultados gerados com base nestes parâmetros mostraram-se muito  eficientes para o que era necessário se mostrar, assim foi feito uma analise sobre os  resultados gerados pelo algoritmo, para que pudesse se escolher o que mais poderia  mostrar ao usuário as informações desejadas. Assim foi observado que os universos  com 3 e 4 clusters iriam suprir a necessidade deste estudo, porém para uma melhor e  mais simples visualização dos dados, foi escolhido o universo com 3 clusters para que  fossem feitas as análises mais a fundo. O universo escolhido pode ser observado através  da Figura 4.            Figura 4. Centroids.       Através destas informações geradas, podemos observar que algumas das  internações decorrente de doenças relacionadas com o saneamento ambiental  inadequado esteve a diminuir durante o perı́odo analisado, tais como, doenças de  transmissão feco- oral, transmitidas através do contato com a água, Geo-helmintos e  tenı́ases. Porem como pode ser ver nas figuras 5 e 6, as doenças transmitidas por  inseto vetor e relacionadas com a higiene mostraram-se instáveis durante o perı́odo  analisado, podendo ver em um primeiro momento entre os clusters 2 e 1 uma  diminuição de ocorrências significativa, podem entre os clusters 1 e 0 ocorreu um  aumento nestas ocorrências, assim podendo demonstrar que pode ter ocorrido algum  fator externo ou que o saneamento ambiental referente a estes problemas não esta  sendo tratado de forma correta pelas entidades cor- respondentes.   Também pode se notar a diminuição de ocorrências relacionadas a  transmissão feco-oral teve uma grande queda.   Também vale ressaltar que as doenças relacionadas a transmissão feco-oral     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   77        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     tiveram uma redução substancial em suas ocorrências, mostrando assim que a  entidade responsável para tratar do saneamento ambiental referente a esta área teve  uma grande preocupação com a quantidade de casos que estavam acontecendo e assim  puderam me- lhorar o seu serviço.            Figura 5. Doenças transmitidas por inseto vetor.          Figura 6. Doenças relacionadas com a higiene.      3. Conclusão e trabalhos futuros  Conforme as experiências realizadas nos dados obtidos, podemos notar que com o  passar do tempo as internações decorrentes a doenças relacionadas com o saneamento  ambiental inadequado, vem diminuindo em sua maioria, mostrando assim, que o Paı́s  vem melhorando as suas práticas em relação a este problema que pode representar um  grande risco para a população caso não tratado. Porem pode notar-se também que em  relação a algumas doenças houve uma diminuição na sua ocorrência e após algum     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   78        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 71-78 Nov/2015     perı́odo de tempo houve uma elevação dos casos, este ponto é de suma importância para  a pesquisa, porque ela demonstra um problema que pode estar acontecendo em certas  áreas, que o governo federal estava tratando, mas que por algum motivo não está dando  tanta importância quando deveria.   Desta forma para que se possa ter mais detalhes sobre o problema em  questão, devesse avaliar não somente a quantidade de internações relativas a este tipo  de doença,mas também em que circunstancias as mesmas ocorreram, como perı́odo  do ano, se a época que teve aumento na ocorrência foi um perı́odo chuvoso ou não  e entre outras variáveis que seriam de grande ajuda em uma futura analise.   Os próximos trabalhos a serem executados devem levar em consideração  mais variáveis a serem tratadas, para que assim possa se ter um universo mais amplo e  assim poder gerar melhores informações e análises.     Referências  Brasil (2014). Visão geral da prestação de serviços de água e esgoto.   Brasil (2015). Portal brasileiro de dados abertos.   Laudon, K. and Laudon, J. (2011). Sistemas de Informações Gerenciais:  Fundamentos da inteligência de negócios: gestão da informação e de banco de  dados.   Neri, M. C. (2011).  Os emergentes dos emergentes : Reflexões globais e ações  locais para a nova classe média brasileira.   O’brien, J. A. (2011).   Sistemas de Informação e As Decisões Gerenciais Na Era  da Internet.   OMS (2009). Global health risks - Mortality and burden of disease attributable to  selec- ted major risks.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   158        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015     Oficina de Design Participativo: engine humana para  validação de jogabilidade e mecânica de um jogo educacional   digital e acessível     Adriana Gomes Alves¹; Karla D.P. Cathcart¹; Ana Elisa Ferreira Schmidt²; Luis   Henrique de Melo Santiago¹;   ¹Laboratório Intertech- Universidade do Vale do Itajaí (UNIVALI)   Itajaí - SC - Brasil   ²Instituto Federal Catarinense - (IFC - Camboriú)   Camboriú - SC - Brasil   adriana.alves@univali.br, karlacathcart@hotmail.com, anaelisa@ifc camboriu.edu.br, lhg9312@hotmail.com     Abstract The game "The Postman Challenge" aims to work higher psychological  functions: memory, logical reasoning, spatial sense and coordination in the assistive  thecnology context. We developed workshops in order to validate game concepts  (interface, mechanics, art, interaction) with children participation - Game target  audience - in simulation activities from the perspective of participatory design (PD).  This papers describes these workshops that took place at 02 schools at Itajai and  Balneário Camboriú-SC-Brazil with 48 students total (between age of 7 and 9 years  old). The workshops’ dynamic consisted of students and researchers simulate the  game mechanics acting as human engines. Children’s feedback, collected during  workshops, were crucial to validate game design and its mechanic.     Resumo O jogo "O Desafio do Carteiro" tem por objetivo trabalhar funções  psicológicas superiores, tais como memória, raciocínio lógico, noção espacial e  coordenação no contexto da tecnologia assistiva. Para tal realizou-se oficinas a fim  de validar conceitos (interface, mecânica, arte, interação) com o envolvimento das  crianças em simulações, na perspectiva do design participativo (DP). O artigo  descreve oficinas realizadas em duas escolas Municipais, de Itajaí e de Balneário  Camboriú/ SC, com 48 alunos com idades entre 7 e 9 anos. A dinâmica consistiu em  alunos e pesquisadores efetuarem os processos realizados pelo computador como  engines humanas. O feedback das crianças, coletado durante as oficinas, foi  fundamental para validar o game design e a mecânica do jogo.      1 INTRODUÇÃO  No ano de 2014 um grupo interdisciplinar de pesquisadores - Ciência da Computação,  Engenharia de Computação, Design de Jogos, Fisioterapia e Educação - iniciou um  projeto de pesquisa cujo objetivo é o desenvolvimento de soluções em interação para  jogos digitais acessíveis [Alves et al 2015]. Pretende-se criar, desenvolver, adaptar e  avaliar jogos digitais, tendo por base o conceito de design universal e de interfaces  naturais utilizando dispositivos não convencionais de interação para proporcionar  acessibilidade a crianças com e sem deficiências. A acessibilidade é compreendida  como a garantia às pessoas com deficiências ou mobilidade reduzida de uma utilização  segura e autônoma de espaços, mobiliários, produtos e informações [Alves e Aguiar     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   159        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015     2014]. Adota-se neste projeto a abordagem de design participativo (DP) [Rocha e  Baranauskas 2000] como subsídio para elicitar elementos de jogabilidade (gameplay)  para a produção dos jogos que visam a educação de crianças em fase de alfabetização,  independentemente de suas características. Entende-se aqui por jogabilidade a  experiência de interação entre o jogador e o jogo, bem como o conjunto de regras,  ambientes e ações permitidas que o definem [Mello e Perani 2012].   A equipe desta pesquisa elaborou o projeto de um jogo educacional digital que  possui características que trabalham as funções psicológicas superiores, tais como:  memória, raciocínio lógico, noção espacial e coordenação, as quais vêm ao encontro dos  objetivos do projeto. Esta decisão se pauta em Vigotski (1998, p. 131) que afirma     [...] Os anos escolares são, no todo, o período ótimo para o aprendizado de   operações que exigem consciência e controle deliberado; o aprendizado dessas   operações favorece enormemente o desenvolvimento das funções psicológicas   superiores enquanto ainda estão em fase de amadurecimento. Isso se aplica   também ao desenvolvimento dos conceitos científicos que o aprendizado   escolar apresenta `a crianças.     Com o objetivo de validar as ideias do jogo, sua mecânica e a arte, antes mesmo   da sua implementação digital, produziram-se como etapa inicial do DP oficinas com  alunos do terceiro ano do Ensino Fundamental, em duas escolas da rede pública dos  municípios de Itajaí e Balneário Camboriú no estado de Santa Catarina. Por meio de um  protótipo de baixa fidelidade elaborado em papel, a oficina propôs uma brincadeira com  os alunos utilizando cartazes e cartas para simular a mecânica do jogo. Cunhamos o  termo engine humana para representar que a mecânica do jogo nesse experimento foi  executada por pessoas. A coleta destes dados deu-se por meio de vídeos e anotações por  parte dos pesquisadores e subsidiaram as análises e revisões do jogo proposto. A  pesquisa foi autorizada pela Direção das Escolas e pelos pais ou responsáveis por meio  do “Termo de Consentimento Livre e Esclarecido para Pais ou Responsáveis”.   Pretende-se neste artigo demonstrar a experiência das oficinas para validação da  proposta de um jogo educacional digital, como técnica de DP envolvendo o público alvo  do jogo. Desta forma, na seção 2 é justificada a realização da oficina, na seção 3 a  oficina é descrita, na Seção 4 são descritos os materiais e métodos utilizados, a Seção 5  apresenta os resultados e discussões e, por fim, a Seção 6 as conclusões deste trabalho.     2 JUSTIFICATIVA  O projeto em que este trabalho se insere tem como um dos seus principais focos a  criação de um jogo educacional digital por meio da aplicação de princípios do design  participativo como forma de envolver o usuário final (alunos) na proposta do jogo desde  sua concepção. Sendo assim, surgiu a necessidade de conhecer o interesse e as  impressões dos alunos ao jogar o jogo, mesmo antes do início do seu desenvolvimento  computacional. A forma encontrada para realizar tal tarefa foi por meio de oficinas que  possibilitassem a participação dos alunos e professores na definição da mecânica do  jogo, de forma lúdica e didática.   Essa forma lúdica de aplicar o jogo antes dele se tornar digital permite que a  criança desenvolva a percepção de como o jogo funciona dentro do mundo digital. O  jogador pode perceber as possibilidades de desenvolvimento do jogo antes mesmo que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   160        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015     ele seja implementado pelos programadores e, assim, propor alterações na sua  jogabilidade e mecânica.   O jogo em desenvolvimento é nomeado “O Desafio do Carteiro” e trata-se de  uma aventura vivida pelo jogador no papel de um carteiro, cujo objetivo é entregar  cartas e encomendas. Essas estão espalhadas pelo cenário de uma cidade e o jogador  precisa realizar missões que envolvem a entrega delas em diferentes locais: uma escola,  lanchonete ou corpo de bombeiros. A cada entrega o carteiro se depara com problemas  na forma de minigames (puzzles), que ao solucioná-los, o ajudam a prosseguir para  próxima fase e entregar as cartas e encomendas.   O jogo oferecerá uma experiência interativa por meio de interfaces naturais entre  jogador e o ambiente do jogo. Esta interação acontece por meio de poses optativas  capturadas pelo sensor do Kinect. O Microsoft Kinect é um sensor que permite às  pessoas interagirem com o computador diretamente com seus corpos de uma maneira  natural, sem a necessidade de utilizar dispositivos como mouse, teclado ou joysticks. O  sensor permite ao computador perceber a terceira dimensão do jogador e do ambiente,  entender quando o usuário fala, saber onde ele está enquanto está caminhando,  interpretar seus movimentos e traduzi-los para um formato que os desenvolvedores  podem utilizar para construir novas experiências. (ZHANG, 2012).    A narrativa é apresentada no prelúdio e orienta o jogador quanto à jogabilidade,  objetivo e tipo de desafios que serão encontrados durante as missões que deverão ser  resolvidas.     3 DESCREVENDO AS OFICINAS  As oficinas com alunos tiveram o propósito de auxiliar nos seguintes aspectos  relacionados à proposta do jogo, “O desafio do Carteiro”: testar a sua jogabilidade;  verificar o interesse dos alunos na sua mecânica; verificar a proposta de interface de  interação; coletar impressões a respeito da arte do jogo; verificar se a complexidade dos  conteúdos pedagógicos está adequada; verificar se as crianças consideraram o jogo  divertido e, por fim, verificar se as crianças com deficiência também conseguem  entender e jogar o jogo de forma divertida.     3.1 MATERIAIS E MÉTODOS  Optou-se por validar o jogo utilizando materiais concretos e uma dinâmica para  simulação do jogo. Baseando-se no projeto do jogo elaborado na fase de concepção,  foram construídos cenários em cartazes contendo os diferentes ambientes do jogo: o  mapa da cidade, a praça onde se passa a primeira missão e um minigame. Além desses,  elaborou-se um cartaz para simulação da barra de energia e das vidas do jogador. A  Figura 1 apresenta os cartazes com os cenários do jogo.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   161        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015       Figura 1: Visão dos cenários do jogo (cidade, praça, vida, minigame)     A primeira missão, do jogo, que se passa na praça da cidade, propõe apresentar   itens coletáveis que podem dar energia ao jogador ou fazê-lo perder energia. Esses itens  aparecem aleatoriamente no cenário e o jogador deve estar atento para coletá-los ou não.  Para simular esta mecânica, os itens foram impressos em plaquinhas onde alguns alunos  seguravam plaquinhas com alimentos e lixos. Um pesquisador “controlava” os alunos,  dando um pequeno toque no ombro para que a placa fosse virada e apresentada ao  jogador.  Um outro aluno, no papel de jogador observava a placa que foi virada e fazia,  ou não, a pose necessária para coletar o item. Conforme as regras do jogo propostas, ao  selecionar os elementos que aparecem na Praça, a barra de energia é atualizada, e esta  tarefa foi realizada por um bolsista do projeto, adicionando ou retirando plaquinhas da  barra de vida.   Escolhido o elemento chave da missão, que no caso da Praça é uma carta, o  aluno passava para o minigame que apresenta um desafio a ser resolvido. Os  pesquisadores dirigiam o aluno que estava no papel de jogador para o cartaz do  minigame, o qual continha uma sequência de elementos incompleta, a qual necessitava  ser completada pelo jogador. O jogador deveria fazer a pose indicada no cartaz e  correspondente à carta faltante na sequência apresentada.  A Figura 2 presenta a  interface proposta para o minigame de sequenciação, bem como a equipe atuando na  simulação do jogo. O cartaz foi elaborado com peças coladas com velcro, de forma que  a cada simulação uma nova sequência pudesse ser apresentada, reposicionando as  cartas.     Figura 2: Visão da aluna jogando o minigame        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   162        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015     Ao desvendar a sequência correta dos elementos do minigame, o jogador recebia  pontos que deveriam ser apresentados no cartaz da barra de vida e a carta para ser fixada  (com velcro) junto à Escola no cenário da cidade, simbolizando que este desafio do jogo  tinha sido cumprido com sucesso.   Com o propósito de avaliar a arte do jogo, foram apresentadas algumas  alternativas de personagens para o Carteiro. Estas consistiam em personagens com  fisionomia de animais (Figura 3 e Figura 4) e outras com formas humanas (Figura 5 e  Figura 6). Utilizou-se por estratégia realizar uma votação entre os alunos para definir  qual tipo de personagem mais os agradava.                                                     Figura 3: Coelha carteira                               Figura 4: Urso Carteiro                        Figura 5: Carteira              Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   163        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015                          Figura 6: Carteiro      4 RESULTADOS E DISCUSSÃO  As oficinas ocorreram no primeiro semestre de 2015, com turmas de alunos do terceiro  ano do ensino fundamental, com idades entre 7 e 9 anos, nas escolas Escola Básica  Municipal Gaspar da Costa Morais - Itajai/SC e Centro Educacional Municipal  Presidente Médici - Balneário Camboriú/SC. Dentre os 48 alunos participantes, existiam  alguns com necessidades especiais, como: Síndrome de Asperger (autismo), deficiência  intelectual e outras alterações cognitivas que podem dificultar o entendimento de  atividades escolares.     As oficinas contaram com os pesquisadores do projeto e dos acadêmicos  bolsistas, que realizaram atividades de observação, orientação e também de engine  humana. Em cada uma das escolas, realizou-se uma seção da oficina com a participação  de todos os alunos, ora no papel de jogador, ora no de engine humana, ou seja,  realizando as atividades que serão feitas pelo computador no jogo educacional digital.  Durante a execução da oficina, observou-se a reação das crianças em termos de níveis  de interesse, suas sugestões e os potenciais educacionais com relação a ideia de jogo.   O design participativo configurou-se por meio da validação da engine do jogo  pelo seu público alvo. Os alunos como sujeitos participantes da pesquisa, além de  atuarem no jogo, foram observadores do funcionamento proposto.  Após simular várias  vezes o jogo, (fazendo gestos, segurando folhas e realizando algumas ações) como se  fossem eles mesmos os recursos do computador, estes tiveram um momento para expor  suas ideias e análise crítica.   As crianças jogaram muito atentas e todas estavam muito interessadas em  participar, fazendo com que atrapalhassem por vezes os colegas enquanto estavam  escolhendo a carta ou segurando a carta. Quase todas as crianças participaram, apenas  uma criança com deficiência Mental não quis participar da oficina, sua deficiência  dificultou o entendimento dele sobre o jogo. De maneira geral os alunos demonstraram  estar se divertindo com a brincadeira, a grande maioria achou muito fácil de descobrir a  sequência do minigame mesmo que as sequências fossem alteradas e o grau de  dificuldade fosse aumentado.   Os alunos gostaram da jogabilidade pois acharam que é fácil realizar o  movimento e o jogo executar a ação. Além disso também gostaram da mecânica, pois  tiveram a experiência de se colocar no “lugar do computador”. Muitos acharam os  cenários muito interessantes e organizados. Todos perceberam que o carteiro pode  coletar tanto itens ruins como itens bons, sendo que os bons aumentam a vida e os ruins  diminuem. Outras ideias partiram das crianças: sugeriram colocarmos uma onça para     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   164        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 158-164 Nov/2015     correr atrás do Carteiro e colocar bicicleta ou skate para ajudar o carteiro a fazer as  entregas das cartas.   Na votação realizada para aferir o interesse dos alunos na escolha tipo de  fisionomia do carteiro (animal ou humano) obteve-se como resultado da votação: na  escola Medici os alunos preferiram a fisionomia de humanos e na escola Gaspar os  alunos preferiram a fisionomia de animais. Porém, ao juntarmos os votos das duas  escolas a maior parte dos alunos optou pelas figuras humanas representando os avatares  do jogo, com a justificativa de terem se identificado mais com as personagens humanas  do que com as personagens de animais.   5 CONSIDERAÇÕES FINAIS   As oficinas permitiram avaliar o potencial educacional e de entretenimento do jogo a ser  desenvolvido. Os detalhes de funcionamento de toda a mecânica do jogo foram  colocados à prova durante a simulação. As oficinas tiveram o propósito de contribuir  para que as crianças percebessem de que forma nasce a ideia de um jogo, pois mostra o  seu complexo planejamento e elaboração até a fase final de implementação que resulta  no próprio jogo. Todos perceberam que muito trabalho existe para que um jogo chegue  ao computador. Ficou evidente que os alunos se divertiram muito jogando, participaram  e colaboraram tanto como jogadores como parte de engines humanas, quando se fizeram  passar pelo próprio computador. De uma maneira divertida os alunos foram envolvidos  e contribuíram com sua opinião e sugestões para melhorar o jogo sobre vários aspectos,  desde a arte, as cores utilizadas para o cenário e a escolha dos avatares, algo que é  fundamental quando se fala de Design Participativo. De forma geral o feedback vindo  das crianças foi muito positivo e foi de essencial importância para o término da criação  do jogo.    REFERÊNCIAS   ALVES, A. G. et al., (2015) Exploring Technological Innovation towards Inclusive  Education: Building Digital Games – An Interdisciplinary Challenge. In: Procedia -  Social and Behavioral Sciences. Elsevier, 2015. Access:  http://www.sciencedirect.com/science/article/pii/S1877042815011027. Acessed:  11/mai/2015   ALVES, G. M. T.; AGUIAR, Y.P.C., (2014) Acessibilidade e Tecnologia Assistiva no  Ambiente Educacional: Mapeamento Sistemático. In.: 20ª Workshop de Informática  na Escola (WIE 2014). Disponível em: http://www.brie.org/pub/index.php/wie/article/view/3079/2587. Acesso em: 05/mai/2015.   MELLO, V.; PERANI, L., (2012) Gameplay x playability: defining concepts, tracing  differences. In: Proceedings of SBGames 2012, 2- 4 November  Brasília – DF –  Brazil. 157-164.   ROCHA, H. V. R.; BARANAUSKAS, M. C. C., (2000) Design e avaliação de  interfaces humano-computador. Escola da Computação 2000. São Paulo; IME-USP.   VIGOTSKI, L. S., (1998) Pensamento e linguagem. 2. ed. São Paulo, SP: Martins  Fontes, 1998.   ZHANG, Zhengyou. (2012) Microsoft Kinect Sensor and Its Effect. In: IEEE Computer  Society. 2012. Disponível em:  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6190806. Acesso em: 21  out 2015.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   47        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015     Padronização de Processos: BI e KDD   Nara Martini Bigolin   Departamento da Tecnologia da Informação -Universidade Federal de Santa Maria  98400-000 – Frederico Westphalen – RS – Brazil   nara.bigolin@ufsm.br   Abstract: The Business Intelligence (BI) and the Knowledge Discovery in  Databases(KDD) process are the extraction of interest patterns and  features, which are not explicitly stored in databases. Such discovery may  play an important role to understanding data, capturing intrinsic  relationships between the information. This motivates the study and  development of mechanisms to automates knowledge discovery for  automatic knowledge acquisition. In this context this work presents a  knowledge automatic acquisition cycle,integrating these two processes.    Key-Words: Business Intelligence, Knowledge Management, Knowledge  Discovery in Databases   Resumo:  Inteligência Empresarial e  Descoberta de Conhecimento  em Banco de Dados são os nomes dados a uma vasta categoria de  programas aplicativos e tecnologias usadas para extrair, armazenar, analisar  e transformar grandes volumes de dados, produzindo conhecimento capaz  de auxiliar a empresa a tomar as melhores decisões nos negócios. Isso  motivou o estudo e a aplicação de uma técnica de extração de conhecimento  para aquisição automática de conhecimento. Nesse contexto, este trabalho  propõe um ciclo de aquisição automática de conhecimento, integrando estes  dois processos.   Palavras-chave: Inteligência Empresarial, Gestão de Conhecimento, Descoberta  de Conhecimento.   1.  Introdução   Tanto a inteligência empresarial (Davenport, 1998; Kimball  2010) quanto o processo  de Descoberta de Conhecimento em Banco de Dados (DCBD)  (Fayyad, 1996, Herbert  1998) utilizam técnicas de extração de conhecimento para obter conhecimento  implícito. O DCBD é um conceito utilizado para denominar a exploração de  informações implícitas em grandes volumes de dados. Essa tecnologia surgiu pela  necessidade e pela dificuldade de explorar grandes bancos de dados de empresas. A  inteligência empresarial é o conhecimento e a previsão dos ambientes interno e externo  à empresa, orientando as ações gerenciais, tendo em vista a obtenção de vantagens  competitivas (Choo, 1998). Neste contexto, dois enfoques diferentes, porém  complementares, foram desenvolvidos, na tentativa de solucionar esses problemas: um,  pela comunidade de Banco de Dados e outro, pela comunidade de Inteligência  Artificial. A comunidade de Banco de Dados desenvolveu Sistema de Gerenciamento de  Banco de Dados (SGBD), que tem por objetivo oferecer ferramentas que possibilitam o  armazenamento e a manipulação de grande quantidade de informações estruturada e um     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   48        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015     acesso rápido a elas. A maior preocupação no desenvolvimento deste tipo de sistema é o  aspecto de modelagem dos dados, as linguagens de consulta e a eficiência na  recuperação da informação. A comunidade de Inteligência Artificial interessou-se pela  mineração de dados (extração de informações implícitas a partir de pequenas  quantidades de dados) e a aprendizagem a partir de um pequeno conjunto de  informações.  A combinação dessas duas abordagens originou a área de Descoberta de  Conhecimento em Banco de Dados. As técnicas tradicionais de aprendizagem (em  inglês Machine Learning) descobrem conhecimentos implícitos a partir de dados  extraídos do mundo real, enquanto as técnicas de mineração utilizam dados extraídos de  bancos de dados. No primeiro caso, os dados de entrada para a mineração são  representados em uma estrutura simples, e as informações relevantes são definidas pelo  especialista. Já no segundo caso, além da estrutura e os tipos de dados serem  complexos, o volume das informações é muito grande e, parte deste conjunto, pode ser  irrelevante. Assim, é necessário efetuar dois tratamentos: um, para encontrar um  subconjunto de informações apropriado (limpeza) e outro para adaptar essas  informações em uma estrutura (transformação) aceitável pelas ferramentas de  mineração de dados.     A seleção das informações relevantes é tão importante quanto o reconhecimento  de padrões, pois sem os dados apropriados, dificilmente algum conhecimento útil será  extraído do banco de dados. Para selecionar a amostra adequada é fundamental que haja  um entendimento do domínio da aplicação e um prévio conhecimento dos dados  relevantes, para que se possa estabelecer as metas do processo de descoberta de  conhecimento implícito do ponto de vista do usuário. O segundo tratamento consiste em  simplificar a estrutura complexa dos dados para um formato reconhecível pelas técnicas  de mineração de dados.     Neste contexto, este artigo propõe um ciclo para aquisição automática de  conhecimento baseado no processo de descoberta de conhecimento em banco de dados e  no ciclo de inteligência empresarial. O restante do artigo está organizado da seguinte  forma: na próxima seção são descritos o processo de descoberta de conhecimento e o  ciclo de inteligência empresarial. Na terceira seção, a proposta do ciclo de aquisição  automática de conhecimento é apresentada.  Finalmente, as considerações finais são  discutidas.    2. Processo de Descoberta de Conhecimento e Ciclo de Inteligência  Empresarial   Nesta seção serão descritos os dois processos que aquisição de conhecimento, suas  etapas e funcionamento. Inicialmente, apresentaremos o processo de descoberta de  conhecimento e, após, o ciclo de inteligência empresarial.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   49        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015        Figura 1. Processo de Descoberta de Conhecimento    O processo de DCBD (Fig. 1) (Fayyad, 1996) e o ciclo de inteligência  empresarial (Fig. 2) (Herring 1997) têm o mesmo objetivo, auxiliar na gestão de  informação, através de extração de informações implícitas em grandes bancos de dados.  O processo de descoberta de conhecimento envolve cinco etapas sucessivas: seleção,  processamento e transformação dos dados; mineração de dados; interpretação/avaliação  do conhecimento. Essas etapas podem ser generalizadas em três grandes fases: préprocessamento, mineração e pós-processamento de dados.     O pré-processamento é uma das fases mais demoradas do processo de DCBD,  pois consome cerca de 80 % dos esforços necessários para concluir todo o processo.  Nessa fase são realizadas as tarefas de seleção, de processamento e de transformação  dos dados. A seleção de dados consiste em selecionar os dados relevantes, para resolver  um problema específico. Na etapa de processamento e tratamento de dados, os dados  selecionados devem ser tratados e colocados em uma estrutura apropriada que será  utilizada na etapa de mineração de dados.     A mineração de dados consiste em extrair modelos a partir dos dados  selecionados e processados através do uso de algoritmos de aprendizagem. Esses  algoritmos permitem a classificação e a caracterização de um conjunto de dados. O  resultado desta etapa é um modelo de conhecimento, que pode ser na forma de grafos,  de árvores de decisão ou de regras do tipo se premissa então conclusão (Han, 2011).     O pós-processamento é realizado através das etapas de avaliação e apresentação  dos padrões, que são responsáveis pela identificação e análise dos padrões interessantes  que representam informação implícita, bem como, a forma como esta informação será  apresentada ao usuário. A interpretação/validação formata o conhecimento obtido e  apresenta ao usuário ou reutiliza no sistema.    Para Herbert (1998) “inteligência empresarial é o conhecimento e previsão dos  ambientes interno e externo à empresa, orientando as ações gerenciais, tendo em vista a  obtenção de vantagens competitivas”.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   50        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015      A inteligência empresarial vem como uma tecnologia inovadora na  implementação de soluções nesta área, sendo fundamentada em benchmarking e em  pesquisa acadêmica. Benchmarking é o processo contínuo de comparar resultados de  uma empresa, através de indicadores que irão ajudar a empresa a implementar ações que  melhorem suas performances. A inteligência empresarial segue a linha do data  warehouse evolutivo.     A inteligência empresarial segue três princípios básicos: modularidade, alta  orientação ao negócio do cliente e trabalho cooperativo. O conceito de modularidade é  utilizado em todos os níveis da inteligência empresarial. É a capacidade de dividir em  módulos integráveis formadores do data warehouse evolutivo, possibilitando que sejam  desenvolvidos em processos separados. A inteligência empresarial é orientada ao  negócio do cliente, oferecendo aos tomadores de decisões uma visibilidade oportuna e  consistente dos pontos - chaves dos seus negócios, alcançando todas as funções  empresariais de sua empresa de forma integral, clara e objetiva. Para permitir uma  melhor aplicação e concentração de recursos humanos e de tempo, o trabalho  cooperativo vem com responsabilidade e requisitos bem definidos dos processos. O  envolvimento do cliente é essencial no desenvolvimento de projetos de inteligência  empresarial e a participação ativa do cliente sustenta a objetividade e a transparência da  tecnologia de inteligência empresarial.       A tecnologia da informação auxilia no sentido de possibilitar que a partir de  dados, obtém-se informações, seguido de conhecimento para auxiliar nas  ações a serem tomadas pela empresa.        Figura 2.  Fluxo de informações    Este fluxo de informação é obtido através do uso do ciclo de inteligência  empresarial. Este ciclo, adaptado por Herring 1997 é apresentado na abaixo.                 Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   51        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015                                     Figura 3. Ciclo da Inteligência Empresarial       O ciclo de inteligência empresarial (Terra 2000) é composto de quatro fases:  planejamento e coordenação; coleta, processamento e armazenamento; análise e  validação da informação; disseminação e utilização.    O planejamento e coordenação é a fase na qual são definidos: as necessidades  de informatização da empresa, o banco de dados e as funcionalidades do sistema, assim  como, os produtos que utilizarão a inteligência empresarial.    A coleta, processamento e armazenamento da informação envolvem a busca  de fontes de informações para o atendimento às necessidades de estratégia do negócio.    Na análise e validação da informação as informações coletadas na etapa  anterior, muitas delas sem uma aparente conexão entre si, são analisadas nesta etapa  pelas redes de especialistas da área, com o objetivo de verificar a consistência das  informações, estabelecer relações e avaliar o impacto destas para a organização.     A disseminação e utilização da inteligência encerram o ciclo de inteligência  empresarial, quando disponibilizam o resultado do processo para os usuários da  inteligência. As mudanças ocasionadas pela tecnologia usada para gerar, disseminar,  acessar e usar a informação demanda por habilidades e competências relacionadas ao  acesso, uso e disseminação da informação (Paletta, 2014).     Na seção seguinte, é proposto e descrito o ciclo de aquisição automática de  conhecimento que foi baseado no processo de descoberta de conhecimento em banco de  dados e no ciclo de inteligência empresarial.   3. Ciclo do processo de aquisição automática   O ciclo foi baseado no processo de descoberta de conhecimento proposto por Fayyad,  (1996) e pelo ciclo de Inteligência Empresarial adaptado por Herring (1997). O objetivo  final é alimentar um banco de dados com conhecimento adquirido do próprio banco de  dados. O ciclo tem oito fases: seleção dos dados, limpeza dos dados, tratamento dos  dados, extração do conhecimento, avaliação do conhecimento, interpretação do  conhecimento, modelagem do conhecimento e inclusão no banco de dados.   Decisores e  Usuários da  Informação   Recursos,  Competências e  Métodos   Base de  Conhecimento e  Redes de   Avaliação do  Processo   Análise e Validação   Análise e Validação   Coleta, Processamento e  Armazenamento   Disseminação e  Utilização     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   52        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015      O processo inicia pela seleção dos dados, a qual é realizada pelo auxílio da  linguagem de consulta do Sistema Gerenciador do Banco de Dados vinculado à  aplicação. Nesta etapa são selecionados os dados relevantes para fazer a extração  posterior do conhecimento; a limpeza dos dados consiste em retirar os valores  inválidos, incorretos e irrelevantes para a extração de conhecimento; a transformação  dos dados tem o objetivo de formatar os dados numa estrutura compatível com as  ferramentas de extração de conhecimento, que aceitam somente formato simples do tipo  atributo/valor e com valores discretizados; a extração é responsável pela mineração de  dados e extração dos padrões a partir dos dados fornecidos; a avaliação de  conhecimento tem o objetivo de analisar o que foi gerado, se o mesmo é válido e  relevante; na interpretação, o auxílio de um especialista do domínio é requerido, para  classificar o conhecimento obtido em comprovado, novo ou irrelevante; uma vez o  conhecimento validado, a modelagem deste conhecimento é efetuada para a inserção  dentro do banco de dados. Nesta etapa uma metodologia de modelagem deve ser  utilizada e, finalmente, na fase de inserção, o banco de dados é alimentado com novo  conhecimento descoberto.     Figura 4. Ciclo da Aquisição Automática de Conhecimento       No contexto de uma análise comparativa entre as três metodologias (o processo  de descoberta de conhecimento em banco de dados, o ciclo de inteligência empresarial e  o ciclo de aquisição automática de conhecimento), pode-se afirmar que a última  permite, devido ao nível de simplicidade e detalhamento, que usuários não especialistas  de informática possam extrair conhecimento a partir  de bancos de dados.    Abaixo, segue o quadro das fases do ciclo de AAC, do processo de DCBD e do  ciclo de Inteligência Empresarial.            Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   53        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015     Tecnologias Etapas   Ciclo de AAC Domínio da  Aplicação   Seleção, Limpeza  e Transformação   Extração e  Avaliação do   Conhecimento   Modelagem e  Inclusão no Banco  de Dados   Processo de  DCBD    Seleção e  Processamento  Tratamento   Mineração  Análise/   Interpretação       Ciclo de  Inteligência  Empresarial   Planejamento e  coordenação   Coleta,  Processamento e  Armazenamento    Análise e  Validação da  Informação   Disseminação e  Utilização da  Inteligência   Tabela 1: Quadro comparative       O processo de descoberta de conhecimento se mostra mais restrito, comparado  aos dois ciclos. O ciclo de Inteligência Empresarial tem seu foco na organização dos  processos de uma empresa, enquanto que o ciclo de aquisição automática de  conhecimento se situa na exploração das informações utilizando as tecnologias de  informações disponíveis.   4. Conclusão   Neste trabalho foi proposto um ciclo de aquisição automática de conhecimento e  validada com cinco estudos de caso em domínios bem distintos. Este ciclo possibilita  uma melhoria na qualidade de prestação de serviços das empresas, independente de seu  domínio de atuação. Comprovou-se também que em todos os estudos de caso obteve-se  conhecimento novo, relevante e muito importante para a tomada de decisão.    Outra conclusão importante é que a partir dos testes realizados, o ciclo de  aquisição de conhecimento permitiu extrair informações ocultas e extremamente  importantes para a tomada de decisões, que com a utilização de uma ferramenta  convencional e experiência de especialista não seria possível de obter-se.     A maior contribuição deste trabalho foi a proposta de um ciclo simples e capaz  de ser usado em qualquer domínio de aplicação e por profissionais de qualquer área.  Neste contexto, a aplicabilidade do ciclo de aquisição de conhecimento em quase todos  os domínios de aplicação, torna esta tecnologia como a mais promissora do momento e  com sucesso garantido para todas as empresas.    Como trabalhos futuros, se pretende modelar, através da metodologia UML,  todos os conhecimentos adquiridos e inseri-los em um banco de dados, construindo  assim um banco de conhecimento. Todo o conhecimento adquirido e não armazenado  pode ser perdido. Uma vez armazenado num banco de dados, pode-se utilizar como  fonte de novas descobertas de conhecimento. Pretende-se também integrar as quatro  etapas no planejamento estratégico de uma empresa.           Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   54        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 47-54 Nov/2015     Referências Bibliográficas  Choo, C. W. “The knowing organization: how organizations use information to  construct meaning, create knowledge, and make decisions”. Oxford University Press,  1998.   Davenport T.H. and Prusak, L. “Conhecimento Empresarial: como as organizações  gerenciam o seu capital intelectual”. 5 ed. Rio de Janeiro, Campus, 1998,   Fayyad, U. et al.. Knowledge discovery and data mining: towards a unifying  framework. In: Proceedings of the 2nd International Conference on Knowledge  Discovery & Data Mining. Editors: Simoudis, E.; Han, J.; Fayyad, U. August 1996.    Han J., Kamber M. and Pei J. Data Mining: Concepts and Techniques, 3rded. The  Morgan Kaufmann Series in Data Management Systems.  Morgan Kaufmann  Publishers, July 2011.    Herbert, A. Edelstein. Introduction to Data Mining and Knowledge Discovery, 2º  Edition, Two Crows Corporation, 1998.   Herring, J. P. “Producing CTI that meets management meeds and expectations” SCIP  Competitive Technology Intelligence Symposium. Boston 1997.   Kimball R. Ross M.,Thornthwaite W. Mundy J. Becker B.  The Kimball Group Reader:  Relentlessly Practical Tools for Data Warehousing and Business Intelligence. 2010.   Paletta, C.F. and Maldonado E. P. “Inteligência Estratégica e Informação Perfil  profissional na Era da WEB 3.0”. Revista Inteligência Competitiva. São Paulo, v. 4, n.  2, p. 1-10, abr./jun. 2014.     Terra. J C. “Gestão do conhecimento: o grande desafio empresarial”.  São Paulo:  Negócio Editora, 2000.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   95        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015     Perspectivas da implantação de uma rádio escolar: uso de  equipamentos tecnológicos e o desenvolvimento de habilidades   Anderson Daniel Stochero1, Lauren Linck Nilson2   1 Pós-graduando em Gestão estratégica e de marketing e, graduado em Administração  pelo Instituto Cenecista de Ensino Superior de Santo Ângelo (IESA),  Graduando em   Tecnologia em sistemas para a internet pelo Instituto Federal Farroupilha (IFF), campus  Santo Ângelo – RS.    anderson_stochero@yahoo.com.br  2 Mestranda em Ensino Científico e Tecnológico, e graduada em Ciências Biológicas  pela Universidade Regional Integrada do Alto Uruguai e das Missões (URI), campus   Santo Ângelo, Pós-graduada em Interdisciplinaridade na Educação Básica, pela  Universidade Federal da Fronteira Sul (UFFS), campus de Cerro Largo – RS   laurenlincknilson@gmail.com     Abstract. This article discusses the effects of technology in the process of  construction of knowledge through the implementation project of a school  radio in São Miguel das Missões – RS. The methodology consists of a  questionnaire to students participating in the project in order to get a  perspective on the effects in the implementation process of this project. As a  result it was possible to identify a positive contribution towards the  development of skills and the expansion of knowledge.     Resumo. Este artigo aborda os efeitos da tecnologia no processo da  construção do conhecimento através do projeto de implementação de uma  rádio escolar no município de São Miguel das Missões – RS. A metodologia  desenvolvida consiste na aplicação de questionário aos alunos participantes  do projeto a fim de obter uma perspectiva acerca dos efeitos no processo de  implementação deste projeto. Como resultado foi possível identificar a  contribuição positiva em relação ao desenvolvimento de habilidades e a  expansão de conhecimentos.   1. Introdução     Atualmente, devido a rápida expansão tecnológica de modo acelerado, a qual  abrange a sociedade em praticamente sua totalidade, faz-se necessário que a escola  também se atualize frente a essas tecnologias a fim de acompanha-la. Neste sentido,  passou a ser estudado inúmeras propostas de implantação de ferramentas alternativas no  universo escolar, com o objetivo de inovar as aulas e o dia a dia tornando a busca pelo  saber mais agradável e prazerosa tanto para os educandos quanto para educadores.   Dentre as diversas propostas que alcançam o ambiente educacional, a que o  presente trabalho pretende destacar diz respeito a implantação de uma rádio, transmitida  somente nas dependências internas da escola. Tendo a necessidade do uso de softwares,  gratuitos e demais equipamentos técnicos e eletrônicos, os quais foram adquiridos pela  escola a fim de promover o desenvolvimento das atividades diárias da rádio. Nesse     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   96        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015     sentido, os softwares podem ser caracterizados, segundo Velloso (2011), como os  programas que permitem atender às necessidades dos usuários. Enquanto os hardwares  são os equipamentos propriamente ditos, bem como seus periféricos de entrada e saída,  a máquina e seus componentes físicos.    O uso dos softwares de acordo com Pressman (2011) abrange programas  executáveis em praticamente qualquer mídia eletrônica, afetando praticamente todos os  aspectos da vida de um indivíduo como no comércio, cultura e cotidiano. No caso deste  estudo, os softwares contribuem para o desenvolvimento das atividades da rádio  possibilitando a criação e veiculação de mídias criadas pelos alunos em conjunto com os  equipamentos necessários.    Nesse contexto, se faz necessária a utilização de outros recursos além dos  softwares específicos tais como o Audacity, caracterizado como um editor de áudio  conforme apresentou Gambaro (2010) em seu tutorial. E o ZaraRádio, que de acordo  com manual específico, se caracteriza como um programa reprodutor de áudio e não  para a transmissão via internet, este programa tem por finalidade a automação e  transmissão de mídias sonoras. Também se faz necessário contar com o suporte de  hardwares a fim de possibilitar o melhor desenvolvimento das atividades da rádio  escolar.    Dentre os recursos que se fazem imprescindíveis para o bom funcionamento da  rádio podemos destacar alguns equipamentos tais como: Computador com drive de  reprodução de CD, DVDs e pen drive equipado com os softwares necessários; Internet;  Headset (fones de ouvido e microfones); Caixas acústicas; Mesa de som e Amplificador  de áudio (RATTON, [201-]).   Sendo possível considerar as tecnologias, produtos da sociedade e da cultura,  estas são criadas, imaginadas, fabricadas e reinterpretadas durante o seu uso pelos  homens. Porém o seu sentido reside nas intenções dos usuários que as trocam e  formulam, permitindo inovações, modificações ou adaptações do uso das ferramentas  tecnológicas aos mundos próprios dos utilizadores (BIANCO, 2010).    Com essas modificações na rotina escolar, o ambiente estudantil, segundo Citelli  (2000), pode ser repensado, como um espaço midiativo cada vez mais interligado com  as novas linguagens, e responsável por contribuições nas transformações científicas,  tecnológicas, culturais e de comportamento.   Por esse motivo diversos pesquisadores e instituições acreditam que o uso de  tecnologia tem uma contribuição bastante significativa de modo que todos tenham  acesso universal a educação, a qualidade de ensino e aprendizagem (UNESCO, 2014).   A partir desta contextualização inicial evidenciou-se a possibilidade de  compreender a importância do uso de softwares e equipamentos de mídia na  implantação do projeto Rádio Escolar, o que contempla a formação do jovem na sua  totalidade. Assim, este artigo tem por objetivos: (i) apresentar uma reflexão sobre as  experiências vivenciadas na implantação da Rádio Escolar fazendo uso de mídias  tecnológicas em uma escola de ensino médio da rede pública do município de São  Miguel das Missões, RS; (ii) descrever os avanços e dificuldades encontrados pelos  alunos durante o desenvolvimento das atividades da Rádio.     2. Metodologia     Para realizar os propósitos deste estudo foram elaboradas sete questões  distribuídas em um questionário referentes a implantação da Rádio Escolar durante o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   97        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015     recreio de uma Escola do Município de São Miguel das Missões – RS , sendo esta uma  atividade coordenada em conjunto por professores e alunos.   Deste modo destaca-se a importância da interação dos jovens com as  tecnologias, bem como para com a pesquisa quando considerada como um princípio  educativo e científico e, é através dessa interação escolar com a educação que segundo  Pedro Demo (1998) que os educandos se tornarão cidadãos e que sua aprendizagem será  mais flexível, eficaz e autônoma.    E, através dos questionamentos se torne possível construir estratégias de  aprendizagem e estilos motivacionais adequados enfatizando a educação como processo  de formação da competência histórica humana. Assim, ensino e práticas pedagógicas  diferenciadas andam juntos e o trabalho como um todo pode se caracterizar como  pesquisa em sala de aula.    O método usado para análise dos dados baseia-se em Bardin (2011) que divide o  processo em três etapas, ou seja, etapa 1. Pré-análise; 2. Exploração do material e 3.  Tratamento dos resultados, a inferência e a interpretação.   A pesquisa se classifica como qualitativa, pois pretende interpretar e  compreender como os jovens veem os benefícios da implantação da rádio na escola bem  como seu aprendizado e a sua repercussão em suas vidas.   Os estudantes participantes da pesquisa foram identificados com a letra A  seguidos por um número (Exemplo: A1, A2, A3...) e, responderam de modo espontâneo  a oito questões relativas ao processo de implantação da rádio. Correspondem ao grupo  de alunos responsáveis pela idealização do programa de Rádio na escola denominado de  “Rádio Pátio”, são cinco alunos do segundo ano do Ensino Médio.   Considerando que este artigo é decorrente de uma atividade pedagógica e,  baseando-se nos princípios éticos da pesquisa, serão omitidos os nomes dos alunos da  escola na qual foi desenvolvido o trabalho.     3. Análise de dados     A primeira pergunta teve por objetivo verificar, na opinião dos participantes,  quais as possíveis contribuições que a implantação da rádio na escola proporcionou no  se próprio processo de formação. Entre os participantes respondentes, 03 participantes  reconhecem que a participação nas atividades da rádio contribui para o desenvolvimento  de novas habilidades, bem como a aquisição de novos conhecimentos, conforme  mostram os seguintes depoimentos:     A implantação da rádio expandiu meus conhecimentos para áreas de que eu  nunca tinha me interessado antes, com isso, estou buscando mais  aprendizagem sobre o assunto (A1).  Contribuiu muito em meus conhecimentos, pois já penso em uma profissão  que vai envolver um pouco isso de falar em público, e também é bom para  irmos aprendendo várias coisas que podem ser bem aproveitadas mais  futuramente (A3).  [...] aprendi como realmente funciona uma rádio e adquiri mais  conhecimentos de informática (A4).      Essa afirmação é reforçada por Kenski (2003) ao afirmar que o homem transita  culturalmente mediado pelas tecnologias que lhe são contemporâneas, fazendo com que  estas transformem suas maneiras de pensar, sentir, agir. Mudando também suas formas  de se comunicar e de adquirir conhecimentos.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   98        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015      Após essa possibilidade de mudança 02 alunos afirmam que a participação na  rádio pode contribuir para suas futuras profissões, e também pode exercer alguma  influência sobre o desenvolvimento de habilidades, ao afirmar que: “Me fez ter menos  vergonha de falar em público, mesmo sendo só a voz (A4)”.    Ao serem questionados sobre a possibilidade de dar continuidade neste projeto,  se aperfeiçoando através de cursos e também na possibilidade de tornar esta sua  profissão, todos os alunos manifestaram desejo de continuar com o projeto, o que  denota o quanto este está sendo importante para o seu crescimento pessoal. Porém, até o  presente momento não pensaram, nessa especificamente como uma futura profissão, de  acordo com depoimentos:     A princípio não, pois tenho outras ideias de profissão, e a rádio está  servindo como um aprendizado tanto para mim como para meus colegas  (A3).  Dar continuidade no projeto na escola sim, mas nunca pensei em tornar esta  a minha profissão (A4).      Quando questionados se tiveram facilidade para aprender a manusear o  programa da rádio, todos os participantes responderam que sim. E, essa afirmação se  justifica pelo fato de que os estudantes atuais já nasceram num universo digital,  conectados a internet e dispositivos móveis, pois fazem parte da chamada geração de  nativos digitais.   O contexto apresentado acima faz menção ao universo o qual os nativos digitais  estão adaptados, pois tem a capacidade de realizar várias tarefas ao mesmo tempo,  tratando-se de uma geração que integra a mídia cada vez mais à sua vida (ALVES,  2007). Sendo assim, é fundamental compreender que essa geração estabelece diálogos  com grande facilidade, o que permite sua fácil interação com os elementos tecnológicos.   Desse modo, para a implantação do programa de rádio escolar, uma sala foi  equipada com os materiais adequados para o funcionamento da mesma. Foi  acondicionado no local, uma mesa de som, caixa de som, computador com os softwares  de execução: Audacity e ZaraRádio, bem como os demais matérias utilizados para a  execução do programa de rádio durante o recreio escolar.   O Programa ZaraRádio é um software gratuito e completo que tem por  finalidade a automação das emissões de rádio, caracterizando-se como um programa  robusto, estável e com inúmeras possibilidades para a emissão automatizada de uma  estação de rádio, bem como ferramenta de auxilio para o locutor, fácil e rápida que o  ajuda no trabalho diante do microfone (FRANCISCO; SOBRAL, 2010).   Porton (2014) ainda destaca esta ferramenta como um software ideal para o  desenvolvimento de uma rádio escolar, pois além de ser gratuita oferece inúmeros  recursos de manipulação.   Enquanto isso, como complemento para este programa se faz importante à  utilização do software Audacity, um software livre, ou seja, que possui seu código-fonte  aberto e possível de modificações, de forma que qualquer pessoa pode fazer downloand  e usar o programa livremente, bem como modificar seu código-fonte. Além disso, o  usuário pode encaminhar sugestões para os desenvolvedores oficiais, e até mesmo  desenvolver ou aprimorar ferramentas, as quais poderão ser incorporadas em novas  versões. Este software possibilita um modo simples e rápido à produção de áudio,  através de uma plataforma simples e barata para pequenas peças sonoras. Facilita o  processo, para pessoas que queiram iniciar na edição de áudio e desejam aprender as  funções mais comuns em qualquer software. (GAMBARO, 2010).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   99        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015      O Audacity é um software de gravação e edição de voz, permitindo ao usuário  manipular ondas de áudio digital. Além de gravar som diretamente do programa,  importa muitos formatos de som. Sendo necessário apenas um microfone conectado ao  computador para que as edições possam ser feitas (PORTON, 2014).    Quando questionados sobre as dificuldades que enfrentaram no processo 01  aluno afirmou que sentiu dificuldades em operar a mesa de som. Já 03 alunos afirmaram  sentir dificuldade em superar a timidez conforme relato: “Achei mais difícil falar no  microfone para a escola inteira ouvir, pois mesmo que ficamos dentro de uma sala  reservada, ainda temos receio de errar alguma coisa (A3)”.   Desse modo a rádio tem a função de ressaltar características específicas do  trabalho com a mídia, que remetem a questões relativas a aproximação dos gêneros  textuais da esfera da mídia do ambiente discursivo escolar, visto que ampliam a visão de  mundo dos estudantes, acostumados na escola a associar o ato de ler apenas à leitura de  textos do ambiente discursivo literário, adquirindo assim capacidade de transmitir  informações com segurança e confiabilidade, bem como uma interação entre diferentes  públicos (BALTAR et al., 2006).     Sobre a motivação para a participação do projeto da rádio, 03 alunos  associaram a sua participação na rádio como forma de interação e diversão e, outros 02  afirmaram que o seu objetivo ao integrar a equipe foi adquirir novos conhecimentos,  conforme relato: “Porque é algo bom, interagir com as pessoas, tornar o intervalo mais  divertido, aprender coisas novas fora da sala de aula (A4)”.    De acordo com as características sociais e culturas, atualmente as tecnologias  diferenciam-se por contribuírem no processo de ampliação da capacidade intelectual do  indivíduo, possibilitando centralizar conhecimentos e informações em uma rede técnica  informatizada e posteriormente utilizar tais conhecimentos no processo de criação de  novos conhecimentos e mecanismos para processar informações. (BIANCO, 2010).   Já, ao serem questionados sobre o motivo da proposta de implementação de uma  Rádio interna na escola, todos os alunos relataram sentir a necessidade de ter uma maior  interação entre os alunos no horário do recreio. E, outros 03 alunos destacaram que é  muito bom usar esse espaço como sendo um instrumento de troca de informações, de  acordo com os relatos:      Interação em geral com os alunos, informações e diversão (A1).  Porque é uma certa forma de interação com os alunos da escola, algumas  vezes notamos que muitos não sabem as informações que são passadas pelos  professores (A3).     O questionamento que se faz pertinente é de como integrar valores culturais  existentes na história do rádio com as tecnologias emergentes. Tem-se a consciência de  que este veiculo de informação continuará a ser sonoro porém com funções multimídia,  desta forma, fazendo-se necessário agregar uma linguagem flexível a fim de que se  torne possível diversificar conteúdos, chegando ao inevitável caminho da integração da  programação com os novos formatos de distribuição, capazes de compatibilizar voz,  dados e imagens. (BIANCO, 2010).     Nesse contexto a programação da rádio é criada pelos alunos e divide-se em  várias etapas, dentre as quais a hora do recado, músicas variadas e, informativos sobre a  rotina da escola. Isso ocorre através das notícias divulgadas na rádio, na qual os  adolescentes transmitem informações de interesse do grupo de alunos e professores.  Então, por meio da transmissão por altofalantes, os alunos e equipe de professores e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   100        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015     funcionários tomam conhecimento do dia a dia escolar, bem como tem acesso a material  atualizado (ASSUMPÇÃO, 1999).   Outro fator que se sobressai no relato dos alunos é o fato de terem como objetivo  a inovação na escola através de atividades diferenciadas e que envolvem os demais  alunos e professores da escola, ao afirmar que:      Nosso objetivo era fazer algo que inovasse com a escola. Algo diferente onde  podíamos ter mais interatividade com os alunos, animando o recreio de  todos (A2).      As rádios escolares caracterizam-se então por ser instrumentos de interação  sociodiscursiva entre os integrantes da comunidade escolar. Deste modo os programas  produzidos para a rádio são elaborados por estudantes e professores e, eventualmente,  contam com a participação da direção, quando em decorrência de alguma atividade  especial (datas comemorativas). E, um fator de fundamental importância é o fato de que  apesar de ser transmitida apenas nas dependências da escola, os temas abordados vão  além dos limites escolares, buscando contribuir para que os ouvintes e produtores  possam acessar o discurso de outras esferas da sociedade (BALTAR, 2006).     4. Considerações finais     Esse trabalho apresenta uma reflexão sobre os benefícios da temática de  implantação de um programa de rádio nas dependências de uma escola pública, fazendo  uso de um conjunto de materiais, que possibilita a veiculação de informações  diariamente durante os intervalos das aulas. Para tanto, com base nos dados obtidos foi  possível elaborar as conclusões apresentadas a seguir.   Sobre o uso de softwares gratuitos e demais equipamentos midiáticos  necessários para o efetivo funcionamento de rádios escolares constata-se que estes são  de fundamental importância para o desenvolvimento de um trabalho bem elaborado e  organizado, possibilitando que os alunos tenham acesso a tecnologia durante a execução  do programa na escola.   Outro aspecto relevante foi o fato de os alunos terem demonstrado facilidade no  manuseio do software e demais equipamentos, mesmo sem ter um contato prévio com  tais materiais. E isso se deve ao fato destes estarem inseridos no contexto tecnológico,  sendo conhecidos como nativos digitais.    Uma conclusão teórica mostra que o fato de existir inúmeras possibilidades para  o uso de tecnologias na escola, permite aos alunos desenvolver habilidades, as quais  poderão ser utilizadas em seu futuro, ou mesmo servir para a superação de dificuldades,  como por exemplo, de oratória e aquisição de novos conhecimentos. Permitindo, assim,  que o aluno busque novas fontes de informações, adquirindo autonomia na sua  aprendizagem, ou seja, desenvolve sua capacidade de interpretar e transmitir de maneira  formal e informal as informações obtidas para os programas diários da rádio.    Percebe-se que é necessário que a escola deixe de ser um espaço fechado para  discussões e projetos diferenciados de ensino para que se torne um local de aprendizado  compatível com o atual contexto tecnológico, através do uso de ferramentas adequadas.      5. Referências       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   101        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 95-101 Nov/2015     ALVES, L. R. G. Nativos Digitais: Games, Comunidades e Aprendizagens. In:  MORAES, U. C. de. (Org.). Tecnologia Educacional e Aprendizagem: o uso dos  recursos digitais. Livro Pronto: São Paulo, 2007, v. , p. 233-251   ASSUMPÇÃO, Z. A. de. Radioescola: uma proposta para o ensino de primeiro grau.  São Paulo: Annablume, 1999.    BALTAR, M.; GASTALDELLO, M. E. T.; CAMELO, M. A.; LIPP, B. M. Rádio  escolar: uma ferramenta de interação sociodiscursiva. Rev. Brasileira de Linguística  Aplicada, v. 8, n. 1, 2008.   BARDIN, L. Análise de conteúdo. São Paulo: Edições 70, 2011.    BIANCO, N. R. D. Promessas de mudanças na programação e na linguagem das  emissoras digitalizadas. In: CARVALHO, J. M. de; MAGNONI, A. F. (orgs.). O  novo rádio: Cenários da radiodifusão na era digital. São Paulo: Senac de São Paulo,  2010.   CITELLI, A. Comunicação e educação: A linguagem em movimento. São Paulo: Senac,  2000   DEMO, P. Educar pela pesquisa. 3. ed. Campinas : Autores Associados, 1998   FRANCISCO, D. J.; SOBRAL, S. B. D. S. Rádio educação: a trajetória do programa  rádio EDUC-SE. Revista EDaPECI. ano 2.n.5. 2010. Disponível em:<  http://www.edapeci-ufs.net/revista/ojs-2.2.3/index.php/edapeci>. Acesso em: 18.out.  2015.   GAMBARO, D. Tutorial do audacity: uma visão geral para amadores e iniciantes. São  Paulo: Universidade Anhembi Morumbi, 2010.   KENSKI, V. M. Tecnologias e Ensino Presencial e a Distância: Práticas Pedagógicas.  São Paulo: Papirus, 2003.   PORTON, S. de S. A. de B. Prática edocomunicativa no espaço escolar: construindo  ecossistemas comunicativos com a linguagem radiofônica. 2014. 215 p. Dissertação  (Mestrado em Educação). Universidade do Estado de Santa Catarina – UDESC, SC,  Florianópolis, 2015.   PRESSMAN, R, S. Engenharia de Software: Uma abordagem profissional. New York:  McGrow-Hill, 2011.   RATTON, M. Manual de estúdio. [201-] Disponível em:<  http://dirsom.com.br/index_htm_files/Manual%20de%20Estudio.pdf >. Acesso em:  17. Out.2015.   UNESCO. TIC na educação no Brasil. Disponível em: <  http://www.unesco.org/new/pt/brasilia/communication-and-information/access-toknowledge/ict-in-education/>. Acesso em: 28.out.2014   VELLOSO, F. de C. Informática: conceitos básicos. 8 ed. Rio de Janeiro: Elsevier,  2011.    ZARARADIO. Manual Zararadio. Disponível em:<  http://www.zarastudio.es/downloads/manual2_en.pdf>. Acesso em 17.out.2015.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   132        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     Predição do tempo de vida de baterias de Lítio Íon Polímero  utilizando o Modelo Rakhmatov e Vrudhula    Luana Fransozi1, Marcia de F. Brondani1, Airam Sausen1, Paulo S. Sausen1   1Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Programa de PósGraduação Stricto Sensu em Modelagem Matemática, Departamento de Ciências Exatas   e Engenharia, Rua Lulu Ilgenfritz, 480, Bairro São Geraldo, 98700-000 – Ijuí, RS,  Brasil.   Luh.fransozi@hotmail.com, marciabrondani@yahoo.com.br,  {airam,sausen}@unijui.edu.br      Abstract. In this work, the mathematical modeling of Lithium Ion Polymer  batteries lifetime is carried out. For this study, it is used an analytical model,  called Rakhmatov and Vrudhula model (RV). This model has two empirical  parameters which are estimated using experimental data from a test bed. The  simulations are performed using the Matlab computational tool, adopting a  vast array of discharge currents. The model validation consists of a  comparative analysis between the simulated results and the experimental data.  The results have shown that the RV model has good accuracy, obtaining an  average error of 1.08%.    Resumo. Neste trabalho é realizada a modelagem matemática do tempo de  vida de baterias de Lítio Íon Polímero (Li-Po) a partir do modelo analítico  denominado Rakhmatov e Vrudhula (RV).  Este modelo possui dois  parâmetros empíricos, os quais são estimados utilizando dados experimentais  de uma plataforma de testes. As simulações são realizadas na ferramenta  computacional Matlab, adotando um amplo conjunto de perfis de descargas.  A validação do modelo consiste em uma análise comparativa entre os  resultados simulados e os resultados experimentais. Os resultados mostram  que este modelo apresenta resultados satisfatórios, obtendo um erro médio de  1,08%.    1. Introdução  O crescente avanço em tecnologia móvel tem facilitado e intensificado o acesso a  informação, principalmente devido à propagação do acesso à internet, e ao uso de redes  sem fio. As diversas aplicações disponibilizadas em dispositivos móveis implicam no  aumento do consumo de energia, normalmente fornecida por baterias recarregáveis. A  capacidade de uma bateria é finita, limitando o tempo operacional destes dispositivos.  Desta forma, tem-se a necessidade de realizar estudos relacionados à vida útil das  baterias, objetivando a investigação de métodos eficazes para a predição dos seus  tempos de vida.    O tempo de vida de uma bateria é definido como o intervalo de tempo decorrido  durante o processo de descarga, até que seja atingido o nível de cutoff, ou seja, o tempo  que a bateria leva para atingir a quantidade mínima de energia necessária para manter o  dispositivo operacional (Rakhmatov e Vrudhula, 2001). Uma maneira de predizer este  tempo é fazer uso da modelagem matemática para representar o processo de descarga de  energia das baterias. Ao longo dos anos, diferentes modelos matemáticos são  desenvolvidos com esta finalidade. Estes modelos são divididos em categorias de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   133        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     acordo com as características abordadas, dentre estes destacam-se: os modelos  eletroquímicos (Fuller e Newman, 1994), os modelos elétricos (Chen e Rincón-Mora,  2006; Tremblay, 2009), os modelos estocásticos (Chiasserini e Rao, 1999), os modelos  analíticos (Rakhmatov e Vrudhula, 2001; Manwell, 1993), os modelos via teoria de  Identificação de Sistemas (Romio, 2012) e os modelos híbridos (Kim, 2011). Cada  modelo possui um nível de complexidade e, de acordo com as propriedades levadas em  consideração, são utilizados para um determinado fim. Ressalta-se que neste trabalho é  dada ênfase aos modelos analíticos, mais especificamente, ao modelo Rakhmatov e  Vrudhula (RV).   Os modelos analíticos são considerados computacionalmente eficientes e  flexíveis, podendo ser facilmente estendidos para diferentes tipos de baterias. Nestes  modelos, as principais propriedades da bateria são modeladas utilizando-se um conjunto  reduzido de equações, agregando acurácia e facilidade na sua implementação  (Jongerden e Haverkort, 2008). Dentre os modelos analíticos, é escolhido o modelo RV  que dentre suas diversas características, destaca-se a capacidade de capturar duas  importantes características não lineares que ocorrem no processo de descarga: o efeito  da taxa de capacidade e o efeito de recuperação (Silva, 2014).   Neste contexto, o objetivo deste trabalho é realizar a modelagem matemática do  tempo de vida de baterias de Li-Po utilizando o modelo RV, a fim de simular a descarga  de energia destas baterias e assim, possibilitar a predição dos seus tempos de vida. As  simulações são realizadas na ferramenta computacional Matlab, considerando um amplo  conjunto de perfis de descargas. A validação do modelo é realizada a partir da  comparação entre os tempos de vida simulados e os tempos de vida experimentais  médios, obtidos a partir de uma plataforma de testes.    Assim, o artigo está organizado da seguinte forma. Na Seção 2 são descritas as  equações do modelo RV. Na Seção 3 são apresentados a plataforma de testes utilizada  na obtenção dos dados experimentais, o procedimento adotado para a coleta dos dados e  a estimação dos parâmetros do modelo RV. Na Seção 4 é apresentada a validação do  modelo RV. E finalmente, na Seção 5 é apresentada a conclusão.   2. Modelagem Matemática  Nesta seção é apresentado o modelo RV, utilizado neste trabalho para a predição do  tempo de vida de baterias de Li-Po. O modelo RV (Rakhmatov e Vrudhula, 2001)  descreve a evolução da concentração de espécies eletroativas no eletrólito, durante o  processo de descarga de uma bateria. O modelo baseia-se em simplificações de  fenômenos complexos e considera dois processos principais: as reações eletroquímicas  na superfície do eletrodo e a difusão dos íons no eletrólito (Rakhmatov, Vrudhula e  Wallach, 2002).   O processo de difusão unidimensional é descrito pelas Leis de Fick, dadas pelo  sistema de EDPs descrito a seguir        (1)     onde:  é a concentração de eletrólitos no tempo  e na distância  do eletrodo,    é o fluxo de espécies eletroativas e  é a constante de difusão. Para uma bateria  totalmente carregada, a concentração de espécies eletroativas está uniformemente  distribuída em todo eletrólito, proporcionando a condição inicial       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   134        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015        (2)     Um eletrólito de tamanho  fornece as seguintes condições de fronteira: em  , de acordo com a Lei de Faraday, o fluxo das espécies eletroativas  no   eletrodo é proporcional a corrente , ou seja,       , (3)    onde:  é a área da superfície do eletrodo,  é a constante de Faraday, e  é o número  de elétrons envolvidos na reação eletroquímica na superfície do eletrodo, com isso,       (4)     em , o fluxo é zero, assim,       (5)     Para a resolução do modelo aplica-se o método da Transformada de Laplace e   Transformada de Laplace Inversa, obtendo-se a seguinte solução analítica       ,  (6)     onde:      Considerando         (7)      o parâmetro que está relacionado ao comportamento não linear da bateria e,       (8)    o parâmetro que está relacionado com a capacidade da bateria. Sendo  o tempo de  vida da bateria, com base na equação (6), obtém-se a expressão geral       (9)    que relaciona o tempo de vida  da bateria a partir de um determinado perfil de descarga   . O tempo de vida  é definido como o ponto em que a concentração das espécies  eletroativas na superfície do eletrodo atinge o nível de cutoff.    O modelo RV permite o cálculo do tempo de vida de baterias utilizando  correntes de descargas constantes e variáveis. Especificamente, para uma corrente de  descarga constante, ou seja, , a equação (9) se reduz a        (10)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   135        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     Para casos gerais, pode-se aproximar a corrente de descarga variável no tempo  por uma corrente constante por partes, chamada de função escada de n degraus  (Schneider, 2011). A equação resultante fornece a solução geral do modelo RV para  cargas variáveis,         (11)      A seguir, são apresentados os dados experimentais utilizados para a realização da  modelagem matemática do tempo de vida de baterias de Li-Po.   3. Materiais e Métodos   Nesta seção é apresentada a plataforma de testes utilizada para a realização dos ensaios  experimentais, assim como é descrito o procedimento realizado para a coleta dos dados.  Em seguida, são apresentados os conjuntos de dados experimentais utilizados para a  parametrização e para a validação do modelo RV. Após, é apresentada a estimação dos  parâmetros do modelo RV, realizada a partir do método dos Mínimos Quadrados.  3.1. Plataforma de testes  Os dados experimentais utilizados neste trabalho são obtidos a partir de uma plataforma  de testes, desenvolvida pelo Grupo de Automação Industrial e Controle (GAIC) da  Unijuí, mostrada na Figura 1. Esta plataforma possibilita capturar informações  instantâneas referentes ao processo de descarga de baterias, tais como: corrente,  temperatura, tensão e duração da descarga.        Figura 2. Plataforma de testes    Para a coleta dos dados experimentais é adotada a seguinte metodologia.  Inicialmente, as baterias são conectadas a uma fonte de carregamento externa, sendo  submetidas a um processo de carga completo. Após este procedimento, as baterias são  desconectadas da fonte de carga, e posteriormente, conectadas à plataforma para iniciar  o processo de descarga. Este processo ocorre enquanto as baterias não atingirem a  tensão de cutoff.    Os ensaios experimentais são realizados considerando 31 perfis de  descargas constantes, variando de 50 mA a 800 mA, em intervalos de 25 mA. Para cada  perfil de descarga são realizados 12 ensaios experimentais, e então é calculado o tempo  de vida experimental médio (TVem) do perfil. Para este estudo, são utilizadas oito  baterias de Li-Po novas, modelo PL383562-2C.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   136        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     Os dados experimentais obtidos neste processo são divididos em dois conjuntos.  O primeiro conjunto apresentado na Tabela 1 é formado por 16 perfis de descargas em  mA e os respectivos TVem em minutos, é utilizado para a estimação dos parâmetros do  modelo RV. O segundo conjunto apresentado na Tabela 1 é composto por 15 perfis de  descargas, sendo utilizado para a validação do referido modelo.    Tabela 1. Dados experimentais                                                      A seguir, é apresentada a estimação dos parâmetros do modelo RV considerando  os dados experimentais selecionados para esta finalidade.     3.2. Estimação dos parâmetros  O modelo RV possui dois parâmetros empíricos que necessitam ser estimados: alfa (α) e  beta (β). O parâmetro α está relacionado com a capacidade da bateria, já o parâmetro β  está relacionado com o comportamento não linear da bateria. Para a estimação destes  parâmetros é utilizado o método dos Mínimos Quadrados, que consiste em encontrar o  melhor ajuste para um conjunto de dados, buscando minimizar a soma dos quadrados  das diferenças entre o valor calculado pelo modelo e os dados experimentais (Silva,  2013). Neste estudo, os valores calculados para α e β podem ser visualizados na Tabela  2.     Tabela 2. Parâmetros do modelo RV   Parâmetro Valor  α 26702  β 3,1617       Após o cálculo dos valores destes parâmetros, são realizadas as simulações com o   Conjunto 1 Conjunto 2  Perfis (mA) TVem (min) Perfis (mA) TVem (min)   50 945,14 75 609,91  100 462,64 125 377,61  150 308,08 175 270,69  200 228,31 225 202,74  250 184,25 275 165,65  300 151,61 325 141,22  350 131,23 375 123,30  400 115,97 425 108,34  450 101,82 475 95,32  500 91,52 525 86,33  550 82,77 575 78,31  600 75,70 625 71,86  650 69,37 675 66,45  700 64,35 725 61,12  750 59,59 775 56,87  800 55,48       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   137        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     modelo RV na ferramenta computacional Matlab, considerando os perfis de descargas  selecionados para a validação deste modelo. A seguir, são apresentados os tempos de vida  simulados (TVs) pelo modelo RV, assim como a sua validação.   4. Resultados e Discussões  O modelo RV é validado a partir de uma análise comparativa entre os TVs e os TVem, a  fim de determinar a porcentagem de erro entre estes valores. Os resultados das  simulações do modelo RV são apresentados na Tabela 3, a qual contém para cada perfil  de descarga, o TVem, o TVs, e o erro obtido entre os tempos de vida experimental e  simulado pelo modelo. Também é apresentado o erro médio, calculado pela média  aritmética dos erros encontrados para cada perfil de descarga.    Tabela 3. Validação do modelo RV   Perfis (mA) Tvem (min) TVs (min) Erro (%)  75 609,91 637,22 4,48   125 377,61 375,56 0,54  175 270,69 266,56 1,53  225 202,74 206,56 1,89  275 165,65 168,33 1,62  325 141,22 141,89 0,47  375 123,30 122,56 0,60  425 108,34 107,78 0,52  475 95,32 96,00 0,71  525 86,33 86,56 0,27  575 78,31 78,78 0,60  625 71,86 72,22 0,50  675 66,45 66,56 0,17  725 61,12 61,78 1,08  775 56,87 57,56 1,21   Erro médio: 1,08%      A partir das simulações realizadas é possível perceber que o modelo RV  apresenta resultados satisfatórios para a predição do tempo de vida de baterias de Li-Po,  obtendo um erro médio de 1,08%. Os resultados simulados pelo modelo encontram-se  muito próximos aos resultados experimentais, conforme mostrado na Figura 2.    Considerando os perfis de descargas aplicados nas simulações, o modelo obteve  menor erro no perfil de 675 mA, com 0,17%. O resultado menos satisfatório obtido pelo  modelo é encontrado no perfil de descarga de 75 mA, com erro de 4,48%. Isto acontece  devido à maior influencia dos efeitos não lineares em correntes de descargas mais  baixas.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   138        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015       Figura 2. Resultados experimentais e resultados simulados   5. Conclusão   Neste trabalho foi realizado um estudo acerca da utilização do modelo RV na predição  do tempo de vida de baterias de Li-Po,  objetivando analisar o comportamento destas  baterias durante seus processos de descargas. Para isto, foi realizada a estimação dos  parâmetros do modelo a partir de um conjunto de dados experimentais obtidos em uma  plataforma de testes. Em seguida, foram realizadas as simulações computacionais na  ferramenta computacional Matlab, considerando diferentes perfis de descarga. A  validação do modelo foi realizada por meio de uma análise comparativa entre os  resultados experimentais e os resultados simulados.     A partir dos resultados obtidos conclui-se que o modelo RV é capaz de predizer  com bastante acurácia o tempo de vida das baterias de Li-Po, apresentado um erro  médio de 1,08%. Ressalta-se que estes resultados satisfatórios se devem, em grande  parte, ao fato deste modelo ser capaz de capturar dois efeitos não lineares que ocorrem  durante o processo de descarga de uma bateria: o efeito de recuperação e o efeito da  taxa de capacidade.      Como trabalhos futuros pretende-se analisar o desempenho do modelo RV para  descargas variaveis no tempo, uma vez que neste artigo foram abordadas apenas  descargas constante.    6. Agradecimentos  Os autores agradecem à Unijuí pelo apoio financeiro e ao GAIC, pela infra-estrutura.   Referências  Chen, M.; Rincón-Mora, G. “Accurate electrical battery model capable of predicting   runtime and i-v performance,” IEEE Transactions on Energy Conversion, vol. 21, no.  2, june 2006.   Chiasserini, C.; Rao, R. “Pulsed battery discharge in communication devices,”  Proceedings of the 5th International Conference on Mobile Computing and  Networking, p. 88–95, 1999.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   139        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 132-139 Nov/2015     Fuller, M. D. T. F.; Newman, J. “Simulation and optimization of the dual lithium ion  insertion cell,” Journal of the Electrochemical Society, vol. 141, no. 1, p. 1–10, 1994.   Jongerden, M.; Haverkort, B. “Battery modeling,” Thecnical Report in Faculty  Electrical Engineering, Mathematics and Computer Science, 2008.   Kim, T. “A hybrid battery model capable of capturing dynamic circuit characteristics an  nonlinear capacity effects”. Muly 2012.   Manwell, J. F.; McGowan, J. G. Lead acid battery storage model for hybrid energy  systems, Solar Energy, vol. 50, no. 5, p. 399-405, 1993.   Rakhmatov, D.; Vrudhula, S. “An analytical high-level battery model for use in energy  management of portable electronic systems,” National Science  Foundation’sState/Industry/University Cooperative Research Centers’  (NSFS/IUCRC) Center for Low Power Electronics (CLPE), pp. 1 – 6, 2001.   Rakhmatov, D.; Vrudhula, S.; Wallach, D. A. “Battery lifetime prediction for energyaware computing,” in Proceedings of the 2002 International Symposium on Low  Power Electronics and Design, ser. ISLPED ’02. New York, USA: ACM, 2002, p.  154–159.   Romio, L.; Sausen, A.; Sausen, P. S.; Reimbold, M.. Aplicação de Identificação de  Sistemas no Tempo de Vida de Baterias de Dispositivos Móveis. Vetor (FURG), v.  22, p. 18-33, 2012.   Schneider, K. K., “Modelos analíticos na predição do tempo de vida de baterias  utilizadas em dispositivos móveis,” Dissertação de Mestrado, Universidade Regional  do Noroeste do Estado do Rio Grande do Sul, Ijuí-RS, Março 2011.   Silva, B. F.; Sausen, A. Z. R.; Sausen, P. S.; Reimbold, M. M. P. “Método da procura  em rede melhorado: Uma proposta para a estimação dos parâmetros do modelo de  rakhmatov e vrudhula,” Tendências em Matemática Aplicada e Computacional  (TEMA), vol. 14, no. 3, p. 463–482, 2013.   Silva, B. F.; Sausen, P. S.; Sausen, A.. Parameters Estimation of the Rakhmatov and  Vrudhula Model from the Optimization Method Search in Improved Network. ISRN  Applied Mathematics, v. 2014, p. 1-9, 2014.   Tremblay, O., Dessaint, L. A. "Experimental Validation of a Battery Dynamic Model  for EV Applications." World Electric Vehicle Journal. Vol. 3 - ISSN 2032-6653 - ©  2009 AVERE, EVS24 Stavanger, Norway, May 13 - 16, 2009.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   79        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015     Projeto de Extensão: Capacitação de Docentes com a Lousa  Digital/Projetor Interativo do MEC/FNDE    Isaac Spolti Pazuch1, Marco Antoni1   Gláucio Ricardo Vivian2, Bruno Batista Boniati2   1Universidade Federal de Santa Maria (UFSM) – Frederico Westphalen   2Instituto Federal Farroupilha - Campus Frederico Westphalen  isaacpazuch@yahoo.com.br, marco.antoni910@gmail.com  {glaucio.vivian,bruno.boniati}@iffarroupilha.edu.br   Abstract. This paper describes the execution of an extension project with the  aim of training teachers in the use of ProInfo projector provided by the  MEC/FNDE. During the first phase, four schools in the region were trained.  After the training, we used a questionnaire to evaluate. At the end of the data  were used to verify the acceptance and relevance of the proposed project.   Resumo. Este artigo descreve a execução de um projeto de extensão com o  objetivo de capacitar os docentes na utilização do projetor ProInfo  disponibilizado pelo MEC/FNDE. Durante a primeira fase, quatro escolas da  região foram capacitadas. Após as capacitações, utilizou-se um questionário  para avaliação. Ao final os dados foram utilizados para verificarmos a  aceitação e relevância do projeto proposto.   1. Introdução   Nos anos de 2010 e 2011 o Ministério da Educação (MEC) e a Fundação Nacional para  o Desenvolvimento da Educação (FNDE) disponibilizaram através do Programa  Nacional de Formação Continuada em Tecnologia Educacional o projetor ProInfo. Na  região diversas instituições de ensino receberam o equipamento em questão. Trata-se de  uma iniciativa que possibilita o uso didático-pedagógico das Tecnologias da Informação  e Comunicação (TIC) no cotidiano escolar. O projeto do computador interativo foi  elaborado pela Universidade Federal de Santa Catarina (UFSC) e pela Universidade  Federal de Pernambuco (UFPE) [FNDE 2015].    Além de um projetor, o equipamento é integrado por um computador completo  com acesso a internet e recursos multimídia. O projeto foi elaborado utilizando  softwares livres. Assim o sistema operacional trata-se de uma personalização do Linux  Educacional. Também faz parte do equipamento a lousa digital. Tal recurso possibilita  aos docentes a realização de aulas interativas com os diversos recursos presentes no  computador [FNDE 2015].    A partir da manifestação formal de interesse dessas instituições, elaborou-se o  projeto de extensão intitulado de "Capacitação de Docentes com a Lousa  Digital/Projetor Interativo do MEC/FNDE". O objetivo principal deste projeto é  capacitar os docentes da rede estadual e municipal para utilizar a lousa digital/projetor  interativo. Com isso espera-se estimular a utilização da lousa como recurso didático e  identificar as necessidades pedagógicas que a lousa digital pode ser utilizada. Este  projeto também objetiva a participação dos discentes da instituição nas ações de  extensão da instituição.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   80        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015      Na seção 2 são relatados alguns trabalhos diretamente relacionados com o tema.  Na seção 3 apresentamos os resultados alcançados com o projeto até o momento.  Finalmente na seção 4 apresentamos as conclusões do trabalho.   2. Trabalhos Relatados     Realizamos um levantamento bibliográfico sobre a utilização de lousa digital no  contexto educacional. Encontramos diversos trabalhos, cada qual com um foco e  metodologias especificas. A seguir, relatamos alguns desses trabalhos.    [Savi 2009] descreve uma pesquisa que avaliou o uso de conteúdo multimídia  em escolas públicas durante o piloto de testes de um novo conceito de equipamento  escolar. Durante o estudo, três escolas foram acompanhadas por meio de questionários,  observação e entrevistas para avaliação de como os professores utilizam multimídias, as  dificuldades encontradas e a reação dos alunos. As conclusões do trabalham apontam  que não basta inserir equipamentos digitais nas escolas, é preciso apoiar o professor  para ele primeiro aprender a operar o equipamento. Em seguida, o professor precisa de  suporte para entender como fazer uso pedagógico do projetor, aprender a encontrar  conteúdos multimídia e a planejar aulas com eles. É preciso que se tenha a compreensão  que ao se disponibilizar novas tecnologias nas escolas as práticas profissionais dos  professores sofrem alterações, exigindo deles novas competências.    [Amaral e Nakashima 2006] apresentam em seu trabalho algumas reflexões a  respeito da lousa digital como um instrumento que proporciona a inserção da linguagem  audiovisual no contexto escolar. A utilização da lousa digital aumenta a interatividade  com as atividades propostas pelo professor. No trabalho são apresentadas duas  possibilidades de atividades pedagógicas, nas áreas de Ciências e Língua Portuguesa,  que poderão ser aplicadas na educação infantil, com alunos de cinco a seis anos. Essa  tecnologia reflete a evolução de um tipo de linguagem que não é mais baseada somente  na oralidade e na escrita, mas também é audiovisual e dinâmica, pois permite que o  sujeito além de receptor, seja produtor de informações. Ao final, [Amaral e Nakashima  2006] concluem que a lousa digital surge como uma ferramenta de apresentação de  conteúdos escolares que oportuniza uma aprendizagem visual e participativa, devido sua  característica de interagir com os programas disponibilizados, utilizando o próprio dedo.  O que irá fazer a diferença na inserção dessa tecnologia da informação e comunicação  na educação é justamente a criatividade do professor, isto é, ao propor atividades  utilizando a lousa digital como ferramenta mediatizadora do processo educativo, o aluno  poderá aprender agindo, experimentando e fazendo algo na prática utilizando a  linguagem audiovisual.    O trabalho de [Honório et al 2011] apresenta o Quadro Interativo como um  recurso didático que pode ser incorporado ao trabalho docente. Apresenta-se, também, o  desenvolvimento e avaliação de uma sequência didática, em Matemática, com o tema  Relações Métricas no Triângulo Retângulo, para à 8ª série (9º ano ou 14 anos) do  Ensino Fundamental, utilizando os recursos do Quadro Interativo. Os resultados do  trabalho apontam que o Quadro Interativo é um recurso didático importante para uso em  sala de aula, com os conteúdos de Matemática, agrega tecnologia e recursos  metodológicos para o desenvolvimento de sequências didáticas, onde uma vantagem é a  possibilidade da utilização de diferentes recursos, com padrão superior de qualidade,  como links, textos com exemplos em movimento, ou seja, um conteúdo visual com  maior qualidade.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   81        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015      A pesquisa de [Nakashima, Barros e Amaral 2009] objetivou apresentar uma  proposta de utilização da lousa digital, como um instrumento tecnológico interativo, que  possibilita a elaboração de atividades pedagógicas, associadas à Teoria dos Estilos de  Aprendizagem. Os autores salientam que a lousa digital incorpora todos os recursos que  o computador oferece, mas com o diferencial de permitir a interação entre o professor e  os alunos, favorecendo a construção coletiva do conhecimento. Os referenciais de  Estilos de Aprendizagem utilizados no trabalho se baseiam nas investigações que  defendem que Estilos de Aprendizagem são os traços cognitivos, afetivos e fisiológicos,  que servem como indicadores relativamente estáveis, de como os alunos percebem,  interagem e respondem aos seus ambientes de aprendizagem. Ao finalizar a pesquisa os  autores destacam que ao integrar a lousa digital à metodologia de ensino e  aprendizagem, tanto o professor como o aluno beneficiar-se-ão com a qualidade de  acesso, gestão e apresentação dos conteúdos educativos. A transformação das  possibilidades que a lousa digital oferece em ações práticas dependerá da disposição e  da criatividade do professor em tornar sua metodologia de ensino mais dinâmica, a fim  de elevar a concentração e o envolvimento do aluno durante a aula. Os materiais  produzidos com os recursos da lousa digital conseguem abranger múltiplos estímulos,  como a audição, a visão e o tato, considerando que as pessoas possuem diferentes  Estilos de Aprendizagem e que aprendem com mais eficiência se mais de um sentido for  mobilizado.    O trabalho de [Gomes 2011] faz um relato experiência com o uso da Lousa  Digital Interativa por profissionais da educação infantil. O trabalho ressalta que diante  da grande presença das Tecnologias de Informação e Comunicação (TIC) em nossa  sociedade, é possível perceber que os ambientes escolares também estão sendo  invadidos por diferentes tecnologias, sendo que uma delas é a Lousa Digital Interativa.  Pelo fato desta tecnologia oferecer diferentes tipos de ferramentas que são interessantes  para serem utilizadas em atividades pedagógicas para as crianças inseridas no contexto  escolar da educação infantil, surgiu a necessidade de elaborar junto com profissionais  atuantes nesta etapa da educação básica, diferentes práticas pedagógicas possíveis de  serem realizadas fazendo uso da lousa digital interativa. O trabalho finaliza concluindo  que as atividades pedagógicas construídas pelos participantes usaram diferentes  ferramentas, mas algumas dentre as disponibilizadas pelo programa foram pouco  aproveitadas, como, por exemplo, o gravador e a criação de animações. Imagens, escrita  e links foram recursos amplamente utilizados nas atividades propostas. A partir da  elaboração e da apresentação das atividades pedagógicas construídas pelos participantes  das oficinas realizadas, foi possível perceber que a lousa digital interativa oferece uma  grande diversidade de ferramentas que poderão ser utilizadas na elaboração de  diferentes tipos de atividades pedagógicas, com diferentes temas e conteúdos, para  crianças inseridas no contexto escolar da educação infantil.    [Kalinke 2013] em seu trabalho intitulado “Uma experiência com o uso de  Lousas Digitais na formação de professores de Matemática” ressalta que as Lousas  Digitais (LD) e os Objetos de Aprendizagem (AO) estão sendo inseridos no contexto  escolar e apresentam diferenciais interessantes quando utilizados em atividades  educacionais, em especial aquelas relacionadas à Matemática. É importante conhecer as  suas características e saber utilizá-los de forma que estes diferenciais agreguem valores  aos processos pedagógicos. Para tanto, acredita-se ser importante que os futuros  professores sejam levados a conhecê-las ainda durante suas graduações. As conclusões  do trabalho evidenciam que as LD são tecnologias cujas particularidades e  peculiaridades são mais bem exploradas quando nelas são utilizados os OA. Como as     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   82        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015     LD e os OA são recursos recentes no cenário educacional brasileiro, é de fundamental  importância preparar os professores e futuros professores para o uso destas e de outras  tecnologias.   3. Metodologia   A metodologia empregada consiste inicialmente em identificar instituições de ensino  que possuem o equipamento. A partir dessa constatação, realizou-se uma visita  motivacional com o propósito de estimular a utilização do equipamento e constatar  necessidades. Durante a visita buscou-se definir uma data para realização do  treinamento onde a maioria dos docentes estivesse presentes. A partir disso procuraramse através da seção de trabalhos relatados exemplos de utilização do equipamento. Com  base nestas informações elaborou-se um curso de capacitação de 2 horas. Após o curso  apresentamos um questionário com a finalidade de avaliar o treinamento.   4. Resultados Obtidos   Em um primeiro momento, realizamos uma visita de aproximadamente uma hora em  cada instituição a fim de conhecermos a sua infraestrutura, equipamentos e necessidades  especificas. Na tabela 1 pode-se visualizar o cronograma de visitas realizadas. Além da  equipe responsável pelo projeto atual.    Tabela 1. Cronograma de visitas iniciais    Data Horário Instituição   27/06/2015 10:00 I. E. E. Madre Tereza   03/06/2015 08:00 E. E. E. B. Sepé Tiaraju   03/06/2015 10:30 E. M. E. F. Afonso Balestrin   12/06/2015 13:30 E. E. E. F. Afonso Pena   12/06/2015 14:30 E. E. E. F. Cardeal Roncalli    Observou-se que as instituições de ensino das redes públicas (municipal e  estadual) receberam o projetor proinfo do pregão 42/2010, fabricado pela Diebold com  o Linux Educacional versão 4. Este sistema operacional se caracteriza por possuir um  vasto conjunto de pacotes de softwares educacionais instalados por padrão. No entanto  o mesmo não possui a lousa digital integrada. Esta foi disponibilizada posteriormente  pelo MEC como um acessório de uso externo ao projetor, podendo inclusive ser  utilizada em um computador normal com o sistema operacional Windows. No caso das  instituições federais, o projetor entregue foi o fabricado pela Daruma correspondente ao  pregão 72/2011. Este último possui a lousa digital totalmente integrada e uma versão  personalizada do Linux Ubuntu. Na figura 1a pode-se visualizar o projetor da Diebold e  na figura 1b o projetor da Daruma.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   83        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015        Figura 1: Projetores Proinfo    Posteriormente realizamos um estudo a fim de conhecermos melhor os  projetores Proinfo. Utilizamos como referências os manuais disponíveis para os  equipamentos [DIEBOLD-a 2011] [DIEBOLD-b 2011] [DIGIBRAS 2013] [NEITZEL  2009], bem como as experiências/metodologias relatadas na seção 2. A partir dessas  informações elaboramos um plano de ensino e material didático para a capacitação de  duas horas. O plano de ensino do curso foi definido da seguinte forma: i) utilização do  software de lousa digital.  ii) utilização de aplicativos educacionais pré-instalados no  computador da lousa. iii) utilização do projetor incorporado à lousa. iv) acessar  conteúdo didático on-line através da lousa. v) gravar uma aula para posteriormente  disponibilizar aos alunos.    Para o treinamento sobre o software da lousa digital, procuramos apresentar  todas as ferramentas disponíveis na lousa. Para demonstração utilizamos exemplos do  dia a dia dos docentes e procuramos propor a participação deles em atividades a fim  proporcionar uma maior interação.    Procuramos demonstrar à utilização dos softwares de forma concentrada por  área. A seguir apresentaremos os softwares do Linux Educacional que compõe o  treinamento: i) ciências: tabela periódica (Kalzium). ii) geografia: planetário (KStar),  treinamento em geografia (KGeography). iii) idiomas: alfabeto (KLettres), verbos  espanhol (KVerbos), jogo da forca (KHangMan), ordenação de letras (Kanagram). iv)  matemática: desenho de funções (KmPlot), frações (KBruch), porcentagens  (KPercentage), geometria interativa (Kig). v) português: jogo do Simon diz (blinKen),  vocabulário (KWordQuiz), digitação (KTouch).    Para demonstração e utilização de conteúdos on-line procuramos utilizar portais  direcionados para educação como o Domínio Público (dominiopublico.gov.br), TV  Escola (tvescola.mec.gov.br), Portal do Professor (portaldoprofessor.mec.gov.br) e  Objetos Educacionais (objetoseducacionais2.mec.gov.br).    Foram capacitadas pelo projeto até o momento quatro escolas da região, são  elas: Escola Estadual de Ensino Fundamental Afonso Pena, Escola Estadual de  Educação Básica Sepé Tiarajú, Escola Estadual de Ensino Médio Cardeal Roncalli e  Instituto Estadual de Educação Madre Tereza. Na tabela 2 podem-se visualizar os  participantes em cada curso de capacitação realizado. Na figura 2 podem-se visualizar  os docentes e instrutores ao final de um treinamento realizado na E. E. E. F. Afonso  Pena.           Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   84        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015      Tabela 2. Participantes nas capacitações    Data Hora Local Docentes   20/07/2015 13:30 E. E. E. F. Afonso Pena 15   21/07/2015 18:00 E. E. E. B. Sepé Tiaraju 36   22/07/2015 08:30 E. E. E. F. Afonso Pena 19   22/07/2015 13:30 I. E. E. Madre Tereza 26   23/07/2015 08:30 E. E. E. F. Cardeal Roncalli 16   23/07/2015 13:30 E. E. E. F. Cardeal Roncalli 20       Figura 2: Docentes e instrutores ao final do treinamento    Até o momento foram capacitados 132 professores de escolas municipais e  estaduais.  Desse total 112 (84%) responderam o questionário de avaliação sobre o  projeto. O questionário consiste de cinco questões sobre: temática apresentada no curso,  clareza de exposição dos conteúdos, emprego do tempo, recursos utilizados na atividade  e formato do curso. Cada questão possui cinco possíveis respostas: muito bom, bom,  indiferente, regular e insatisfatório. Na tabela 3 podem-se visualizar os quantitativos e  percentuais para o questionário.   Tabela 3. Resultado da pesquisa de satisfação   Critério Muito Bom Bom Indiferente Regular Insatisfatório Totais   1. Temática 83.93% 16.07% 0.00% 0.00% 0.00% 100%   2. Clareza 81.25% 18.75% 0.00% 0.00% 0.00% 100%   3. Emprego tempo 75.00% 25.00% 0.00% 0.00% 0.00% 100%   4. Recursos 84.82% 15.18% 0.00% 0.00% 0.00% 100%   5. Formato curso 78.57% 21.43% 0.00% 0.00% 0.00% 100%    Além da pesquisa de satisfação, foi possibilita aos docentes a escrita de  sugestões/críticas sobre o projeto de forma anônima. Nesse sentido obtiveram-se  diversos relatos, a seguir destacamos alguns: "Materiais de excelentes recursos  didáticos, foi de muita importância para o corpo docente da instituição", “Uma temática  de grande valia para o aperfeiçoamento da prática docente. A tecnologia, quando bem  utilizada, auxilia/contribui e muito no trabalho desenvolvido nas escolas”, ”De grande     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   85        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015     importância com a realidade das tecnologias em nosso dia a dia”, “É uma ferramenta  nova que os professores precisam praticar”, “Gostaria que tivesse outros cursos nessa  área”, “Boa apresentação, orientação que vem ao encontro desse novo instrumento de  trabalho para nós professores”.   5. Conclusões e Trabalhos Futuros    Após a execução do projeto de extensão, constatou-se com base nas avaliações  dos docentes e principalmente nas sugestões que o mesmo contemplou uma necessidade  das instituições. A partir das sugestões percebeu-se que a maioria dos docentes tem  interesse em utilizar as TICs como ferramenta educacional.   O termino do projeto de extensão está previsto para o final no ano de 2015. Dessa forma  ainda está previsto as capacitações dos docentes nas seguintes instituições: Instituto  Estadual de Educação 22 de Maio, Escola Municipal de Ensino Fundamental Afonso  Balestrin, Instituto Federal Farroupilha Campus FW e Escola Estadual de Ensino Básico  José Zanatta.   Referencias   AMARAL, S. F.; NAKASHIMA, R. H. R. (2006) “A linguagem Audiovisual da Lousa  Digital Interativa no Contexto Educacional’. Educação Temática Digital, v. 8, p. 3350.   DIEBOLD. (2011) “Guia de Referência Rápida de Operação LS-5580 Projetor  Proinfo”.   DIEBOLD. (2011) “DESCRIÇÃO DO SOFTWARE Projetor Proinfo LINUX  Educacional”.   DIGIBRAS. (2013) "Manual do usuário do sistema de Lousa Interativa Portátil  uBoard".   FNDE. (2015) “Computador Interativo e Lousa Digital (Projetor Proinfo)”. Disponível  em: <http://www.fnde.gov.br/portaldecompras/index.php/produtos/computadorinteratvo-projetor> Acessado em: 14 de setembro de 2015.   GOMES, E. M. (2011) “Uma experiência com o uso da Lousa Digital Interativa por  profissionais da educação infantil”. ETD : Educação Temática Digital, v. 12, p. 268286, 2011.   HONÓRIO, B. G.; GROENWALD, C. L. O.; BAYER A. (2011) “Quadro Interativo na  Educação Matemática” XIII Conferencia Interamericana de Educação Matemática -  CIAEM, Recife/PE.   KALINKE, M. A. (2013) “Uma experiência com o uso de Lousas Digitais na formação  de professores de Matemática”. In: XI Encontro Nacional de Educação Matemática.  Curitiba/PR.   NAKASHIMA, R. H. R.; BARROS, D. M. V.; AMARAL, S. F. (2009) “O uso  pedagógico da lousa digital associado à teoria dos estilos de aprendizagem”. Revista  de Estilos de Aprendizagem, v. 2, p. 169-178.   NEITZEL. L. C. (2009) "Instalação dos Pacotes Educacionais no Linux Educacional  3.0". NTE Joinville, SC. 2009.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   86        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 79-86 Nov/2015     SAVI, R. (2009) “Utilização de Projeção Multimídia em Salas de Aula: observação do  uso em três escolas públicas”. Simpósio Brasileiro de Informática na Educação,  Florianópolis/SC.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   31        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015     Proposta de um processo de recrutamento e seleção de  profissionais em uma fábrica de software      Erivan de Sena Ramos  Universidade Estácio de Sá   São Paulo – São Paulo – Brasil  erivansr@gmail.com     Resumo. Este artigo apresenta uma proposta para o processo de  recrutamento e seleção de profissionais em uma fábrica de software de uma  empresa de grande porte. Inicialmente foi construído um referencial teórico  abordando os conceitos de estrutura organizacional, destacando sua  importância. Também foram expostas a principais características presentes  em um processo de recrutamento e seleção de profissionais. Em seguida foi  apresentada a proposta definida para a fábrica de software, a qual foi obtida  por meio de um comitê formado por profissionais da empresa.      Abstract. This article presents a proposal for the recruitment and selection of  professionals in a software factory of a large company. Initially a theoretical  framework addressing the concepts of organizational structure was built,  highlighting its importance. They were also exposed to major features present  in the process of recruitment and selection of professionals. Then it was  presented the proposal set for the software factory, which was obtained  through a committee of business professionals.      1. Introdução  O conceito de processo tende a aumentar na medida em que as organizações tenham  como matéria prima um conteúdo cada vez mais intelectual e vendam produtos de  valores intangíveis. A tendência é que cada vez mais as técnicas e práticas de gestão  empresarial serão adequadas às organizações que estão se estruturando por processos.  Atualmente, nas empresas é tendencioso que o foco seja somente nas atividades e  habilidades individuais, o que ocasiona em uma perda da visão sobre o processo e das  habilidades de equipe; neste cenário é necessário que haja um redesenho para  possibilitar a melhora na gestão organização [Gonçalves 2000].    Por meio do processo de recrutamento e seleção a organização tem capacidade  de verificar os perfis capacitados para exercer as vagas disponíveis na empresa,  escolhendo o profissional correto para o cargo adequado. O processo de recrutamento e  seleção realizado de forma adequada irá garantir as condições para uma gestão  otimizada, promovendo mais sucesso à empresa, menor rotatividade de profissionais,  além de conseguir maiores resultados com profissionais mais eficientes e  comprometidos com os objetivos estratégicos da organização [Michel 2007].    Diante desta importância, este trabalho apresenta uma proposta de um processo  de recrutamento e seleção em uma fábrica de software de uma empresa de grande porte.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   32        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015      Devido a rotatividade de profissionais na fábrica de software e contratação de  profissionais que não atendiam ao perfil técnico necessário, bem como, a inexistência de  um modelo sólido de recrutamento e seleção, foi identificada a necessidade de uma melhora  no processo de contratação dos profissionais. Para isso foi instituindo um comitê que definiu um  processo de acordo com a realidade e necessidade da fábrica de software.      2. A importância da utilização de processos   Atualmente manter processos definidos em uma organização é condição básica para que  a empresa responda de maneira eficaz às mudanças ocorridas no mercado competitivo.  A definição de processos tem como base realizar uma coordenação do trabalho, o qual  está intrinsicamente ligado com a maneira de como os recursos e as atividades se  relacionam no dia-a-dia da organização e como estão sendo geridas para gerar  aprendizado e promover melhorias nas operações, o qual deve derivar-se da própria  ação de dividir e organizar o trabalho em si [Paim Et Al. 2009]    Paim et al. (2009), lista os seguintes resultados e benefícios oriundos da  utilização de processos nas organizações:   • Uniformização do conhecimento e modelos do negócio;   • Melhoria no processo de comunicação e fluxo de informações;   • Padronização do processo conforme;   • Melhoria na Gestão Organizacional;   • Aumento da compreensão teórica e prática dos processos;   • Redução de tempo e custos;   • Aumento na satisfação dos clientes;   • Aumento na produtividade dos profissionais envolvidos no processo;   • Redução dos defeitos.     3. O processo recrutamento e seleção nas organizações  O recrutamento e seleção são etapas de um mesmo processo composto por atividades  que devem ser norteadas de acordo com o negócio e o objetivo estratégico da empresa  [Caxito 2007].     Segundo Chiavenato (2009) o recrutamento tem como objetivo atrair candidatos  ao processo seletivo da organização. O recrutamento pode ser: interno (candidatos que  já atuam na organização) ou externo (candidatos fora da organização). O foco do  recrutamento pode estar baseado em cargos, mantendo o status quo da organização, ou  baseado em competências para aumentar a competividade da organização.    Ao ser finalizado a etapa de recrutamento, dar-se inicio a segunda etapa do  processo: a seleção [Caxito 2007]    Chiavenato (2009) conceitua que a seleção tem como objetivo “filtrar” os  melhores candidatos que apresentam as características desejadas pela organização. O  processo de seleção de pessoas é composto por várias fases sequenciais, enfrentadas     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   33        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015     pelos candidatos recrutados, e durante os obstáculos enfrentados nestas fases, o  candidato pode progredir no processo ou ser eliminado do processo de seleção.     Um processo de recrutamento e seleção bem definido é importante em uma  organização, pois tem como objetivo agregar talento humano dotando-a das  competências essenciais necessárias [Chiavenato 2009].      4. O processo recrutamento e seleção: A relação entre a Gestão de  Tecnologia da Informação e Gestão de Recursos Humanos   Caxito (2007) expõe que a Área de Recrutamento e Seleção, subordinada a Gerência de  Recursos Humanos, deve está envolvida diretamente desempenhando as seguintes  funções:   • Planejamento: definir objetivos e recursos a serem utilizados;   • Organização: estruturar os recursos de forma que permita alcançar os objetivos  preestabelecidos;   • Execução: colocar em prática o planejamento;   • Controle: verificar os resultados obtidos e comparar com os resultados  esperados.    A Gestão de um processo de recrutamento e seleção deve considerar  cuidadosamente os indivíduos e suas relações sociais, bem como, os objetivos  estratégicos da empresa, utilizando-se dos diversos recursos de que dispõem para tomar  as decisões pertinentes às suas funções (Caxito 2007). Para Pereira, Primi e Cobero  (2003) o processo de seleção é a chave para o sucesso do negócio e conhecer a  adequação da seleção de pessoal é algo fundamental para uma adequada contratação,  para impedir gastos financeiros e dispêndio de tempo devido a uma seleção de  profissionais errônea.    Conforme o PMBOK (2013) a realização desta atividade requer que gestor dos  profissionais a serem contratados avaliem os recursos selecionados para a equipe,  conforme  as competências necessárias para desenvolver as atividades do projeto.    O estudo de Amâncio, Costa, Camargo e Penteado (2009) apresenta a aplicação  de um processo de recrutamento e seleção de profissionais de tecnologia da informação  em uma fábrica de software de pequeno porte. A implantação do processo obteve  resultados significativos, com a amenização de dificuldades tais como a alta rotatividade  de pessoal.     Para o processo definido neste trabalho, a Gestão de Tecnologia da Informação  tem papel crucial, pois estará envolvido diretamente com o objetivo de melhorar o  recrutamento e seleção dos profissionais realizado pela Gerência de Recursos Humanos.       5. O Recrutamento e Seleção de Profissionais de Tecnologia da  Informação   A OECD (2005) apresenta um estudo onde indica que um dos desafios mais críticos em  organizações de tecnologia da informação trata-se do aperfeiçoamento das práticas de  recrutamento.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   34        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015      Iannini (2011) confirma que muitas empresas de tecnologia da informação além  possuírem vários problemas na gestão dos recursos humanos (tais como falta de mãode-obra, e retenção de talentos), também possuem processo de recrutamento e seleção  inadequados.    A organização para a qual se indica o objeto deste estudo trata-se de uma  empresa de consultoria de serviços de tecnologia de informação com uma fábrica de  software, que padece dos problemas apontados por OECD (2005) e Iannini (2011).     A organização possui um processo de recrutamento e seleção sem padrões e tem  ocasionado em contratações errôneas, aumento da rotatividade de profissionais. Faz-se  necessário o estabelecimento de um processo padrão com o objetivo de melhorar um  processo tão importante dentro da empresa.      6. Comitê para definição de processos organizacionais  Para definição da proposta para o processo de recrutamento e seleção de profissionais,  foi constituído um Comitê de Processos Organizacionais, formado por profissionais e  Gestores de Recursos Humanos e Gestores operacionais com o compromisso de:    • Realizar reuniões semanais, no período de dois meses para elaborar uma  proposta para o processo de recrutamento e seleção de profissionais para a  fábrica de software;   • Estudar e propor a Diretoria da empresa, medidas para assegurar a estruturação  dos processos organizacionais, adequando-os ao cumprimento da missão da  empresa e melhoria da qualidade dos processos e atividades da equipe;   • Assegurar a implantação e manutenção dos processos organizacionais  estabelecidos e aprovados;   • Incentivar estudos e debates visando ao aperfeiçoamento permanente da  estrutura e dos processos organizacionais, inclusive estabelecendo estreita  articulação com outras equipes;   • Apreciar e deliberar sobre propostas apresentadas;   • Assegurar a implantação das medidas aprovadas.   A proposta de processo de recrutamento e seleção de profissionais elaborada  pelo Comitê de Processos Organizacionais está apresentada no capitulo 7, onde são  apresentadas: o objetivo, as etapas (contendo o processo modelado em BPMN -  Business Process Model and Notation, conforme a Figura 1), os indicadores/metas, e os  resultados esperados pela empresa.      7. Proposta do processo de recrutamento e seleção de profissionais  Foi apresentado à diretoria da empresa um documento com a proposta para o processo  organizacional com instruções complementares as atividades realizadas, no sentido de  promover a análise e melhoria dos processos de seleção e recrutamento de profissionais,  com o intuito de conduzir a fábrica de software ao caminho da excelência gerencial dos  recursos humanos com ênfase nos resultados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   35        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015      O processo sugerido pretende estruturar a sequência de trabalhos desenvolvidos,  integrando o Departamento Pessoal e a Gestão de Tecnologia da Informação, visando a  análise, a simplificação ou a melhoria dos processos, como forma de promover a  permanente busca da melhoria de desempenho e qualidade das atividades executadas  cotidianamente.      7.1  Objetivo do processo de recrutamento e seleção de pessoas  O processo de seleção tem como objetivo buscar pessoas capazes de agir com  criatividade, iniciativa e autonomia, que se integrem em um esforço coletivo na busca  de excelência no atendimento ao cliente.     Para que a equipe possa contar com os talentos que mais eficazmente respondam  às necessidades dos negócios, é necessário identificar a qualidade e o potencial dos  mesmos. Afinal, contratar é o processo de ajustar entre si três formas complexas e em  constante mutação: o candidato, a empresa e o mercado.   7.1.1  Etapas do processo   Fluxo do processo de recrutamento e seleção   Gestor de Tecnologia da Informação Gestor de RH  Selecionar de  curriculos  Agendar entrevistas  individuais  Encaminhar ficha de  contratação para RH   Solicitar abertura de  vaga  Início  X  Profissional aprovado na  Entrevista com RH  Profissional reprovado  na entrevista com RH  Realizar entrevista técnica   Aplicar teste técnico  Realizar entrevista  gerencial  Realizar entrevista RH  Aplicar teste  comportamental  Aplicar teste  raciocínio lógico  X  Profissional selecionado  Profissional reprovado  na entrevista técnica  Profissional excluído do processoProfissional contratado    Figura 1.  Fluxo do processo de recrutamento e seleção elaborado pelo Comitê de   Processos Organizacionais     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   36        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015     a. Solicitar Abertura da Vaga:    Solicitar abertura da vaga, para o perfil do profissional necessário para  divulgação pelo Departamento de Recursos Humanos - RH.    Responsável: Gestor de Tecnologia da Informação     b. Selecionar Currículos:   Selecionar currículos de acordo com o perfil do profissional necessário. Etapa  eliminatória.   Responsável: Gestor de RH      c. Agendar Entrevistas Individuais:   Agendar entrevistas individuais com cada candidato com o currículo escolhido para  o processo de seleção.   Responsável: Gestor de RH     d. Realizar Entrevista RH:   Realizar a entrevista com a equipe do Departamento de Recursos Humanos – RH,  compreendendo os seguintes itens:   i.Aplicar teste comportamental  Este teste tem como objetivo demonstrar de forma clara e simples qual o perfil  comportamental mais evidente do candidato. Apresentando seus comportamentos  positivos, isto é, características que impulsionam a sua carreira, assim como  possíveis comportamentos limitantes, que podem prejudicar na conquista de suas  metas e objetivos. Etapa eliminatória.  Responsável: Gestor de RH.   ii.Aplicar teste de raciocínio lógico  Este teste tem com objetivo apresentar aos candidatos um pequeno número de  problemas complexos quantitativos, com a intenção de buscar candidatos que  consigam estruturar uma linha de argumentação sólida e bem fundamentada. Etapa  eliminatória.  Responsável: Gestor de RH.      e. Realizar Entrevista Técnica:   Realizar a entrevista com a equipe do Projeto, compreendendo os seguintes itens:   i.Aplicar teste técnico  Este teste tem como objetivo avaliar a qualidade da estruturação e do entendimento  na solução de problemas, incluindo o desenvolvimento da estratégia de solução.  Etapa eliminatória.  Responsável: Gestor de Tecnologia da Informação   ii.Realizar entrevista gerencial  Esta entrevista tem como objetivo avaliar o grau de motivação demonstrado em  relação à carreira de consultoria e à empresa. Podem ainda ser julgadas as  qualidades pessoais e interpessoais do candidato, incluindo liderança, trabalho em  equipe, curiosidade intelectual, foco em resultado, pragmatismo e visão crítica.   O entrevistador terá feedback sobre o desempenho em cada etapa do processo  seletivo, e endereçará pontos específicos de interesse, antes de tomar a decisão final  sobre a contratação.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   37        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015     O entrevistador deve apresentar mais detalhes sobre a vaga, a empresa e o projeto.  Etapa eliminatória.  Responsável: Gestor de Tecnologia da Informação      f. Encaminhar ficha de contratação para RH  Após confirmação da contratação pelo Gestor de Tecnologia a Informação, deve ser  encaminhada ficha do empregado para contratação junto ao Departamento de  Recursos Humanos – RH.  Responsável: Gestor de Tecnologia a Informação      7.1.2   Indicadores e Metas  Este processo, elaborado pelo Comitê de Processos Organizacionais, estabelece os  seguintes indicadores e metas para o processo de recrutamento e seleção dos  profissionais para a fábrica de software da empresa:     • Estabelecer padrão de recrutamento e seleção.  • Contratar o profissional certo para a vaga certa.  • Diminuir rotatividade de profissionais contratados.      7.1.3   Resultado esperado para a empresa  O resultado esperado para a empresa é obter a maturidade de um processo de seleção  bem feito resulta na contratação de um staff adequado às atividades da para a fábrica de  software.      8.  Conclusão  Um dos maiores problemas das empresas do seguimento de tecnologia da informação  trata-se da inadequação do processo de recrutamento e seleção, o qual é algo essencial  para melhorar a qualidade dos profissionais que irão compor a empresa.     Neste trabalho foi definido um processo macro para uma empresa de consultoria  de serviços de tecnologia de informação com uma fábrica de software, que não possui  processo padronizado ou definido no recrutamento e seleção. O processo foi definido  em uma empresa de grande porte por um comitê liderado pelo autor deste artigo.    Como trabalhos futuros, prevê-se a efetiva implantação do processo; realizar  uma pesquisa quantitativa, na qual se observe a melhoria do processo e o impacto na  gestão de tecnologia da informação e na gestão de recursos humanos da empresa.      9.  Referências   AMÂNCIO, Stella Fonseca.  COSTA, Heitor Augustus Xavier. CAMARGO, Valter   Vieira. PENTEADO, Rosângela Aparecida Dellosso. Gerência de Recursos  Humanos para uma Fábrica de Software de Pequeno Porte. Junhode 2009.  Ouro  Preto/MG.   CAXITO, Fabiano de Andrade (2007). Recrutamento e seleção de pessoas. Curitiba:  IESDE Brasil,.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   38        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 31-38 Nov/2015     CHIAVENATO, Idalberto (2009). Recursos Humanos - O Capital Humano das  Organizações. 9 ed. São Paulo: Elsevier – Campus.   GONÇALVES, José Ernesto Lima (2000). As empresas são grandes coleções de  processos. RAE - Revista de Administração de Empresas. São Paulo, v. 40, n. 1, p. 619.   IANNINI, Túlio Ornelas (2011). O Perfil dos Profissionais de Tecnologia da  Informação. Belo Horizonte: Centro de Capacitação Orientar.   MICHEL, Murilo (2007). Tipos de recrutamento e sua importância para uma Gestão  adequada de pessoas aplicadas a Empresas. Revista científica eletrônica de  administração. Dezembro de 2007. Garça/SP, n. 13.   OECD – Organização de Cooperação e Desenvolvimento Econômicos. Perspectivas da  Tecnologia da Informação (2003). São Paulo: SENAC.   PAIM, Rafael. CARDOSO, Vinicius. CAULLIRAUX, Heitor. CLEMENTE, Rafael  (2009). Gestão de Processos: Pensar, agir e aprender. Porto Alegre: Bookman.   PEREIRA, Fabiana Marques. PRIMI, Ricardo. COBERO, Claudia (2003) Validade de  testes utilizados em seleção de pessoal segundo recrutadores. Psicologia: teoria e  prática. São Paulo: Pepsic.   PMBOK, Um Guia do Conhecimento em Gerenciameto de Projetos (2013). Project  Management Institute. 5ª Edição, Pennsylvania - USA 2013.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   165        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     Simulando Cenários para Redes Definidas por Software      Gabriel Marchesan1, Roseclea Duarte Medina1      Universidade Federal de Santa Maria (UFSM)   Avenida Roraima, 1000 – 97.105-900 – Santa Maria – RS – Brasil  1Grupo de Redes de Computadores e Computação Aplicada (GRECA)   {gmarchesan, rose}@inf.ufsm.br     Abstract. Nowadays the processes which involve the implementation and  deployment of the computer networks are limited by the choices of  standardized equipments from renowned manufacturers who in the most times  use proprietary softwares. To overcome these problems, the Software-Defined  Network (SDN) architecture was created, which makes it possible to the  networks to be customized according to the capability and requirement of the  environment. In this paper, it will be shown, in a general way, the main  concepts of the Software Defined Network by simulating two use case  scenarios with the SDN MiniNet tool.     Resumo. Atualmente, os processos que envolvem a implementação e  implantação das redes de computadores são limitados às escolhas de  equipamentos padronizados de fabricantes renomados, que na maioria das  vezes fazem uso de softwares proprietários. Para superar estes problemas,  surgiu a arquitetura Software-Defined Network (SDN), fazendo com que as  redes sejam customizadas de acordo com a capacidade e necessidade do  ambiente. Neste trabalho, será discorrido, de uma maneira geral, os  principais conceitos sobre Redes Definidas por Software, simulando dois  cenários de uso com a ferramenta SDN MiniNet.     1. Introdução    Para mitigar alguns dos problemas que existem nas redes atuais, como por exemplo,  limitação dos equipamentos padronizados que fazem uso de softwares proprietários,  grande demanda das tabelas de roteamento, complexidade de diversos protocolos,  grande número de aplicações executadas pelos usuários gerando gargalos na rede, surge  um novo conceito de arquitetura de rede, chamado de Software-Defined Network (SDN)  ou Redes Definidas por Software.     As SDNs constituem um novo paradigma para o desenvolvimento de pesquisas  em redes de computadores. Este paradigma vem adquirindo espaço e grande atenção de  parte da academia e das grandes indústrias da área de redes de computadores [GUEDES  et al., 2012].    As SDNs vão permitir que os programadores inventem novos métodos de  implantação de redes adequadas às diferentes necessidades dos usuários para otimizar o  desempenho de suas aplicações e consequentemente suas tarefas.   Esse novo  paradigma sugere o desacoplamento entre o plano de dados (hardware especializado) e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   166        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     plano de controle (executado em um ou mais servidores, os quais são responsáveis pela  programação das ações realizadas pelo hardware) [GUEDES et al., 2012]. Através desta  separação, e utilizando-se o protocolo OpenFlow, será permitido que os administradores  possam definir fluxos de dados e determinar quais caminhos os mesmos devem  percorrer, por exemplo, quando um switch ou roteador recebe um pacote, ao invés de  tomar a decisão sozinho, o pacote será enviado ao controlador, que utilizará critérios  que foram estabelecidos para tomar a decisão, criando dessa maneira as regras de  encaminhamento do fluxo de dados [COSTA, 2013].   Como as redes de computadores se tornaram uma infraestrutura crítica na nossa  sociedade globalizada, fazer experimentos em redes reais torna-se impraticável, pois  além do alto valor agregado dos equipamentos, os riscos de ocorrer possíveis problemas  seriam grandes e causariam transtornos no dia a dia nos diversos serviços que dependem  do uso da rede. Dessa maneira, com o plano de controle da rede à disposição dos  estudantes e pesquisadores da área, os mesmos podem aplicar suas novas ideias, em  simuladores de redes, sem violar as regras existentes de roteamento e sem causar  problemas nas redes em funcionamento [GUEDES et al., 2012].   Considerando o que foi exposto acima, o objetivo deste trabalho é explorar as  funcionalidades e os recursos oferecidas pelo simulador SDN MiniNet, dessa forma  possibilitando que professores e alunos possam utilizar o mesmo para realizar o estudo e  a prática das SDNs através de testes e simulações sem interferir na rede em produção.  Ademais, também tem como objetivo através do uso das simulações, deixar mais claro o  entendimento teórico e o comportamento prático dos dispositivos simulados, dessa  forma facilitando a interpretação e a abstração de informações aprendidas em ambientes  acadêmicos, consequentemente agregando novas competências e assim contribuindo  para um melhor ensino-aprendizagem da área de redes de computadores.   A próxima seção apresenta uma abordagem geral sobre SDN, também citando o  controlador utilizado no desenvolvimento deste trabalho. A seção 3, descreve o  simulador utilizado para a realização dos cenários, citando outros dois simuladores que  também implementam o protocolo OpenFlow, o qual permite a implementação das  SDNs. A seção 4, descreve as principais características do simulador MiniNet. A seção  5, descreve os cenários que foram simulados no trabalho. Por fim, a seção 6 descreve as  considerações finais e algumas sugestões para trabalhos futuros.      2. Redes Definidas por Software    Apesar da grande expansão da Internet, em termos de quantidade de dados trafegados,  de usuários conectados, de penetração e uma vasta gama de aplicações, não observou-se  significativamente uma evolução em sua arquitetura nos últimos anos. Algumas  modificações que já foram realizadas na arquitetura da Internet, não estão sendo  suficientes para atender as demandas de novas aplicações que vem sendo inseridas todos  dias na Rede.    Ao longo dos anos, a Internet tornou-se comercial, e os equipamentos de rede  tornaram-se “caixas pretas”, ou seja, implementações integradas verticalmente baseadas  em software fechado sobre hardware proprietário [COSTA, 2013]. Além disso, as redes  vem se tornando parte da infraestrutura crítica de diversos ambientes, pois sua utilização  é essencial em trabalhos empresariais, comerciais, domésticos, acadêmicos, entre  outros.  Com todos esses problemas surgindo, muitos pesquisadores afirmam que a arquitetura  de redes de computadores em geral e a rede mundial (a Internet) atingiram um nível de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   167        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     amadurecimento que as tornaram pouco flexíveis [GUEDES et al., 2012]. O resultado  desse modelo é o já reconhecido engessamento da Internet [CHOWDHURY;  BOUTABA, 2009]. Dentre estas novas propostas, a Universidade de Stanford e a  Universidade da Califórnia em Berkeley, propuseram esse novo paradigma de rede,  denominado SDN, como um novo conceito aberto a toda a comunidade de  pesquisadores de tecnologias e soluções de redes [MCKEOWN et al., 2008].    Esse novo paradigma, apresentado na figura 1, sugere a separação entre o plano  de dados (também chamado de plano de encaminhamento) responsável pelo  encaminhamento dos pacotes com base em regras, e o plano de controle, responsável  pelo controle da rede em geral, permitindo ao controlador o gerenciamento das entradas  da tabela de encaminhamento e das regras associadas ao tráfego desejado, dessa  maneira proporcionando uma melhor visão global sobre toda a rede e ficando a cargo  dele toda a inteligência da rede.          Figura 1 – Paradigma SDN  (BRITO, 2013)      Para estabelecer a comunicação entre o plano de controle e o plano de  encaminhamento foi preciso criar e padronizar uma API, sendo então estabelecido o  protocolo OpenFlow, um protocolo aberto que possibilita o desenvolvimento de  mecanismos programáveis baseado em tabelas de fluxos em diferentes switches e  roteadores [MCKEOWN et al.,2008], ele estabelece uma comunicação segura entre os  switches e o controlador, o qual utiliza esse canal para monitorar e estabelecer fluxos  conforme a inteligência estabelecida pelo software [MOZZAQUATRO et al., 2013].    Para a realização deste trabalho foi utilizado o controlador POX, o mesmo  possui uma boa curva de aprendizado, e além disso, foi especialmente projetado para o  desenvolvimento de softwares, componentes, contribuindo muito em pesquisas e no  ensino do protocolo OpenFlow, portanto sendo escolhido para utilização do presente  trabalho [HERVÁS, 2014]. Ademais, o POX disponibiliza uma interface mais simples e  uma pilha SDN mais organizada, facilitando nas pesquisas e nos estudos desta área  [COSTA, 2013].                    É importante ressaltar que SDN é uma abstração de mais alto nível do que o  protocolo OpenFlow, pois esse é uma tecnologia recente e que pode ser usada para  viabilizar a implementação das SDNs.      3. Simuladores SDN     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   168        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015       Como já citado anteriormente neste trabalho, as redes de computadores se tornaram uma  infraestrutura crítica na sociedade globalizada. Nesta situação, dificilmente pode-se  fazer experimentos em redes reais, pois além dos possíveis riscos que podem ser  gerados, é impraticável a construção de laboratórios e experimentos reais devido ao alto  valor dos equipamentos.   Com isso pode-se optar em fazer os testes e experimentos através de simulações  em simuladores de redes, assim, obtém-se uma modelagem de um ambiente mais  próximo do mundo real, dessa forma, possibilitando a avaliação de mais cenários, a um  custo e tempo razoavelmente pequeno se comparado com testes em ambientes físicos,  além disso, os simuladores são ferramentas essenciais para o estudo e evolução da  computação, especialmente na área de redes de computadores [DOURADO; FILHO;  MARQUES, 2011].   Em relação ao mundo acadêmico, por meio dos simuladores, professores podem  complementar o ensino de diversos temas e conteúdos mais técnicos na área de redes,  ajudando aos alunos na elucidação de conceitos abstratos e difíceis de se entender,  assim, agregando no aprendizado do aluno e instigando os mesmos a participarem mais  das aulas, dessa forma, melhorando como um todo o processo de ensino-aprendizagem.   Neste trabalho foi utilizado o simulador MiniNet para a realização das  simulações, o qual permite uma rápida prototipação de uma grande infraestrutura virtual  de rede, executando em um kernel real, com a utilização de apenas um computador  [MININET, 2015]. Além disso, o MiniNet cria uma rede virtual OpenFlow com um  controlador, switches, hosts e links, também permite desenvolver topologias  personalizadas utilizando scripts em Python [CONTERATO et al., 2013].              É importante ressaltar que além do MiniNet, existem outros simuladores SDN  que implementam o protocolo OpenFlow, como por exemplo, o NS-3 (Network  Simulator 3) e o EstiNet. O NS-3 disponibiliza dois controladores, que executam  funções básicas, permitindo que determinados fluxos de dados ou sejam descartados  pelo switch, ou realizem o processo de aprendizagem tradicional dos switches, onde  cada máquina é detectada e mapeada para uma porta específica do switch  [CONTERATO et al., 2013].   Ademais, o NS-3 também possui algumas limitações didáticas e técnicas, como  por exemplo, uma curva de aprendizado difícil, um módulo OpenFlow que não simula  de forma tão fidedigna uma rede OpenFlow real, não possuindo suporte ao tráfego TCP  entre o switch e o controlador e ao Spanning Tree Protocol (STP), entre outras  limitações. Já o EstiNet é um simulador proprietário, podendo ser utilizado para a  realização de simulações com vários controladores, também possibilita o modo de  simulação quanto o de emulação. O EstiNet apresenta como algumas desvantagens, o  fato de ainda não existir muito material disponível na Internet para estudo e pesquisa,  ainda ser pouco conhecido e utilizado para simulações em redes em geral, em especial  para SDNs, possuir uma curva de aprendizado de nível médio para difícil, e  principalmente por ser um software proprietário, o que inviabiliza um trabalho  acadêmico.  4. Cenários    Para a realização dos cenários de simulação, foi utilizado alguns dos  módulos/componentes fornecidos juntamente quando se instala o controlador POX,  sendo recomendado instalar o mesmo na própria máquina virtual VM MiniNet. É  importante ressaltar que em algumas versões mais recentes da VM MiniNet o  controlador POX já encontra-se instalado, já nas mais antigas, é preciso instalar o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   169        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     mesmo. Para este trabalho, foi realizada as simulações do cenário Switch e de um  cenário que possui loops em sua topologia de rede, sendo eliminado os loops através do  uso do STP (Spanning Tree Protocol).     4.1 Switch    Neste cenário foi simulado o comportamento do dispositivo switch em SDN. O switch  ou “comutador”, é um dispositivo que opera na camada 2 (enlace de dados) do modelo  de referência OSI. Ao contrário dos Hubs, os switches registram na tabela de repasse os  endereços MAC dos dispositivos que estão ligados a cada porta do equipamento. Então  o switch encaminha os pacotes de acordo com o endereço MAC de destino, sendo  considerado um dispositivo “inteligente” que tem a função de aprender com a rede e  depois apenas encaminhar o pacote para à máquina de destino específico.   Para a implementação deste cenário foi utilizado o módulo  “forwarding.l2_learning”. Para a realização deste cenário, foi utilizada uma topologia  de rede que consiste de três hosts ligados a um switch OpenFlow, e este a um  controlador OpenFlow. Para criar essa topologia, em um terminal SSH, basta apenas  executar o comando:   • “sudo mn --topo single,3 --mac --switch ovsk --controller remote”       Após isso, para abrir três janelas separadas, uma para cada host de modo que  facilite a visualização e o gerenciamento dos hosts, basta executar o comando  “xterm h1 h2 h3”.                Após isso, em outro terminal SSH, para poder ser inicializado o componente   “forwarding.l2_learning”, é preciso apenas acessar o diretório do “pox” e executar o  seguinte comando:    • “./pox.py log.level --DEBUG forwarding.l2_learning”  Prosseguindo o cenário, é executado um “ping” do h2 para o h3 (neste trabalho   utilizado com o endereço IP 10.0.0.3), após pingar um pacote do h2 para h3, através de  alguma ferramenta de captura de pacotes (por exemplo, “tcpdump” ou “wireshark” que  já vem instalado nas versões mais recentes da VM MiniNet) é possível observar que não  há fluxos de pacotes trafegando no h1. Portanto, como na outra máquina (h1) da rede  não está trafegando pacotes, e sim somente no destino específico (h3), assim, pode-se  observar que o componente está se comportando como um switch.             Através dessa simulação com a utilização das ferramentas de capturas de pacotes,  fica muito mais fácil de entender o funcionamento do dispositivo switch, pois é possível  visualizar de forma prática como é o comportamento do mesmo nas redes de  computadores, elucidando os conceitos teóricos, como por exemplo, o uso do protocolo  ARP para realizar a descoberta dos endereços MAC dos hosts da rede.     4.2 STP (Spanning Tree Protocol)    Neste cenário, será simulado uma topologia de rede que contém loops, isto é, uma  topologia que forma um anel/ciclo fechado, dessa forma a rede não consegue achar as  portas para realizar o encaminhamento dos pacotes. Para solucionar esse problema, é  utilizado o Spanning Tree Protocol (STP). Para realizar esse cenário, a figura 2 mostra a  topologia utilizada. Essa topologia é constituída de três switches e três hosts, sendo que  cada host está ligado a um switch, formando um ciclo fechado, consequentemente  gerando loop na rede.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   170        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015          Figura 2 – Topologia ocorrendo loop na rede  (Autoria própria)      Neste trabalho não será explicado como foi implementado o script, utilizando-se  a linguagem Python, da topologia que foi exposta anteriormente. Após fazer o script, é  preciso nomear ele (nesse exemplo, nomeou-se como “topo_loop.py”), salvar o mesmo  no diretório “/mininet/custom” e então para executar o script e gerar a topologia, basta  executar:    •  sudo mn --custom topo_loop.py --topo mytopo   Para fazer um teste, é executado o comando “pingall” para ver se os hosts irão   comunicar-se, é possível então observar que os hosts não comunicam-se, evidenciando  assim que a topologia realmente apresenta loop na rede. Para solucionar o problema de  loop presente na rede, em outro terminal SSH, entre no diretório do “pox” e  simplesmente execute o comando a seguir.   • ./pox.py openflow.spanning_tree --no-flood --hold-down openflow.discovery  forwarding.l2_pairs   Agora será preciso mais uma vez executar o script e gerar novamente a  topologia citada anteriormente, após isso, pode-se executar novamente o comando  “pingall” e é possível observar que agora os hosts conseguem se comunicar. Portanto,  pode-se constatar que realmente funciona o STP, eliminando o loop da rede.   Neste cenário foi utilizado uma topologia mais simples, mas é importante  ressaltar que com uma topologia mais complexa, como por exemplo com 8 switches e  16 hosts foi realizado a simulação e o STP também funcionou perfeitamente. Percebe-se  que a grande vantagem da utilização da SDN para esse caso, é que o controlador POX  vai ser o elemento responsável da rede, então é preciso somente implementar e executar  a aplicação do STP no controlador, que dessa forma o STP já será aplicado em todos os  equipamentos da rede, assim não sendo preciso por exemplo, fazer a configuração  manualmente do STP em cada equipamento da rede, facilitando o trabalho do  administrador de redes.     6. Considerações Finais    O paradigma SDN é um assunto bastante recente e começou a ser explorado a pouco  tempo. Mesmo assim, levantou grande interesse na área devido às suas capacidades de  aumentar significativamente a flexibilidade da estrutura da rede, a fim de fornecer  serviços com mais facilidade, ajustando-se às características da aplicação. Como prova     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   171        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     do interesse de especialistas nas SDNs, está o fato de já existirem no mercado os  primeiros dispositivos comerciais baseados no protocolo OpenFlow.   Através deste trabalho buscou-se apresentar inicialmente um breve contexto das  redes de computadores, ficando evidenciado que a atual arquitetura das Redes é pouco  flexível, pois mesmo que tenha sofrido algumas modificações nos últimos anos, estas  não foram suficientes para atender as demandas de novas aplicações que cada vez mais  vem sendo inseridas no contexto tecnológico.   Ainda, o presente trabalho buscou apresentar os principais conceitos sobre  Redes Definidas por Software, como por exemplo, os vários aspectos que envolvem o  protocolo OpenFlow, o controlador da rede, sendo utilizado o POX, o qual foi  especialmente desenvolvido para o ensino e pesquisa das SDNs.  Por fim, através do  simulador SDN MiniNet juntamente com a utilização dos recursos oferecidos pelo  controlador POX, foi realizada a implementação e a simulação dos cenário Switch, e do  cenário que possui loop em sua topologia, sendo eliminado o mesmo através do uso do  protocolo STP.    Em suma, apesar do paradigma ser recente, considerando o presente sucesso das  SDNs, acredita-se que esta nova tecnologia realmente irá trazer muitos avanços para o  desenvolvimento de novos serviços, aplicações e soluções para a área de redes de  computadores como um todo.               Por fim, como sugestão de trabalhos futuros, pode-se citar o desenvolvimento e  a implementação de mais cenários, a integração com Ambientes Virtuais de  Aprendizagem, a realização de testes em equipamentos físicos em uma rede real sem  afetar o tráfego em produção, a utilização e o estudo dessa nova tecnologia em cursos de  redes de computadores, expandindo o paradigma SDN, dessa maneira agregando novos  conhecimentos, contribuindo tanto na formação técnica quanto na científica de seus  entusiastas.     7. Referências       Brito, S. H. B. (2013) “Blog LabCisco: paradigma sdn de redes programáveis”.  Disponível em <http://labcisco.blogspot.com.br/2013/07/paradigma-sdn-de-redesprogramaveis.html >. Último acesso em: 24 jun. 2015.   Chowdhury, N.; Boutaba, R. (2009) “Network virtualization: state of the art and  research challenges”. IEEE Communications Magazine, v.47, n.7, p.20–26.   Conterato, M.; Oliveira, I.; Ferreto, T.; Rose, César A. F. (2013) “Avaliação do suporte  à simulação de redes OpenFlow no NS-3”, p.3–6.   Costa, L. R. (2013) “OpenFlow e o Paradigma de Redes Definidas por Software”.  Monografia de Graduação – Instituto de Ciências Exatas – Departamento de Ciência  da Computação - Universidade de Brasília.   Dourado, G. G. M.; Filho, G. P. R.; Marques, M. (2011) “A Importância da Simulação e  o uso do Network Simulator 3 na Pesquisa Científica”.   Guedes, D., Vieira, L.F.M., Vieira, M.M., Rodrigues, H. e Nunes, R.V. (2012) “Redes  Definidas por Software: uma abordagem sistêmica para o desenvolvimento das  pesquisas em Redes de Computadores”. XXX Simpósio Brasileiro de Redes de  Computadores e Sistemas Distribuídos - SBRC, p.160–210.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   172        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 165-172 Nov/2015     Hervás, O. R (2014) “Software Defined Networking”. Dissertação de Mestrado -  Universitat Politécnica de Catalunya.   Mckeown, N.; Anderson, T.; Balakrishnan, H.; Parulkar, G.; Peterson, L.; Rexford, J.;  Shenker, S.; Turner, J. (2008) “OpenFlow : enabling innovation in campus  networks”, p.1–6.   Mininet (2015) “Mininet: an instant virtual network on your laptop (or other pc)”.  Disponível em < http://mininet.org/ >. Último acesso em 24/06/2015.   Mozzaquatro, B. A.; Machado, C. C.; Lucca, M. R. B. (2013) COFFEE: controlador  openflow de fluxo para escoamento eficiente de streaming de vídeo. XII Simpósio de  Informática - SIRC 2013, p.20–25.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   149        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015     SWUAA - Sistema Web Unificado de Acompanhamento de  Alunos do Instituto Federal Farroupilha – Campus Alegrete   Arthur R. da Silva1, Iverton A. da Silva. dos Santos1   1Centro de Informática – Instituto Federal Farroupilha – Campus Alegrete  Alegrete – RS – Brazil   {iverton.santos,mtvolpato}@gmail.com  Abstract. This paper describes a web system for tracking students, focusing on  disciplinary matter. As a case study took the Instituto Federal Farroupilha - Campus  Alegrete. Fundamentally, the built application will facilitate the integration between  teachers, administrative staff and Student Assistance Coordination, as regards  communication and violations solution to the Coexistence Student Regulations of the  Institution.   Resumo. Este artigo descreve um sistema web para acompanhamento de alunos, com  foco na questão disciplinar. Como estudo de caso tomou-se o Instituto Federal  Farroupilha – Campus Alegrete. Fundamentalmente, a aplicação construída  facilitará a integração entre professores, técnicos administrativos, Coordenação de  Assitência Estudantil e Setor de Apoio Pedagógico, no que se refere a comunicação e  solução de infrações ao Regulamento de Convivência Discente da Instituição.   1. Introdução     No Brasil manter um ambiente de sala de aula propício à aprendizagem pode ser difícil.  Se um ou mais alunos atrapalharem a aula, o mal comportamento pode prejudicar outros  alunos ou diminuir o tempo destinado às atividades acadêmicas. Em vez de esperar  enquanto o mal comportamento de um aluno recai sobre o resto da classe (ou no  professor), a direção da escola pode tomar medidas preventivas para manter os alunos  produtivos e felizes (MORO, 2009).   Atualmente no Rio Grande do Sul a um grande desafio encontrado pelo  educador em relação à indisciplina em sala de aula. Costuma-se compreender a  indisciplina no meio educacional, como a manifestação de mau comportamento,  bagunça, agitação, falta de respeito com colegas e professores. Ela se manifesta nos  corredores da escola, nos intervalos de aula, na sala de aula, nas visitas, nos eventos da  escola, na entrada e na saída (URRUTH, 2011).   O Instituto Federal Farroupilha - Campus Alegrete, possui a CAE –  Coordenação de Assistência Estudantil e também o SAP – Setor de Apoio Pedagógico,  em que cada servidor ao perceber uma atividade discente que não seja compatível com o  Regulamento de Convivência discente ou atitude indisciplinada comunica a estes  setores. A CAE contem uma ficha de papel individual de acompanhamento da vida  escolar do aluno e ali ficam registrados os encaminhamentos, porém quando necessária  a intervenção de outros setores como o SAP, cada servidor faz suas próprias anotações e  encaminhamentos em papéis e editores de textos, pois não há um local único de  registros e de acesso fácil a essas informações. Isto dificulta ao servidor saber como está  o andamento das notificações realizadas, o que pode desestimular comunicações futuras  por parecer que não estão ocorrendo intervenções dos setores de acompanhamento  discente ou replicar o trabalho tendo encaminhamentos diferentes pela fala de  comunicação.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   150        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015     Neste sentido, desenvolveu-se um sistema web unificado de acompanhamento e  comunicação do comportamento de alunos para instituição, no qual busca ajudar a  instituição a ter um maior acompanhamento sobre atitudes dos seus alunos, tendo seu  foco no registro de informações pela parte do professor e servidores TAE o tratamento  dos encaminhamentos sendo função do CAE – Coordenação de Assistência Estudantil.   A aplicação teve processo de desenvolvimento envolvendo pedagogos, professores  e o coordenador da CAE. Ela pode ser acessada pela internet e foi desenvolvida com as  ferramentas PHP (Hypertext Preprocessor) (BUYENS, 2002), JavaScript (DUCKETT,  2010),  Jquery (GOODMAN , 2001) e o MySQL (BUYENS, 2002). Nas próximas  seções são descritos os principais requisitos funcionais, assim como resultados de  implementação desta aplicação.   2. O Regulamento de Convivência Discente do IF Farroupilha  O Regulamento de Convivência Discente do IF Farroupilha (RGIFFARROUPILHA,  2014) tem a finalidade de estabelecer os direitos e deveres dos discentes matriculados  nos cursos do Instituto Federal Farroupilha em relação à convivência na comunidade  acadêmica.    Por sua vez estabelece também as medidas disciplinares e aplicação das medidas  disciplinares. No que se refere as medidas disciplinares, as mesmas estão classificadas  como faltas leves, medias ou graves. Cabe ao Setor de Assistência Estudantil de cada  Campus, em conjunto com a comunidade escolar, elaborar os regulamentos de  convivência da Moradia Estudantil e do Refeitório, que devem estar de acordo com as  normas gerais previstas nos regulamentos institucionais e aprovados pelo Colegiado do  Campus e Conselho Superior.   3. SWUAA – Implementação e Resultados   Nas próximas seções são apresentados os módulos de maior relevância do sistema para,  de forma que os resultados obtidos possam ser visualizados claramente. A figura 1,  demonstra a tela de login do sistema. De acordo com o login, tem-se o acesso aos  módulos (1) Administrador (2) Professor ou TAE (3) CAE-SAP – Coordenação de  Assitência Estudantil e Setor de Apoio Pedagógico, com as suas funcionalidades  respectivas, explicadas nas seções a seguir.          Figura 1 – Tela de Login do SWUAA.           3.1 Módulo Administrador     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   151        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015     Os usuários do papel Administrador ao fazer login, já pode visualizar gráficos com  índices de infração leve, grave, ou média.  Além disso, pode realizar cadastro de   alunos, cursos e usuários do nos diferentes perfis do sistema, conforme figura 2.          Figura 2 – Funcionalidades do Usuário Administrador        3.2 Módulo do Professor e Técnico Administrativo - TAE  Os usuários no papel deste módulo inicialmente visualizarão os gráficos com números  que se referem aos seus registros encaminhados de infração mensal.  No menu da  página dos servidores, tem-se as opções Aluno, Gráficos, Relatórios, Encaminhamentos  em Aberto, Encaminhamentos Encerrados e Sair.    A opção Alunos permite acesso e busca a todos alunos por nome, curso, ou  turma de modo que, caso necessário, possa gerar um encaminhamento sobre o mesmo,  conforme figura 3.        Figura 3 – Opção de alunos        Ao clicar no botão gerar encaminhamento o professor acessa uma tela onde ele  informa a turma, data, níveis da infração e descrição da infração (conforme o  Regulamento de Convivência Discente), podendo também dar sugestões de atitudes a  ser tomadas e anotar observações do acontecimento, conforme figura 4.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   152        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015       Figura 4 – Tela de registro de encaminhamento     Na opção gráficos, conforme figura 5, o professor ou servidor TAE tem a opção   de visualizar gráficos mensais dos seus encaminhamentos do ano atual e ainda realizar  pesquisa por anos anteriores. O gráfico em forma de pizza contem três cores e cada cor  equivale a um nível da infração, leve (Azul), média (Vermelho) e grave (Laranja).         Figura 5 – Grafico mensal de encaminhamentos do servidor        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   153        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015     Por sua vez, a opção Relatórios contem vários filtros de relatórios em PDF, para  facilitar o servidor na sua pesquisa, conforme figura 6.             Figura 6 – Tela de opções de relatórios    O Relatório por Aluno e Intervalo de Datas, permite selecionar o nome do   discente e as visualizar possíveis ocorrências em um período letivo. Já o Relatório Geral  por Intervalo de Datas demonstra todas as ocorrências de um intervalo, em toda a  instituição. Por fim, o Relatório dos Encaminhamentos em Aberto, demonstra  informações dos encaminhamentos que a CAE ainda não registrou nenhuma solução no  sistema.  A figura 7, demonstra o exemplo do Relatório pelo aluno Carlos Ricardo no  período de maio de 2015, os detalhes são vistos ao clicar no botão visualizar, gerando o  relatório conforme figura 8.        Figura 7 – Relatório dos Encaminhamentos por Aluno e Data.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   154        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015       Figura 8 – Detalhes do registro de encaminhamento de aluno.     Na opção do menu Encaminhamento em Aberto, o servidor tem o controle de   seus encaminhamento que ainda não foram encerrados, ele pode acompanhar o  andamento de suas notificações, podendo busca-los por nome do aluno, nível de  infração ou data, conforme figura 9. Neste menu há ainda um número que indica a  quantidade de encaminhamentos em aberto. No exemplo da figura 9, existem 3  encaminhamentos em aberto.          Figura 9 – Opção de visualização dos encaminhamentos em aberto.        Na opção do menu Encaminhamentos Encerrados, o servidor visualiza os  encaminhamentos que tiveram algum retorno da CAE. Fundamentalmente o usuário  desta opção ao clicar em visualizar terá acesso a todos os detalhes que decorreram para  a solução do problema com aquele aluno em questão, conforme figura 10.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   155        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015       Figura 10 – Encaminhamentos encerrados     3.3 Módulo CAE-SAP - Coordenação de Assistência Estudantil   Neste módulo a CAE  ou o SAP tem todas as funcionalidades (relatórios,  gráficos, geração de encaminhamentos, etc...) pertinentes ao módulo Módulo do  Professor e Técnico Administrativo – TAE, descrito na seção 3.2. Neste sentido, o  diferencial do mesmo é a questão do tratamento das ocorrências. Quando o usuário  deste módulo clica no menu Encaminhamentos em Aberto, ele pode visualizar o  encaminhamento feito pelo Professor ou TAE e pode então dar uma providência para a  questão. Ao abrir o encaminhamento ele vê quem o encaminhou, o recurso utilizado no  momento, e também a sugestão deixada para solução, conforme figura 11.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   156        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015          Figura 11 – Tela de Encerramento de Encaminhamento.     Por fim, a opção cadastro de infrações é onde são cadastradas as infrações, seus  níveis e descrições, conforme o Regulamento de Convivência Discente, descrito na  seção 2.   4. Conclusão    Este trabalho descreveu uma aplicação WEB focada na gerencia de comunicação   de situações disciplinares em instituições de ensino, com base nas demandas do Instituto  Federal Farroupilha - Campus Alegrete. O trabalho foi inspirado na constatação de que  a instituição foco do trabalho realizava a atividade de forma manual, e assim os dados e  registros eram armazenados de forma antiquada e com pouca velocidade e muitas vezes  redundantes.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   157        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 149-157 Nov/2015     Acredita-se, por meio dos testes e encontros com professores, o SAP e a CAE,  que a aplicação impactará positivamente no Instituto Federal Farroupilha – Campus  Alegrete, e facilitará a integração professores-técnicos administrativos-CAE no que se  refere ao acompanhamento de alunos.    Como trabalhos futuros, podemos apontar a implantação definitiva no Campus.  Também espera-se a ampliação da esfera de acompanhamento, extendendo a aplicação  para registros de problemas pedagógicos e de aprendizado. Desejamos fazer  experimentos do comportamento antes e depois dos alunos após a implantação. Por fim,  pretende-se disponibilizar acesso aos pais, de modo que tenham informações em tempo  real sobre seus filhos, favorencendo a integração  da educação por meio da escola e  família.   Referências       RGIFFARROUPILHA. O Regulamento de Convivência Discente do IF Farroupilha.  Disponível em: <  http://www.svs.iffarroupilha.edu.br/site/midias/arquivos/201482112449365regulame nto_de_convivencia_discente_2014.pdf > Acesso em: julho de 2015.   BUYENS, JIM. APRENDENDO MYSQL E PHP. 1ª ED. SÃO PAULO: MAKRON  BOOKS, 2002.   DUCKETT, J. BEGINNING HTML, XHTML, CSS, AND JAVASCRIPT. INDIANA:  WILEYPUBLISHING, INC., 2010.   URRUTH, Marlete. INDISCIPLINA NA SALA DE AULA, Pelotas: Garcia, 2011,  p.34.   GOODMAN, DANNY. JAVASCRIPT: A BÍBLIA. RIO DE JANEIRO: ELSEVIER,  2001.   MORO, MARIANNE. Dicas para lidar com mal comportamento na sala de aula. eHow  Brasil, 2009.           
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   140        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     Sistemas de Identificação por Radiofrequência (RFID) Ativos  Integrados com Comunicações Via Satélite   Claiton P. Colvero1, Ricardo M. Zago1, Aluizio d’Affonsêca Netto2, Rodolfo Saboia3   1UFSM – Universidade Federal de Santa Maria, CTISM, Av. Roraima, 1000 – Prédio 5  – Santa Maria - Brasil - CEP: 97105-900   2I-Dutto/INMETRO - Prédio da Incubadora de Projetos do Inmetro, LAB 16, Duque de  Caxias - Rio de Janeiro - Brasil - CEP: 25250-020   3DMTIC/INMETRO - Prédio 6 do Inmetro, Duque de Caxias - Rio de Janeiro - Brasil -  CEP: 25250-020    claiton@redes.ufsm.br, afnetto@idutto.com, rssouza@inmetro.gov.br    Abstract. This paper describes the development of an integration project of  active radiofrequency identification transponders (RFID) for operation over  satellite communication network. To make efficient the use of the channel, it  has developed a pioneering communication protocol between active  transponders and satellite standard messaging system, observing the power  consumption parameters and bandwidth of this channel. With the implemented  protocol for bandwidth optimization, it is possible to monitoring up to 10  active RFID transponders in real time over each satellite message, and each  transponder has an estimated average battery life up to three years.   Resumo. Este trabalho descreve o desenvolvimento de um projeto de  integração de transponders de identificação por radiofrequência (RFID)  ativos para operação sobre uma rede de comunicação via satélite. Para  viabilizar o uso do canal com eficiência foi elaborado um pioneiro protocolo  de comunicação entre os transponders ativos e um sistema de mensagens via  satélite padrão, observando-se os parâmetros de consumo de energia e  capacidade deste canal de comunicação. Com o protocolo de otimização de  banda implementado é possível monitorar em tempo real até 10 transponders  RFID ativos em cada mensagem enviada pelo sistema de satélite, sendo que  cada transponder possui uma estimativa de vida média da bateria de 3 anos.   1. Introdução  Modernos sistemas de identificação eletrônica têm sido implementados nos últimos  anos em áreas estratégicas da indústria, com o grande desafio de fornecer as  funcionalidades de identificação da forma mais autônoma possível. Adicionalmente  tem-se observado uma crescente tendência em expandir os limites desse controle através  do monitoramento remoto e em tempo real. Para atender aos requisitos de identificação  eletrônica com baixa interação humana nos processos, os dispositivos de identificação  por radiofrequência (RFID) ativos apresentam uma grande aplicabilidade. Estes  sistemas operam através da leitura e identificação de dados codificados em  transponders RFID, também conhecidos como tags, que são capazes de transferir essas  informações por uma rede de comunicação sem fio formada entre os dispositivos.   A nomenclatura “ativos” define que estes transponders RFID utilizam uma fonte  de energia ativa, geralmente alimentados por uma bateria, para realizar a comunicação     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   141        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     com eficiência. Essa fonte é responsável por fornecer energia para suprir o sistema de  transmissão de sinais de radiofrequência e de leitura das informações de identificação.  Este artifício mantém a comunicação por longos períodos de tempo e com maior  potência de transmissão [Dobkin, 2008], o que proporciona uma maior dinâmica de  leitura. Esta superior dinâmica representa na prática uma maior distância de  identificação, e consequentemente um maior nível de automação, embora ainda exista  neste caso um limite relativamente baixo de cobertura se considerarmos a operação de  forma remota.   Para o acesso das informações remotamente e em tempo real, se torna necessária  a utilização de outros sistemas de telecomunicações complementares que possuam uma  maior capacidade de cobertura e transporte das informações. Embora redes de  comunicação de longa distância estejam presentes em muitos ambientes, o foco deste  trabalho é oferecer cobertura também em regiões de difícil acesso a estas tecnologias,  como aplicações em alto mar (offshore), embarcações em viagens globais, desertos,  regiões de baixa densidade demográfica, entre outros [Alvarenga, 2012]. Para estes  ambientes descritos anteriormente, a comunicação via satélite representa uma das  melhores alternativas em relação à disponibilidade do enlace e custo de implantação.   2. Metodologia   2.1. Integração de tecnologias  Este projeto tem como premissa a utilização de diferentes tecnologias de comunicação  através do compartilhamento dos recursos de rede de forma eficiente e transparente,  possibilitando a instrumentação e coleta de dados de identificação e rastreamento  remoto e em tempo real. A coleta de informações relevantes e precisas de forma  automática pelo sistema, assim como o transporte das mesmas de forma eficiente,  depende da correta integração das tecnologias de comunicação utilizadas.   A tecnologia RFID ativa em geral não utiliza protocolos de comunicação  regulamentados pelas principais agências de telecomunicações mundiais, e desta forma  costumam apresentar protocolos proprietários ou fechados [Ahson e Ilyas, 2008] em  seus produtos comerciais. A aplicação de padrões e protocolos de comunicação  proprietários gera um risco de descontinuidade tecnológica e carência de flexibilidade  tecnológica. Esta característica eventualmente pode até gerar a necessidade de  substituição de todos os dispositivos instalados no caso de problemas desta natureza. Da  mesma forma, a integração das diferentes tecnologias de comunicação disponíveis pode  se tornar muito complicada, uma vez que não existem normas específicas de utilização e  operação.   Para garantir a aplicabilidade destes processos de identificação por  radiofrequência em ambientes remotos de forma autônoma, principalmente  compartilhando recursos dos meios de comunicação disponíveis, tornou-se necessária a  criação de um pioneiro protocolo para operação dos transponders ativos, com  otimização dos dados para a completa integração com outros sistemas. Os tags ativos  normalmente operam em redes de comunicação de curta distância PAN (Personal Area  Network), na banda ISM (como por exemplo, 2,45 GHz), utilizadas para interligar  sensores locais ou sistemas de identificação eletrônica [Radio Regulations, 2012] sem a  necessidade de solicitar uma autorização especial dos órgãos reguladores locais para  operação, desde que devidamente caracterizadas como emissões de radiação restrita e  não ionizante.   O projeto contempla o desenvolvimento de um sistema completo de  identificação por radiofrequência baseado na tecnologia RFID ativa, integrado com um     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   142        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     sistema de comunicações via satélite para longas distâncias, assim como as demais  redes de comunicação disponíveis para o acesso remoto. Na Figura 1 pode-se observar  os dispositivos IDC1 e IDG1, que respectivamente correspondem aos dispositivos  desenvolvidos para realizar a comunicação entre os transponders RFID ativos e os  transceptores de comunicação via satélite utilizados. Esta integração dos dispositivos  RFID instalados em campo com um sistema de comunicação via satélite está sendo  desenvolvido para expandir a área de monitoramento de uma rede PAN de identificação  eletrônica, possibilitando o acesso remoto de longa distância a estas informações.   RFID1  RFID2  RFID3  RFID4  RFID5  RFIDN ...  IDC1 IDG1 Servidor  Internet  Rastredor Via satélite  Leitor RFID  Link Satélite  Monitorização a distância Clientes  Rede de  sensores  PAN    Figura 1.  Rede de aquisição e comunicação de dados do IDC1     Estes dispositivos RFID ativos podem ser monitorados em um ambiente hostil   ou em longas distâncias com apoio da rede via satélite, aumentando sua capacidade para  monitorar remotamente diversos dispositivos em tempo real. O protocolo de integração  desenvolvido garante a alta disponibilidade e eficiência de uso da banda de  comunicação via satélite, viabilizando a utilização comercial em larga escala com baixo  custo global.   2.2. Definição do protocolo e do hardware  Para o desenvolvimento do projeto foi utilizado um Transceiver NRF24LE1 (Nordic)  com microcontrolador integrado e um sistema de transmissão via satélite para a rede da  Globalstar, na banda L de frequências (em torno de 1,6 GHz), com modulo STX2  (Globalstar), microcontrolador MSP430FR5739 (Texas Instruments) e módulo GPS de  localização H2035A (Maestro). Os dispositivos montados para os ensaios, que estão  demonstrados na Figura 2, foram programados em linguagem C, com plataformas de  desenvolvimento estabelecidas pelos fabricantes dos módulos. O espectro utilizado  pelos tags ativos, especificado pelos transceivers da Nordic, ocupa os canais na mesma  faixa de 2,4 GHz de outros sistemas de comunicação, como o Wi-Fi. A estratégia de  prevenção de interferências adotada pelo protocolo é o FHSS (Frequency-hopping  spread spectrum) [Ahson e Mohammad, 2008], que consiste em chavear aleatoriamente  a portadora em 5 canais (2,404, 2,425, 2,442, 2,463 e 2,477 GHz), até que a  comunicação entre os dispositivos seja estabelecida. Neste experimento os canais mais  utilizados pela transmissão foram os canais 1 (2,404 GHz) e 2 (2,425 GHz), dada a  robustez dos enlaces com os dispositivos, principalmente contra as interferências de  sinal com o Wi-Fi.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   143        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015        (A) (B)   Figura 2.  Hardware desenvolvido para realização dos ensaios com os  protocolos. (A) Antenas e leitor do tag ativo (IDC1) acoplado. (B) Módulo de   transmissão via satélite STX2 e unidade de processamento compondo o IDG1   Os estados de operação, que estão demonstrados na Figura 3, foram adequados  ao formato de transmissão do sistema via satélite da Globalstar simplex, que permite no  máximo 54 bytes de tamanho de mensagem, limitando o envio de informação pela rede  em 10 identificadores (IDs) para Tags ativos. A operação dos tags é definida pela  resposta recebida da base, que define os tempos de ativação para os dispositivos da rede,  e dessa forma, determina o consumo de energia para cada um dos dispositivos.       Figura 3.  Estados de operação do sistema de leitura e operação dos tags RFID   O protocolo desenvolvido especificamente para a integração dos sistemas de  comunicação deste projeto utiliza o formato demonstrado na Tabela 1, onde pode-se  observar que estão sendo definidos bytes de identificação e controle dos dispositivos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   144        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015       Tabela 1.  Formato dos dados utilizados na comunicação entre os dispositivos   do projeto (tags e base – host)   Pacote de Dados IDC1 (bytes)   Dado Nome Descrição   B0   TAG ID  (6 bytes)   Identificação dos tags. Número  único para cada dispositivo   definido em firmware.   B1   B2   B3   B4   B5   B6 FRAME DE CONTROLE  Contador de pacotes enviados   usado para controle de perda de  pacotes.   B7 COMANDO  Comandos usados para controlar   dispositivo (device) e enviar  parâmetros de configuração   B8   DADOS E  ESTADOS   Dados de configuração e  argumentos do comando.   B9   B10   B11   B12   B13   B14   CRC 16   CRC calculado utilizando um  polinômio de 16 bits para   verificação da integridade dos  pacotes.   Calculado utilizando os bytes de  dados   (B0 a B13).   B15        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   145        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     2.3. Medições de desempenho  Neste projeto foram utilizados transponders RFID ativos para se obter uma melhor  dinâmica dentro de uma determinada área especificada de coleta de dados de  identificação eletrônica. Nesta configuração, é importante observar e caracterizar de  forma correta o consumo médio destes dispositivos ao longo do tempo. Estas  informações devem ser utilizadas para gerar as especificações dos dispositivos em  relação ao planejamento de sua manutenção preventiva, uma vez que possuem uma  bateria ativa como fonte de alimentação e devem ser substituídas em intervalos de  tempo conhecidos.   A medição de consumo de energia dos dispositivos foi direcionada para  representar uma melhor aproximação dos valores máximos obtidos na operação real,  seguindo procedimentos metrológicos definidos pelo Inmetro. O consumo foi  referenciado diretamente com a capacidade de energia fornecida pela bateria, sendo  monitorada a variação da corrente de alimentação do dispositivo em operação através de  um osciloscópio digital, adicionando-se um resistor de 100 Ω como sensor de corrente.  As medições foram efetuadas durante as transmissões de informação, enquanto o  circuito estava ativo na rede, e durante o estado de hibernação. Neste procedimento os  módulos NRF24LE1 foram posicionados à uma distância de 0,85 m entre a base e o tag  ensaiado.   As medições de desempenho da transmissão do sistema foram realizadas em  campo aberto para minimizar os efeitos de multipercurso de propagação, que são típicos  destas frequências. Da mesma forma, o ambiente selecionado foi o campus do Inmetro  em Xerém, Duque de Caxias -RJ, com o intuito de fornecer uma boa base metrológica  para a reprodutibilidade dos resultados obtidos. Neste ambiente, pode-se padronizar as  medições com a eliminação de qualquer eventual interferência de sinais da tecnologia  Wi-Fi, tornando essas fontes de ruído negligenciáveis nestas medições.   Como procedimento, de uma forma mais ampla, uma destas placas foi mantida  conectada em um computador portátil, enquanto que a outra atuava como sendo o host  remoto, posicionado inicialmente a 10 m da interface anterior. Essas medições foram  reproduzidas com incrementos de distância entre elas em uma razão de 10 metros a cada  nova medição. Foram repetidos estes experimentos até alcançar os tempos médios de  transmissão da ordem de 1 segundo.   Para a verificação da presença de eventuais sinais de espúrios não intencionais  que pudessem afetar as medições nos ensaios em ambiente externo foi utilizado um  analisador de espectros de radiofrequência (MS2721B, Anritsu), posicionado em uma  linha de visada direta com o sistema em análise, a 2 m da base de leitura dos tags. Ao  total foram realizadas três campanhas de medições (com a média do analisador de  espectros definida com 20 interações), sem a presença de sinal dos módulos Nordic,  com objetivo de caracterizar o piso de ruído no local da medição. Estes resultados foram  utilizados para a calibração das medições de desempenho do sistema em operação.   3.  Resultados e Discussão   Como principal premissa deste projeto foi definido que o sistema desenvolvido deveria  apresentar a possibilidade de integração entre os dispositivos de identificação por  radiofrequência ativos sobre um canal de comunicações via satélite. Essa integração  entre os sistemas é necessária para aumentar a distância da rede de identificação RFID  local e proporcionar o controle de forma remota em tempo real. Como o canal de  comunicações via satélite opera sob demanda e possui tempos de ociosidade entre as  transmissões dos dados, a otimização de uso de banda deste meio representa a  possibilidade de interconectar sistemas RFID em ambientes remotos e hostis, com     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   146        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     centrais de controle e monitoramento distantes, mantendo um baixo custo relativo de  comunicação através do compartilhamento destes recursos.   Após a calibração e análise de todos os dados obtidos nas campanhas de  medições deste projeto, foram geradas tabelas de consolidação dos resultados. A Tabela  2 está demonstrando exemplos de valores de corrente de entrada típicos obtidos.  Considerando-se o pior caso para o modo TX (modo de transmissão), onde o dispositivo  permanece ativo por 1 ms, o consumo de energia à plena carga é de 8,1 mA. Por outro  lado, no modo inativo, onde o dispositivo consome 1,2 µA com tempo de inatividade  mínimo estabelecido em 2 s, este apresenta um consumo médio de 4,05 µA. Com estes  resultados, pode-se observar que utilizando uma bateria CR2032 de 220 mAh (típica em  motherboards de computadores), esta poderia fornecer uma vida útil para dispositivo  RFID ativo de até 6 anos. Entretanto, nos ensaios em laboratório foi observado um  consumo atípico com esse tipo bateria de até 8,3 µA (em alguns casos), o que limitaria  no pior caso a operação do dispositivo em 3 anos sem manutenção.     Tabela 2.  Corrente de alimentação dos módulos Nordic     Modo de operação do dispositivo RFID ativo   Hibernando Transmitindo TX Esperando ACK  Consumo Médio 1,2 µA 8,1 mA 7,5 mA     A eficiência da transmissão impacta diretamente na ocupação da banda   disponível na comunicação via satélite, e desta forma também foi devidamente  caracterizada para definir a melhor metodologia de otimização dos pacotes de dados  neste meio. Na Tabela 3 pode-se observar os tempos médios para a transmissão dos  dados de identificação em função da distância que se encontram. Observa-se uma  tendência de incremento no tempo de transmissão com o aumento da distância entre os  dispositivos de transmissão e recepção. Este valor de tempo deve ser observado para  distâncias muito grandes, uma vez que pode atingir limiares de operação e comprometer  a disponibilidade do sistema.     Tabela 3.  Tempo de transmissão em função da distância entre os hosts    Distância entre os hosts   10 m 20 m 30 m 40 m 50 m   Tempo médio - TX 203,0 ms 216,08 ms 200,88 ms 256,69 ms 325,69 ms     Nesta tabela pode-se ainda observar valores acima do intervalo de tempo  máximo especificado, em torno de 200 ms (estimado nos ensaios), como o caso de  325 ms para a distância de 50 m. É importante observar que estes valores deverão ser  omitidos neste projeto, pois frequentemente foi verificada a presença de erros de  comunicação entre os nós da rede. Também é importante observar que as estimativas de  distâncias de identificação deste projeto são de no máximo 30 m. Esse limite é  justificado para oferecer a possibilidade de operação em ambientes onde a emissão de  radiação é controlada, como áreas explosivas ou inflamáveis. Estes dispositivos foram  configurados para operar com potência máxima de transmissão de 0 dBm (1 mW) e  sensibilidade de -94 dBm para recepção, minimizando a possibilidade de causar ignição  nestes ambientes.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   147        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     4. Conclusão  Neste projeto foi desenvolvido um sistema de integração de modernos dispositivos de  identificação por radiofrequência ativos com enlaces de comunicação via satélite, para  aplicações direcionadas à ambientes de difícil acesso ou hostis. Esta integração  proporcionou o incremento na dinâmica leitura e de identificação dos dispositivos RFID  desenvolvidos através do compartilhamento de banda da comunicação via satélite,  possibilitando o monitoramento e identificação de bens e ativos com alta  disponibilidade, de forma remota e em tempo real.   Através do protocolo elaborado para este projeto foi possível monitorar em  tempo real até 10 transponders ativos em cada mensagem enviada pelo sistema de  comunicações via satélite. Estas informações de identificação foram recebidas em um  servidor remoto localizado em uma distância muito superior a dinâmica de leitura típica  dos dispositivos RFID ativos utilizados, com alta disponibilidade e baixo custo de  implementação.   Por se tratar de dispositivos de identificação ativos, foram realizados diversos  ensaios em laboratório e em campo para determinar com maior exatidão qual o tempo  médio recomendado para realização de manutenções periódicas para substituição da  bateria interna. Os resultados obtidos apontam que por segurança cada tag RFID  utilizado possui uma estimativa mínima de vida útil de sua bateria em torno de 3 anos,  embora em condições ideais de utilização possam alcançar até o dobro deste tempo de  operação.   Concluindo os ensaios, também foi avaliada a eficiência da comunicação dos  transponders RFID em função de sua distância, uma vez que operam em baixas  potências de transmissão. Mesmo que o tempo de transmissão sofra um incremento  considerável de acordo com o aumento da distância, os resultados obtidos demonstram  que nesta configuração ainda atendem os critérios de dinâmica e seletividade  especificados para aplicação em diferentes ambientes de instrumentação.   O protocolo de comunicações implementado já está na fase de ensaios finais,  onde vem demonstrando excelentes resultados. Isto nos permite visualizar a futura  expansão da rede de monitoramento via satélite para dispositivos RFID de pequeno  volume e custos reduzidos, quando comparado ao sistema de rastreamento  convencional. Os sistemas ainda demonstram uma ótima capacidade de monitorar  dispositivos a uma distancia de até 50 m da base de leitura, permitindo formar redes  adaptativas de sensores e monitoramento de pequeno raio de cobertura, ideal para  aplicações de localização de dispositivos RTLS (Real Time Location System) em que se  deseja manter a seletividade.   5. Apoio Financeiro  Este projeto está sendo financiado pelo CNPq, FINEP e FAPERJ, visando apoiar  atividades de pesquisa, desenvolvimento e inovação em produtos e serviços através de  aporte financeiro na forma de Subvenção Econômica, e recursos humanos através de  Bolsas de Estudo, de acordo com a Lei nº 10.973/2004 (Lei da Inovação), Lei nº.  10.973/2004, regulamentada pelo Decreto nº. 5.563/2005, e Lei Estadual nº.  5.361/2008, regulamentado pelo Decreto Estadual nº. 42.302/2010.   6.  Referências  Dobkin, Daniel M., The RF in RFID: Passive UHF RFID In Practice, Newnes 2008   ISBN 978-0-7506-8209-1, chapter 8.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   148        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 140-148 Nov/2015     Ahson, Syed A. and Ilyas, Mohammad (2008). RFID handbook: applications,  technology, security, and privacy Boca Raton: CRC Press. p. 478. ISBN  9781420054996.   Alvarenga, F. R. P, et al., Utilização do sistema de posicionamento integrado (SPI)  durante as operações off-shore na Petrobras, IV Simpósio Brasileiro de Ciências  Geodésicas e Tecnologias da Geoinformação, Recife, maio de 2012, p. 001 -  007.   "Radio Regulations, Edition of 2012". ITU-R. Retrieved 2014-11-10.   Adair, Nick, Radio Frequency Identification (RFID) Power Budgets for Packaging  Applications, PGK-491, pp. 2-11, November 2005.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   124        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     Supervisionamento de Coordenadas Espaciais de um  Quadricóptero Baseado em Redes de Petri Colorida   Raif C. Gomes1, George André Pereira Thé1   1Departamento de Engenharia de Teleinformática– Universidade Federal do Ceará  (UFC)   Caixa Postal 6007 – 60455-970 – Fortaleza – CE – Brasil  raif.carneiro@gmail.com, george.the@ufc.br     Abstract. This paper aims to develop a CPN (Coloured Petri Net) able to supervise  a quadrotor, UAV (Unmanned Aerial Vehicles) rotary-wing, characterized by a  structure typically symmetrical and cross, with the use of the tool CPN Tools,  4.0.0. Thus, allowing the supervision of a quadrotor graphically, intuitively and  low cost.    Resumo. Este trabalho tem como objetivo, desenvolver uma RPC (Rede de Petri  Colorida) capaz de supervisionar um quadricóptero, VANT (Veículos Aéreo Não  Tripulado) de asas rotativas, caracterizado por uma estrutura, tipicamente,  simétrica e cruzada, com a utilizacão da ferramenta gratuita CPN Tools, versão  4.0.0. Possibilitando assim, o supervisionamento de um quadricóptero de forma  gráfica, intuitiva e de baixo custo.     1. Introdução   Cada vez mais, grandes empresas multinacionais como Google, Amazon e até o  Facebook investem no uso de VANT’s (Veículos Aéreos Não Tripulados) ou drones  tanto para solucionar problemas de logística, quanto para levar o acesso à internet a  áreas remotas.    Em breve milhares de drones poderão ser vistos nos céus realizando tarefas  cotidianas como guiar um turista pela cidade ou até acompanhar crianças até a escola.  Apesar da tendência de um aumento exponencial no uso de VANT’s nos próximos anos,  eles ainda possuem um valor elevado e somente podem ser operados em aplicações  profissionais por pessoas qualificadas e/ou através de softwares dispendiosos.    Com base nisso, é imperativo o desenvolvimento de um modelo supervisor que  possibilite o barateamento do custo operacional envolvido no controle dos  equipamentos supracitados, já que por meio desse, pessoas com conhecimentos básicos  em drones por exemplo, poderiam manusear um quadricóptero. É neste contexto que se  propõe o uso de Redes de Petri Coloridas. Conforme [Murata 1989], as Redes de Petri e  suas extensões são classes de modelos conceituais, as quais podem ser usadas na  modelagem dos mais diversos tipos de sistemas computacionais.    Assim, este trabalho tem como objetivo, desenvolver uma RPC (Rede de Petri  Colorida) capaz de supervisionar um quadricóptero ou quadrotor, VANT com asas  rotativas, caracterizado por possuir quatro motores, com a utilização da ferramenta  gratuita CPN Tools, versão 4.0.0 de forma gráfica, intuitiva e de baixo custo.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   125        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     2. Metodologia   Para desenvolver a Rede de Petri Colorida proposta, foi realizado um levantamento  bibliográfico, o qual culminou na escolha dos softwares empregados nesta pesquisa.  Essa seleção, deu-se a partir da necessidade de se utilizar programas de modelagem já  consolidados no meio científico, graças a confiabilidade na geração de gráficos e dados  por eles.    Desta forma, foi escolhido o CPN Tools, versão 4.0.0, o qual é ferramenta livre  voltada para modelagem através das Redes de Petri e suas extensões. Assim o modelo  referido foi empregado para supervisionar um quadricóptero em condições ideais, que  foi implementado e simulado com o uso do software de modelagem matemática Matlab,  versão 2014.a, conforme [Gomes and Aquino 2013]. Para o cálculo das forças atuantes  na estrutura do quadricóptero, utilizou-se a equação da força e a do momento angular, as  quais podem ser observadas, respectivamente, por (1) e (2):           (1)  Onde:      dp- Derivada do momento linear.      dt  - Derivada do tempo.      F  -  Força.       Onde:    (2)      dl - Derivada do momento angular.      N - Torque.     Diante disso, as expressões matemáticas anteriores foram decompostas para que o  estudo da atitude e altitude do quadricóptero fossem realizados. Assim, obteve-se as  equações (3) e (4), as quais estão em conformidade com os resultados encontrados por  [Jirinec 2011].          (3)  Onde:      m   - Massa.      dV  - Derivada da velocidade linear.      We - Velcodade angular.      V    - Velocidade linear.        (4)  Onde:      I  - Matriz identidade.     F= d p d t  N = d l d t  F= m∗  d V +  W e×  V  N = I∗  d W e+  W e× (  V ∗I )    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   126        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     Isto posto, na Figura 1, é exposto um protótipo de um drone usado como referência  na implementação citada.          Figura 1: Prótotipo de um quadricóptero.     Posteriormente, notou-se a necessidade de comunicar os dois modelos   desenvolvidos, já que tais modelagens iriam interagir entre si. Deste modo, a partir de  [Gallasch and Kristensen 2001], percebeu-se indispensável a presença de um servidor  elaborado em linguagem de programação Java, capaz de mediar a conexão entre os  modelos citados. Logo, foi utilizado o NetBeans, ambiente de desenvolvimento  integrado gratuito, versão 8.0, para a implementação do Middleware referido.    Portanto, as informações provenientes do MatLab ou do CPN Tools foram recebidas  pelo servidor que posteriormente, as encaminhava para a RPC ou para o drone,  respectivamente. A forma de conexão entre os softwares supracitados ocorreu por meio  de socket, o qual Segundo [Kurose 2010], é uma interligação entre um servidor e um  cliente. Destaca-se que ocorreu a aplicação do TCP (Transmission Control Protocol) na  camada de transporte de dados via socket, proporcionando assim, confiabilidade na  entrega de todas as informações. Para tanto, a Figura 2 apresenta o diagrama que  sintetiza o que foi descrito.      Figura 2: Diagrama representando a interligação entre softwares utilizados na pesquisa.     Na Figura 2, constata-se a existência de dois clientes(MatLab e CPN Tools) e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   127        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     somente um servidor(Java), os quais possuem uma interligação do tipo full duplex, ou  seja, podem realizar transmissões e recepções, simultaneamente, durante toda a  conexão. Ademais, na Tabela 1, constata-se os tipos de dados enviados e recebidos por  cada bloco da Figura 2.      Tabela 1: Tipos de dados enviados e recebidos por cada bloco da Figura 2.     Matlab Servidor(Java) CPN Tools   Envia [Ack] [Ack] / [x,y,z] [x,y,z]  Recebe [x,y,z] [Ack] / [x,y,z] [Ack]            A partir da Tabela 1, nota-se a presença de dois tipos de pacotes diferentes, o [Ack],   responsável pela sinalização de recebimento das coordenadas espaciais, e o [x,y,z], o  qual carrega as informações relativas ao posicionameno do equipamento simulado.  Desta forma, o CPN Tools gera os pacotes do tipo [x,y,z] e os envia ao servidor(Java),  os quais são retransmitidos ao drone simulado no MatLab. Posteriormente, o MatLab  transmite um pacote do tipo [Ack] ao CPN Tools por intermédio do Middleware  utilizado, quando o veículo aéreo chega aos valores alvos, inicialmente, definidos.    Vale ressaltar que a arquitetura de comunicação desenvolvida facilitará a supervisão  de qualquer quadricóptero real, já que o bloco MATLAB, no qual executa-se a  simulacão do drone, poderá ser, facilmente, substituído por um quadrotor físico,  respeitando-se, apenas, os padrões do TCP para que haja a comunicação do servidor  (Java) com o veículo aéreo referido.    No que tange ao supervisor desenvolvido neste trabalho, a RPC modelada apresentou  duas subpáginas, as quais interagem entre si para gerar os setpoints, isto é, valores alvos  de posicionamento a serem transmitidos ao quadricoptero simulado no MatLab. Desta  maneira, a Figura 3, demonstra a página principal do modelo proposto criado no CPN  Tools.      Figura 3: Comportamento geral da rede de Petri colorida desenvolvida.   Com base na Figura 3, nota-se a presença de quatro blocos principais, sendo o  primeiro intitulado Inicia, responsável pelo estabelecimento da comunicação via socket  entre o CPN Tools e o servidor desenvolvido. O segundo localiza-se ao lado esquerdo  do bloco anterior, denominado COORDENADAS, que representa a primeira subpágina  da RPC e é responsável pela geração de coordenadas aleatórias espaciais de posição e o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   128        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     envio dessas ao MatLab para que sejam assumidas pelo quadrotor inicialmente.   Na parte inferior da figura em análise, nota-se o bloco nomeado por ACOES, o qual   simboliza a segunda subpágina desenvolvida, atuando na criação de novas posições  aleatórias do quadricóptero e, também, na transmissão de tais informações para o  software MatLab. Enfim, o quarto e último bloco, designado Display1, armazena as  posições alcançadas pelo drone durante toda a simulação, permitindo assim, o  supervisionamento do equipamento controlado.    Com base nos antecedentes, pode-se inferir que na RPC, os retângulos sempre  desempenham ações, os quais são chamados de transições e as elipses atuam como os  estados do sistema modelado no tempo discreto, denominados lugares. Para um melhor  detalhamento da modelagem criada no CPN Tools, na Figura 4 são expostos alguns  componentes da subpágina chamada COORDENADAS.         Figura 4: Comportamento geral da rede de Petri colorida desenvolvida.     A partir da Figura 4, o lugar designado Entrada, recebe uma sinalização por parte da   página principal observada na Figura 3, informando que a conexão do CPN Tools com  MatLab foi realizada. Após essa ação, as transições T21 e T22 conceberam as  coordenadas horizontais x e y uma vez que a posição vertical inicial do quadricóptero  sempre será zero. Já T23 faz envio dos dados para o quadricóptero. Em seguida, o  MatLab envia uma confirmação da recepção das informações a RPC, essa recepção é  representada pelo retângulo, recebe1.    É importante frisar, que os componentes da subpágina COORDENADAS, são  semelhantes as encontradas na ACOES, existindo apenas um acréscimo de uma  transição e de um lugar, os quais são responsáveis pela geração da coordenada vertical  z.    3. Resultados e Discussão   Com base nos procedimentos técnicos metodológicos mencionados, foram iniciados os  testes com os modelos desenvolvidos em conjunto com o Middleware, servidor em  Java, com a finalidade de comprovar a funcionalidade do supervisor implementado.    Inicialmente, foram feitos 50 testes, os quais eram compostos por: 1) pela  inicialização da comunicação entre a RPC modelada com o MatLab; 2) a geração de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   129        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     coordenadas iniciais aleatórias; e 3) por fim novas localizações randômicas, com o  intuito de englobar os possíveis setpoints envolvidos em uma teleoperação de um  quadrotor real.    Após a verificação do perfeito funcionamento do sistema, realizou-se mais 100  ensaios, os quais proporcionaram a compreensão de como os setpoints gerados e  enviados ao MatLab estavam relacionados com as resposta comportamentais do drone  simulado. Tal fato está de acordo com os resultados de [Jensen 1997], pois segundo ele,  as Redes de Petri permitem a identificação dos estados e ações de qualquer sistema  modelado de modo claro, graças as representações gráficas disponíveis. Por meio da  Figura 5, observa-se a página principal da RPC implementada, ao final de um ensaio.      Figura 5: Página principal da RPC implementada ao final de um ensaio.     Na Figura 5, nota-se que ao fim do teste feito, o quadricóptero simulado assumiu as   posições horizontais x=1 e y=1 e a coordenada vertical z como já citado, inicialmente, é  igual a zero. Essas informações são explicitadas pelo lugar L25 na figura acima. Além  do posicionamento inicial, pode-se constatar que novas coordenadas aleatórias de  localização, x=1, y=1 e z=1, foram geradas a partir do supervisor e essas atingidas,  posteriormente, pelo drone referido. Tais dados, são expostos no lugar, denominado  Display1. Desta forma, a cada ensaio é possível efetuar o monitoramento do sistema  controlado em tempo real. Para um melhor entendimento do que foi relatado, na Figura  6, expõem-se os setpoints sendo alcançados ao longo do tempo pelo quadrotor simulado  no caso de posicionamento inicial, x=1,y=1 e z=0, configuração essa, anteriormente,  abordada.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   130        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015       Figura 6: Setpoints sendo alcançados ao longo do tempo pelo quadricóptero simulado   em sua configuração de posicionamento inicial.     De acordo com [Jensen 1997], as redes de Petri, também, possuem a capacidade de   exibir as características dos Sistemas a Eventos Discretos. Isto posto, realizou-se uma  análise da RPC modelada, através das ferramentas built-in encontradas no software  CPN Tools. Dessa maneira, com a avaliação dos dados retornados a partir verificação  citada, pode-se afirmar que não houve a presença de conflitos ou erros estruturais ou  comportamental no modelo supervisor criado, garantindo o perfeito funcionamento da  RPC implementada.    Os métodos aqui apresentados e discutidos estão em consonância aos usados por  [Batista and Giovanni 2008], os quais propõem um sistema de navegação para robôs  móveis terrestres por meio de Redes de Petri Coloridas. Entretanto, há diferenças entre  as ações tomadas pelos equipamentos envolvidos e os níveis de sofisticação presentes  nos sistemas de supervisionamento referidos.    4. Conclusão   Portanto, a partir da modelagem e simulação dos sistemas dinâmicos supracitados,  percebeu-se uma operacionalidade menos complexa em relação aos métodos  tradicionais, os quais apresentam uma extensa quantidade de váriaveis numéricas usadas  para o supervisionamento do drone. Tais parâmetros são contituídos por ângulos de  guinada, arfagem e rolagem, velocidade de rotação de cada hélice, posicionamento  espacial e torques presentes no equipamento supervisionado. Isto posto, pode-se inferir  uma redução de custos referentes a mão-de-obra especializada, pois com utilização do  modelo proposto, o quadricóptero não necessitará de pessoas, altamente, qualificadas  para guiá-lo ou monitorá-lo.    Ademais, convém destacar que todos os procedimentos realizados em nível de  simulação, poderão ser transferidos para uma aplicação prática, possuindo,  teoricamente, os mesmos níveis de funcionalidade aqui apresentados e que no caso de  uma RPC de supervisionamento mais sofisticada seja implementada, as ferramentas  built-in do CPN Tools propiciarão a verificação de possíveis erros não previstos na  modelagem.    Assim, qualquer quadricóptero será capaz de ser monitorado, remotamente, por meio  do supervisor aqui apresentado, desde que tal equipamento siga as especificações de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   131        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 124-131 Nov/2015     conexão com o servidor desenvolvido nesta pesquisa.    5. Agradecimentos   Os autores agradecem a CAPES pelo suporte financeiro e a Fundação NUTEC, pelas  apoio administrativo.    Referências    TOC \f \n 1-9 Batista, Í. J. L. B. and Giovanni, C. (2008). Modelo de navegação para  robôs móveis baseados em redes de petri coloridas. Master’s thesis, Universidade  Federal do Ceará, Fortaleza.    Gallasch, G. and Kristensen, L. M. A. (2001). Comms/cpn: A communication  infrastructure for external communication with design/cpn. In Third Workshop and  Tutorial on Practical Use of Coloured Petri Nets and the CPN Tools, pages 75–91.  DAIMI.    Gomes, R. C. and Aquino, F. J. A. (2013). Simulação de voo vertical de um  quadricóptero usando software livre. Congresso Tecnológico InfoBrasil Ti —  Telecom, pages 1– 4.    Jensen, K. (1997). Coulored petri net: Basic concepts. Springer, 2th edition.    Jirinec, T. (2011). Stabilization and control of unmanned quadcopter. Master’s thesis,  Master of Science in Space Engineering-Czech Technical University, Prague.    Kurose, J. F. e ROSS, K. (2010). Redes de Computadores e a Internet. Pearson, 5th  edition.    Murata, T. (1989). Petri nets: Properties, analysis and application. In Proceedings of the  IEEE, pages 541–580. IEEE.        
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   212        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015     Um aplicativo de lembrete de tarefas para alunos, pais e  professores integrado ao Moodle   Fábio Goulart Andrade, Monique Invernizzi,   Mauricio Covolan Rosito, Júlia Marques Carvalho da Silva   Instituto Federal de Educação, Ciência e Tecnologia do Rio Grande do Sul –  Campus Bento Gonçalves – Bento Gonçalves, RS – Brasil   fabio.andrade@bento.ifrs.edu.br, nique.invernizzi@gmail.com,  mauricio.rosito@bento.ifrs.edu.br, julia.silva@bento.ifrs.edu.br  Abstract. This paper describes an application for mobile devices designed to  facilitate course management in virtual environment Moodle. The solution  results from a study of the main difficulties faced by teachers users of virtual  learning environments (VLEs). The application consists of a support tool for  teaching tasks which displays reminders of activities to be evaluated by the  teacher. Through this, we intend to investigate the relationship between the  use of VLEs by teachers and the development of tools that support their  teaching practice. The application can also be used by students and their  parents, since it allows the monitoring of school tasks through notifications.  The optimization potential offered by the tool will be measured at the home  institution based on the Affective Dimensions of Distance Learning Tutor.   Resumo. Este artigo descreve um aplicativo para dispositivos móveis que visa  facilitar o gerenciamento de cursos no ambiente virtual Moodle. A solução é  resultado de um estudo sobre as principais dificuldades enfrentadas por  docentes usuários de ambientes virtuais de ensino e aprendizagem (AVEAs). O  aplicativo consiste em uma ferramenta de apoio às tarefas didáticas que exibe  lembretes de atividades a serem avaliadas pelo professor. Através deste,  pretende-se verificar a relação entre o uso de AVEAs por professores e o  desenvolvimento de ferramentas que deem suporte à prática docente. O  aplicativo também pode ser utilizado por alunos e seus responsáveis, uma vez  que permite o acompanhamento de tarefas escolares por meio de notificações.  O potencial otimizador oferecido pela ferramenta será medido na instituição  de origem com base nas Dimensões Afetivas do Tutor EaD.   1. Contextualização  A popularização de tecnologias modernas, como o computador e a internet, tem impacto  significativo nos mais variados segmentos da sociedade atual. No contexto da educação,  o uso de novos recursos tecnológicos em sala de aula deixou de ser uma realidade  distante, passando a ser visto como parte desejável - e por vezes imprescindível - no  processo de ensino-aprendizagem [Kenski 2007].   Dentre as alternativas disponíveis, o Ambiente Virtual de Ensino e  Aprendizagem (AVEA) é um sistema informatizado voltado a educadores e educandos.  Através de um conjunto de ferramentas online, docentes são capazes de disponibilizar  conteúdos, solicitar e receber trabalhos, avaliar tarefas submetidas e comunicar-se com  os alunos [Roebuck 2012].   De modo semelhante, os dispositivos móveis demonstram grande potencial para  o intermédio de atividades educacionais. O termo mobile learning (também chamado mlearning) descreve o uso de tecnologias móveis (como tablets e smartphones) para     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   213        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015     possibilitar a aprendizagem "a qualquer hora e em qualquer lugar". Exemplos de mlearning incluem o uso de aparelhos celulares para acessar recursos didáticos, produzir  conteúdos e comunicar-se com professores e colegas fora do espaço da sala de aula  [UNESCO 2015].   Os dispositivos móveis podem ainda ser utilizados em associação com outras  Tecnologias de Informação e Comunicação (TIC). É o caso do AVEA Moodle, que  possui uma versão oficial em forma de aplicativo (Figura 1). O Moodle Mobile  (disponível para Android e iOS) apresenta as principais funcionalidades de sua versão  web, tais como acesso ao conteúdo dos cursos, leitura e envio de mensagens, download  e visualização de materiais, dentre outros [MOODLE 2015].       Figura 3. Moodle Mobile, o aplicativo oficial do Moodle    Diante do vasto conjunto de possibilidades, uma nova postura é esperada dos  profissionais do ensino. Mas qual seria a opinião dos mesmos quanto às mudanças em  sua metodologia de trabalho?   Gubert e Machado (2009) afirmam que "[...] o professor tem sido desafiado a  ultrapassar seu papel autoritário e de dono da verdade para se tornar um articulador,  pesquisador crítico e reflexivo e principalmente que se aproprie dos recursos  tecnológicos disponíveis em ambientes virtuais". Para Rosa (2013), no entanto, o  domínio tecnológico exigido do professor usuário de TICs é consideravelmente alto,  muitas vezes distante de sua realidade ou capacitação prévia. Neste sentido, Silva  (2009) defende a necessidade de formação tecnológica adequada, apontando para um  possível subaproveitamento das interfaces disponíveis atualmente.   De modo geral, pouco se sabe a respeito do docente assistido por meios digitais.  Pesquisas referentes ao uso de ambientes virtuais tendem a ser centradas no aluno e em  suas necessidades cognitivas. O professor, embora igualmente importante no processo, é  frequentemente esquecido [Kinshuk et. al 2001].   O trabalho descrito a seguir é resultado de um estudo conduzido no primeiro  semestre de 2015. Este buscou identificar as principais dificuldades vivenciadas por  professores e pesquisadores brasileiros que utilizam algum tipo de ambiente virtual.   Com base nos dados analisados, foi desenvolvido um aplicativo para  dispositivos móveis integrado ao ambiente Moodle. Os resultados e conclusões obtidos  serão detalhados nas seções subsequentes.   2. A Pesquisa  Setenta e oito professores e pesquisadores de diferentes instituições de ensino foram  entrevistados por meio de um questionário eletrônico. Quando perguntados a respeito de  suas dificuldades, cerca de 90% dos participantes afirmou já ter enfrentado problemas  no uso de AVEAs.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   214        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015      Dentre as adversidades relatadas por eles, o acompanhamento de discussões em  fóruns aparece como um fator crítico, especialmente para turmas numerosas. A  administração de múltiplas disciplinas também foi bastante mencionada, sendo  considerada complexa por exigir maior dedicação e tempo do docente.   A fim de mitigar estas situações, uma solução orientada ao gerenciamento de  cursos foi elaborada. O ambiente virtual escolhido para a implementação da mesma foi  o Moodle, utilizado por aproximadamente 75% dos entrevistados (Figura 2).       Figura 4. AVEAs utilizados por professores e pesquisadores entrevistados     3. Aplicativos Similares  Facilitar a organização da rotina escolar ou acadêmica é um objetivo comum a diversas  soluções computacionais na atualidade. Embora a maior parte destas ferramentas se  destinem ao aluno, algumas possuem elementos relevantes para professores. Exemplos  de aplicativos gratuitos com temática relacionada incluem: My Study Life, Student  Agenda, inClass, e Complete Class Organizer.   My Study Life - recurso multiplataforma que permite registrar e acompanhar  atividades, provas e exames. Com ele o usuário pode gerenciar cursos e tarefas do dia-adia, sendo notificado a respeito de aulas e prazos. Também é possível criar e  compartilhar cronogramas com um grupo específico, como os alunos de uma escola.  Esta funcionalidade pode ser particularmente útil para professores, embora ainda esteja  em fase de testes [ Mystudylife.com 2015].   O aplicativo se destaca pela interface colorida e moderna (Figura 3), além de  possuir um dashboard que facilita a visualização dos dados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   215        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015       Figura 5. Dashboard do aplicativo My Study Life    Student Agenda - Alternativa desenvolvida por estudantes para estudantes com  ênfase na organização de compromissos. Atua basicamente como um calendário,  embora também permita marcar eventos e tarefas como concluídos e registrar notas  (Figura 4). Oferece lembretes das próximas atividades e possibilita incluir fotos para  descrever os eventos [Play.google.com 2015].         Figura 6. Dashboard do aplicativo My Study Life    inClass - Com mais de 1 milhão de downloads em todo o mundo, este aplicativo  também permite o gerenciamento de um cronograma de aulas e tarefas através de um  dispositivo móvel (Figura 5). Destaca-se pelas chamadas "notas multimídia", onde é  possível gravar vídeos e áudios, inserir arquivos e até mesmo realizar impressões. Além  disso, possui integração com o Facebook e iTunes. Atualmente, está disponível somente  para iOS.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   216        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015       Figura 7. Telas do aplicativo inClass    Complete Class Organizer (CCO) - Além das características comuns aos outros  aplicativos mencionados, o CCO (Figura 6) dispõe de funcionalidades específicas para  facilitar anotações em aula, como por exemplo um sincronizador de áudio e texto.  Outras opções incluem uma calculadora de notas, importação de arquivos de texto e  integração com Dropbox e Google Drive. O aplicativo está disponível somente na   AppStore.         Figura 8. Tela do aplicativo Complete Class Organizer   4. Ferramenta Desenvolvida  O aplicativo IFRS-BG Moodle foi desenvolvido com base em necessidades relatadas  por docentes e tem como principal objetivo o de facilitar o gerenciamento de cursos no  ambiente virtual Moodle. Do ponto de vista do professor, este pode ser um aliado na  administração de tarefas, visto que reúne informações relevantes de todos os cursos aos  quais o usuário está associado.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   217        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015       Figura 9. Tela inicial do IFRS-BG Moodle    A tela inicial (Figura 7) segue o esquema de cores do Moodle da instituição,  permitindo autenticação por meio de login/e-mail e senha. Em caso de perda de senha, o  aplicativo também oferece links para a página do Moodle, onde é possível realizar o  procedimento de recuperação ou troca da mesma.   Após autenticar-se, o usuário é redirecionado para a tela de lembretes (Figura 8),  onde poderá visualizar notificações de próximas atividades seguidas de registros dos  últimos 30 dias. Caso haja tarefas a ser avaliadas, novas postagens em fóruns ou  qualquer outro evento significativo desde o último acesso, estes serão exibidos em uma  seção própria, discriminando-se o número de entradas novas e o total já verificado.       Figura 10. Tela de lembretes e notificações do professor    Todas as atividades listadas incluem nome, prazo (data e hora) e disciplina. Cada  tipo de tarefa possui um ícone próprio, os mesmos utilizados pelo Moodle.   Além dos professores, alunos e seus responsáveis também poderão se beneficiar  do aplicativo, já que as notificações oferecidas permitem um acompanhamento direto da     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   218        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015     rotina escolar. Os usuários serão alertados quanto a provas, tarefas pendentes e demais  atividades dos cursos a eles relacionados.   5. Conclusões  No que se refere ao uso de AVEAs por professores, a falta de recursos tecnológicos  adequados se destaca como uma das principais dificuldades enfrentadas pelos docentes.  Diversas são as tarefas relacionadas ao ensino que podem ser facilitadas por meio de  novas ferramentas. O levantamento realizado junto a professores e pesquisadores  permitiu conhecer sua perspectiva a respeito dos ambientes virtuais que utilizam, ao  passo que estudos sobre o assunto costumam focar exclusivamente nas necessidades e  desejos do aluno.   A popularidade crescente de dispositivos móveis, aliada à praticidade que  oferecem, demonstra potencial para fins educativos, atualmente explorado no contexto  do m-learning. Aplicativos para gerenciamento de horários e rotina acadêmica em geral  são relativamente comuns, podendo ser encontrados de forma gratuita nas principais  plataformas.   A alternativa proposta no aplicativo IFRS-BG Moodle integra a funcionalidade  de lembretes com o ambiente virtual Moodle. Diferentemente do aplicativo oficial, no  entanto, sua ênfase está na simplicidade, trazendo somente as informações mais  relevantes para o acompanhamento de um ou mais cursos.   Funcionalidades adicionais presentes em ferramentas semelhantes - como  upload de arquivos e integração com redes sociais - não foram implementadas, uma vez  que tais recursos não se enquadram no escopo do projeto. Quanto à interface, a  ferramenta não apresenta atrativos visuais específicos como o My Study Life e CCO,  mas preserva a identidade visual do AVEA pelo uso de ícones e esquema de cores já  conhecidos pelos usuários do Moodle.   Como trabalhos futuros, pretende-se avaliar o potencial de otimização oferecido  pelo aplicativo na própria instituição de origem. Para isto, serão analisados registros do  ambiente virtual em momento anterior e posterior ao uso da ferramenta. As métricas  adotadas serão as Dimensões Afetivas do Tutor EaD [Cunha, Silva and Bercht 2008],  através das quais espera-se verificar se o desenvolvimento de novas ferramentas pode  afetar positivamente a sociabilidade, comunicabilidade, pontualidade,  comprometimento, meticulosidade e iniciativa do professor.   Referências  Completeclassorganizer.com (2015) "Complete Class Organizer",   http://www.completeclassorganizer.com, September.   Cunha, C., Silva, J. and Bercht, M. (2008) "Proposta de um modelo de atributos para o  aprimoramento da comunicação afetiva para professores que atuam na educação à  distância", In: Simpósio Brasileiro de Informática na Educação, SBIE.   Gubert, R. and Machado, M. (2009). "A prática docente e o novo paradigma  educacional virtual", In: IX Congresso Nacional de Educação – EDUCERE, 2009,  Champagnat.   Inclassapp.com (2015) "inClass - The last school app you'll ever need",  http://www.inclassapp.com, September.   Kenski, V. (2007) "Educação e tecnologias: o novo ritmo da informação", Papiros,  Campinas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   219        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 212-219 Nov/2015     Kinshuk, Tretiakov, A., Hong, H. and Patel, A. (2001), "Human teacher in intelligent  tutoring system: a forgotten entity". In: IEEE International Conference on Advanced  Learning Technologies, IEEE, p. 227-230.   MOODLE (2015). "Moodle Mobile", https://docs.moodle.org/dev/Moodle_Mobile,  September.   Mystudylife.com (2015), "My Study Life", https://www.mystudylife.com, September.   Play.google.com (2015) "Student Agenda",  https://play.google.com/store/apps/details?id=com.clawdyvan.agendadigitalaluno,  September.   Roebuck, K. (2012). "Virtual Learning Environments (VLE): High-impact Strategies -  What You Need to Know: Definitions, Adoptions, Impact, Benefits, Maturity,  Vendors", Emereo Pub, Dayboro.   Rosa, R. (2013) "Trabalho docente: dificuldades apontadas pelos professores no uso das  tecnologias", In: VII Encontro de Pesquisa em Educação, UNIUBE, p. 214-227.   Silva, M. (2009) "Formação de professores para a docência online", In: Actas do X  Congresso Internacional Galego-Português de Psicopedagogia, Universidade do  Minho.   UNESCO (2015). "Mobile Learning",  http://www.unesco.org/new/en/unesco/themes/icts/m4ed, September.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   235        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     Um estudo de caso de um curso baseado em SPOC e abordagem  centrada no aluno   Júlia Marques da Silva, Bianca Neves, Bruno Guerra, Júlia Studer, Letícia  Heinmann, Marco Antônio Canossa, Maria Eduarda Romagna, Karina Letícia   Pinto      LADS - Instituto Federal de Educação, Ciência e Tecnologia do Rio Grande do Sul  (IFRS) - Bento Gonçalves, RS -Brazil      Resumo. A evolução do ensino a distância demanda de novos estudos para  melhoria contínua do ensino-aprendizagem, tornando o aluno mais consciente e  presente neste processo. Este artigo trata do estudo de caso de um curso que utiliza  abordagens Small Private Online Course (SPOC) e ensino centrado no aluno.  Assim, busca-se verificar a aplicabilidade destes conceitos tendo como ferramenta a  plataforma Moodle, e como estudo de caso um curso de programação web.   1. Introdução   O uso de ambientes virtuais de ensino-aprendizagem vem se tornando popular a cada dia, seja  para suporte a disciplinas presenciais ou em cursos ofertados totalmente a distância.  Entretanto, percebe-se que as práticas pedagógicas neles aplicadas buscam repetir o modelo  tradicional, onde se oferecem conteúdos e exercícios os quais devem ser acessados de forma  linear. Algumas mudanças nesse cenário são percebidas, como no caso da arquitetura Massive  Open Online Course (MOOC), onde instituições de ensino prestigiadas, disponibilizam cursos  de forma gratuita aos interessados. Contudo, dada a quantidade expressiva de inscritos, os  cursos criam sensação de afastamento entre os participantes, uma vez que os encontros são  pouco oportunizados.    Como uma vertente contrária ao MOOC, o Small Private Online Course (SPOC)  apresenta-se como um retorno as experiências iniciais da educação a distância, onde o tutor  dispõe de um grupo pequeno de alunos, permitindo a aproximação mais frequente entre os  participantes.    Ainda, como forma de possibilitar o aluno a escolher o seu próprio caminho de  aprendizagem, delegando-o maior autonomia, encontra-se a abordagem centrada no aluno.  Nela, cabe ao aluno decidir qual conteúdo e quando deseja estudar, algo que a tradicional  abordagem centrada no professor não permite, uma vez que o professor é quem decide os  rumos da disciplina.    O presente artigo visa investigar a seguinte questão: “É possível desenvolver  um  curso no Moodle onde o aluno se auto-regule utilizando as abordagens SPOC e abordagem  centrada no aluno?”. Para responde-la, selecionou-se como estudo de caso o curso de  programador web, o qual é composto por cinco disciplinas independentes.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   236        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     2. Abordagens Educativas e Tecnológicas Utilizadas   O presente artigo questiona a possibilidade de se utilizar a abordagem educativa da  aprendizagem centrada ao aluno e a abordagem tecnológica de Small Private Online Course  (SPOC) no ambiente virtual Moodle. Desta forma, as subseções a seguir descrevem como  estes conceitos se constituem.   2.1. Small Private Online Course (SPOC)   O Small Private Online Course consiste na oferta de cursos online com número limitado de  alunos, de forma que eles sejam atendidos por tutores, e por este motivo, devem ser  custeados. Na literatura, trata-se de um conceito recente, fato este observado em Burge et al,  (2015) onde buscaram definições para o SPOC em um debate. Contudo, sua prática vem  sendo adotada em diversos cursos há alguns anos.     Logo, o objetivo do SPOC é garantir a qualidade do ensino, não deixando o aluno  sozinho no processo ensino-aprendizagem. Downes (2013) reforça que o modelo SPOC é a  melhor forma de transmitir conhecimento a um grupo pequeno de pessoas, oferecendo uma  abordagem mais humana, não apenas focada em um sistema programado.    Desta forma, acredita-se que a combinação do SPOC com a aprendizagem centrada no  aluno, possa ser a arquitetura de ensino a distância ideal para o estudo de caso do curso de  programador web.   2.2 Ensino centrado no aluno   Tradicionalmente, o cenário da sala de aula envolve um professor que pré-seleciona os  conteúdos que ele acredita ser importante para a formação do aluno dentro de um plano  pedagógico curricular. Ao aluno, cabe assistir à aula expositiva e, em seguida, provar que  assimilou tal conhecimento através de exercícios de repetição ou solucionando problemas. Por  vezes, o professor verifica a aprendizagem durante o processo, podendo realizar ajustes ao seu  planejamento prévio. Porém, a possibilidade do aluno ser um agente participativo no processo  educativo, não é incentivada. As características aqui citadas compõem o que se define por  “abordagem centrada no professor” (Klein, 1998).    Como uma alternativa a esta, encontra-se a “abordagem centrada no aluno” (Learner  Centered-Approach - LCA). Nela, o aluno escolhe o que e como quer aprender, tornando-se  um agente ativo e responsável por sua trajetória. Por sua vez, o professor é considerado como  um companheiro da aprendizagem, auxiliando e orientando os alunos; portanto, cabe ao  próprio professor mudar a sua forma de ensinar (Overby, 2011). Segundo Nanney (2004)  possuem vantagens sobre a abordagem tradicional centrada no professor, permitindo que os  indivíduos possam lidar com seus próprios interesses e necessidades de aprendizagem e  avançar em níveis cada vez mais complexos de conteúdo para aprofundar o seu conhecimento  e apreciar assunto.    Dentro do contexto de uso de ambientes virtuais de aprendizagem, ambas abordagens  podem ser aplicadas. Entretanto, “abordagem centrada no aluno” oferece qualidades  essenciais para o estudo de caso proposto. Uma delas, por exemplo, é a autoavaliação que o  aluno tem ao longo do curso, medindo a sua eficácia no curso e reduzindo a complacência. Ou  seja, oferecendo a possibilidade de replanejar a forma em que ele está aprendendo.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   237        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     3. Estudo de caso: curso de programador web   Considerando a investigação proposta neste trabalho, foi proposto um curso de programador  web como estudo de caso. O curso é composto de quatro disciplinas: HTML, CSS, JavaScript  e PHP; ofertados sequencialmente, observando-se os pré-requisitos de aprendizagem de tais  conteúdos. Ainda, cada disciplina foi organizada em quantidade de aulas específicas, dado o  conjunto de conteúdos a serem apresentados.    O curso teve um professor conteudista, responsável pela estruturação dos conteúdos e  elaboração dos materiais didáticos; além de uma equipe de tutores, especialistas nas  disciplinas, responsáveis pela mediação da aprendizagem (comunicação direta com os  estudantes) e acompanhamento (verificação e correção dos exercícios).    A partir das características do curso de programador web, o passo seguinte da pesquisa  consistiu-se na elaboração do course design, isto é, o planejamento de como os conteúdos  instrucionais (vídeos e exercícios) devem ser dispostos ao aluno. Neste caso, a organização  didática respeitou aplicação das técnicas de SPOC e abordagem centrada ao aluno.    Inicialmente, foi necessário compreender conteúdos essenciais para entendimento dos  conhecimentos técnicos na formação de programação web: HTML, CSS, JS e PHP. Em  seguida, foram elaborados os materiais didáticos (vídeos e exercícios), observando a técnica  de LCA, permitindo ao aluno escolher o próprio caminho de aprendizagem e nível de  aprofundamento.    A partir dos recursos didáticos construídos, foi realizada a organização dos mesmos  em cursos da plataforma Moodle. Para isto, foram usados os recursos: arquivo e tarefas. Na  opção arquivos, foram disponibilizados vídeos contendo definições e exemplos. E as tarefas  possibilitaram o exercício prático, contendo todos os tópicos da disciplina. A Figura 1a ilustra  parte da organização da disciplina “JavaScript”, e a Figura 1b demonstra uma tarefa com  exercícios práticos.      Figura 1. (a) Estrutura geral de uma disciplina; (b) tarefa     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   238        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015      Sob a perspectiva do conceito SPOC, além do uso das ferramentas citadas, faz-se  necessária a oferta de um mecanismo de comunicação entre alunos e tutores. Ou seja, apesar  do aluno poder percorrer livremente os conteúdos, conforme orienta a abordagem centrada ao  aluno, ele pode necessitar dialogar com os colegas e até mesmo o professor, a fim de sanar  alguma dúvida. A fim de oportunizar tal comunicação, optou-se pelo uso de fórum de  discussão no formato pergunta/resposta, pois uma vez que um aluno apresenta algum  questionamento, este e sua respectiva resposta ficam disponíveis aos demais colegas; e do  diário de bordo, para dúvidas ou assuntos individuais. Ainda, é possível contatar o tutor  através do recurso de mensagem privada ou e-mail.   Ao iniciar o curso, os alunos já possuíam acesso ao material de todas as aulas de  duração e podiam consultá-lo quando quisessem, através da plataforma Moodle, com um  prazo para o envio dos exercícios, que eram corrigidos pelos tutores. Ainda, cabe esclarecer  que cada aluno foi designado a um tutor específico, responsável pelo acompanhamento de sua  aprendizagem durante todo o curso.   Para a verificação da aprendizagem são disponibilizados exercícios práticos, isto é, o  desenvolvimento de trechos de códigos correspondentes a linguagem do curso. Os exercícios  possuem três níveis de dificuldade, com as respectivas pontuações: fácil (1 ponto), médio (2  pontos) e difícil (3 pontos). Em cada aula solicita-se uma lista de exercícios, onde o aluno  deveria somar 6 pontos, cabendo a ele escolher os exercícios a serem realizados e entregues,  podendo, inclusive, ultrapassar a pontuação máxima.    A presença dos alunos é verificada através de relatórios fornecidos automaticamente  pelo Moodle, que indicava quem havia acessado os materiais e exercícios.    4. Resultados iniciais   Neste momento, o curso encontra-se em andamento, sendo que as disciplinas de  HTML e CSS já foram finalizadas; e, portanto, tendo como próximas atividades a oferta das  disciplinas de JavaScript. Desta forma, aqui são apresentados os resultados obtidos até o  presente.   A divulgação do curso ocorreu 2 meses antes do seu início, onde foi realizada uma  pré-inscrição online. Os interessados poderiam indicar quais disciplinas desejariam cursar,  não havendo, portanto, obrigatoriedade de cursá-lo na íntegra. Isto se deve à caracterização do  curso, onde tradicionalmente se encontra pessoas que conhecem certas temáticas, porém  desejam explorar outras. Reforça-se que esta estratégia está interligada com a proposta da  abordagem centrada ao aluno, onde o aluno é capaz de selecionar, isto é, julgar o que deseja  estudar. Acredita-se que ao obrigar o aluno cursar todas as disciplinas, dispararia-se um efeito  desmotivador. Nesta etapa, obteve-se 169 inscritos nas disciplinas de HTML e CSS, 154 em  JavaScript, e 180 em PHP. Percebeu-se também que a maioria das inscrições foram  registradas em todas as disciplinas, havendo um pequeno incremento na disciplina de PHP;  sugerindo que há pessoas com conhecimentos básicos em programação web, os quais desejam  apenas se aprofundar neste conhecimento.   Após a inscrição nas disciplinas desejadas, os inscritos receberam uma mensagem com  as instruções para cadastro na plataforma Moodle e nas respectivas disciplinas. Nesta etapa,  verificou-se que apenas 65% (110 inscritos) efetivaram a matrícula na disciplina de HTML e  48% (82) em CSS. Tal fato é preocupante, pois demonstra que o interesse inicial não  prosseguiu até a matrícula; relacionando a uma possível sensação de aproveitamento da     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   239        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     oportunidade inicial, porém não havendo disponibilidade posterior ou real interesse quando  esta se concretiza.   Tal fato pode ser corroborado com o número de participantes de cada disciplina, isto é,  quantos alunos de fato participaram em algum momento, e por fim, a concluíram. Nota-se que  36% dos inscritos iniciais realmente participaram, sendo que 15% finalizaram o curso de  HTML. Já em CSS, 21% participaram e 6% concluíram. Os valores descritos são  apresentados na Tabela 1.   Tabela 1.  Números dos alunos dos cursos via Moodle   Cursos Inscritos Matriculados Participantes Concluintes   HTML  169 110 61 27   CSS 169 82 37 11   Embora não seja foco deste trabalho, questiona-se os motivos que levam o baixo  engajamento dos alunos, principalmente, ao verificar um alto número de inscritos, o que  demonstra algum interesse. Alguns relatos dos estudantes, afirmam a dificuldade do assunto  abordado e a falta de tempo para dedicar-se ao mesmo. Isto foi comprovado na prática da  tutoria, onde frequentemente surgiam questionamentos sobre possíveis postergações nos  prazos das atividades.    Em relação as atividades avaliativas, conforme dito anteriormente, em cada aula é  oferecido um conjunto de questões de nível fácil, médio ou difícil. Na disciplina de HTML  (que contém 3 aulas), foram submetidos o total de 300 exercícios. Na primeira aula foram  enviadas 150 questões fáceis, 100 médias e 50 difíceis. Na segunda, menos de 50 atividades  de cada nível. E na terceira houve um aumento no número de entregas de exercícios, sendo 80  fáceis, 65 médios e 30 difíceis.   Na disciplina de CSS foram entregues 175 exercícios; sendo que na primeira aula: 110  fáceis, 45 médios e 20 difíceis; na segunda: 60 fáceis, 50 médios e 5 difíceis; e na terceira: 30  fáceis, 30 médios e nenhum exercício difícil. Os dados das disciplinas são apresentados na  Figura 2.      Figura 2. Nível de dificuldade das questões entregues por disciplina   Observa-se assim que, de modo geral, houveram alunos que tentaram realizar  atividades dos diversos níveis; porém, na disciplina de CSS, verifica-se que na 1a aula, houve  uma tendência mais expressiva em optar por questões fáceis. Isto pode sugerir que os alunos,  inicialmente, desconheciam o assunto ou optaram por questões mais simples a fim de se  assegurar de sua aprendizagem. Algo que no decorrer do curso, percebe-se que houve uma     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   240        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     tendência em trocar por questões do nível médio. Já em HTML, verifica-se que houve um  padrão de escolhas nas três aulas quanto a dificuldade, porém houveram alunos que não  participaram da aula 2, retornando para a aula 3.   5. Conclusões   Os ambientes virtuais de ensino-aprendizagem vêm sendo utilizados por instituições de  ensino, os quais podem ser oferecidos sob a abordagem MOOC ou SPOC. Por outro lado, sob  o ponto de vista educacional, a organização didática pode favorecer a aprendizagem centrada  no professor ou no aluno.    A pesquisa apresentada buscou responder a pergunta: “É possível desenvolver um  curso no Moodle onde o aluno se autorregule utilizando as abordagens SPOC e aprendizagem  centrada no aluno?”. Para responde-la, elaborou-se um estudo de caso, de um curso cujas  características convergem para a abordagem SPOC e aprendizagem centrada no aluno.    A abordagem SPOC foi implementada através da participação constante da tutoria. Os  tutores ficaram responsáveis por auxiliar os alunos por meio do Fórum de Dúvidas e do  Diário de Bordo. Também orientaram os alunos através da correção das atividades postadas,  mostrando os erros cometidos e como melhorar o código das atividades por meio dos  feedbacks, ferramenta disponível na plataforma.   Quanto a abordagem centrada ao aluno, percebe-se que o curso pode promovê-la  através da adaptação do currículo, segmentando-o. Entretanto, a implementação em sua  totalidade, por mais que seja tecnicamente viável, nem sempre é uma opção didaticamente  favorável. Ainda, há conteúdos que precisam ser visto de forma sequencial a fim de  compreendê-lo. No estudo de caso, apresenta-se a possibilidade do aluno escolher as  disciplinas a cursar, obtendo certificado por disciplina, porém para o conteúdo interno há a  necessidade de estruturá-lo sequencialmente, embora não se limite o aluno quanto ao seu  caminho de aprendizagem. Isto é, não há restrições para acessar qualquer um dos materiais  didáticos ou exercícios dentro da disciplina.    Na prática, verificou-se que vários alunos entregaram as atividades no prazo  estabelecido, e sempre buscavam melhorar suas habilidades na área do curso. Infelizmente,  alguns alunos não postaram as tarefas, e outros não acessaram o Moodle desde a data de  abertura do curso. Estes dados confirmam que, apesar de ser muito útil, os cursos virtuais  ainda não têm a mesma taxa de presença do que uma aula tradicional.    Outras interações foram desenvolvidas, como a relação entre o tutor e o aluno na  correção das atividades, apontando o que o aluno havia feito de maneira correta, ou elementos  que o tutor achava interessante nas respostas dos alunos. Este é um dos elementos que mais  deve ser explorado em um ambiente virtual, pois ao contrário de uma sala de aula, não há uma  interação tão grande entre o aluno e o tutor. Ainda, sabe-se que alguns detalhes devem ser  melhorados, como a taxa de presença dos alunos, e a interação entre o tutor e o aluno,  segundo foi observado pelos próprios tutores.   Referências   Burge, J. et al. SPOCs: What, Why, and How. In: Proceedings of the 46th ACM Technical  Symposium on Computer Science Education. ACM, 2015. p. 595-596.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   241        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 235-241 Nov/2015     Downes, S. The quality of massive open online courses. Disponível em: http://cdn. efquel.  org/wp-content/blogs. dir/7/files/2013/05/week2-The-quality-ofmassive-open-onlinecourses-StephenDownes. Pdf. Acessado em: maio, v. 15, p. 2013, 2013.   Fox, A. From moocs to spocs. Communications of the ACM, v. 56, n. 12, p. 38-40, 2013.   Klein, L. F. Alegria de aprender, alegria de avaliar. In: OSOWSKI (org.). Provocações da sala  de aula. São Paulo: Loyola, 1998.   Nanney, B. (2004) Student-centered learning. Retrieved November, v. 30, p. 2012.   Overby, K.: Student-Centered Learning: ESSAI: The College of DuPage Anthology of  Academic Writing across the Curriculum, v. 9, n. 32, p. 109-112, 2011.          
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   39        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     Um Método para Minimizar Falhas de Segurança em Redes  WLAN 802.11b/g: Controlando Acessos Provenientes de   Dispositivos Móveis    Leandro Ferreira Paz3, Rodrigo Petter Daniel1, Vinícius Maran2, Cristiane  Ellwanger1   1 Departamento de Ciências Exatas e Engenharias – Universidade Regional do Noroeste  do Estado do Rio Grande do Sul (UNIJUÍ)    Caixa Postal 489 – 98.900-000 – Santa Rosa RS – Brasil     2 Coordenadoria Acadêmica – Universidade Federal de Santa Maria (UFSM)  Av. Presidente Vargas, 1958 – Cachoeira do Sul – RS – Brasil     3 Instituto Federal de Educação, Ciência e Tecnologia Farroupilha   Rua Uruguai, 1675, Bairro Central, Santa Rosa – RS – Brasil  {rodrigo.daniel, cristiane.ellwanger}@unijui.edu.br,   viniciusm@inf.ufsm.br, leandro.paz@iffarroupilha.edu.br     Abstract. Wireless networks play a fundamental role for organizations to  evolve both technologically and economically. Allied to this, the proliferation  of mobile devices has brought the convenience of connection between  devices, anytime, anywhere. However, in this scenario the vulnerability of  wireless networks has become a worrying factor because often access to  corporate networks does not provide levels of security required for sensitive  data traffic. With this, this paper proposes a method for implementing a  wireless  802.11b/g  secure with  a  focus  on  mobile devices  in  order to   protect  the confidential information of companies.   Resumo. Redes sem fio possuem papel fundamental para que as  organizações consigam evoluir tanto tecnologicamente como  economicamente. Aliado a isto, a proliferação dos dispositivos móveis   trouxe  a comodidade de conexão entre dispositivos, a qualquer momento, em  qualquer lugar. No entanto, neste cenário,  a vulnerabilidade das redes sem  fio tornou-se um fator preocupante, pois muitas vezes o acesso interno às  redes corporativas não oferecem níveis de segurança necessários para o  tráfego de dados sigilosos. Com isto, este artigo propõe um método para  implementar redes sem fio 802.11b/g segura com foco em dispositivos móveis  a fim de proteger as informações confidenciais de empresas.   1. Introdução  Em 2015, uma pesquisa realizada pela Fortinet [Fortinet, 2015] levantou que as redes  sem fio representam o ponto mais vulnerável da infraestrutura de tecnologia da  informação. Os dados apontam que 49% das organizações classificam a infraestrutura  sem fio como o elemento de maior exposição as atividades de roubo de dados. Além  disso, 43% das empresas fornecem acesso a dispositivos móveis meramente como  convidados e 13% permitem isso sem aplicar nenhum controle de acesso.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   40        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015      Vários trabalhos se direcionam a proteção de informações organizacionais a  partir de dispositivos móveis. Silva & Ludwig [2011] propõem uma metodologia para  auditar redes sem fio 802.11b/g, com base em seis fases de auditoria, abordando um  planejamento que vai desde o desenho do mapa topográfico da rede, que contém o  leiaute onde a auditoria será feita até a captura de dados para análise por ferramentas,  emprego de protocolos de segurança, monitoração da rede e aumento da segurança das  aplicações, entre outros. Trabalhos como os de Cansian et al., [2004] e Pinto & Gomes  [2011] ressaltam as vulnerabilidades e ameaças das redes wireless tais como as falhas  no protocolo WEP, relatam as susceptibilidades às invasões externas e a descriptografia  de pacotes.    Embora tais trabalhos sejam de suma relevância para a área de segurança das  informações, eles não demonstram de forma clara como ela pode ser preservada. Diante  do exposto, o presente artigo propõe um método de implementação de uma rede WLAN  local 802.11b/g para dispositivos móveis, cujo acesso externo é segurado por uma  conexão criptografada através de uma Virtual Private Network (VPN). A vantagem de  usar uma VPN para dispositivos móveis é garantir um nível adequado de segurança para  os sistemas críticos conectados quando uma infraestrutura de rede subjacente por si só  não pode fornecê-la.    O artigo está estruturado da seguinte forma: Na Seção 2 é apresentada uma  descrição das redes sem fio e suas classificações e características. Na Seção 3 é  demonstrado como o método proposto foi concebido. Na Seção 4 são descritos os  cenários e ferramentas utilizadas. Na Seção 5 são apresentados os resultados da  aplicação do método e na Seção 6 são apresentadas as conclusões deste trabalho e  trabalhos futuros.   2. Redes Sem Fio 802.11: Classificações e Características  O padrão IEEE 802.11 tem por objetivo documentar e padronizar Wireless Local Area  Network (WLAN). Esse padrão é constituído por diversos subgrupos, onde cada um  deles possui novos implementos e melhorias. Esses subgrupos recebem uma letra, em  ordem alfabética, conforme são desenvolvidos ou planejados, referenciados como  802.11b, 802.11g e 802.11i.  Em redes sem fio as topologias que seguem o padrão IEEE  802.11 são duas: ad hoc e infraestruturadas. A primeira é independente, ou seja, não  necessita de um ponto de acesso para que exista comunicação entre os dispositivos  conectados. Já a segunda, que é abordada nesta pesquisa, possui a necessidade que toda  a comunicação entre os dispositivos móveis passe por um ponto central como um  Access Point (AP) ou um roteador.    Redes infraestruturadas sem fio são similares ao da telefonia celular, onde há  obrigatoriedade de que a comunicação passe por um ponto central, ou seja, ainda que os  dispositivos conectados na rede estejam bastante próximos, os mesmos não podem se  comunicar diretamente. Duas premissas são utilizadas neste contexto, ou se usa uma  comunicação ad hoc, ou se utiliza uma estação de suporte à mobilidade da rede  infraestruturada, neste caso.  2.1. Propriedades do IEEE 802.11b/g Relacionadas à Segurança  O IEEE 802.11b é o padrão mais utilizado atualmente [Pinto & Gomes, 2011], embora  desatualizado ele ainda fornece acesso para muitos dispositivos antigos. Operando numa  frequência de 2.4 GHz e utilizando o protocolo Wired Equivalent Privacy (WEP), o  802.11b possui limite para 32 usuários conectados, com taxa de transmissão de 11  Mbps. O padrão 802.11g trabalha na faixa de 2.4 GHz, transmitindo a 54 Mbps. Embora     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   41        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     o padrão 802.11n tenha aumentado seu uso, os padrões 802.11b/g ainda são usados em  muitas configurações [Morimoto, 2011]. Uma característica importante do padrão  802.11n é poder operar na mesma faixa de frequência do 802.11b, desta forma duas  configurações podem trabalhar juntas.    O principal problema apontado no padrão 802.11b/g é seu protocolo de  criptografia [Cansian et al., 2004]. Este protocolo propõe uma forma de conexão  semelhante das redes cabeadas, cuja segurança é baixa. O protocolo WEP utiliza um  vetor pseudorrandômico de 24 bits em conjunto com uma senha de 40 ou 104 bits  programada pelo usuário, para criptografar os pacotes enviados pelos dispositivos sem  fio. Tal falha é ocasionada na geração dos vetores de inicialização, quando ocorrem  vetores com uma estrutura singular de modo que se possa prevê-los. Estes são chamados  de "vetores de inicialização fracos" [Cansian et al, 2004].   3. Método Proposto para Implementação de rede VPN  O método proposto neste trabalho tem por intuito minimizar os impactos das  vulnerabilidades existentes em sistemas críticos, se apoiando nos trabalhos realizados  por Cansian et al., [2004]; e Pinto & Gomes [2011], ressaltando a metodologia  apresentada por de Silva e Ludwig [2011], para auditoria de redes sem fio 802.11b/g a  fim de auxiliar os profissionais a identificarem as vulnerabilidades da rede. A  abordagem do presente método (Figura 1) permite ao usuário não somente a análise da  solução implementada, mas também salientar aspectos importantes na efetividade da  segurança de redes wi-fi.      O método apresentado na Figura 1 constitui-se de quatro etapas: Estruturação da  rede, Configuração estabelecida com o servidor, Conexão com os clientes e Aplicação  da metodologia proposta por Silva & Ludwig [2011]. Esta quarta etapa é considerada  um processo contínuo, então sua posição pode ser tanto no fim como no início do  método.    A Fase de Estruturação da Rede refere-se à forma em que a rede é montada. O  AP necessita estar conectado diretamente ao servidor VPN e este, por sua vez, deve  estar conectado à rede interna da empresa. Essa estruturação em duas redes distintas  possibilitará somente aos dispositivos autenticados na VPN, acesso aos demais recursos.     Já a Fase de Configuração com o Servidor tem por intuito minimizar as  vulnerabilidades do protocolo WEP, utilizando-se de um servidor VPN. Para isto,  optou-se pela utilização do software OpenVPN (https://openvpn.net/). Após, foi  realizado o download do OpenVPN Access Server Virtual Appliance, e foram   Figura 1: Método para implementação da rede VPN.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   42        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     realizadas as configurações de rede básicas do servidor. Primeiramente é necessário  configurar o OpenVPN para que todas as requisições de internet passem pelo servidor.  Fazendo isto, os dados transmitidos via wireless estarão encapsulados na conexão VPN.    Por fim, a Fase de Conexão com os Clientes tem por intuito estabelecer em elo  de comunicação entre os mesmos de forma mais efetiva em termos de segurança, ou  seja, após o servidor ser configurado para receber o tráfego de internet e disponibilizar  os serviços de rede que estejam depois dele. O estabelecimento da conexão a partir de  um computador (independentemente de sistema operacional) é realizado acessando o  endereço IP do servidor a partir de qualquer navegador, fazendo a autenticação e  realizando o download o OpenVPNClient (https://openvpn.net/). Para conectar-se a  VPN utilizando um smartphone com sistema operacional Android, é necessário baixar,  instalar e configurar o OpenVPN. Após a instalação, o procedimento para conectar-se é  semelhante ao do Linux, ou seja, necessário acessar o IP do servidor através de um  navegador, autenticar-se e baixar o arquivo de configuração.    Para validação do método proposto com o estabelecimento das fases acima  apresentadas, e os procedimentos a elas relacionados, a metodologia foi aplicada em um  estudo de caso, no qual se especificou um contexto de aplicação, a seleção das  ferramentas mais adequadas para a extração de informações realmente úteis e a análise  dos resultados provenientes da realização do mesmo, sendo estes descritos nas seções  subsequentes.   4. Cenário e Ferramentas Utilizadas  O escopo do ambiente de estudo é constituído de uma rede infraestruturada composta  por: um Access Point (AP), um servidor VPN, um switch e recursos da rede protegida e  os dispositivos móveis (Figura 2). Como também para utilizar as ferramentas da  organização e ainda manipular arquivos como num servidor File Transfer Protocol  (FTP), por exemplo, o acesso também será feito pela VPN. Isto é considerado um ponto  importante com relação à segurança de sistemas corporativos, assim, a prática de uma  rede privada virtual aumenta significativamente a segurança nos acessos a sistemas  críticos [Klein, 2012].     A VPN é uma forma de a segurança interna da rede, pois ela permite a  criptografia por tunelamento garantindo a confidencialidade, autenticação e integridade  das informações recebidas e enviadas [Rossi & Franzin, 2000]. O objetivo é combater  algumas vulnerabilidades que o protocolo WEP apresenta usado no padrão 802.11b/g  como injeção de tráfego, redirecionamento de mensagens, obtenção do segredo  compartilhado [Catafesta, 2004].      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   43        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015       Figura 2: Rede VPN.    Neste cenário a realização de testes de segurança e a implementação do método  foram utilizados alguns aplicativos, conforme demonstra a Tabela 1. A utilização, para  concretização do método proposto, justifica-se por serem softwares gratuitos,  multiplataforma e de fácil instalação.   Tabela 1: Ferramentas utilizadas nos testes de implementação.    Aplicativo      Categoria     Versão     Plataforma     Valor     Aircrack-ngSuite     Sniffer     1.1     Linux/Windows     Gratuito     Kismet     Sniffer     2011-03-R2     Linux     Gratuito     OpenVPN     Server e Client     1.8.4     Linux/Windows     Gratuito     Wireshark     Sniffer     1.8.3     Linux/Windows     Gratuito    A ferramenta Aircrack-ng (http://www.aircrack-ng.org/) é uma suíte de  aplicativos para verificação de redes sem fio. Um de seus aplicativos é o Airodump-ng  (http://www.aircrack-ng.org/) que captura pacotes, gerando um arquivo com extensão  cap. A leitura deste arquivo é feita pelo Aircrack-ng, que tem o objetivo de quebrar a  senha de encriptação WEP. Já a ferramenta Kismet (http://www.kismetwireless.net/) é  usado para descoberta das redes sem fio, enquanto o Wireshark  (https://www.wireshark.org/) captura os pacotes de uma determinada rede.   5. Resultados Advindos da Aplicação do Método  Para demonstrar a viabilidade do método proposto, foram realizados testes no cenário  apresentado na Figura 2. Em um primeiro momento, foram feitas tentativas de invasão  na rede wi-fi. Como resultado obteve-se a confidencialidade da informação  comprometida quando a senha WEP pôde ser descoberta com o uso do Aircrack-ng  Suite e o Kismet.  Este último conseguiu interceptar o BSSID e SSID da rede e o canal  que estava operando. Com esses dados foi possível capturar pacotes com Airodump-ng  e, com 40.000 pacotes a chave foi descoberta com o Aircrack-ng (Figura 3).       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   44        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     Figura 3: Captura de pacotes (A) e descoberta de senha (B), respectivamente, com  Airodump-ng e Aircrack-ng.    A Figura 3 demonstra as vulnerabilidades do protocolo WEP para fornecer  segurança nas redes sem fio 802.11b/g. Assim, faz-se necessário o uso de uma camada  adicional de segurança na rede quando se utiliza criptografia WEP. A análise e filtragem  do trafego da rede foi feita utilizando-se do software Wireshark, o que permitiu  acompanhar a ocorrência da criptografia no túnel no tráfego de dados durante a VPN. O  funcionamento da VPN foi verificada a partir do estabelecimento de uma sessão File  Transfer Protocol (FTP).    É possível verificar (Figura 4 A) que os dados trafegados na VPN estão  criptografados. Em outro teste (Figura 4 B) a VPN foi desativada e a sessão FTP foi  iniciada. O Wireshark foi ativado para captura dos pacotes. Nota-se que os dados que  trafegam pela rede estão totalmente descriptografados, contendo informações  confidenciais tais como o nome do usuário da sessão, senha e comando efetuados  durante a sessão FTP.     Figura 4: Dados criptografados pela VPN capturados pelo Wireshark (A) e desprotegidos   (B).    Atualmente, o OpenVPN tem destaque como uma implementação open source  sobre TLS. A criptografia de chave pública é o método mais conhecido do protocolo  TLS. A outra forma é a convencional, a criptografia com a chave que foi distribuída.  Nos testes realizados a autenticação do cliente foi feita por password, em casos de VPN  host LAN isto é permitido. A senha é enviada diretamente para o servidor através de  uma conexão segura, ou seja, há uma preautenticação do servidor perante o cliente.    Desta forma, o risco de a senha ser capturada durante o transporte por um  desconhecido é descartada. Esta autenticação é feita através do certificado de chave  pública do servidor, cuja instalação é feita manualmente [Moreira, 2010]. Alguns pontos  com relação à segurança proposta ficaram sem proteção como Engenharia Social, falsos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   45        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     APs e ataques internos, demonstrado na Figura 5. Por outro lado, a captura de dados,  invasões externas e utilização de recursos por pessoas não autorizadas tiveram proteção  com o uso da VPN.      Figura 5: Pontos protegidos e desprotegidos da rede implementada.    Ainda que alguns fatores estejam desprotegidos, minimizaram-se as  vulnerabilidades do protocolo WEP onde as chaves de segurança trocadas podem ser  previstas. O uso de uma VPN neste caso fornece uma melhor efetividade na proteção  dos dados, pois a criptografia no túnel garante a autenticidade, a integridade e o sigilo  das informações. Se for comparado com os trabalhos de autores citados neste artigo,  eles somente utilizam o protocolo WEP como camada de proteção.   6. Conclusão e Trabalhos Futuros  É de fundamental importância manter os dados confidenciais fora do alcance de  usuários mal intencionados, protegendo as informações de ataques passivos e ativos.  Assim, é aconselhável utilizar uma camada a mais de segurança e que a mesma esteja  configurada de maneira adequada. Pois, como foram relatadas, algumas das  propriedades das tecnologias wireless atuais mais utilizadas (IEEE 802.11b/g) não são  capazes de prover tal segurança, deixando os dados trafegados à disposição de qualquer  usuário que souber como interceptá-los.    Neste artigo foi proposto um método para implementar uma VPN diretamente  sobre um AP que repassa o sinal para os usuários, ao contrário dos demais que utilizam  algum meio de comunicação sem fio em conjunto com uma VPN para interligar duas  LANs distintas. O objetivo é garantir que a comunicação dos dispositivos móveis  (notebooks, smartfones, tablets, etc) com os pontos de acessos sem fios seja feita de  forma segura e restrita apenas a quem tiver autorização.    Como trabalhos futuros, sugere-se pesquisar um método que programe o mesmo  tipo de segurança em uma rede doméstica, visto que atualmente a quantidade de  hotspots inseguros de uso particular é superior aos corporativos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   46        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 39-46 Nov/2015     7. Referências Bibliográficas  Cansian et al. Falhas Políticas de Configuração: uma análise dos riscos para as redes   sem fio na cidade de São Paulo. In: SIMPÓSIO DE SEGURANÇA EM  INFORMÁTICA, 6, 2004, São José dos Campos. Anais. São Paulo: IFSJC.  Disponível em:<http://www.acmesecurity.org/sites/default/files/publicacoes/artigos/  acme-artigo-ssi-2004-wlan.pdf>.  Acesso em:  20 ago. 2015.   Catafesta, Márcio. Implementação de um Mecanismo de Filtragem de Pacotes para um  Ponto de Acesso Sem Fio. 2004. Disponível em:<http://guaiba.ulbra.tche.br/  pesquisa/2004/resum os/sistemas/seminario/173.PDF>. Acesso em: 19 ago. 2015.   Fortinet. Wireless Network the Weakest Security Link in Enterprise IT Infrastructure,  According to Fortinet Global Survey of IT Leaders. 2015. Disponível  em:<http://www.fortinet.com/press_releases/2015/global-survey-wireless-networkweakest-security-link.html>. Acesso em: 26 ago. 2015.   IEEE 802.  Wireless  Local  Area  Network:  the  working  group  for  WLAN   standarts.  2010. Disponível em:<http://www.ieee802.org/11/index.shtml>. Acesso  em: 24 ago. 2015.   Klein, Eduardo. Gestão de Segurança de Dispositivos Móveis. 2012. Disponível em:<  http://www.mobiltec.com.br/blog/index.php/gestao-de-seguranca-de-dispositivosmoveis/>. Acesso em: 03 ago. 2015.   Moreira, André. Redes de Computadores – Redes Privadas Virtuais (VPN) Protocolo  PPP. 2010. Disponível em: <http://www.dei.isep.ipp.pt/~andre/documentos/RCOMP                                                       /T9.pdf>. Acesso em: 10 jul. 2015.   Morimoto, Carlos E. Redes Wireless atualizado (sétima e última parte). 2011.  Disponível em:<http://www.hardware.com.br/guias/redes-wireless/80211g-1.html>.   Acesso em: 26 jul. 2015.   Pinto, Pedro MicaelT.L.N; Gomes, Antônio Ricardo Leocádio. Segurança na  Conectividade Wifi em Dispositivos Móveis: estudo de caso do iPhone. RevistaExacta. Belo Horizonte, n. 3, dez. 2011. Disponível  em:<http://revistas.unibh.br/index.php/dcet/article/view/331/406>. Acesso em: 01  jul. 2015.   Rossi, Marco Antonio G.; Franzin, Oswaldo. VPN – Virtual Private Nwtwork.2000.  Disponível em:<http://www.gpr.com.br/download/vpn.pdf>. Acesso em: 06 jul.  2015.    Silva, Fabiano; Ludwig, Glauco Antonio. Desenvolvimento de uma Metodologia para  Auditoria em Redes Sem Fio IEEE 802.11b/g. In: Simpósio Brasileiro em Segurança  da Informação e de Sistemas Computacionais, 8, Gramado. Anais. Rio Grande do  Sul: UFRGS. Disponível em:<http://labcom.inf.ufrgs.br/ceseg/anais/2008/data/pdf/  st02_02_wticg.pdf>. Acesso em: 30 jun. 2015.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   109        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015     Utilização de Businnes Intelligence para análise de evasão  escolar nos diferentes níveis de ensino do Instituto Federal   Farroupilha Campus São Vicente do Sul   Filipe Kulinski Mello1, Eliana Zen1, Maicon de Brito do Amarante1   1Instituto Federal Farroupilha – Campus São Vicente do Sul (IFFarroupilha SVS)   CEP 97420-000 – São Vicente do Sul– RS – Brasil.   filipe-kulinski@hotmail.com, {maicon.amarante, eliana.zen}  @iffarroupilha.edu.br   Abstract. In the São Vicente do Sul Campus of the Farroupilha Federal  Institute, the school dropouts is challenging, being harmful to the life of the  student and, as well for the institution. The first step in treating this problem is  collecting information on the current situation. With this in mind, this study  aims to use Business Intelligence tools and techniques in the investigation of  school dropout in the São Vicente do Sul Campus. This information are shown  through charts and tables showing historical data and trends, easing the  visualization of situations that present more risk of dropout.     Resumo. No Campus São Vicente do Sul do Instituto Federal Farroupilha, a evasão  escolar é desafiadora, sendo prejudicial tanto para a vida do aluno como para a vida  da instituição. O primeiro passo para o tratamento desse problema é o levantamento  de informações sobre a situação atual. Levando em conta essa necessidade, este  estudo tem como objetivo utilizar ferramentas e técnicas de Business Intelligence na  investigação da evasão escolar do Campus São Vicente do Sul. Essas informações  serão mostradas através de gráficos e tabelas apresentando dados históricos e  tendências, facilitando a visualização das situações que mais apresentam risco de  evasão.   1. Introdução  O planejamento é uma das atividades de maior complexidade para o gestor.  Compreender o cenário atual e pensar no futuro são duas tarefas desafiadoras por si só.  Fazer isso sem informações estratégicas que apoiem a decisão pode se tornar inviável. A  evasão escolar no Campus São Vicente do Sul do Instituto Federal Farroupilha ilustra  precisamente o dilema da decisão. De onde obter informações para embasar a tomada de  decisão? Um sistema de gestão acadêmica centralizado, que cubra as diversas áreas  institucionais, com dados corretamente atualizados, parece uma solução tentadora. No  entanto, chegar a este nível de maturidade pode levar muito tempo, talvez um tempo  precioso demais para ficar esperando. Deste modo, como utilizar as informações  existentes, ou ainda, apenas aprimorar algumas coletas pontuais de dados, para desde já  gerar informações estratégicas, que subsidiem a tomada de decisão?     É neste cenário que surge com força a inteligência de negócios, do inglês  Business Intelligence, ou simplesmente BI. A implantação de uma ferramenta de BI  passa pelas fases de extração, transformação, carga e geração de conhecimento. Durante  a fase de extração, diferentes bases de dados, como planilhas, documentos e banco de  dados, são extraídas para uma plataforma uniforme. Posteriormente, durante a  transformação, dados redundantes e irrelevantes são descartados e informações que não  possuíam nenhuma ligação são integradas. Finalmente estes dados são carregados e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   110        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015     organizados para uma Data Warehouse, ou depósito de dados, onde as informações são  consolidadas e centralizadas (Kimball e Caserta, 2004).    Neste sentido, este projeto tem como objetivo analisar a evasão a partir da  compreensão da realidade dos alunos, suas dificuldades e seu grau de satisfação com a  instituição, permitindo que assim crie-se um plano de ação que vise reduzir a evasão  escolar. As ferramentas e técnicas de BI são um meio concreto para compreendermos  nossa realidade, ao passo que entrega uma importante ferramenta de gestão que dará  apoio à tomada de decisão.   2. Referencial Teórico  Com o objetivo de fornecer ferramentas que sustentarão a compreensão deste trabalho,  esse capítulo visa expor de forma objetiva a fundamentação teórica relacionada ao tema.   Serão contextualizados assuntos inerentes ao objeto de pesquisa, tais como: Business  Intelligence, On-line Analytical Processing e Data Warehouse.   2.1 Business Intelligence  Business Intelligence, ou simplesmente BI, é um conjunto de conceitos e metodologias  de gestão que, fazendo uso de dados extraídos de uma organização, proporciona ganhos  nos processos decisórios gerenciais. Baseia-se na capacidade analítica de ferramentas  que integram todas as informações necessárias ao processo decisório. O objetivo do  Business Intelligence é extrair dados estruturados de base de dados, planilhas do Excel,  documentos de texto etc, transformá-los e carregá-los em uma Data Warehouse,  processo esse denominado ETL (Extraction, Transformation, Loading). A partir dos  dados carregados na Data Warehouse é possível gerar Relatórios, Dashboards e cubos  OLAP que suportem o processo decisório e gere vantagens competitivas (Delsosto,  2014). A Figura 1 exemplifica o processo de Business Intelligence descrito acima.     Figura 10. Funcionamento básico do business intelligence    O termo Business Intelligence foi primeiramente utilizado pela empresa de  consultoria na área de sistemas da informação Gartner Group. Porém, a origem do  conceito se iniciou nos anos 70, com base nos sistemas de geração de relatórios de  Sistemas de Informação Gerencial (SIG). Segundo Leme Filho (2004), BI é um  conjunto de serviços aplicações e tecnologias combinadas para agregar valor, gerenciar  e analisar informações. Diante dessa premissa o ambiente de Business Intelligence deve  possuir cinco características básicas, quais sejam: (a) Extrair e integrar dados de  múltiplas fontes; (b) Fazer uso da experiência, democratizando o capital intelectual; (c)  Analisar informações contextualizadas, num nível de totalização e agrupamento maior;  (e) Identificar relações de causa e efeito; e (d) Desenhar cenários, criar simulações e  estudar tendências.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   111        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015     2.2 Data warehouse  Data Warehouse, ou em português armazém de dados, é um depósito de dados único,  gerado a partir de diversas fontes de dados, que contém somente informações  consideradas importantes para a empresa, ajudando a apoiar as decisões gerenciais. É  considerado o principal elemento do BI.     A meta principal de um Data Warehouse é a criação de uma visualização única  dos dados que residem em diversos bancos de dados físicos, fornecendo aos usuários  um modelo de trabalho dos dados da empresa. O acesso a esses dados melhora a  qualidade dos serviços e o atendimento ao cliente, ajudando a companhia a avaliar  atividades emergentes do negócio (Gonçalves, 2003). O Data Wharehouse é  considerado o principal elemento do BI.   2.2.1 ETL (Extraction, Transformation and Loading)  Segundo Sezões, Oliveira e Baptista (2006), ETL é um conjunto de processos que  permite às organizações extrair dados de fontes de informação diversas e reformulá-los  e carregá-los para uma nova aplicação (base de dados, geralmente um Data Warehouse)  para análise.   A ideia principal do ETL é coletar dados de diferentes fontes, mas que sejam  pertinentes a uma única regra de negócio. Segundo Kimball e Caserta (2004), o  processo de ETL divide-se em três etapas principais: (1) Etapa de extração, onde são  coletados dados de diferentes tipos e sistemas de origem; (2) Etapa de transformação,  onde são aplicadas séries de regras e funções que padronizam o formato dos dados  extraídos; (3) Fase de Carga, onde os dados transformados são transferidos para os  locais de destino, como Data Warehouse e Data Marts.    2.3 Cubos OLAP (On-line Analytical Processing)  A tecnologia OLAP representa a possibilidade de se trabalhar os dados, com operadores  dimensionais, possibilitando uma forma múltipla e combinada de análise (Barbieri,  2001).   A característica principal dos sistemas OLAP é permitir uma visão conceitual  multidimensional dos dados armazenados, através de cubos (Figura 3). Um cubo é uma  estrutura composta de dimensões e de uma tabela fato. As dimensões representam os  eixos do cubo e correspondem a atributos do domínio analisado. A tabela fato é  constituída de medidas (dados) de uma tabela de fatos coletados dentro do domínio  analisado. As medidas são relacionadas às dimensões (Tronto e Sant’anna, 2004).       Figura 2 Estrutura de um cubo OLAP     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   112        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015      Com a utilização de cubos OLAP, é possível visualizar determinados cubos de  informações de diferentes ângulos, e de vários níveis de agregação, permitindo a análise  de um grande volume de dados em tempo real e obtenção de relatórios analíticos. É  forma rápida de obtenção de informações gerenciais para a tomada de decisão dos  gestores.   3. Materiais e métodos  Para a implementação do projeto proposto foram utilizadas apenas ferramentas gratuitas  e open source, das quais pode-se citar: (a) Pentaho BI Server 5.0.1, responsável por toda  a camada servidora da plataforma do Pentaho; (b) plug-ins Saiku, Pentaho Dashboards  Editor e Pentaho Data Acess, utilizados para a visualização de dashboards e Cubos  OLAP; e (c) Pentaho Report Designer, para a geração de Relatórios Estatísticos. Para o  desenvolvimento de cubos OLAP foram utilizadas as ferramentas Mondrian  Workbench, Pentaho Data Integration (Kettle) e o Sistema Gerenciado de Banco de  Dados PostgreSQL.    3.1 Pentaho  A plataforma Pentaho possui um servidor web que disponibiliza um conjunto de  serviços, dos quais destaca-se a autenticação de usuários, relatórios, análises  exploratórias, dashboards, dentre outras. A plataforma Pentaho BI é constituída por dois  servidores web, um para acomodar a aplicação do usuário final, chamada Pentaho User  Console (BIServer-CE), e o outro para acomodar a aplicação do Administrador,  chamada Pentaho Administration Console.   A utilização da ferramenta Pentaho Bi-server mostrou-se eficaz no  desenvolvimento da pesquisa, devido a facilidade de se construir e acessar todas as  funcionalidades e resultados gerados dinamicamente pela ferramenta por meio de uma  interface web amigável e intuitiva, destacando também o fato de ser uma ferramenta  gratuita, com excelente documentação e referências bibliográficas.   4. Metodologia de pesquisa  A presente pesquisa pode ser definida como quantitativa tradicional, já que que busca  apresentar fatos através da descrição e interpretação de fatos isolados. Segundo Berto e  Nakano (2000), a pesquisa qualitativa envolve natureza empírica, relações de causa e  efeito, hipóteses bem formuladas e métodos lógico-dedutivos que permitem replicar  resultados através da generalização.   A pesquisa realizada levou em consideração a base de dados do sistema  acadêmico do Instituto Federal Farroupilha Campus São Vicente do Sul e considerou  dados do período compreendido entre janeiro de 2010 e dezembro de 2014. O processo  de pesquisa foi divido em quatro etapas: (1) estudo do estado da arte; (2) coleta análise e  processamento de dados; (3) construção de gráficos, compilação de informações  estratégicas; e (4) análise e avaliação dos resultados. A Tabela 1 descreve melhor cada  uma das etapas envolvidas no processo de pesquisa.    Etapa Descrição  1 Visou obter uma melhor compreensão do problema, através do estudo do   estado da arte e das ferramentas empregadas durante a pesquisa.  2 Utilizou-se a ferramenta Data Integration Kettle da suíte Pentaho para coletar   dados relevantes do sistema acadêmico do Campus, os quais, posteriormente,  foram carregados em uma Data Warehouse,    3 Envolveu a compilação das informações de acordo com os dados coletados da  fase anterior. Foram utilizadas ferramentas da suíte Pentaho para gerar  relatórios, dashboards e um Cubo OLAP apresentando informações     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   113        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015     relacionadas a evasão escolar proporcional ao número de alunos matriculados.  4 Realizou-se a análise dos dados, avaliando a relação de evasão/matrícula,   buscando estabelecer relações e correlações de causa e efeito, procurando  discrepâncias e refinando a apresentação dos resultados.    Tabela 1. Etapas do processo de pesquisa     A análise dos dados foi dividida em três dimensões: de ensino, de espaço e de  tempo. A dimensão de ensino apresenta a evasão dos alunos conforme o curso e nível de  ensino; a dimensão de espaço mostra os dados conforme a localização do aluno evadido,  sendo dividida em evasão por cidade e por distância da cidade de endereço do aluno; e a  dimensão tempo, que mostra a evasão por idade e período do curso em que ocorreu a  evasão. Neste trabalho é descrita a análise dos dados relativa a dimensão de ensino.   5. Resultados  Na análise de resultados, foi observado os dados de evasão dos cursos e dos níveis de  ensino do Campus. A análise levou em consideração o número total de matrículas, o  total de evasões e a relação matricula/evasão, esta última, relacionada ao comparativo  entre alunos evadidos e matriculados em determinado período.   5.1 Evasão por nível de ensino  Primeiramente, foram analisados os dados de evasão referentes aos níveis de ensino da  instituição. A Tabela 1 apresenta o número de matrículas, evasões e relação  matrícula/evasão.     Tabela 2. Evasão por nível de ensino    Com relação ao nível médio é possível observar que houve um aumento de  5.86% no percentual de evasão e uma queda de 107 alunos matriculados no período de  2013. No ano seguinte, o número de matrículas aumentou em 109 enquanto a relação  matrícula/evasão subiu proporcionalmente ao número de alunos.   Quanto ao nível superior, também houve uma queda de 66 matrículas em 2013  juntamente com um aumento de 1,21 % no percentual de evasão em relação a 2012.  Porém, diferentemente do nível médio, o número de matrículas continuou a cair em  2014, havendo uma diminuição de 98 alunos matriculados e um aumento de 4.86 % na  relação matrícula/evasão.    A maior queda de matrículas em 2013 ocorreu no nível técnico, pois houve uma  diminuição de 316 matrículas e um aumento de 4,09 % na relação matrícula/evasão. A     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   114        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015     queda de matrículas continuou ocorrendo no ano seguinte, havendo uma diminuição de  140 matrículas e aumento de 4,95 % na relação matrícula/evasão.   Ao analisar os dados, pode-se considerar que o nível técnico possui a situação de  evasão mais grave entre os três níveis, pois tem o maior percentual de evasão, além de  apresentar uma maior queda de matrículas de 2012 para 2013 e uma diminuição de  matrículas entre o período de 2010 a 2014.   5.2 Evasão por curso  A Tabela 2 mostra a relação matrícula/evasão (representada pelo símbolo “%”) dos dez  cursos com maior ocorrência de evasão no instituto, ordenados pelo número total de  evasões. Analisando essa tabela, é possível observar um aumento considerável na  relação evasão/matrícula de todos os cursos no período de 2010 a 2014.     Tabela 3. Evasão por Curso    O curso Técnico em Informática foi o que apresentou a situação mais grave de  evasão, já que possuiu o maior percentual de evasão no ano de 2014, 37,36%, tendo  também o maior aumento em relação a 2013, chegando a 20,33 %. Também pode-se  chamar atenção aos cursos Técnico em Secretariado e Tecnólogo em Análise e  Desenvolvimento de Sistemas, que também apresentaram um alto percentual de evasão  em 2014, além de um aumento no percentual de evasão de 7,53% e 10,35%,  respectivamente, em relação a 2013.   Os menores índices de evasão ocorreram nos cursos Tecnólogo em Gestão  Pública e Técnico em Agricultura, onde houve 11,79% e 11,49% de evasão no ano de  2014 e um aumento de 1,31% e 3,47%, respectivamente, em relação a 2013. Os cursos  que não possuem percentual ainda não haviam sido criados no determinado período.   6. Conclusão  Certamente, a implementação de um sistema de Business Intelligence (BI) é de grande  valia para a gerência de uma instituição. As ferramentas oferecidas por essa tecnologia  são cada vez mais necessárias nos processos de tomada de decisão. A maior vantagem  do BI é permitir acesso a informação de qualidade em um curto período de tempo,  permitindo aos gestores conhecerem melhor a realidade da instituição.   Através da implementação do sistema de BI no Campus, foi possível entregar  aos gestores uma plataforma de fácil acesso à informação, apresentando um cubo  OLAP, gráficos e relatórios que facilitam a consulta a informações e o cruzamento de  dados relacionados a evasão escolar.          Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   115        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 109-115 Nov/2015      A partir desse projeto, foi possível entender melhor a situação da evasão no  Campus. O estudo apresentou situações em que o aluno tem mais chance de evadir, que  até então eram desconhecidas pelos gestores. Através dele foi possível observar o  aumento crescente da evasão em todos os níveis de ensino, sendo mais grave nos cursos  de nível técnico, juntamente com outras tendências de evasão, como cursos com  maiores índices de abandono de alunos. Futuramente, essas informações poderão ser  utilizadas na geração de estratégias para mitigar a evasão escolar no Campus São  Vicente do Sul.    Referências  KIMBALL, R e ROSS, M. The Data Warehouse Toolkit: The Definitive Guide to   Dimensional Modeling. Kimball Group, 2013.   KIMBALL, R e CASERTA, Joe. The Data Warehouse ETL Toolkit: Practical  Techniques for Extracting, Cleaning, Conforming, and Delivering Data, Kimball  Group, 2004.   LEME FILHO, Trajano. Business Intelligence no Microsoft Excel. Rio de Janeiro,  Axcel Books do Brasil, 2004.   ARRUDA, Cláudio. Estudo para implantação de um DataWarehouse em um ambiente  eempresarial. Santa Catarina, 2003.   BARBIERI, Carlos. BI- Businesss Intelligence: Modelagem & Tecnologia. Rio de  Janeiro, Axcel Books do Brasil , 2001.   TRONTO, I. F. Barcellos e SANT’ANNA, Nilson. Um Roteiro para Construção de  Cubos e Consultas OLAP. 2004. Disponível  em:http://mtcm18.sid.inpe.br/col/lac.inpe.br/worcap/2004/10.05.09.36/doc/WorCap QuatroIris.PDF.   SEZÕES, Carlos; OLIVEIRA, José; BAPTISTA Miguel. Business Intelligence. Porto:  Sociedade Portuguesa de Inovação, 2006.   BERTO, R. M. V. S., and Davi Noboru NAKANO. "A produção científica nos anais do  Encontro Nacional de Engenharia de Produção: um levantamento de métodos e tipos  de pesquisa." Revista Produção 9.2 (2000): 65-76.   KIMBALL, R.; CASERTA, J. The Data Warehouse ETL Toolkit. Indianapolis: Wiley  Publishing, Inc, 2004.             
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   196        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     Utilização de Sistema de Detecção e Prevenção de Intrusos  modo NIDS   Denis Pohlmann Gonçalves¹   ¹Coordenação de Tecnologia da Informação – Instituto Federal Farroupilha campus São  Vicente do Sul (IFFARROUPILHA-SVS) - São Vicente do Sul – RS – Brazil   denis.goncalves@iffarroupilha.edu.br  Abstract. This meta-paper presents the results obtained from the use of an  intrusion detection system using the tool called Snort, running on free  software adapted for firewall, pfSense. This technology has been used at the  edge of the network infrastructure of computers of Instituto Federal  Farroupilha campus São Vicente do Sul. Its use provided great security to the  academic environment against attacks and intrusion, showing good results.   Resumo. Este artigo apresenta os resultados obtidos com a utilização de um  sistema de detecção de intrusos utilizando a ferramenta chamada Snort, sendo  executada sobre o software livre adaptado para firewall, pfSense. Esta  tecnologia foi utilizada na borda da infraestrutura da rede de computadores  do Instituto Federal Farroupilha campus São Vicente do Sul. Sua utilização  proporcionou grande segurança para o ambiente acadêmico contra ataques e  intrusões, mostrando resultados consideravelmente satisfatórios.   1. Introdução  Segundo [Tanenbaum 2003] desde o início da década de 1990, onde a internet se tornou  comercial, houve um crescimento exponencial de dispositivos na rede de dados, através  dos grandes avanços das tecnologias em hardware e software, possibilitando cada vez  mais a troca de informações entre seus usuários. Além das demandas atuais, novos  serviços sempre estão surgindo, com aplicações de inúmeras funcionalidades, como  transferências de informações sigilosas e operações financeiras, necessitando uma  infraestrutura que garanta a proteção e transmissão segura das informações.   Qualquer serviço, computador ou rede que esteja acessível via Internet pode ser  alvo de um ataque, assim como qualquer computador com acesso à Internet pode  participar de um ataque [Cert 2015]. Os incidentes normalmente ocorrem explorando a  vulnerabilidade, visando diferentes alvos, tais como, empresas diversas, instituições  bancárias, instituições governamentais e usuários domésticos. Para isso, utilizam  variadas técnicas, como, negação de serviço, phishing, worms, trojans, spywares e  keyloggers. Sendo assim, o uso de um sistema de detecção e prevenção de intrusos  torna-se indispensável em qualquer infraestrutura que se deseja ter uma camada extra de  segurança contra ameaças.   Este artigo apresenta resultados da utilização de um sistema de detecção e  prevenção de intrusos (IDS/IPS) em modo NIDS, chamado Snort, executando sobre um  sistema operacional baseado em FreeBSD e implementado no firewall de borda da  infraestrutura de redes do Instituto Federal Farroupilha campus São Vicente do Sul  (IFFarroupilha-SVS). Contudo, não serão abordados tópicos de instalação do sistema  operacional e da ferramenta Snort. Esta pesquisa contribui com os resultados obtidos  que poderão auxiliar os administradores de rede no tratamento de incidentes em dois  aspectos principais, sendo, a coleta de informações referentes aos tipos mais frequentes     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   197        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     de ataques sofridos e os bloqueios que poderão ser efetuados de forma autônoma com o  mecanismo IPS, prevenindo ataques futuros e recorrentes.   A estrutura deste artigo apresenta na Seção 2 conceitos fundamentais dos  sistemas de detecção e prevenção de intrusos. A Seção 3 apresenta a implementação do  sistema IDS/IPS. Na Seção 4 são apresentados os resultados obtidos com a  implementação do sistema. A Seção 5 apresenta alguns trabalhos relacionados e na  Seção 6 as considerações finais do artigo e trabalhos futuros.    2. Conceitos fundamentais  Para entendimento do artigo esta seção descreve alguns conceitos fundamentais sobre os  sistemas IDS, como funções, tipos de sistemas de detecção de intrusão, localização do  sensor e mecanismo de bloqueio.   2.1. IDS  Um sistema de detecção de intrusão (Intrusion Detections System - IDS) é um  mecanismo que tem como principal função detectar diversos ataques e intrusões em  redes de computadores, proporcionando uma camada muito grande de segurança,  tornando-se um mecanismo essencial em um ambiente corporativo. O IDS trabalha  como uma câmera ou alarme contra as intrusões, podendo realizar a detecção com base  em algum tipo de conhecimento, como assinaturas ou em desvios de comportamento  [Nakamura 2007].   Segundo [Nobre 2007], os IDS são sistemas autônomos que funcionam em  tempo real no modo de escuta, considerados sniffers, analisando todo o tráfego de rede e  detectando tentativas não autorizadas de acesso a infraestrutura lógica, sendo  considerados como uma das principais ferramentas de defesa contra invasores.      Com base em dados dos incidentes relacionados a tentativas de  ataque e invasões que aconteceram no Brasil, recebidos pelo [Cert 2015], são mantidas  as estatísticas sobre as notificações a ele reportadas, sendo estas voluntárias. Na Figura  1, são mostrados por categoria, os incidentes reportados ao Cert.br de janeiro a  dezembro de 2014.     Figura 1. Incidentes reportados ao Cert.br em 2014      Considerando estas notificações é constatado uma incidência grande de fraudes  realizadas, possivelmente ocorrências em que as instituições ou usuários tenham sofrido  com perdas financeiras. Podemos perceber que as tentativas de ataques acontecem em  variadas categorias, sendo que firewalls convencionais não são capazes de detectá-las.  Estes firewalls utilizam somente controle de camada de rede e transporte, não possuindo  a habilidade de verificar o conteúdo dos pacotes, em contrapartida, os IDS são capazes  de analisar os pacotes a nível de aplicação e reconhecer padrões de tráfego malicioso se  identificado. Empresas que detenham informações sigilosas correm grande risco de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   198        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     roubo, fraude, dentre outros, se não possuírem algum sistema de segurança eficaz contra  esses tipos de ataques, como por exemplo, um sistema IDS.   Existem dois tipos primários de IDS, sendo o baseado em host e o baseado em  rede. Com o aprimoramento das tecnologias levou ao desenvolvimento do IDS híbrido  (Hybrid IDS), que utiliza as características do HIDS e NIDS.  2.1.1. HIDS  O sistema de detecção de intrusos baseado em host (Host-Based Intrusion Detection  System - HIDS) faz o monitoramento do sistema, com base em informações de arquivos  de logs ou de agentes de auditoria. O HIDS pode ser capaz de monitorar acessos e  alterações em importantes arquivos do sistema, modificações nos privilégios dos  usuários, processos do sistema, programas que estão sendo executados, uso da CPU,  entre outros aspectos, como a detecção de port scanning [Ranum 2001].  2.1.2. NIDS  O sistema de detecção de intrusos baseado em rede (Network-Based Intrusion Detection  System - NIDS) monitora a atividade do tráfego em um determinado segmento de rede,  utilizando normalmente suas interfaces de rede em modo promíscuo. A detecção é feita  com a captura dos pacotes e análise comparativa com padrões ou assinaturas conhecidas  pelo NIDS.    Uma característica relevante do NIDS é a sua possibilidade em detectar os  ataques de rede em tempo real. Como o sensor atua em modo promíscuo no mesmo  segmento de rede de um host atacado, por exemplo, ele pode capturar os pacotes  referentes ao ataque, analisar e responder aproximadamente ao mesmo tempo em que o  ataque é executado [Shah 2001].  2.1.3. IPS  Os sistemas IDS que capturam o tráfego para somente análise tem sua operação em  modo passivo, não sendo possível gerenciar o tráfego de pacotes na rede. Segundo  [Nakamura 2007] já os IPS com operação em modo inline diferem da operação passiva  na forma de captura de tráfego, sendo capazes de detectar e prevenir os ataques. Esses  sistemas que operam no modo inline são chamados de sistemas de prevenção de  intrusão (Intrusion Prevention System - IPS).   Os IDS inline são capazes de finalizar as conexões enviando mensagens do tipo  “drop” antes que cheguem ao destino, como acontece nas atividades de um firewall,  diferentemente do que acontece nos IPS com operação em modo passivo, onde possuem  formas de atuação normalmente com o envio de mensagens “TCP reset”, possibilitando  ao atacante obter informações que podem ser relevantes aos ataques [NetScreen 2002].   3. Implementação  Para a implementação do sistema de detecção e prevenção de intrusos que foi utilizado  no ambiente em questão deste artigo, foram utilizados alguns materiais descritos nas  subseções a seguir, bem como os métodos. A instalação e configurações básicas dos  componentes não são abordadas, visto que o foco deste artigo são os resultados da  implementação.    3.1. Hardware  O hardware utilizado para hospedar o serviço é um servidor de rack de 1u, composto de  placa-mãe Serverboard X8DTi-F, 2 processadores Intel(R) Xeon(R) CPU E5540 de  2.53GHz contendo 8 cores físicos + 8 cores virtuais totalizando 16 CPUs, 12 GB de  memória RAM DDR3 1333 Mhz, 2 Hard Disks SAS 1000 rpm de 600GB cada  utilizados em modo RAID0, 2 interfaces ethernet de 1000baseT full-duplex on-board e  2 fontes de alimentação de 750W.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   199        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     3.2. Sistema Operacional  Para o sistema operacional foi implementado o pfSense. O projeto pfSense é um firewall  de rede de código fonte aberto, com base no sistema operacional FreeBSD composto de  um kernel personalizado e incluindo pacotes de software livre terceiros para  funcionalidades adicionais, assim sendo capaz de fornecer a mesma funcionalidade, ou  mais, dos firewalls comerciais comuns [Pfsense 2015].    Segundo [Laskoski 2014], o projeto pfSense, desde sua criação em 2004, sempre  desejou agregar novos serviços, tais como, VPN, proxy, autenticação de usuários, IDS,  possuindo atualmente dezenas de pacotes adicionais que lhe permitem requisitar o posto  de firewall UTM, visto que pode realizar a maioria das atividades de sistemas desse  porte.   3.3. Snort  Snort é uma ferramenta NIDS open-source desenvolvida por Martin Roesch sendo  muito popular pela sua flexibilidade nas configurações de regras e constante atualização  diante das ferramentas de invasão de licença livre. Seu código fonte otimizado, é  desenvolvido em módulos utilizando a linguagem C possuindo documentação de  domínio público [Snort 2015].   Optou-se pela escolha de implementação do Snort devido ao sistema estar  consolidado há vários anos no mercado, além de constante desenvolvimento de  atualizações do sistema e de suas regras de detecção, também chamadas de assinaturas.  Seus módulos são capazes de analisar o conteúdo dos cabeçalhos quanto dos pacotes em  redes IP, produzindo grande quantidade de informação sobre os ataques detectados.   Além de realizar análises em tempo real com suporte a diversos protocolos a nível de  rede e aplicação, sobre o conteúdo hexa e ASCII, uma das principais características do  seu funcionamento é a ampla possibilidade de tratamento dos alertas gerados, através de  ações que vão desde mensagens ao administrador de rede a bloqueios de tráfego.   Outro ponto que apoiou a escolha do Snort foi a característica do sistema ser  baseado em assinaturas, trabalhando somente em comparação com seu banco de regras,  ao contrário dos sistemas de detecção por anomalias que parte do princípio da detecção  com base em ações diferentes das atividades normais de sistemas. Segundo [Kizza  2005], os IDS baseados em anomalias possuem algumas desvantagens como, falsos  positivos equivocadamente sinalizados como intrusão em relação a atividades anômalas,  porém não intrusivas e falsos negativos, por não produzirem alguma anomalia  perceptível, assim tendo intrusões não detectadas.   3.4. Metodologia  Utilizando o hardware descrito na seção 3.1, foi instalada a versão mais recente do  sistema pfSense, atualmente v.2.2.2, sendo configuradas todas as questões inicias de  endereçamento, roteamento, autenticação e os controles de camada de transporte,  utilizando a política padrão de bloqueio total, liberando somente o necessário. Após, via  gerenciador de pacotes do pfSense, foi instalado o Snort em sua versão mais recente,  atualmente v.3.2.4.    Para o funcionamento do mecanismo de comparação de assinaturas do Snort, é  necessário popular o seu banco de dados de assinaturas instalando as rules. Para isso, foi  criado um usuário no site da comunidade e então baixadas as assinaturas registradas,  que são mantidas pela comunidade e possuem frequentes atualizações. Logo após, foi  definida e configurada a interface wan para atuação do Snort, sendo esta a primeira  interface de entrada de pacotes da instituição.    Em relação ao desempenho de detecção, considerando o hardware utilizado  descrito na secção 3.1, ficou definido o uso do algoritmo AC-STD (Aho-Cosarick     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   200        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     Standard) devido a utilizar uma quantidade moderada de memória, porém com alta  performance. O Aho-Corasick é um algoritmo inventando em 1975 pelos pesquisadores  do Bell Labs Alfred V. Aho e Margaret J. Cosarick. Sua função é realizar pesquisas em  strings com o objetivo de localizar palavras chaves em textos, a partir de uma única  interação, utilizando como base um dicionário com um conjunto finito de palavras  chave. [Aho e Corasick 1975].   Como critério para a escolha das rules a serem utilizadas no IDS em questão,  foram tomadas como base as informações referentes aos tipos e frequência de ataques  divulgadas pelo Cert.br e apresentadas na secção 2.1. Logo foram selecionadas as  seguintes, scan.rules, botnet-cnc.rules, phishing-spam.rules, spyware-put.rules,  vírus.rules, trojan.rules, worm.rules, dos.rules, ddos.rules e sql.rules, considerando as  demais rules disponíveis para futura aplicação.   Para a utilização do sistema IPS, o pacote Snort instalado já acompanha a  solução barnyard2, sendo que para sua ativação foi necessário apenas configurações  basicamente relacionadas aos logs de eventos. O período de bloqueio definido para  potenciais atacantes foi de 15 dias, tendo como critério utilizado a seguinte situação. Por  exemplo, se for definido um prazo de bloqueio muito grande ou até indefinido, no  momento do ataque há a possibilidade do atacante estar conectado a provedores de  acesso à internet que forneçam endereços IP em modo dinâmico “DHCP Server”, fato  muito comum. Assim, logo após o atacante obter um novo endereço IP, seu antigo fica  disponível para um novo usuário, que porventura poderá utilizá-lo e acessar serviços  hospedados na instituição, mesmo considerado tráfego legítimo, não será possível  estabelecer a comunicação por seu endereço IP já estar bloqueado. Entretanto, se for  escolhido um prazo pequeno, como o definido, ainda manterá segurança e evitará perdas  de conectividade.      Com o objetivo de monitorar e promover a segurança de toda a rede acadêmica  do campus, foi escolhido a borda da infraestrutura como localização de instalação da  solução IDS, assumindo assim a posição de roteador, firewall de perímetro e solução de  detecção e prevenção de intrusos, em modo NIDS. A Figura 2 mostra a localização da  solução na infraestrutura.         Figura 2. Localização da solução NIDS no IFFarroupilha-SVS      4. Resultados  A partir da implantação do sistema descrito, todo o tráfego entre a internet e o campus,  passou a ser monitorado e analisado pelo IDS, estando em funcionamento desde então.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   201        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015      Apesar do Snort estar configurado para detecção de apenas algumas das  assinaturas mais conhecidas, sua efetividade foi considerada satisfatória, analisando o  ambiente desprotegido antes de utilizar o sistema de prevenção de intrusos, foco desta  implementação.   Para apresentação dos resultados, foram coletados informações atualizadas,  geradas a partir dos alertas do IDS em Agosto de 2015, mês de escrita deste artigo, no  período de 01/08/2015 a 31/08/2015, totalizando 31 dias. Com base nessas informações  foram detectados 7730 alertas, em sua maioria escaneamento de portas e serviços,  incluindo algumas tentativas de conexões a banco de dados.   Após análise das informações obtidas, foi observado uma grande frequência de  alertas dos tipos “(spp_sip) Content length mismatch” e “ET SCAN Sipvicious UserAgent Detected, ambos tendo como alvo a porta destino 5060 e utilizando o protocolo  UDP. Com base nesta situação, percebeu que os atacantes estavam primeiramente  tentando descobrir serviços ativos que permitam registros SIP (Session Initiation  Protocol), para logo após, iniciar ataques com o objetivo de fazer ligações telefônicas  sem custo para o intruso, utilizando a tecnologia VOIP (Voice Over internet Protocol).  A Figura 3 apresenta as informações obtidas com base nos tipos de alertas gerados.     Figura 3. Tentativas de ataques sofridas entre 01/08/2015 a 31/08/2015        Todas as atividades consideradas tentativas de ataque que geraram alertas  tiveram seus endereços IP de origem bloqueados pelo mecanismo IPS do Snort,  conforme ação previamente configurada.  Alguns tráfegos legítimos foram  reconhecidos pelo IDS como atividade suspeita de ataque, aproximadamente 1% do  total de alertas, tendo seus hosts de origem bloqueados e posteriormente sendo  removidos manualmente. Esta ação conhecida como “falso positivo” torna-se uma  dificuldade encontrada, ocasionando um grande impacto em relação a conectividade dos  hosts que tem seu tráfego legítimo dentro da normalidade, porém bloqueados  indevidamente.    A questão de falsos positivos ocorridos nos sistemas IDS em softwares livres  está sendo minimizada pelos desenvolvedores de suas comunidades de acordo com as  contribuições das regras de detecção mais aprimoradas, podendo ser considerado um  trabalho futuro de pesquisa.   5. Trabalhos Relacionados   Uma análise bibliográfica e estudo de caso de comparação entre dois sistemas de  detecção de intrusos baseados em assinaturas, Snort e Suricata, foi mostrado no trabalho  de [Murini 2014], aonde utilizou dados sintéticos da DARPA para avaliação dos  resultados.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   202        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015      Em [Cunha Neto 2005] é mostrado o Snort como ferramenta de detecção e  prevenção de intrusos baseado no método de detecção por conhecimento de assinaturas,  bem como sua instalação e configuração em ambiente Linux.    Em [Perlin, Nunes e Kozakevicius 2011] é apresentado os principais conceitos  relacionados ao desenvolvimento de sistemas detectores de intrusão em redes de  computadores, com foco voltado para detecção de intrusão por anomalias, um dos  métodos utilizados nos IDS, baseada na transformada Wavelet.    Esta pesquisa demonstra a eficácia do Snort como sistema IDS baseado na  detecção por assinaturas, apresentando resultados obtidos com dados das tentativas de  intrusões sofridas no ambiente acadêmico em questão, contribuindo assim, com os  administradores de redes e pesquisadores da área de tecnologia em segurança da  informação.     6. Considerações finais  Apesar do campus de São Vicente do Sul manter na sua infraestrutura de redes  diferentes mecanismos de segurança, como firewalls, soluções antivírus, VPN, DMZ,  dentre outros, não estavam sendo suficiente para prevenir alguns tipos de ameaças.    Esta pesquisa e implementação do sistema de detecção e prevenção de intrusos  baseada em rede utilizando assinaturas, proporcionou uma camada extra de segurança  para a rede acadêmica do local, tornando possível detectar e prevenir diversos métodos  de ataques, protegendo assim todos os sistemas e hosts internos.  Além disso, permitiu  o monitoramento e documentação dos possíveis ataques futuros, auxiliando e orientando  o administrador de redes do local como proceder com os incidentes de segurança.   Algumas assinaturas desenvolvidas pela comunidade do Snort ainda estão  gerando falsos positivos, causando bloqueios indesejados. Análise e testes com essas  regras estão sendo efetuadas para que não ocorram indisponibilidade de algum sistema e  ao mesmo tempo possam somar a base de dados de conhecimento do IDS.  6.1. Trabalhos futuros  Os conhecimentos obtidos através da implementação descrita neste artigo bem como a  efetividade do sistema IDS podem ser ampliados através de futuras pesquisas, sendo  algumas apontadas a seguir:   Modificar e/ou parametrizar as assinaturas do Snort para otimizar suas detecções  a fim de minimizar os falsos positivos.   Aplicar as demais rules disponíveis da comunidade do Snort e verificar seu  funcionamento e efetividade.   Comparar o Snort com outros sistemas de detecção de intrusos como o Suricata.    Referências  Aho, A. V. e Corasick, M. J. (1975) “Efficient String Matching: An aid to bibliographic   search”, Comm. Of the ACM 18, n.6: 333-340.   Cert br (2015) “Centro de Estudos, Resposta e Tratamento de Incidente de Segurança no  Brasil”, http://www.Cert, Julho.    Cunha Neto, R. P. (2005) “Implementação de Ferramenta para detecção de Intrusão”,  em Caderno de Estudos Ciência e Empresa, FAETE, v.02, p. 01-06.   Kizza, J. M. (2005) “Guide to Computer Network Security”, New York, NY:Springer.   Laskoski, J. (2015) “O que é pfSense”, http://goo.gl/eIsL3L, Setembro.   Murini, C. T. (2014) “Análise dos Sistemas de Detecção de Intrusão em Redes: Snort e  Suricata Comparando com Dados da Darpa”, UFSM, TCC, Janeiro.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   203        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 196-203 Nov/2015     Nakamura, E. T. (2007) “Segurança de Redes em Ambiente Corporativos”, Novatec  Editora, São Paulo.   NetScreen Technologies, Inc. (2002) “Intrusion Detection and Prevention – Protecting  Your Network From Attacks”.   Perlin, T., Nunes, R. C. e Kozakevicius, A. J. (2011) “Detecção de Anomalias em Redes  de Computadores através de Transformadas Wavelet”, em Revista Brasileira de  Computação Aplicada (ISSN 2176-6649), Passo Fundo, v. 3, n 1, p. 02-15, mar.  2011.   Pfsense (2015) “pfSense Open Source Security”, https://www.pfsense.org, Agosto.    Ranum, M. J. (2001) “Coverage in Intrusion Detection Systems”, NFR Security, 26 de  Agosto.    Shah, B. (2001) “How to Choose Intrusion Detection Solution”, Sans Institute, 24 de  Julho.   Snort (2015) “The Open Source Network Intrusion Detection System”,  https://www.Snort.org, Julho.    Tanenbaum, A. S. (2003) “Redes de Computadores”, 4. ed. Elsevier, Rio de Janeiro.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   21        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     Técnicas de Suavização de Imagens e Eliminação de Ruídos     Carlos H. Sanches1, Paulo J. Fontoura1, Phillypi F. Viera1, Marcos A. Batista1     1Instituto de Biotecnologia – Universidade Federal do Goiás Regional Catalão (UFG)  Catalão – GO – Brasil     carlossanhces,paulojunior.fontoura,fernadesphillypi323: @gmail.com     Abstract. This article is intended to display picture smoothing techniques. The  goal is to demonstrate the operation of these techniques and how they were  developed. Four ways of smoothing are presented, namely: Median filter,  Kuwarama filter, Average filter and Gaussian filter, all are constituted as  different forms of image smoothing. For comparison are adopted theoretical  knowledge about the filters obtained through research.     Resumo. Este artigo tem a finalidade de apresentar técnicas de suavização de  imagens. O objetivo é demonstrar o funcionamento destas técnicas e como  foram desenvolvidas. São apresentadas quatro formas de suavização, quais  sejam: filtro de Mediana, filtro de Kuwarama, filtro de Média e filtro  Gaussiano, todas se constituem como diferentes formas de suavização de  imagem. Para a comparação são adotados conhecimentos teóricos sobre os  filtros obtidos por meio de pesquisas.      1. Introdução   Na atualidade, sabe-se a importância das imagens no cotidiano, pois elas fazem parte da  vida dos seres vivos e estão presentes em todos os lugares, por meio de propagandas,  informativos, livros, revistas, etc., constituindo-se como uma das fontes principais de  informação usadas pela humanidade. O grande uso de imagens está relacionado à  quantidade de informação que uma unicá imagem pode trazer, fazendo com que a  pessoa que está a sua frente crie uma interpretação própria sobre a mesma. Então, podese dizer que as imagens estão na sociedade tanto por uma questão de entretenimento  quanto por uma questão profissional.    Devido à grande importância das imagens existe a necessidade de sempre  manter a boa qualidade das destas. O que é complexo, porém, possível para os seres  humanos. Diferentes técnicas foram e vêm sendo criadas para garantir a qualidade das  imagens. Essas técnicas são desenvolvidas por meio do processamento digital de  imagens, que procura garantir uma melhora significativa em sua qualidade. Um dos  principais problemas de uma imagem são os ruídos. Existem vários tipos de ruídos que  são causados por diferentes formas, entre eles, destaca-se Salt and Pepper Noise e  Gaussian Noise.   Para combater tais ruídos foram criadas técnicas de suavização. Algumas delas  são comparadas e analisadas no decorrer deste trabalho, ressaltando-se alguns dos seus  pontos positivos e negativos. Uma das funcionalidades dos filtros é reduzir o ruído e  preparar as imagens para processamento, tal como a segmentação. Há, entre os filtros     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   22        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     abordados, dois Não-Lineares: de Kuwahara, Mediana e de Média, que não são  passíveis de análise no domínio de Fourier, e são baseados em operações sobre os  quadros de pixel vizinhos e um filtro lineares: o Gaussiano, que é um filtro de passa  baixa, onde permite uma passagem de frequência abaixo da sua frequência de corte.      2. Fundamentação Teórica   2.1 Filtros   Um filtro procura fazer a varredura e a extração das informações que, extraídas, servem  para analisar uma imagem, possibilitando a correção de imperfeições na mesma e a  criação de ruídos ou borrões no momento de transmissão. Filtros estão divididos em  duas formas: filtros no domínio da frequência e filtros no domínio do espaço. [Carvalho  2003]    Um filtro de domínio do espaço faz a filtragem no espaço, sendo esta  considerada uma operação local devido à forma como acontece a filtragem e também ao  nível de cinza existente em um determinado ponto, dependendo do ponto original e dos  seus vizinhos. O filtro funciona usando uma máscara de deslocamento que é composta  por matrizes nas quais cada posição possui uma determinada associação a uma posição.  O primeiro passo é feita uma máscara convolução que funciona como uma forma de se  captar a informação da imagem. Ela é posicionada em cima do pixel em que se deseja  fazer a operação de suavização. Então, a máscara faz o cálculo de acordo com os  vizinhos do pixel escolhido e isto é feito com todos os pixels até se obter uma nova  imagem, sendo o cálculo feito com o pixel escolhido no momento com os seus vizinhos,  porém, esse cálculo é feito para alterar um único pixel equivalente ao pixel central no  momento para o mesmo pixel na imagem com os resultados da filtragem.    De acordo com [Müller e Daronco 2000], máscara de convolução é o processo  de calcular a intensidade de um determinado pixel em função da intensidade de seus  vizinhos. Esse procedimento está descrito na figura 1.          Figure 1. Equação convolução       A equação é feita através de uma ponderação, em que se utilizam pesos  diferentes para pixels vizinhos diferentes. A matriz de pesos é chamada de núcleo da  convolução. Para obter o novo valor do pixel, multiplica-se o núcleo pelo valor da  imagem original em torno do pixel, elemento a elemento, e soma-se o produto, obtendose o valor do pixel na nova imagem.      2.2.  Filtros de suavização e Ruídos   Os filtros de suavização podem ser classificados em dois grupos Lineares e NãoLineares.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   23        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     1) Filtros Lineares: filtros lineares são aplicados a uma operação linear e são passíveis  de análise no domínio de Fourier ou a um domínio de frequência. Eles são utilizados em  diversas áreas, não somente no processamento de imagem digital. Sua finalidade é  eliminar frequências ou ruídos indesejáveis.    Os filtros de suavização Lineares podem ser classificados como filtros de passabaixa, passa-alta, passa-banda. Um filtro de suavização tem a finalidade de criar um  efeito desfocado na imagem. Com esse processo se consegue reduzir a diferença entre  certo pixel e seus vizinhos. Usados em uma etapa de pré-processamento os filtros de  suavização, segundo [Gonzales e Woods 2002], são utilizados tanto para a retirada de  pequenos detalhes de uma imagem antes da extração de objetos maiores, como para  fazer a conexão de pequenas descontinuidades, em linhas ou curvas. Após o uso de um  filtro de suavização o resultado obtido no pixel que foi processado é a média entre ele e  seus vizinhos, reduzindo assim os ruídos, porém, com o risco de afetar a imagem de  forma se altere muito a imagem real.      2) Filtros Não-Lineares: diferentemente dos filtros lineares eles não possuem um  operação linear e também não são passíveis da analise do domínio de Fourier domínio  de frequência. Esses tipos de filtros realçam ou minimizam ruídos por meio de  variância. Essa média irá variar de acordo com calda filtro e a forma como são  implementados.      3) Ruídos: ruídos são informações indesejáveis em uma imagem, que podem ser  causados pela variação de brilho ou por falsas informações dentro das imagens.  Conforme apresentado em [Seara 1998], toda aquisição de imagens é propícia a algum  tipo de ruído. Sabe-se que ruídos sempre aconteceram no ambiente digital. Ruídos são  algo inevitável e não há uma forma de prevê-lós. Nas imagens existem dois tipos de  ruídos específicos: Gaussian Noise (Ruído Gaussiano) e Salt and Pepper Noise (Ruído  de Sal e Pimenta): Gaussian Noise ou (Ruído Gaussiano) é um ruído que apresenta uma  distribuição de Gaus. Ruído Gaussiano é um ruído estatístico que tem uma função de  densidade e de probabilidade, formado pela má iluminação, por altas temperaturas ou  problemas na transmissão da imagem, deixando-a até mesmo extremamente danificada  [Klein e Gal-lager 2001]. O ruído Salt and Pepper Noise ocorre a partir de erros na  transmissão de dados. Com a transmissão da imagem, algum pixel pode se corromper,  alterando os tons de cinza de cada pixel vizinho, conforme [Ribeiro 2006].      2.3. Filtros explorados   1) Filtro de Kuwahara: é um filtro não linear e de suavização capaz de agir sobre as  imagens, sem comprometer sua nitidez e as posições das bordas. Graças a isso, é  conhecido por ser um tradicional filtro de preservação de bordas de desfoque. Trabalha  dividindo uma janela em quatro sub-janelas que se sobrepõem. Em cada sub-janela são  calculadas uma média e um variância. O valor de saída é definido como a média da subjanela com a menor variação e esse valor será atribuído ao pixel central de cada região  analisada pelo algoritmo. De acordo com [Young et.al 1998], o filtro de Kuwahara pode  ser implementado por uma grande variedade de formas em relação à divisão de suas  janelas, Uma das formas que se pode demonstrar o algoritmo é descrita por uma janela  de ordem quadrática de tamanho J = K = 4L + 1, onde L é um número inteiro, J, número     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   24        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     de linhas, e K, número de colunas. A janela é dividida em quatro regiões, como  mostrado na figura 2.                        Figure 2. Representação: forma de funcionamento do kuwaraha.      2) Filtro de Mediana: de acordo com [Jain et.al 1995], é o mais eficiente para eliminar  ruídos do tipo Sal e Pimenta e ruídos impulsivos, retendo os detalhes da imagem porque  eles não dependem dos valores que são significativamente diferentes dos valores típicos  em uma vizinhança. O cálculo do filtro de Mediana é feito selecionando um  determinado pixel, que será o pixel do cálculo no momento. Lembrando que a Mediana  é o valor do pixel selecionado de um conjunto qualquer, que é composto por ele e seus  vizinhos, organizados em ordem de grandeza quando a cardinalidade é ímpar. No caso  da cardinalidade ser par, a Mediana é o valor da média dos dois valores centrais. Na  figura 3 é apresentado um exemplo com um conjunto de pixel de cardinalidade ímpar.                          Figure 3. Exemplo: Vizinhança Mediana.      Após o valor da mediana ser encontrado, o mesmo é atribuído ao equivalente pixel  escolhido na imagem, resultando na suavização. Por exemplo, em uma vizinhança de  matriz 3x3, o quinto maior valor será considerado a mediana e assim por diante, de  acordo com o tamanho da vizinhança desejada (Figura 4).             Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   25        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015                   Figure 4. Valores da vizinhança.     O filtro trabalha em nível de cinza, mantendo, de certa forma, o formato original  das imagens e eliminando ruídos sem muita perda de nitidez.      3) Filtro de Média: é um filtro simples, intuitivo e fácil de ser desenvolvido, porém,  eficiente para o propósito de filtrar imagens, pois ele reduz a quantidade de variação de  intensidade entre um pixel e seus vizinhos, eliminando ruídos. A ideia é simplesmente  substituir cada valor de pixel em uma imagem com o valor médio de seus vizinhos,  incluindo ele mesmo, o que produz o efeito de eliminar os valores de pixels que são  representativos de seus arredores. O filtro de Média é um filtro Não-Linear, sendo assim  e´ baseado em torno de uma janela, que apresenta a quantidade de pixel para ser  calculada a media´. Observe-se uma janela 3x3, como mostrado na figura 5.                   Figure 5. Cálculo da média do filtro de Media´.      A média será calculada a partir da soma de todos elementos e divisão pela  quantidade total deles. Assim, obtêm-se o valor médio da intensidade de pixel de cada  janela.      4) Filtro Gaussiano: apresenta diferentes particularidades que o tornam útil em  diferentes áreas de processamento de imagens. Algumas dessas diferentes utilidades  foram descritas por [Faria 2005] em sua dissertação de mestrado. O filtro Gaussiano  geralmente é usado como um filtro de passa-baixa por deixar passar as baixas  frequências, mas elimina os valores relacionados às altas frequências apresentadas em  [Pedrini 2004]. O filtro Gaussiano tem esse nome por usar a função Gaussiana para  obter os valores da máscara. Esta função é representada na figura 6.              Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   26        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015             Figure 6. Equação do filtro Gaussiano em 2-D.      Nesta equação, σ é o desvio padrão, e quanto maior seu valor, maior a largura do  filtro Gaussiano e maior o grau de sua suavização. A figura 7 mostra a máscara típica  para implementar o filtro Gaussiano, resultante de um σ = 1.                     Figure 7. Máscara 5x5 com desvio padrão 1.          O filtro Gaussiano em duas dimensões tem o grau de suavização igual em  ambas as direções, pois funções Gaussianas são simétricas em relação à rotação. Neste  filtro, assim como em outros, a suavização da imagem é realizada através da  substituição de cada pixel pela média ponderada dos pixels vizinhos. Porém, o filtro  Gaussiano funciona de forma que o peso dado a um vizinho decresce monotonamente  com a distância do pixel central. O grau de suavização está relacionado ao tamanho da  máscara, pois, quanto maior a sua largura, maior o grau de suavização que será aplicado  pelo filtro Gaussiano. O custo computacional requerido por um filtro Gaussiano é  relativo ao tamanho da máscara      3. Resultados   A proposta do trabalho está centrada em analisar as técnicas que implementam filtros de  suavização e utiliza-las. Desse modo, analisa-se o uso dos quatro filtros: de Mediana, de  Média, Gaussiano e de Kuwahara. Será realizada uma comparação entre os resultados  obtidos, de modo que se compreenda sobre suavização e a forma como os filtros  funcionam, tendo em vista que o trabalho mostra técnicas de suavizações diferentes,  mas com o mesmo objetivo.   Os Resultados obtidos com as suavizações são apresentados, nesta seção, como  forma de demonstrar o efeito de cada uma das técnicas. Propõe-se uma conclusão  relatando as diferenças entre os resultados das técnicas. Tais resultados serão  apresentados em forma de imagens que passaram pelo processo de cada algoritmo dos  filtros apresentados neste trabalho.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   27        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015        Na figura 8a é mostrada uma imagem com ruído de Sal e Pimenta e podem ser  observadas bem nítidas suas deficiências. A figura 8b traz o resultado da aplicação do  filtro de Mediana, em que a imagem parece quase a mesma, respeitando-se os traços da  imagem original sem os ruídos. Os resultados do filtro de Kuwahara são apresentados  na Figura 8c, que mostra a aplicação do algoritmo sobre a imagem original da figura 8a.  A figura 8d exemplifica a aplicação do filtro Gaussiano e a 8e a imagem após a  aplicação do filtro de Média.                                          Figure 8. Imagem original e as aplicação dos filtros.      Na figura 9a, é demonstrada uma nova imagem em que serão aplicados os  filtros. Na figura 9b aparece o efeito após aplicação do filtro de Mediana. A figura 9c  mostra os resultados, após aplicação do filtro de Kuwahara. Já figura 9d apresenta os  resultados após aplicação do filtro de Gaussiano, e na figura 9e, o filtro de Média. Após  analisar as imagens com ruído de Sal e Pimenta, será apresentada uma nova imagem  com um ruído Gaussiano e será exibida a mesma imagem após aplicação dos filtros.                          Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   28        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015                                            Figure 9. Imagem original e as aplicação dos filtros.      Na figura 10a, mostra uma nova imagem com ruído e a aplicação do filtro de  Mediana é demonstrada na figura 10b. A figura 10c apresenta a aplicação do filtro de  Kuwahara. Na figura 10d, apresenta implementação do filtro Gaussiano. Na figura 10e  implementação do filtro de média.                                    Figure 10. Imagem original e as aplicação dos filtros.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   29        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     4. Conclusões      Pode-se concluir que as técnicas de suavização apresentadas, são técnicas eficientes e  tradicionais no cenário do processamento digital e produziram um resultado satisfatório.  Elas funcionaram de acordo com o proposto no trabalho e foi desenvolvida uma  conclusão como forma de apresentar os resultados obtidos.   Em relação aos resultados obtidos pelo uso dos filtros, o ruído de Sal e Pimenta  apresentado em duas imagens foi melhor eliminado pelo filtro de Kuwahara, pois este  preserva bem as bordas e mantem´ aspectos importantes das imagens originais. Já o  filtro de Mediana consegue eliminar bem o ruído, mas não preserva bem a tonalidade  dos pixels, o filtro de Media´ elimina poucos ruídos e deixa a imagem muito embaçada  e o filtro Gaussiano, por sua vez, não elimina ruídos de Sal e Pimenta. No ruído  Gaussiano, o filtro de Kuwahara foi o que obteve melhor resultado. O filtro de Mediana  não foi muito eficiente, pois deixou mais clara a imagem, porem,´ eliminou bastante  ruído, já filtro Gaussiano eliminou bastante, mas não manteve a preservação das bordas,  deixando muito desfocada a imagem.   O filtro de Média não foi muito eficiente na eliminação de ruídos e também não  manteve aspectos originas da imagem. Como conclusão, o filtro de Kuwahara  apresentou bons resultados se comparado aos demais na eliminação dos dois tipos  distintos de ruídos, em outras palavras, o algoritmo do filtro de Kuwahara foi melhor  qualificado entre os demais filtros apresentados nesse trabalho, provavelmente pela  forma como divide a imagem em regiões e utiliza a menor variância, o que mantem os  aspectos originais da imagem, preserva bem as bordas, não apresentando muitas  distorções.      5. Referências     CARVALHO, A. A. de.(2003). Estudo e implementação de algoritmos clássicos para  processamento digital de imagens. Monografia apresentada ao Departamento de  Ciência da Computação da Universidade Federal de Lavras.   FARIA, D. R.(2005). Reconhecimento de impressões digitais com baixo custo  computacional para um sistema de controle de acesso. Dissertação (Mestrado),  Universidade Federal do Paraná.   GONZALES, R. e WOODS, R.(2002). Digital Image Processing. Prentice Hall, 2nd  Edition.   JAIN, R., KASTURI, R. e SCHUNCK, G. B. (1995). Machine Vision. McGraw-Hill,  first Edition.   MULLER, D. N. e DARONCO, E. L.(2000). Filtros espaciais passa-baixa. Disponível  em http://www.inf.ufrgs.br/ danielnm/docs FiltrosEspa ciaisPassaBaixa.pdf . Acesso  em : 20/05/2014.   KLEIN, T. E. e GALLAGER, R. G.(2001). Power control for the additive white  Gaussian noise channel under channel estimation errors. IEEE International  Symposium. 14nd Edition.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   30        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 21-30 Nov/2015     PEDRINI, H.(2004). Apostila de Processamento de Imagens. Análise de Imagens  Digitais: Princípios, Algoritmos e Aplicações˜. Departamento de Informática-UFPR.   RIBEIRO, B.(2006). Suavização de Imagens. Disponível em: www.ic.uff.br/  aconci/suavizacao.pdf. Acesso em: 26/05/2014   YOUNG, I. T., GERBRANDS, e J VAN VLIET, L. J.(1998). Fundamentals of image  processing Delft University of Technology Delft, The Netherlands. Disponível em:  http://tnw.tudelft.nl/fileadmin/Faculteit/TNW/doc/FIP 2.2.pdf. Acesso: 20/05/2014.   SEARA, D. M.(1998). Visão Geral de Detecção de Bordas. Disponível em:  www.inf.ufsc.br/ visao/ bordas.html. Acesso em: 20/05/2014.   
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   299        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 299-302 Nov/2015     Aprendizagem por Reforço Clássica e Conexionista: análise de  aplicações   Thais L. Silva, Maury M. Gouvêa Jr.   Instituto Politécnico – Pontifícia Universidade Católica de Minas Gerais  Av. Dom José Gaspar, 500 – 31.535-901 – Belo Horizonte – MG – Brazil   thaisl.silva@hotmail.com, maury@pucminas.br  Resumo. A aprendizagem por reforço é um paradigma do tipo não  supervisionado, onde o agente aprende sem um professor – sem exemplos  rotulados. Assim, pode-se aprender em tempo real, pela experiência de executar  uma ação e avaliar seu sucesso. Neste artigo apresenta-se dois exemplos de  aprendizagem por reforço: um baseado no modelo clássico, utilizando o  algoritmo Q-Learning, o outro baseado em sistema conexionista, utilizando uma  rede neural artificial. No último caso, a aplicação é voltada à Tecnologia  Assistiva. Em ambos os exemplos, mostra-se que o agente aprendeu com suas  próprias ações, melhorando seu desempenho com o tempo.   1. Introdução  Dentre os paradigmas de aprendizagem de máquina, a aprendizagem por reforço (AR) se  destaca na robótica por não necessitar de exemplos de treinamento, isto é, o agente aprende  em tempo real, com seus próprios erros, interagindo com seu meio. Essa característica da  AR ganha destaque em situações em que não se conhece em detalhes o ambiente no qual o  agente está inserido, sem qualquer histórico de comportamento a ser seguido. Alguns  exemplos desses ambientes são as situações de desmoronamento, grande profundidades  oceânicas e, até mesmo, exploração espacial.    A aprendizagem por reforço pode ser clássica ou conexionista. O modelo clássico  usa algoritmos, como o Q-Learning [Sutton e Barto 1991]. A aprendizagem por reforço  conexionista é baseada em redes neurais artificiais [Haykin 2001].  Na aprendizagem  por reforço, o agente executa uma ação que é avaliada por um crítico, que dá ao agente um  sinal de reforço positivo ou negativo que é utilizado para se auto ajustar e, assim,  aperfeiçoar suas ações. Apesar de haver uma pré-programação, os algoritmo ou modelos  analíticos possuem parâmetros cujos valores ótimos são muito difíceis de ajustar  previamente, sem que situações reais aconteçam. Assim, uma possibilidade promissora de  se ajustar esses parâmetros é a AR, que usará as ações pré-definidas para avaliar o  desempenho dos parâmetros do sistema que sofrerão adaptações em função das avaliações  do crítico.   2. Aprendizagem por Reforço  A aprendizagem por reforço (AR) é um paradigma que não necessita de histórico de  ocorrências, de exemplos de comportamento ou padrões. Por isso, a sua aplicação é voltada  a tarefas que necessitam de adaptação em tempo real, como exploração de ambientes  desconhecidos ou dinâmicos.  A aprendizagem por reforço pode ser clássica [Sutton  e Barto 1991] ou conexionista neurais [Hertz et al. 1991]. Em qualquer dos métodos,  clássico ou conexionista, na aprendizagem por reforço o agente interage com o ambiente,  recebendo um sinal de reforço que varia conforme seu desempenho nas ações executadas.  Com ações boas ou ruins, o sinal de reforço é usado pelo agente para se adaptar ao meio.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   300        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 299-302 Nov/2015     2.1. AR Clássica  A aprendizagem por reforço permite a um determinado agente aprender interagindo com o  ambiente sem a presença de um tutor. Dessa forma, o agente decide qual ação tomar  buscando uma política ótima por meio de recompensas.  A Figura 1 mostra que em cada  passo da interação o agente de aprendizagem observa o estado, no instante k, do  ambiente, s(k), e escolhe uma determinada ação, a(k). O agente realizada essa ação,  modifica-se o estado do ambiente, s(k+1), que retorna ao agente, por meio de um crítico,  um sinal de reforço, r(s, a), que pode ser uma recompensa ou penalização.     Figure 13. Ciclo percepção-ação da AR    Por meio de tentativa e erro o agente aprende em relação ao ambiente, criando um  mapa estado-ação. O objetivo do aprendizado é definir qual ação tomar a cada iteração que  maximize o valor da recompensa [Sutton e Barto 1991].  2.2. AR Conexionista  A aprendizagem por reforço conexionista é baseada em redes neurais. O agente, na Figura  1, é constituído de uma rede neural que aprende em tempo real [Hertz et al. 1991]. O agente  percebe o ambiente e toma uma decisão. O crítico analisa a ação e a considera como a  desejada ou não dependendo da qualidade da ação. O sistema de aprendizagem utiliza um  algoritmo de aprendizagem supervisionada para efetuar os ajustes dos pesos da rede neural.   Na AR Conexionista, em vez de um conjunto de exemplos de treinamento, existe  apenas o sinal de reforço, r, que pode ser 1, para um sinal de reforço positivo, ou –1, para  um sinal de reforço negativo. Assim, os exemplos de treinamento são construídos em  tempo real, pela regra             −=−  = =  1se 1se  jj  jj j  rS rS  d             (1)     sendo d j a j-ésima saída desejada fruto da ação do agente analisada pelo crítico. Essas  regras sugerem que a rede neural será mais propensa a executar ações que foram  recompensadas, e vice-versa.    Para construir as regras de treinamento, compara-se dj com o valor médio da saída,  <Sj>, isto é, δj = dj – <Sj>. Os pesos da rede neural serão atualizados, como segue     Δwki  = η rj δj yj                                                  (2)     sendo Δwki o i-ésimo peso do neurônio k e η a taxa de aprendizagem.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   301        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 299-302 Nov/2015     3. Aplicações de Aprendizagem por Reforço Conexionista  Esta seção apresenta dois exemplos de aprendizagem por reforço, a primeira conexionista e  a segunda clássica, usando o método Q-Learning. As próximas subseções apresentam os  dois métodos de aprendizagem.  3.1. Aplicações de AR Conexionista  Este exemplo de AR Conexionista apresenta uma bengala eletrônica para deficientes  visuais que detecta obstáculos remotamente, sem contato físico, emitindo uma vibração que  alerta o usuário. Um sistema de aprendizagem on-line adapta o sistema de alerta ao padrão  de comportamento do usuário. Um método de aprendizagem conexionista adapta a  distância de alerta em função da velocidade do usuário. De uma forma suave, a distância de  alerta diminui para usuário mais lentos ou aumenta para usuários mais rápidos.   Uma rede neural artificial com uma saída executa a ação de diminuir ou aumentar a  distância de alerta conforme a velocidade do usuário e as sucessivas detecções de  obstáculos.  Os resultados experimentais mostraram que o módulo de aprendizagem  respondeu de forma esperada e satisfatória aos testes realizados, como mostra a Figura 2.       Figura 2. Distância de alerta média depois de 20 minutos de uso da BIN   3.2. Aplicações de AR Clássica  O exemplo de AR clássica, baseada no algoritmo Q-Learning, apresenta um robô  humanoide que aprende a andar para fim didático. Os motores do humanoide podem  assumir três velocidades: 0, 30 e 50 unidades de potência. Os motores são acionados de  forma intercalada, por 1 segundo. As ações possíveis são não alterar a potência do motor,  diminuir ou aumentar a potência. Quando o robô humanoide identifica um obstáculo,  simulando uma presa, o robô começa a andar. O crítico avalia a ação em função do  deslocamento do robô em relação ao alvo por um período de tempo. Se o robô se desloca  até um limite x1, a ação é punida; se o deslocamento é de x1 até x2, a ação é punida com  menor severidade; finalmente, se o robô se desloca uma distância maior que x2, a ação é  recompensada. A ideia é que se a ação não for boa o suficiente, ela não produzirá um  deslocamento do robô em relação ao alvo e, assim, será punida.   A tabela Q-Learning possui dimensão Ne x Na, sendo Ne o número de estados e Na o  número de ações. No exemplo apresentado, há 2 motores assumindo 3 estados e cada motor  pode executar 3 ações. Assim, Ne = 32 = 9 e Na = 32 = 9. A Tabela 1 mostra a tabela QLearning antes de depois do treinamento on-line, isto é, durante o tempo em que o  humanoide aprende a andar. Sabe-se previamente, pelo fim didático, que o Q(s,a) ótimo é  velocidades (50,50), pois são máximas e não desestabilizam o humanoide e ação (0,0), pois  não alteram a velocidade ótima. Trata-se, portanto, da posição Q(9,5). A Tabela 1, que tem  seus valores iniciais aleatório no intervalo [0,1], tem sua posição Q(9,5) maximizada em     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   302        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 299-302 Nov/2015     relação aos demais valores depois de aproximadamente 20 minutos de treinamento por  reforço, o que demonstra o sucesso da abordagem.   Table 1. Tabela Q-Learning antes e depois do treinamento     4. Conclusão  Este artigo apresentou o desenvolvimento de aplicações com aprendizagem por reforço.  Dois exemplos foram apresentados, o primeiro baseado no modelo clássico, utilizando o  algoritmo Q-Learning, e o segundo baseado em rede neural artificial. Ambos os exemplos  foram casos de sucesso, onde o agente aprendeu a executar sua tarefa em tempo real.   Referências  Sutton, R. S.; Barto, A. G. (1991) “Reinforcement learning: An introduction”.   Massachusetts: MIT Press.   Haykin, S. (2001) Redes Neurais: princípios e práticas. Porto Alegre: Bookman.   Heertz, J., Krogh, A. and Palmer, R.G. (1991) Introduction to the Theory of Neural  Computing. Redwood City: Addison-Wesley Publishing Co.   Alves, F. A. S., Neumann, A. M. M., Gouvêa Jr., M. M. (2014) “Bengala Inteligente Neural  Baseada em Aprendizagem por Reforço para Deficientes Visuais”, Encontro Nacional  de Inteligência Artificial e Computacional, São Carlos.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   311        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 311-314 Nov/2015     Avaliação de desempenho de uma ferramenta de detecção de  intrusão    Thales Nicolai Tavares1, Renato Preigschadt de Azevedo1   1Colégio Técnico Industrial de Santa Maria – Universidade Federal de Santa Maria   (UFSM)   Cep 97.105-900 – Santa Maria – RS – Brasil  {tavares,renato}@redes.ufsm.br     Abstract. This article presents tests performed in an intrusion detection tool in  order to assess their effectiveness with different types of attacks. The tool  under study is the SELKS and was developed by Stamus Networks and aims to  identify the attacks at the time of his execution, because it has a set of tools  able to monitor packets that travel over the network.   Resumo. O presente artigo apresenta testes realizados em uma ferramenta de  detecção de intrusão com o intuito de avaliar sua eficiência com diferentes  tipos de ataques. A ferramenta em estudo é a SELKS a qual foi desenvolvida  pela Stamus Networks e tem como objetivo identificar os ataques no momento  de sua execução, pois ele possui um conjunto de ferramentas capaz de  monitorar os pacotes que trafegam na rede.   1. Introdução   Durante os últimos anos podemos notar que a rede mundial de computadores vem  crescendo de forma muito rápida, e devido a este crescimento temos muitos serviços e  aplicações que utilizamos no nosso dia-a-dia funcionando através da internet. Em  virtude a essa expansão, temos que nos preocupar com a segurança, pois a quantidade  de ataques a sistemas de computadores vem crescendo diariamente.    Este trabalho apresenta resultados de estudos realizados com a ferramenta  SELKS, onde foi analisado o comportamento mediante os ataques. Para a análise da  ferramenta foi utilizado arquivos PCAPs de tráfegos de redes disponibilizados pela  NETRESEC, que é um fornecedor independente de software com foco na área de  segurança de rede e a ferramenta hping3, que é um software para realizar testes de  vulnerabilidades.   2. Objetivo  O objetivo principal deste artigo é mostrar o estudo realizado sobre o desempenho da  ferramenta de detecção de intrusão SELKS, onde foram utilizados tráfegos de redes  disponibilizados pela NETRESEC, bem como os resultados das detecções ocorridas.    Para a análise da ferramenta, foram utilizados arquivos PCAPs de tráfego de  rede disponibilizados pela NETRESEC. Também foi realizado um ataque de negação de  serviço, o qual ocorre quando um dispositivo envia uma grande quantidade de  requisições de um dispositivo para outro, não permitindo a comunicação legítima.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   312        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 311-314 Nov/2015     3. Desenvolvimento  Nos últimos anos, uma tecnologia tem se mostrado uma grande aliada dos  administradores de segurança. São os Sistemas de Detecção de Intrusão (IDS - Intrusion  Detection System), que possuem por objetivo tentar reconhecer um comportamento ou  uma ação intrusiva para alertar um administrador ou automaticamente disparar  contramedidas. [Laureano 2003]    Sistemas detectores de intrusão em redes de computadores são utilizados para  permitir a monitoração do tráfego de dados de uma rede de computadores ou um  segmento de rede. A análise é realizada em dados coletados da rede ou em base de  dados disponíveis ao IDS.  [Murini 2013]   A ferramenta em estudo é a SELKS (Figura 1), que está disponível em  http://www.stamus-networks.com, produto desenvolvido pela Stamus Networks que  tem por objetivo identificar os ataques no momento de sua execução, pois ele possui um  conjunto de ferramentas capaz de monitorar os pacotes que trafegam na rede. Sendo  assim, é realizada uma análise comparando o tipo de tráfego da rede com uma base de  dados que a ferramenta já possui. Esta base de dados é atualizada periodicamente, sendo  possível detectar novos ataques.       Figura 14. Tela inicial SELKS      Para a instalação da ferramenta foi necessário um ambiente virtual, onde foi  utilizada uma máquina para a instalação do SELKS e uma segunda máquina virtual com  o sistema operacional Linux, a qual foi utilizada para injetar tráfegos de rede através dos  arquivos PCAP. Os arquivos PCAPS são tráfegos de rede coletados em um arquivo, o  qual irá analisá-los posteriormente, preferencialmente em uma máquina diferente  daquela da qual o tráfego foi coletado. Os arquivos PCAPS que foram utilizados nos  experimentos são disponibilizados na página http://www.netresec.com da NETRESEC.   O SELKS é uma distribuição baseada no Debian, composto pelos componentes  principais: Suricata IDPS, que é um ID/PS motor baseado em regras e que utiliza regras  desenvolvidas externamente. Ele monitora o tráfego de rede e fornece alertas para o  administrador do sistema quando ocorrem eventos suspeitos; ElasticSearch, que é um  mecanismo de busca open source, desenvolvido sobre o Apache; Logstash para  centralização de logs; Kibana, que é uma plataforma de visualização de dados de código     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   313        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 311-314 Nov/2015     aberto que permite que você interaja com os seus dados através de gráficos; e o  Scirius  que é a interface web dedicada à gestão do conjunto de regras Suricata.   A ferramenta SELKS pode ser utilizada de duas maneiras, a live e a instalável, e  fornece um sistema de detecção de intrusão com o Suricata com seu próprio gerenciador  de regra e gráfico. Para a os testes, foi utilizado a versão instalável, onde foi usada uma  máquina virtual com espaço de disco de 25GB e 4GB de memória.   Como a intenção não é avaliar a eficiência da ferramenta IDS, a segunda  máquina virtual foi utilizada para injetar os arquivos PCAPS baixados da NETRESEC,  utilizando a ferramenta TCPreplay para a reprodução desses tráfegos.   Outro teste realizado foi no ambiente virtual, formado por uma máquina como  servidor web, e outra máquina virtual para realizar um ataque DOS (Denial of Service)  no servidor web. Um tipo de ataque de negação de serviço ocorre quando um  dispositivo envia uma grande quantidade de requisições de um dispositivo para outro,  assim não permitindo a comunicação legítima. Para realizar os experimentos foi  utilizada a ferramenta hping3, que é um software para realizar testes de  vulnerabilidades.   4. Resultados  Após deixar a ferramenta operando sob ataques dos arquivos PCAP,  e logo em seguida  os ataques de DoS, nota-se a alteração do gráfico da ferramenta SELKS (Figura 2).  Percebe-se que a ferramenta consegue detectar a alteração no tráfego de rede e gera  gráficos mostrando que ocorrem ataques contra a rede.        Figura 2. Gráfico de alteração do comportamento da rede        Figura 3. Tabela com endereços de origem e destino     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   314        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 311-314 Nov/2015        Através da análise dos gráficos e tabelas gerados pela ferramenta de detecção de  intrusão ficam evidentes as requisições que originaram o ataque. Nestes gráficos  também são apresentados os endereços IPs de origem e destino.      5. Conclusão  Neste trabalho foi mostrada uma alternativa de ferramenta de detecção de intrusão, a  SELKS. Foi possível perceber que a ferramenta apresenta um rendimento satisfatório ao  detectar ataque no tráfego de rede, pois nos experimentos realizados foram disparadas  diferentes formas ataques contra o servidor e analisado o comportamento da ferramenta  IDS.    Através da análise dos gráficos gerados pela ferramenta de detecção de intrusão,  ficam evidentes as requisições e a mudanças repentinas no tráfego de rede. Sendo assim,  é possível concluir que o uso de um sistema de detecção de intrusão é de grande  importância para o correto funcionamento de uma rede de computadores.   References   Laureano, M.A.P. (2003) Detecção de intrusão em máquinas virtuais. 5º Simpósio de  Segurança em Informática.    Murini, C.T. (2013) Análise de sistema de detecção de intrusão em redes de  computadores. 28ºJornada Acadêmica Integrada.          
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   286        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 286-290 Nov/2015     Computação Afetiva: Uma ferramenta para avaliar aspectos  afetivos em aplicações computacionais.   Saulo William S. Costa, Ailton Lopes de Sousa, Yomara Pires  Laboratório de Desenvolvimento de Sistemas (LADES) – Faculdade de Computação –   Universidade Federal do Pará – Campus de Castanhal, Avenida dos Universitários,  Jaderlândia – Castanhal – PA – Brasil   saulo.si.costa@gmail.com, ailtoonlopes@gmail.com, yomara@ufpa.br     Abstract. This paper aims to evaluate the Affective Aspects in Computer  applications through study of the state of the art in the areas of Affective  Computing, Human-Computer Interaction and case study application. For  this, we will study the Kinect applications for capturing the facial expressions  of the user in order to perform scenario development (case studies) to assess  the affectivity by capturing the user personality traits of the systems.   Resumo. Este artigo tem como propósito avaliar os Aspectos Afetivos em  aplicações Computacionais através de estudo do estado da arte nas áreas de  Computação Afetiva, Interação Homem-Computador e a aplicação de estudo  de casos. Para isso, estudamos as aplicações do Kinect para captura das  expressões faciais do usuário, a fim de realizar a elaboração de cenários  (estudo de casos) para avaliação da afetividade por meio da captura dos  traços de personalidade do usuário dos sistemas.    1. Introdução  Um Sistema de qualidade é essencial para qualquer organização, normalmente as  organizações necessitam de softwares fáceis de serem usados e tenham aceitação por  parte dos usuários. Essa necessidade de tecnologia qualificada e de boa usabilidade  torna a interação do Usuário com a Máquina parte fundamental da construção de um  sistema de alto desempenho. Para contribuir nesse processo de avaliação de usabilidade  de determinado sistema, temos a chamada Computação Afetiva que visa tentar fazer  com que a emoção, existente na comunicação entre pessoas, esteja presente também  durante a interação entre homem e computador [Picard, 1997]. A partir disso,  poderemos inferir através do estado emocional de um determinado indivíduo qual o tipo  de manifestação (positiva ou negativa) este terá ao usar determinado software.   Considerando essas necessidades, o presente trabalho tem por objetivo  apresentar, dentro da visão computacional, uma ferramenta capaz de realizar este  processo de avaliação de usabilidade de Sistemas Computacionais através da captura  dos traços de personalidade de indivíduos baseada em princípios da Afetividade  estudados na Computação Afetiva a partir dos estudos de Picard (1997) e Prates e  Barbosa (2005). As seções 2,3 e 4 descrevem os referenciais teóricos utilizados nessa  pesquisa.  2. Computação Afetiva  Dotar a máquina de emoções humanas é um dos desafios da Computação Afetiva;  Picard (1997) define Computação Afetiva como “Computação que está relacionada  com, que surge de ou deliberadamente influencia emoções”. Este campo de estudo se  divide em duas perspectivas: uma estuda a síntese das emoções em máquinas, quando se     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   287        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 286-290 Nov/2015     deseja inserir emoções humanas na máquina; e a outra investiga reconhecer as emoções  humanas ou expressar emoções por máquinas na interação entre homem-computador.    Dentro da segunda perspectiva, o presente estudo usará de uma ferramenta que  sairá da simples observação ou filmagem do usuário para métricas de caráter emocional  com intuito de estreitar o relacionamento Homem-Máquina a ser usada na avaliação  desses sistemas.  3. Avaliação de Usabilidade   A usabilidade é a característica que determina se o manuseio de um produto é fácil,  rapidamente aprendido, oferece um alto grau de satisfação para o usuário e executa  eficientemente as tarefas para qual foi planejado. Em avaliações no ambiente do  usuário, normalmente a coleta de dados é feita através da observação do uso sendo feito  da aplicação e conversas com os usuários [Prates & Barbosa, 2005].   Oferecer um novo método de avaliação baseado na identificação dos estados  afetivos do usuário permite uma avaliação mais fundamentada. Os benefícios de fazer  os estudos da afetividade dentro da usabilidade interferem positivamente dentro da  adaptação de um sistema computacional ao homem.  4. Interação Homem-Computador  Interação Homem-Computador (IHC) é uma área multidisciplinar que envolve ciência  da computação, psicologia, artes entre outras. Posicionada como subárea da Ciência da  Computação, pode ser definida como avaliação de sistemas interativos no contexto das  atividades do usuário [Pimenta 2006]. Conforme a evolução da tecnologia, algumas  formas de interação vão mudando os paradigmas.    Neste caso podemos destacar o uso do Sensor Kinect [Microsoft Research  2011], que modificou a forma como muitos usuários de jogos eletrônicos utilizam a  forma de interação com o computador.  O Kinect possui um grande potencial, que agora  pode ser usado com a interação direta com o computador indo além do campo para o  qual foi criado.   5. Ferramenta de Reconhecimento Facial  Para realizar a avaliação de usabilidade de um determinado sistema, está sendo  desenvolvida uma ferramenta para realizar o processo de captura e caracterização das  expressões faciais, que serão utilizadas para inferir as emoções de determinado usuário  ao fazer uso do software que está em processo de avaliação. Essa ferramenta consiste  basicamente dos seguintes módulos: Captura de Imagens, Rastreamento das  Características faciais, Classificação e Inferência das emoções. O processo de  funcionamento deste sistema é apresentado na Figura 1.                               Figura 1. Processo de funcionamento da Ferramenta        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   288        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 286-290 Nov/2015     O sistema utilizará as imagens que serão capturadas pela câmera do Kinect  [Microsoft Research, 2011] como entrada para o módulo de Rastreamento das  características faciais. Este módulo faz uso da técnica de detecção de faces chamada de  Viola-Jones [Viola-Jones, 2001] que a partir de uma determinada imagem irá identificar  o rosto de um indivíduo, além disso, faz-se uso de outra técnica chamada de  CANDIDE-3 [Ahlberg, 2001] que realiza a detecção das características faciais ao  encontrar os pontos característicos do rosto de determinados locais de interesse (boca,  olhos, sobrancelhas e nariz). Estas técnicas podem ser implementadas utilizando dos  recursos da Biblioteca do Kinect – SDK [Microsoft Research 2011].    Após a captura de imagem e rastreamento das características faciais,  temos como próxima etapa o módulo para a classificação das expressões que permitirá a  inferência das emoções do usuário. Ekman e Friesen (2002) nos fornecem o sistema  FACS [Ekman et al 2002] que é utilizada para encontrar as Unidades de Ações (UAs)  através dos pontos característicos do rosto que foram encontrados no módulo anterior.  As UAs consistem em um conjunto de músculos que são relaxados ou contraídos e que  resultam em pequeno movimento em uma parte do rosto; no sistema FACS foram  definidas 44 UAs que combinadas geram um grande número de expressões. Após  encontrar as UAs, é realizada a etapa de inferência das emoções, que é feita a partir da  conversão dos valores das unidades de ações encontradas para um conjunto de emoções  que foram estabelecidos pelos estudos de Ekman et al (2002). A expressão facial é de  fato a combinação de UAs; a princípio, esta abordagem possibilita que uma expressão  facial seja entendida como uma combinação de UAs faciais relevantes.   Para realizar a classificação da emoção utiliza-se um algoritmo que tem por  finalidade classificar a emoção que tiver a maior quantidade de UAs associadas à  respectiva expressão facial analisada. Assim, temos como resultado, a inferência de  emoções básicas como alegria, raiva, desgosto e tristeza durante a utilização de  determinado sistema computacional.    6. Experimentos e Resultados Preliminares  Os resultados obtidos até o momento foram realizados em um notebook modelo HP  Pavilion 14-v, Processador Intel Core i5, Memória RAM 4 GB, HD de 500 GB, Sensor  de movimentos Kinect, com emissor e sensor Infravermelho, sensor RGB e um conjunto  de microfones.    Foram implementados alguns recursos para rastreamento das características  faciais e detecção da face disponíveis na biblioteca do Kinect – Kinect SDK [Microsoft  Research, 2011], como o método de detecção de pontos característico da face pelo  CANDIDE-3 e o método Viola-Jones, utilizado para detectar as faces. Os algoritmos  disponíveis na biblioteca foram implementados em linguagem  C#.   Para desenvolvimento da aplicação, foi utilizada a plataforma de  desenvolvimento Microsoft Visual Studio Express 2012, com sistema operacional  Windows. O Banco de dados escolhido foi o MySQL, no qual se deseja fazer o  armazenamento de todos os padrões obtidos na avaliação. Foi criada a interface gráfica  para manipulação da aplicação e interação entre Aplicação e Usuário através do Sensor  Kinect que resultará na detecção do rosto do indivíduo. Esta aplicação engloba uma  ferramenta que visualiza os dados de malha, exibindo uma representação em 3D do  modelo, ferramenta que identifica 100 pontos característicos do rosto do usuário, que  servirá para identificar/determinar posteriormente em determinado cenário (software a  ser avaliado) o estado emocional de um usuário (ver Figura 2).         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   289        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 286-290 Nov/2015         Figura 2.   Interface  de   Manipulação da Ferramenta    Para a fase de teste da aplicação foi projetado o seguinte cenário: seleção de 20  voluntários com conhecimento básico e avançado em informática; um sensor kinect  para captura das faces; um aplicativo desenvolvido pelo Laboratório de  Desenvolvimento de Sistemas – LADES/UFPA. O usuário terá que cumprir as tarefas  solicitadas no aplicativo (LADES/UFPA) dentro de um prazo previamente estabelecido  pelo avaliador. Como o objetivo do teste é saber o quanto o usuário interage com o  aplicativo, não seriam repassados ao usuário informação sobre como utilizá-lo.    7. Considerações   Os resultados obtidos até o momento são motivadores para a proposta de  desenvolvimento de um método de avaliação dos aspectos afetivos em ambientes  computacionais, tendo como base estudo das áreas de IHC, computação afetiva e  psicologia. Os resultados gerados através da aplicação podem ser usados como métrica  para aperfeiçoamento de qualquer ferramenta, na qual o usuário tem interação direta  com a máquina.   Portanto, para as próximas etapas, que compreendem a aplicação da robustez da  base de dados, utilização do cenário de testes  e análise dos resultados obtidos, o  trabalho servirá para diversos tipos de aplicação, não somente das áreas citadas  anteriormente, mas também das potencialidades que algumas ferramentas podem obter,  como o Sensor Kinect.   Para trabalhos futuros, planeja-se o uso da ferramenta para auxiliar na pesquisa  da afetividade em ambientes computacionais para aprendizagem, junto com  profissionais da psicologia, que farão uso dos dados obtidos. Além de contribuir com  subsídios para as aplicações que são desenvolvidas no LADES/UFPA.   Referências  AHLBERG, J. CANDIDE-3 – an updated parameterized face. Report No. LiTH-ISY R2326, Dept. of Electrical Engineering, Linköping University, Sweden, 2001.   CARDOSO, G. S. Criando aplicações interativas com o Microsoft Kinect. Casa do  Código – São Paulo.2013   EKMAN, P.; FRIESEN, W. V.; HAGER, J. C. Facial Action Coding System:  Investigator’s guide. Research Nexus division of Network Information Research  Corporation, Salt Lake City, Estados Unidos, 2002.   MICROSOFT RESEARCH. Programming Guide: Getting Started with the Kinect for  Windows SDK Beta, 2011. Disponível em <http://research.microsoft.com/en-  us/um/redmond/projects/kinectsdk/docs/ProgrammingGuide_KinectSDK.docx>.  Acesso em: 30.ago.2015.   PICARD, R. W. Affective Computing. Cambridge, EUA: The M.I.T. Press, 1997.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   290        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 286-290 Nov/2015     PIMENTA, M. S. A Importância da Interação Homem-Computador. Departamento de  informática aplicada – Instituto de Informática – Universidade Federal do Rio  Grande do Sul – UFRS, 2006.   PRATES, R. O.; BARBOSA, S. D. J. Avaliação de Interfaces de Usuário – Conceitos e  Métodos. Diponível em   <http://homepages.dcc.ufmg.br/~rprates/ge_vis/cap6_vfinal.pdf > . Acesso em  29.ago.2015.   VIOLA, P.; JONES, M. Robust real-time object detection.Technical report, University  of Cambridge, 2001.   
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   266           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 266-269 Nov/2015     E-Lixo: Soluções para o Futuro   Aline Geovanna Soares1, Everaldo Faustino dos Santos Júnior1, Gilvan Coriolano  Neto1, Francisco José Costa Araújo1   1Escola Politécnica de Perambuco – Universidade de Pernambuco (UPE)  CEP – 50720-001 – Recife – PE - Brasil   www.upe.br  Abstract. The quick technological progress caused the obsolescence of electronic  devices in a short time. Originated from the disposal of electronic devices such as  computers, mobile phones, tablets and others, the electronic waste is a growing  problem in society today. The objective of this article is to present the risks  involved in the management of the electronic waste, ways of recovery of such  material and alternative means of production of these technologies, seeking the  reduction of the environmental and social impact generated by e-waste. The  research is developed based on the analysis of texts about electronic waste,  reverse logistics and green technologies, applied to sustainability.   Resumo. O acelerado avanço tecnológico tem causado a obsolescência dos  equipamentos eletrônicos num curto espaço de tempo. Oriundo do descarte de  aparelhos eletrônicos, como computadores, celulares, tablets e outros, o lixo  eletrônico é um problema cada vez mais aparente na sociedade atual. O objetivo  deste artigo é apresentar os riscos envolvidos na gestão dos resíduos  eletroeletrônicos, formas de recuperação desse material e meios alternativos de  produção dessas tecnologias, visando reduzir o impacto ambiental e social  gerado pelo e-lixo. A pesquisa é desenvolvida com base na análise de textos sobre  lixos eletrônicos, logística reversa e tecnologias verdes, aplicados a   sustentabilidade.   1. Introdução   Com o crescente uso de equipamentos eletrônicos no mundo, o descarte desse  material vem causando sérios danos, tanto ao meio ambiente quanto às pessoas que  manuseiam esses resíduos, estima-se que cerca de 50 milhões de toneladas desse lixo são  descartadas anualmente em todo o mundo.   O lixo eletrônico, também denominado de e-lixo, nada mais é que um conjunto de  artigos eletrônicos que não podem mais serem reaproveitados, como computadores,  celulares, notebook, câmeras digitais, tablets, entre outros. Esse material quando descartado  de modo incorreto pode gerar sérios riscos ao meio ambiente. Este fator se dá devido ao uso  de substâncias químicas presentes nos componentes eletrônicos, como mercúrio, cádmio,  arsênio, cobre, chumbo e alumínio, entre outras, que contaminam o solo e os lençóis  freáticos, além de afetar crianças e adultos que trabalham nos lixões em busca de materiais  que possam ser vendidos.   Algumas alternativas para diminuição e reaproveitamento do e-lixo já estão sendo  desenvolvidas, como as tecnologias verdes que se baseiam na utilização mais eficiente de  energia, recursos e insumos na produção desta, assim como uso de matérias primas e  substâncias menos tóxicas na fabricação. Também temos a logística reversa que aborda as  questões que envolvem a recuperação de produtos ou parte destes, visando reduzir a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   267           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 266-269 Nov/2015     quantidade de lixo produzido e o desenvolvimento econômico e social para uma  determinada região.    2. Metodologia   De acordo com relatórios do programa das nações unidas para o meio ambiente  (Pnuma), o lixo eletrônico representa cerca de 5% de todo o lixo urbano produzido no  mundo e estima-se que a produção desses resíduos cresce 40 milhões de toneladas a cada  ano. Estudos também têm revelado que os compostos que servem de matéria-prima para os  produtos tecnológicos, ao chegarem ao meio ambiente, provocam poluição e destruição de  espécies, além de liberação de gases venenosos na atmosférica. Assim, torna-se relevante  avaliar de que maneira as empresas podem contribuir para a solução do problema da  destinação do lixo tecnológico através da Logística Reversa, e da produção de tecnologias  verdes.    2.1. E-lixo nos Países em Desenvolvimento    Os países em desenvolvimento são o destino de 80% do lixo eletrônico produzido  nas nações ricas, mas carecem da infraestrutura, de tecnologias de reciclagem apropriadas e  da regulamentação legal para absorver essa vasta quantidade de detritos como é o caso de  Gana que foi reportado pelo portal G1. Este lixo, cuja existência foi denunciada pelo  Greenpeace, é composto por celulares, aparelhos de TV, computadores e etc. O greenpeace  também já havia identificado depósitos do mesmo tipo na China, Índia e Nigéria.   Vários dos elementos químicos e metais pesados existentes nos equipamentos  eletrônicos podem ter um efeito extremamente nocivo para o meio ambiente, logo afeta as  diferentes formas de vida, inclusive a humana. O cádmio, por exemplo, se acumula no  fígado, pulmões, pâncreas, testículos, coração e nos rins, onde pode permanecer ativo por  30 anos. A intoxicação crônica pode gerar descalcificação óssea, lesão renal, enfisema  pulmonar, além de má-formação nos fetos.   2.2. Logística Reversa   A logística reversa é “instrumento de desenvolvimento econômico e social  caracterizado por um conjunto de ações, procedimentos e meios destinados a viabilizar a  coleta e a restituição dos resíduos sólidos ao setor empresarial, para reaproveitamento, em  seu ciclo ou em outros ciclos produtivos, ou outra destinação.” A intenção é tornar a  logística reversa uma importante ferramenta para solucionar dois problemas muito  importantes: o problema ambiental e o problema social, pois, diminui a quantidade de  resíduos encaminhados para aterros; estimula o uso eficiente dos recursos naturais; reduz as  obrigações físicas e financeiras dos municípios para com a gestão de determinados  resíduos; desenvolve os processos de reutilização, reciclagem e recuperação de produtos e  materiais; promove processos de produção mais limpa; além de estimular projetos de  capacitação para jovens e adultos que tratam desses resíduos, oferecendo benefícios aos  catadores, traduzidos tanto em termos de saúde física como em maiores ganhos financeiros.    Entre os países emergentes, o Brasil por exemplo, procurando aproveitar esses tipo  de lixo sancionou a política nacional de resíduos sólidos, que tem como objetivo instruir e  tornar obrigatória a destinação correta dos resíduos eletroeletrônicos . Segundo a lei  n°12.305, de 2 de agosto de 2010, devem ser estruturados e implementados sistemas de  logística reversa que viabilizam o retorno de certos tipos de resíduos sólidos ao setor  responsável por sua produção/distribuição para a destinação correta.   Empresas como a Claro, Vivo, Tim, Nokia, Sony Ericsson, possuem pontos de  coleta de telefones celulares, tablets, baterias, acessórios e modens, e para se ter uma  ideia, quase 100% dos componentes dos aparelhos podem ser reciclados.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   268           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 266-269 Nov/2015     2.3. Tecnologia Verde    Outra forma de minimizar o impacto ambiental causado pelo e-lixo é desenvolvendo  as chamadas tecnologias verdes, que se baseiam na utilização mais eficiente de energia,  recursos e insumos na produção dessa tecnologia, assim como uso de matérias primas e  substâncias menos tóxicas na fabricação.   Uma das primeiras iniciativas quanto ao material utilizado na confecção de  notebooks foi tomada pela Asustek Computer, de Taiwan. A empresa apresentou no final  de 2007 o Asus EcoBook, que apresenta bambu em seu revestimento. Segundo a empresa,  o cultivo e a colheita do bambu é menos prejudicial à saúde da Terra que a das madeiras  convencionais, por isso este material foi escolhido. Além disso, o bambu é mais  ecologicamente correto que o couro,  material normalmente utilizado para revestir  notebooks, pois, não se utiliza de nenhuma fonte animal. Hoje em dia é possível encontrar  outros dispositivos como teclados e mouses, também construídos com bambu.    Com todo o sucesso que o aparelho celular da Apple, o iPhone, tem feito, não  demoraria para que uma tecnologia verde para ele fosse desenvolvida. A empresa Solar  Arcadia desenvolveu o Solar Leather Flip for iPhone, uma capa para iPhone que é capaz de  carregar a bateria do telefone utilizando a energia solar. A capa funciona de uma maneira  semelhante a dos paineis solares, sendo que já diretamente transforma em bateria para o  celular, sem a necessidade de grandes aparatos. É uma iniciativa relativamente simples e  muito útil, já que nos dias de hoje quase todas as pessoas possuem celulares que geralmente  precisam ser carregados todos os dias , logo a economia de energia seria expressiva.    De todos os materiais utilizados na fabricação de placas e circuitos eletrônicos,  apenas 2% podem ser reaproveitados, isso significa que os outros 98% estão sendo  acumulados em todo o mundo. O grande motivo é a dificuldade em reaproveitar os  materiais, mas o Laboratório Nacional de Física do Reino Unido desenvolveu um novo  conjunto de polímeros que pode resolver boa parte desse problema. Em conjunto com as  empresas In2Tec e Gwent Electronic Materials, o laboratório britânico criou uma placa de  circuito com os polímeros, desenvolvendo um sistema que consegue liberar os  componentes eletrônicos assim que a placa é imersa em água quente. Com isso, os  componentes podem ser derretidos e remontados para que sejam reutilizados. Os  responsáveis pelo projeto estimam que, caso consigam levar o novo sistema para uma  escala comercial, é possível que a parcela de materiais eletrônicos reciclados chegue aos  90%, o que pode garantir uma redução muito importante na quantidade de lixo eletrônico  existente em todo o planeta.    3. Considerações Finais   Diante de todo o cenário ambiental que presenciamos, é indiscutível a importância  de uma gestão que perceba a importância da sustentabilidade. Acreditamos que a  divulgação destas ideias irá estimular profissionais, empresas e cidadãos envolvidos nos  processos de aquisição, implantação e manutenção dos equipamentos tecnológicos, que  podem incorporar essas e outras práticas em suas decisões de compra e gerência do material  eletrônico, visando sempre os impactos socioambientais. Assim, precisamos compreender  que embora as ações pontuais de proteção ambiental sejam importantes e necessárias,  somente uma revolução na forma de produção e descarte desse material vai permitir  mudanças realmente significativas a médio e longo prazo.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   269           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 266-269 Nov/2015     3. Referências  Daniel Pereira (2014) “Lixo Eletrônico – problemas e soluções”,   http://www.sermelhor.com.br/ecologia/lixo-eletronico-problema-e-solucoes.html,  Setembro.   (2010) “Logística Reversa”, http://www.mma.gov.br/cidades-sustentaveis/residuosperigosos/logistica-reversa, Setembro.   Douglas Ciriaco (2009) “Tecnologia Verde”, http://www.tecmundo.com.br/1588tecnologia-verde.html, Setembro.   Convergência Digital  (2012) “E-lixo ganha projeto durante a Rio+20”,  http://convergenciadigital.uol.com.br/cgi/cgilua.exe/sys/start.htm?infoid=30555&sid=16 #.VB8D8hbC7xw, Setembro.   Carlos R. V. Silva Filho (2010) “Programa ABRELPE de Logística Reversa de Resíduos de  Equipamentos EletroEletrônicos - REEE”,  http://www.cve.saude.sp.gov.br/htm/doma/simposio/LOG%CDSTICA%20REVERSA% 20DE%20RES%CDDUO%20EE-ABRELPE.PDF, Setembro.   (2012) “Reciclagem do lixo eletrônico, o e-lixo, é oportunidade de mercado”,  http://g1.globo.com/economia/pme/noticia/2012/10/reciclagem-de-lixo-eletronico-o-elixo-e-oportunidade-de-mercado.html, Setembro.   Fabio Serconek, Karla Pereira e Will Falcão (2013) “Caso 15: Descarte Correto – Manaus,  AM. Artigos de Negócios Sociais”, http://www.projetobrasil27.com.br/2013/10/artigosnegocios-sociais-caso-15/, Setembro.   (2013) “Países pobres são destino de 'de 80% do lixo eletrônico de nações ricas'”,  http://www.bbc.co.uk/portuguese/noticias/2013/01/130118_lixo_eletronico_bg.shtml,  Setembro.   (2013) “ONU lança primeiro mapa global de lixo eletrônico”,  http://exame.abril.com.br/mundo/noticias/onu-lanca-primeiro-mapa-global-de-lixoeletronico/, Setembro.   Felipe Andueza (2010) “ONU: Brasil tem maior produção per capita de lixo eletrônico e  baixa prioridade da indústria e governos”, lixoeletronico.org/blog/onu-brasil-tem-maiorproducao-capita-de-lixo-eletronico-e-baixa-prioridade-da-industria-e-gover, Setembro.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   262           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 262-265 Nov/2015     Ensino de Lógica de Programação Associada à Linguagem  LOGO   Lucas Pacheco Silveira1, Andriel Paz Reis1, Gustavo Rissetti1, Eliana Zen1, Ruan C. B.  Pozzebon1   1Instituto Federal Farroupilha – Campus São Vicente do Sul – (IFFarroupiha)  Rua 20 de Setembro, S/N - CEP 97420-000 - São Vicente do Sul - RS.   lucaspsilveira@live.com, andrielreis@hotmail.com, {gustavo.rissetti,  eliana.zen, ruan.pozzebon}@iffarroupilha.edu.br   Abstract. In the initial semesters of computer science courses, students are faced  with a thinking logically way, unlike what usually happens in our day-to-day. This  can hinder the understanding and development of programming disciplines, and  may lead to the abandonment of the course. For the best performance of the  students in these disciplines, this work analyzes the initial use of LOGO language,  which may help the understanding of logical thinking and programming, through  drawings of geometric shapes through a "turtle" programmed by computer. From  this, the student is able to go to high-level languages more easily.   Resumo. Nos semestres iniciais dos cursos da área de informática, os estudantes  se deparam com um modo de pensar de forma lógica, diferente do que acontece  normalmente em nosso dia-a-dia. Isso pode dificultar na compreensão e  desenvolvimento das disciplinas de programação, podendo ocasionar a  desistência do curso. Para um melhor rendimento dos alunos nessas disciplinas,  neste trabalho, analisa-se a utilização inicial da linguagem LOGO, que pode  auxiliar o entendimento do pensamento lógico e da programação, através de  desenhos de formas geométricas via uma “tartaruga” programada pelo  computador. A partir disso, o aluno tem condições de partir para linguagens de  alto nível com maior facilidade.   1. Introdução  Nos semestres iniciais dos cursos na área de informática, algumas das disciplinas ofertadas  servem para auxiliar os alunos a se adaptarem com o pensamento lógico apresentado nos  sistemas computacionais. Esta “nova” forma lógica de pensar demonstrada aos alunos é  diferente da forma a qual eles estão acostumados em sua rotina diária. Na área de  computação as decisões têm que ser pensadas e planejadas antecipadamente, para que seja  possível prever quaisquer possíveis resultados de cada ação, para então tomar a decisão  correta e assim resolver o problema.   As disciplinas apresentadas no início do curso algumas vezes não são suficientes  para a compreensão da lógica envolvida e da forma de pensamento nessa área,  ocasionando, muitas vezes, a desistência ou evasão do curso, por falta de motivação e pela  não compreensão do que está sendo estudado em sala de aula.    Tendo isso em vista, este trabalho propõe a utilização de uma metodologia de  ensino para tais alunos através da linguagem de programação LOGO. O conhecimento  desta linguagem de programação pode auxiliar os alunos a compreenderem a forma lógica  de pensamento, através de uma alternativa lúdica de aprendizagem, para então,  compreender os conceitos básicos sobre programação.   A Linguagem LOGO pode ser utilizada como um objeto de aprendizagem, visto que  é uma linguagem de programação de fácil entendimento e possui os mesmos conceitos  lógicos de uma outra linguagem mais complexa, podendo então, auxiliar os alunos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   263           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 262-265 Nov/2015     iniciantes na área de computação a entenderem de uma forma mais prática e básica os  novos conceitos a serem abordados no curso.   O restante do artigo está organizado da seguinte forma. A Seção 2 aborda conceitos  relacionados a aprendizagem de programação e a utilização da Linguagem de Programação  LOGO. Na Seção 3, mostra-se a metodologia utilizada para a aplicação do projeto do qual  este trabalho é oriundo. Já, nas Seções 4 e 5, são apresentados os resultados parciais e as  considerações finais obtidas no desenvolvimento deste trabalho.   2. Aprendizagem de Programação e a Linguagem LOGO  Normalmente, nas disciplinas de algoritmos e programação, os estudantes escutam que  existem diversas formas de resolver um mesmo problema, bastando-se pensar e elaborar  um algoritmo para a solução. Porém, a dificuldade para os calouros está justamente na  ordenação de ideias para a montagem de tal algoritmo.   Existem diversas formas de se escrever um programa, assim como existem várias  linguagens com que esse programa pode ser compilado, mas o que nunca muda é a forma  lógica de se pensar o programa em questão. Assim, com este trabalho, visa-se auxiliar  estudantes do nível básico que pretendem ingressar em um curso superior de informática,  tendo em vista que a falta de pensamento lógico usado na programação é uma das maiores  dificuldades que os alunos ligados a esses cursos enfrentam durante o decorrer da  formação. E para isso, propõem-se o uso de uma metodologia através da linguagem de  programação LOGO, descrita na Seção 2.1.  2.1 A Linguagem LOGO  A linguagem de programação LOGO foi desenvolvida no MIT (Massachusetts Institute of  Technology), na década de 1960, por Seymour Papert [MERCADO 2002]. É uma  linguagem de forma interpretada, ou seja, não é utilizado um compilador para transformar o  código-fonte em código objeto para a posterior execução.   A proposta inicial da linguagem era de colocar crianças para comandar um robô ou  uma representação de robô. Um dos primeiros robôs criados para utilizar a linguagem  LOGO lembrava uma tartaruga, desde então a tartaruga passou a ser o ícone da linguagem,  como pode ser observado em alguns dos ambientes destinados ao uso dessa linguagem ou  derivados, como por exemplo o software interpretador da linguagem KTurtle e o software  SuperLogo [KTURTLE 2015; SUPERLOGO 2000].   A linguagem LOGO apresenta diversas características fundamentais para a  compreensão e aprimoramento do raciocínio lógico. Dentre elas, podem-se citar:  exploração de atividades espaciais, fácil terminologia e capacidade de criar novos termos  ou procedimentos [VALENTE 1998].  Através disso, o computador passa a ser usado  como uma alternativa lúdica para os alunos realizarem diversas tarefas, tais como criar  desenhos simples e complexos, através de comandos da linguagem, movimentando o cursor  (a tartaruga) na tela, ou até mesmo comandar um robô que interpreta comandos dessa  mesma linguagem. A linguagem LOGO é composta por comandos chamados de primitivos,  que são os comandos base para começar a aprender a mexer com a tartaruga. Estes  comandos são: parafrente (pf), paratras (pt), paradireita (pd), paraesquerda (pe), entre  outros, como mostra a Figura 1, com um exemplo simples de um desenho de uma casinha  através de comandos da linguagem.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   264           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 262-265 Nov/2015       Figura 11. Comandos Primitivos da Linguagem LOGO    Como pode ser visto no exemplo apresentado na Figura 1, tem-se de “ensinar” a  tartaruga a se movimentar para realizar os desenhos desejados. E é nesse sentido que ao  “ensinar” a tartaruga, o aluno compreende e desenvolve a lógica. Conforme Ripper (1993),  o ato de “ensinar” a tartaruga requer uma nomeação de comandos, que proporciona um  movimento entre rigidez e flexibilidade, na medida que o aluno pode nomear um  procedimento de qualquer forma, mas posteriormente deve obedecer os princípios da  programação, tendo de utilizar e escrever corretamente sempre o mesmo nome a partir do  momento que nomeou algo e quiser utilizá-lo novamente.   3. Metodologia Adotada para a Aplicação do Projeto   Para esta iniciativa de ensinar a lógica de programação aos calouros nos cursos de  computação é utilizada a linguagem LOGO, através do objeto de aprendizagem SuperLogo  3.0 [SUPERLOGO 2000]. Este objeto, totalmente em português, permite a utilização  completa da linguagem, permitindo de forma prática o ensino e observação do rendimento  dos alunos através de desafios.    As aulas para aprendizagem do conteúdo estão sendo realizadas nos laboratórios de  informática do campus, atendendo aos alunos das três séries do curso Técnico de  Manutenção e Suporte em Informática. A organização das aulas consiste em uma aula para  ensinar o conteúdo novo e propor desafios, e a outra para esclarecer as dúvidas dos alunos.    As atividades propostas têm como objetivo relembrar as formas geométricas, pois  são exercícios que possibilitam o conhecimento da linguagem LOGO, uma vez que os  alunos conseguem ver e entender o que está aparecendo na tela do computador enquanto  são digitados os comandos. Assim, alunos são instigados a pensar e elaborar procedimentos  para a realização de atividades específicas, assemelhando-se à funções vistas em linguagens  de programação de alto nível, facilitando assim, a compreensão da lógica envolvida na  programação de computadores. Além disso, os alunos realizam alguns desafios de  programação disponibilizados no portal Projeto Logo [LOGO 2009], para aprimorar o  raciocínio e também auxiliar na avaliação do andamento do projeto.   Para fins de avaliações são feitas várias atividades que utilizam todo o conteúdo  aprendido sobre a linguagem de programação LOGO. A realização de formas geométricas  através da linguagem e desenhos gráficos mais complexos, com o uso de sub-rotinas e  funções, demonstram como o aluno está progredindo.  A proposta de desafios para o  estímulo dos alunos e para avaliar o andamento das aulas é feito a cada duas aulas, quando  é apresentado o conteúdo novo para os participantes.   4. Resultados Parciais  Os alunos têm demonstrado grande facilidade de aprendizagem e demostrado grande  interesse na continuidade e aprimoramento nos conhecimentos de programação. Notou-se  um desenvolvimento lógico e matemático após o início das aulas, o que com o passar do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   265           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 262-265 Nov/2015     tempo tende a melhorar. Diversas dúvidas foram sanadas, e a capacidade de raciocínio e  lógica de programação dos participantes têm se mostrado em elevação, o que corresponde  ao que pode ser observado na literatura [PAPERT 1988].    A linguagem de programação LOGO é considerada uma linguagem de alfabetização  da informática, pois ela ajuda a criar um raciocínio lógico que os alunos ainda não possuem  quando começam a trabalhar com as máquinas. Com isso, essa linguagem ajuda os  estudantes a organizar suas ideias, para que eles consigam planejar e assim solucionar os  problemas propostos [LOGO 2009].   5. Considerações Finais  Este trabalho propõe uma alternativa lúdica de aprendizagem de conceitos relacionados à  programação, e vem se mostrando satisfatório, na medida em que os participantes têm  demonstrado um maior entendimento e evolução na lógica de programação, o que poderá  facilitar a interação com linguagens de alto nível, utilizadas no último ano do curso, na  disciplina de Robótica.    Como trabalho futuro, pretende-se dar continuidade ao projeto com a proposta de os  alunos construírem e programarem seu próprio robô (ArduLOGO) que interpretará a  linguagem LOGO, cujo protótipo já foi construído e encontra-se funcional.   Referências  VALENTE, J. A. (1998) (Org.) Computadores e conhecimento: repensando a educação.   2.ed. Campinas, SP: UNICAMP/NIED.   RIPPER, A. V. (1993) O ambiente LOGO como mediação instrumental. Em Aberto, ano  12, n. 57, p. 51-61, jan/mar Brasília.   SUPERLOGO (2000), Ambiente para Porgramação em Linguagem LOGO – SuperLogo  3.0. Disponível em http://www.nied.unicamp.br/?q=content/super-logo-30. Acesso em:  agosto de 2015.   LOGO (2009) Projeto Logo. Disponível em <http://projetologo.webs.com/logo.html>.  Acesso em: março de 2015.    MERCADO, L. (2002), Novas Tecnologias na Educação: reflexões sobre a prática.  Maceió: EDUFAL.   KTURTLE (2015). Ambiente para Programação em linguagem LOGO - KTurtle.  Disponível em: https://edu.kde.org/kturtle/. Acesso em: agosto de 2015.   PAPERT, S. (1988) LOGO: Computadores e Educação. Tradução de José Armando  Valente. 3a ed. São Paulo: Editora Brasiliense, 1988.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   250           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 250-253 Nov/2015     Ferramenta para Apoio ao Suporte Técnico em uma Rede  FTTx empregando Raciocínio Baseado em Casos   Ricardo Augusto Ferrari1, Sidnei Renato Silveira2, Edison Pignaton de Freitas3   1Curso de Bacharelado em Sistemas de Informação, 2Departamento de Tecnologia da  Informação – UFSM – Universidade Federal de Santa Maria - CESNORS (Centro de   Educação Superior do Norte do RS) Frederico Westphalen – RS   3Instituto de Informática – UFRGS – Universidade Federal do Rio Grande do Sul  ricardo_ferrari01@hotmail.com, sidneirenato.silveira@gmail.com,   edison.p.freitas@ufsm.br Resumo: Este artigo propõe o desenvolvimento de uma ferramenta capaz de  armazenar informações sobre os equipamentos existentes em um provedor de  acesso à Internet, que utiliza a tecnologia de rede FTTx. A partir destas  informações, pretende-se gerar relatórios e, com a utilização de técnicas de RBC  (Raciocínio Baseado em Casos), auxiliar os profissionais que prestam suporte  técnico na identificação e/ou correção de problemas.     Abstract: This paper proposes a development of a tool able to store information  about the hardware within an Internet Service Provider, which uses FTTx  network technology. Afterward this information, is intended to generate reports  and, with the use of CBR techniques (Case-Based Reasoning), help professionals  whose provides technical support, identify and/ or correcting problems.   1. Introdução  Este artigo apresenta o desenvolvimento de um protótipo de ferramenta (para ser aplicada  em um provedor de acesso à Internet que utiliza a tecnologia de rede FTTx11- Fiber to the  x) que permita realizar a documentação dos equipamentos ópticos presentes na rede, desde  a central até o cliente, além de auxiliar os técnicos, por meio de técnicas de RBC  (Raciocínio Baseado em Casos) a solucionar problemas nesta rede. O provedor de acesso à  Internet utiliza, atualmente, um sistema que permite documentar a rede óptica (FTTx),  porém não permite cadastrar determinadas informações (essas informações acabam sendo  cadastradas em planilhas eletrônicas) mais detalhadas que seriam necessárias para efetuar  relatórios específicos desejados, os relatórios gerados pelo sistema não são os desejados  com detalhes.   A rede de fibra óptica (FTTx) neste provedor de acesso à Internet, localizado na  região de Frederico Westphalen – RS, foi implementada há mais ou menos 3 anos. Muitos  dos técnicos que trabalham com essa tecnologia não possuem um conhecimento  aprofundado (teórico e prático); alguns possuem conhecimentos de áreas diferentes, tais  como: técnico de instalação, suporte técnico, Call Center e gerência de redes de  computadores. Isto dificulta a correção de problemas em determinadas situações, seja por  falta de experiência ou conhecimento. Para resolver estes problemas diários, sejam eles de  baixa, média ou alta complexidade, o auxílio de uma ferramenta aplicando técnicas de RBC                                                    11FTTx é o nome genérico para a implantação de cabo de fibra óptica até (ou proximidade de) um local  específico, em direção às instalações do cliente. Utiliza-se o "x" para descrever o local onde termina a fibra  (CARVALHO, 2009, p.32).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   251           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 250-253 Nov/2015     agilizará a solução de problemas, diminuindo o tempo de serviço para resolver a maior  parte dos erros detectados.    Acredita-se que a implementação desse protótipo de ferramenta irá beneficiar a  empresa, permitindo que informações sejam centralizadas e que os relatórios detalhados  necessários sejam gerados, permitindo a correção de erros com mais precisão e agilidade.   2. Referencial Teórico  De acordo com Lagemann (1998, apud FERNANDES, 2005, p.28): “A origem do  Raciocínio Baseado em Casos data de 1977, devido a uma pesquisa na área da ciência  cognitiva, desenvolvida por Schank e Abelson. O desenvolvimento do RBC foi estimulado  pelo desejo de compreender como as pessoas conseguem recuperar informações e que elas,  frequentemente, resolvem problemas lembrando de como solucionaram casos similares no  passado”. Em síntese, o RBC é um instrumento de raciocínio da Inteligência Artificial (IA),  que tem como finalidade buscar a solução de um problema através da adaptação de uma  experiência passada parecida (BARONE, 2003).    O modelo mais aceito para o processo RBC é o Ciclo de RBC proposto por  Aamondt e Plaza (1994, apud WANGENHEIM; WANGENHEIM, 2003), que engloba um  ciclo de raciocínio contínuo composto por quatro tarefas principais (como mostra a Figura  1):     Figura 1. Ciclo do Raciocínio Baseado em Casos    (adaptado de WANGENHEIM; WANGENHEIM, 2003).     Segundo Lorenzi & Silveira (2011) os métodos mais conhecidos para recuperação   de casos, são o vizinho mais próximo, o método de recuperação indutivo e a recuperação  baseada em conhecimento. O método que será utilizado no desenvolvimento do trabalho  será o do vizinho mais próximo, que combina casos recuperados com base no somatório de  pesos das características do novo problema. Os casos com maior similaridade são  retornados do processo de comparação.   Uma Rede Óptica Passiva (PON - Passive Optical Network) é uma rede de acesso  interligada por fibra óptica, por meio de uma topologia ponto-multiponto, composta  somente de componentes ópticos passivos (não necessitam de energia elétrica para seu  funcionamento) entre a central e os equipamentos do cliente (TAKEUTI, 2005).   Existem diferentes tecnologias e padrões de PONs. Os principais são: BPON  (Broadband PON), EPON (Ethernet PON), GPON (Gigabit PON) (BRILLANT, 2008;  FRENZEL Júnior, 2013; KEISER, 2014). As redes Ópticas Passivas que serão utilizadas  para a realização deste trabalho são as EPON e GPON.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   252           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 250-253 Nov/2015      Carvalho (2009, p.32) aborda que “FTTx é o nome genérico para a implantação de  cabo de fibra óptica até (ou próximo de) um local específico, em direção às instalações do  cliente. Utiliza-se o "x" para descrever o local onde termina a fibra”.   Takeuti (2005) cita algumas arquiteturas que fazem parte da tecnologia FTTx,  como: FTTCab (Fiber-to-the-Cabinet), FTTC (Fiber-to-the-Curb), FTTB (Fiber-to-theBuilding), FTTH (Fiber-to-the-Home). As tecnologias FTTH e FTTB serão utilizadas para  a realização deste trabalho, pois são as empregadas no provedor de acesso à Internet que  servirá como estudo de caso.   3. Metodologia Proposta  Este trabalho visa atender uma necessidade de um provedor de acesso à Internet, de  Frederico Westphalen – RS, permitindo uma centralização e melhor documentação da rede  FTTx. Pretende-se implementar um protótipo de ferramenta capaz de gerar relatórios a  partir das informações armazenadas, além de auxiliar os técnicos nas soluções e/ou  detecções de problemas dessa rede, de forma mais precisa e ágil, com o emprego de  técnicas de RBC.   Por meio de conversas informais, com os profissionais de diferentes departamentos  (administração de redes, call center, infraestrutura, suporte e instalação) definiu-se que os  casos (problemas que ocorrem nos equipamentos da rede FTTx) serão armazenados em um  banco de dados, contendo tabelas para armazenar o problema, suas diferentes  características (com valores possíveis e pesos) e soluções propostas.   Desta forma, o sistema proposto, por meio de uma interface web, será capaz de  efetuar consultas e gerar relatórios com os dados cadastrados dos equipamentos ópticos  presentes na rede FTTx (entre a central e o equipamento óptico do cliente), suas  interligações e os clientes da rede óptica FTTx. Por meio da utilização de técnicas de RBC  (Raciocínio Baseado em Casos), será implementada uma ferramenta que seja capaz de  auxiliar os profissionais que prestam suporte técnico na identificação e/ou correção de  problemas presentes na rede FTTx deste provedor de acesso à Internet.    A ferramenta proposta será implementada utilizando-se a linguagem de  programação PHP e o Sistema Gerenciador de Banco de Dados (SGBD) MySql. O SGBD  MySql foi escolhido por tratar-se de um software livre muito conhecido e utilizado na  Internet em aplicações web. Existem muitos serviços de hospedagem de sites que suportam  o MySql e a linguagem de programação PHP, devido ambos funcionarem de forma  adequada em conjunto. O Mysql possui uma grande disponibilidade para quase todos os  sistemas operacionais, tais como Linux, FreeBSD e outros sistemas baseados em Unix;  Windows e Mac OS X), baixa exigência de processamento e também possui vários sistemas  de armazenamento de dados (ALECRIM, 2006).    Após o desenvolvimento do protótipo proposto será realizada uma série de testes  com todas as funcionalidades propostas pela ferramenta, com os profissionais dos  departamentos de administração de redes e call center, pois esses departamentos trabalham  internamente dentro do provedor e fazem interação direta ou indiretamente com os clientes  e os profissionais que trabalham na rede FTTx no ambiente externo, ajudando a realizar  atividades diárias e auxiliando-os na detecção de problemas e na solução dos mesmos, que  dizem respeito à rede FTTx.           Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   253           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 250-253 Nov/2015     Referências  ALECRIM, E. (2006) Banco de dados MySQL e PostgreSQL. Disponível em:   <http://www.infowester.com/postgremysql.php> Acesso em: 08 de junho, 2015.   BARONE, D. A. C. (Org). (2003) Sociedades Artificiais: A Nova Fronteira da Inteligência  nas Máquinas. Porto Alegre: Bookman.   BRILLANT, A. (2008) Digital and analog fiber optic communications for CATV and  FTTx applications. SPIE Press. Disponível em: <  https://books.google.com.br/books?id=UUQiPAlWpTMC&printsec=frontcover&hl=ptBR&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false >Acesso em: 25 de  maio, 2015.    CARVALHO, I. P. M. S. (2009) Estudo e Implementação de Mecanismos Multicast em  Cenários FTTH/GPON. Dissertação (Mestrado) - Curso de Mestrado em Electrónica e  Telecomunicações, Departamento de Electrónica, Telecomunicações e Informática,  Universidade de Aveiro, Aveiro.   FERNANDES, A. M. R. (2005) Inteligência Artificial: Noções Gerais. Florianópolis:  Visualbooks.   FRENZEL Júnior, L E. (2013) Fundamentos de Comunicação Eletrônica: Linhas, Microondas e Antenas. 3. ed. V. 2. Porto Alegre: AMGH.    KEISER, G. (2014) Comunicações por Fibras Ópticas. 4. ed. Porto Alegre: AMGH    LORENZI, F.; SILVEIRA, S. R. (2011) Desenvolvimento de Sistemas de Informação  Inteligentes. Porto Alegre: UniRitter.   TAKEUTI, P. (2005) Projeto e Dimensionamento de Redes Ópticas Passivas (PONs).  Dissertação (Mestrado) - Curso de Engenharia Elétrica, Escola de Engenharia de São  Carlos da Universidade de São Paulo, São Carlos.   WANGENHEIM, C. G.; WANGENHEIM, A. (2003) Raciocínio Baseado em  Casos. Barueri: Manole.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   254           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 254-257 Nov/2015     IATE – Inteligência Artificial e Tecnologia Educacional     Fábio José Parreira, Sidnei Renato Silveira, Maik Basso, Silvana Kliszcz, Adriana  Sadowski de Souza     Universidade Federal de Santa Maria (UFSM) - Centro de Educação Superior Norte   (CESNORS) - Caixa Postal 54 - Frederico Westphalen - RS - Brasil  Departamento de Tecnologia da Informação – Curso de Bacharelado em Sistemas de   Informação  fabiojparreira@gmail.com. sidneirenato.silveira@gmail.com, maik@maikbasso.com.br,   silvana@websetbrasil.com.br, adrianasadowski@gmail.com      Resumo. Este artigo apresenta as atividades que estão sendo desenvolvidas pelo  grupo de pesquisa IATE – Inteligência Artificial e Tecnologia Educacional da  UFSM/Frederico Westphalen. Este grupo tem atuado no estudo e desenvolvimento  de objetos de aprendizagem e jogos educacionais digitais, bem como na aplicação  de técnicas de IA neste contexto.   Abstract. This paper presents the activities being developed by the research group  IATE - Artificial Intelligence and Educational Technology of UFSM/Frederico  Westphalen. This group has been active in the study and development of learning  objects and digital educational games, and the implementation of AI techniques in  this context.   1. Introdução   Na UFSM/Frederico Westphalen existe um grupo de pesquisa denominado IATE-UFSM –  Inteligência Artificial e Tecnologia Educacional. As linhas de pesquisa deste grupo  abrangem: Ambientes Virtuais de Aprendizagem, Inteligência Artificial aplicada à  Educação, Objetos de Aprendizagem e Tecnologia Educacional. Neste contexto, os  integrantes deste grupo vêm desenvolvendo pesquisas nas áreas de EaD (Educação a  Distância), Jogos Educacionais Digitais, Objetos de Aprendizagem e Inteligência Artificial  aplicada à Educação, entre outros temas. Estas pesquisas constituem projetos docentes, tais  como: Estudo e Aplicação de Técnicas de Inteligência Artificial aplicadas à Construção de  Jogos Educacionais Abertos; Objetos de Aprendizagem Hipermidiáticos na Mediação  Pedagógica da Disciplina de Linguagem de Programação Comercial para a Modalidade bLearning; Arquitetura para Adaptação de Cursos na Modalidade de Educação a Distância  empregando Objetos de Aprendizagem.   Além destes projetos de pesquisa, alguns alunos do Curso de Bacharelado em  Sistemas de Informação têm desenvolvido seus projetos de conclusão, na disciplina de  TGSI (Trabalho de Graduação em Sistemas de Informação), em temáticas ligadas ao IATE,  tais como: Desenvolvimento de um Jogo Educacional Digital para Auxílio à Alfabetização  utilizando Redes Neurais e Jogo Educacional Digital para Apoio ao Aprendizado de  Matemática.   Estes projetos de pesquisa e de TGSI, bem como a criação do Curso de Licenciatura  em Computação na modalidade a distância, demonstram a força destas áreas de pesquisa no  campus da UFSM de Frederico Westphalen. Aliada a esta força, tem-se a experiência dos  integrantes do grupo de pesquisa na produção científica e desenvolvimento de projetos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   255           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 254-257 Nov/2015     nesta área. Neste contexto, este artigo apresenta alguns trabalhos que estão sendo  desenvolvidos por este grupo de pesquisa.   2. Referencial Teórico   A construção de jogos educacionais digitais envolve a aplicação de recursos multimídia,  tais como imagens, animações, vídeos e sons. Além disso, um jogo educacional digital é  um recurso que pode ser empregado em atividades voltadas à EaD (Educação a Distância),  podendo ser classificado como um OA (Objeto de Aprendizagem, ou Objeto Educacional).   O conceito de objetos de aprendizagem tem sofrido alterações. A partir das definições  técnicas vinculadas ao seu uso na área educacional, pode-se dizer que objetos de  aprendizagem são unidades formadas por um conteúdo didático como: um vídeo; uma  animação; um texto; uma gravação ou uma imagem, ou seja, objetos de aprendizagem são  unidades de aprendizagem formadas por um conteúdo didático que, agregada a outras,  formam um novo objeto (FALKEMBACH, 2005).    Os jogos educacionais baseiam-se no interesse que as crianças  têm em brincar e jogar e, aproveitando-se disso, criam ambientes de  aprendizagem atraentes e gratificantes, constituindo-se em um recurso  poderoso de estímulo para o desenvolvimento integral do aluno. Os  jogos desenvolvem a atenção, disciplina, autocontrole, respeito a  regras e habilidades perceptivas e motoras relativas a cada tipo de jogo  oferecido. Podem ser jogados de forma individual ou coletiva, sempre  com a presença do educador para estimular todo o processo, observar e  avaliar o nível de desenvolvimento dos alunos, diagnosticando as  dificuldades individuais, para produzir estímulos adequados a cada um  (SILVEIRA et. al., 2012).   Os jogos educacionais digitais são elaborados para divertir os  alunos e aumentar a chance na aprendizagem de conceitos, conteúdos e  habilidades embutidas no jogo. Um jogo educacional digital pode  propiciar ao aluno um ambiente de aprendizagem rico e complexo.  Alguns pesquisadores denominam estes jogos de “micromundos”,  porque fornecem um mundo imaginário a ser explorado e no qual os  alunos podem aprender.   A utilização de técnicas de IA no desenvolvimento de jogos digitais está se tornando  cada vez mais comum, devido ao aumento da complexidade dos jogos e de seus recursos  cada vez mais bem elaborados e realistas. A aplicação dessas técnicas e/ou algoritmos em  jogos pode ser dividida em três grandes blocos relacionados com a sua respectiva área de  atuação, sendo: movimento, tomada de decisão e estratégia de jogo (MILLINGTON;  FUNGE, 2009).   3. Projetos em Desenvolvimento   3.1 Desenvolvimento de um Jogo Educacional Digital para Auxílio à Alfabetização  utilizando Redes Neurais   Este jogo tem o intuito de auxiliar alunos do ensino fundamental, com idade entre cinco e  sete anos, no seu processo de alfabetização. O projeto se trata do desenvolvimento de um  jogo educacional digital que será codificado utilizando tecnologias web tais como HTML5  (HyperText Markup Language), CSS3 (Cascading Style Sheets) e Javascript. O jogo irá     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   256           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 254-257 Nov/2015     dispor de algumas fases para que a criança possa aprender a escrever e identificar  corretamente as vogais do alfabeto.   No decorrer do jogo, Zag (personagem criado para o jogo) acompanhará o aluno por  três níveis diferentes, distribuídos em diversas fases. No primeiro nível de jogo, o aluno  deverá ajudar Zag a encontrar todas as vogais do alfabeto, fazendo a associação correta das  mesmas com figuras do cenário do jogo; por exemplo, encontrar a igreja, que representa a  vogal “I” no cenário do jogo. Já no segundo nível, Zag continua a avançar em seu caminho  e o aluno terá de aprender a escrever todas as vogais em letra de “forma”, escrevendo em  seu dispositivo (computador, tablet ou smartphone) em um quadro branco, seguindo os  pontilhados das letras apresentadas.     No último nível do jogo Zag estará próximo de alcançar o seu objetivo, que é o de  chegar ao aeroporto antes de perder o horário de seu avião. Neste nível o aluno passa por  algumas fases onde terá de escrever as vogais do alfabeto no quadro branco, porém agora  sem o auxílio de pontilhados, aumentando consideravelmente o nível de dificuldade do  mesmo. Neste nível as respostas serão validadas por uma Rede Neural Artificial (RNA),  que irá fazer a comparação dos dados de treinamento, que são as respostas desejadas para  as fases, com a resposta do jogador, definindo se a resposta do jogador está certa ou errada.  O importante a ressaltar nesta etapa é que, a base treinamento que estará disponível para a  fase de teste da RNA já se encontra armazenada no protótipo, não necessitando o  treinamento a cada execução. Além disso, os dados contidos nesta base serão obtidos por  meio de tentativa e erro, onde o conjunto de dados que se mostrar mais relevante perante os  resultados desejados, será utilizado para compor a base de treinamento.  A figura 1  apresenta o protótipo de interface do jogo proposto.      Figura 1: Interface do Jogo (Fonte: dos autores)      3.2 Jogo Educacional Digital para Apoio ao Aprendizado de Matemática   Vários são os conteúdos matemáticos trabalhados pelos professores em sala de aula nos  anos iniciais do ensino fundamental. Entretanto, as operações básicas de matemática  (adição, multiplicação, divisão e subtração) estão presentes em todos os currículos  escolares no ensino básico, fundamental e médio. Neste contexto, definiu-se este conteúdo  para ser aplicado no jogo proposto. A proposta do jogo educacional digital“Vamo$ às  Compras?” não é somente oferecer ao professor uma ferramenta pedagógica de ensino, por     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   257           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 254-257 Nov/2015     meio de um dispositivo tecnológico para estimular a aprendizagem dos alunos no conteúdo  trabalhado em sala de aula mas, acima de tudo, propiciar um ambiente lúdico, por meio de  uma interface gráfica, seguindo as características imprescindíveis para um jogo ser  divertido e agradável. O conteúdo matemático que será trabalhado no jogo envolverá  cenários nos quais as crianças convivem e frequentam diariamente, sendo estes: mercados,  padarias, lojas de roupas, eletrônicos, sorveterias, livrarias e parques de diversão, entre  outros, utilizando-se, como metáfora, as compras que podem ser realizadas nestes cenários.  A Figura 2 apresenta um dos ambientes propostos para o jogo, o ambiente de um  supermercado.     Figura 2: Layout da disponibilidade dos produtos na prateleira do mercado   (Fonte: Dos autores)   3.3 Outras Atividades   Além dos projetos apresentados, o grupo de pesquisa está envolvido na elaboração de um  livro sobre o desenvolvimento de jogos educacionais digitais e objetos de aprendizagem,  aplicando diferentes tecnologias, tais como HTML 5, CSS, JavaScript, Flash e Ardora  (MATANZA, 2015).   Referências  FALKEMBACH, G. A. M. (2005) Concepção e desenvolvimento de material educativo   digital. Revista Novas Tecnologias na Educação,  v. 3, n.1.    MATANZA, J. M. B. (2015) Ardora. Disponível em: <http://webardora.net>. Acesso em  setembro de 2015.   MILLINGTON, I.; FUNGE, J. (2009) Artificial Intelligence for Games. 2. ed. Burlington,  USA: Morgan Kaufman.   SILVEIRA, S. R.; RANGEL, A. C. S.; CIRÍACO, E. L. (2012) Utilização de jogos digitais  para o desenvolvimento do raciocínio lógico-matemático. Canoas: Tear: Revista de  Educação Ciência e Tecnologia. Disponível em:  <seer.canoas.ifrs.edu.br/seer/index.php/tear/article/download/3/3>. Acesso em: 09 de  abril de 2015.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   278        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 278-281 Nov/2015     Implantação de um Sistema Web para a Catalogação e  Comercialização de Produtos da Agroindústria Familiar       Caroline Piovesan de Moraes ¹,Vitor Hugo Lopes ¹, Joel da Silva², Arlindo Jesus  Prestes de Lima²,  José Eduardo Gubert ², Eliseu Liberalesso³   ¹Universidade Federal de Santa Maria (UFSM) – Colégio Agrícola de Frederico  Westphalen (CAFW) – Frederico Westphalen, RS    ²Instituto Federal de Educação, Ciência e Tecnologia Farroupilha - Campus Frederico  Westphalen   ³Agência de Desenvolvimento do Médio Alto Uruguai (AMDAU)  caroline.pm@outlook.com, vtrhugolopes@gmail.com,   joel.dasilva@iffarroupilha.edu.br   Abstract. The diagnostics and development plans of APL (Local Productive  Arrangements) of the Family Agribusiness and Food indicate the difficulties  associated to the process of marketing the products of family farming as one  of the main bottlenecks in the development of APLs. In this sense, this article  proposes an information system able to meet the business rules of trade  centers which greatly benefit the process of marketing the products of family  farming.   Resumo. Os diagnósticos e planos de desenvolvimento dos APLs (Arranjos  Produtivos Locais) da Agroindústria Familiar e Alimentos indicam as  dificuldades relacionadas ao processo de comercialização dos produtos da  agricultura familiar como um dos principais estrangulamentos do  desenvolvimento dos APLs. Neste sentido, este artigo propõe  um sistema de  informação capaz de atender as regras de negócio das centrais de  comercialização que beneficiaria consideravelmente o processo de  comercialização dos produtos da agricultura familiar.   Introdução   No Brasil, o processo de desenvolvimento da agricultura e do meio rural, embora  tenha ampliado a produção de alimentos e a acumulação de capital, vem diminuindo as  possibilidades de reprodução e inserção socioeconômica de uma parcela significativa  dos agricultores familiares.   Em consequência, na maioria dos municípios de economia baseada na  agropecuária, este tipo de desenvolvimento tem contribuído para intensificar o êxodo  rural e o desemprego, assim como para diminuir os orçamentos públicos e enfraquecer  as economias locais (Flach e Marchioro, 2002).   Neste contexto e a partir de intenso debate, a desconcentração agroindustrial,  especialmente a agroindustrialização familiar de pequeno porte, vêm sendo proposta     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   279        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 278-281 Nov/2015     como uma estratégia para ampliar as possibilidades de reprodução socioeconômica na  agricultura familiar e promoção do desenvolvimento local.    Conforme Wilkinson (1996 e 2000), com a crescente integração do sistema  agroalimentar no mercado internacional, o desenvolvimento da agricultura familiar  depende de várias alternativas, e nesse sentido existem novas oportunidades de mercado  que poderiam ser aproveitadas pelos agricultores familiares, assim como possibilidades  de participação destacada nos novos processos de agroindustrialização descentralizada.   Os diagnósticos e os planos de desenvolvimento dos APLs da Agroindústria  Familiar e Alimentos indicam as dificuldades relacionadas ao processo de  comercialização dos produtos da agricultura familiar como um dos principais  estrangulamentos do desenvolvimento dos Arranjos Produtivos Locais, esta dificuldade  se deve principalmente a falta de capacidade técnica necessária, por parte dos  agricultores, para planejar e organizar o processo de comercialização dos produtos em  escala ampliada.    Neste sentido, acredita-se que as entidades gestoras dos APLs podem atuar como  facilitadores do processo de comercialização, através da criação de centrais de  comercialização que serviriam de interface entre os produtores e compradores. Estas  centrais de comercialização podem cumprir seu papel de facilitador a partir do  mapeamento das ofertas e demandas, através do cadastramento dos fornecedores e de  seus produtos e das instituições demandantes de itens da agricultura familiar.   É neste contexto que se insere a proposta, implantar e testar um Sistema Web  que auxilie os Arranjos Produtivos Locais(APLs) de Alimentos e Agroindústria  Familiar do Estado do Rio Grande do Sul na catalogação e comercialização de produtos  da agricultura familiar.    O Sistema     O sistema de comércio desenvolvido é uma iniciativa da ADMAU para  automatizar, controlar as transações realizadas entre prefeituras, agroindústrias,  agricultores e indústrias, fomentando a venda de produtos direcionadas a região norte do  estado do Rio Grande do Sul e estreitando relacionamento entre elas.   A base de dados foi baseada em um documento de requisitos do sistema,  resultado de uma conversa com os representantes da ADMAU, levantando os requisitos  funcionais e não funcionais para atender as necessidades da Agência. Para  desenvolvimento foi utilizado o framework Laravel, baseado em PHP e na arquitetura  MVC, o qual possui diversas características que possibilitam uma melhor agilidade ao  desenvolver sistemas na parte do back-end. Para o front-end foram utilizadas as  linguagens HTML5, CSS3 e JavaScript.   Metodologia   O projeto está sendo executado em etapas distintas. Primeiramente foi realizado  o treinamento dos alunos e a elaboração do material que será utilizado na implantação  do sistema, como, por exemplo, a produção dos manuais contendo as instruções para  utilização das funcionalidades do sistema.   Na sequência, foram identificados, juntamente com a Agência de  Desenvolvimento do Médio Alto Uruguai (ADMAU), os grupos de usuários que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   280        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 278-281 Nov/2015     deverão ser capacitados para o uso do sistema. Nesta fase foi realizado um estudo das  características do APL e das regras de negócio relacionadas com a comercialização dos  produtos da agroindústria familiar.   Por fim, será realizada a capacitação dos operadores do sistema, já utilizando  dados reais do contexto da aplicação. Esta fase prevê a elaboração de relatórios de  avaliação da utilização do sistema bem como o detecção de melhorias que poderão ser  realizadas no sistema.   Resultados preliminares   A partir do desenvolvimento deste projeto, com o cadastramento das instituições  que tenham interesse e necessidade de adquirir produtos da agricultura familiar e de  produtores relacionados com a agricultura familiar, será possibilitada a formação de  redes de ofertantes e a criação de centrais de comercializações com logística de entrega.    Com a utilização do sistema em questão, as instituições beneficiadas poderão ter  maior facilidade para a realização de chamadas públicas centralizadas e também para a  criação de cardápios escolares de acordo com a oferta, respeitando a sazonalidade.    Com a aproximação entre ofertantes e demandantes, o sistema poderá auxiliar as  instituições públicas no cumprimento da legislação, no que se refere a obrigatoriedade  de aquisição de produtos da agricultura familiar.    Além disso, com a execução deste projeto, esperamos possibilitar aos servidores  do Instituto Federal Farroupilha uma maior inserção na comunidade externa,  proporcionando uma melhor leitura da realidade regional e consequentemente uma  melhoria na interação entre a academia e o mundo do trabalho, uma vez que a extensão  universitária funciona de maneira mais satisfatória quando os servidores e, por  consequência, a universidade sabem quais as demandas e ofertas da região onde está  inserida.   Por fim, acredita-se que o sistema poderá tornar-se referência como base de  dados e instrumento de organização e logística entre ofertantes e demandantes de  produtos da agricultura familiar.    Na figura 1, pode ser visualizado o painel de controle de um usuário do tipo  Administrador, a partir do qual se tem acesso a todas as funcionalidades. O sistema tem  como principais funcionalidades os cadastros de Fornecedores, Produtos e  Compradores, também realizando o cadastro de Catálogos, Ofertas e Editais para  Compra de Produtos. Também é possível fazer o Controle de Estoque, pesquisar por  potenciais Compradores e Fornecedores, gerar relatórios diversos, como histórico de  compra e venda e realizar estatísticas diversas que possibilitam análise da real oferta e  demanda.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   281        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 278-281 Nov/2015       Figura 1. Sistema de Comercialização - Painel de Controle do Administrador     Considerações Finais   Na atual etapa deste projeto, está sendo implantado o sistema no APL do Médio  Alto Uruguai, contando com a parceria da ADMAU.   Acredita-se que o Sistema Web para Comercialização de Produtos da Agricultura  Familiar poderá auxiliar na operacionalização das centrais de comercialização e  consequentemente, poderá auxiliar no aumento da renda dos agricultores familiares,  uma vez que podem realizar a relação demanda/oferta, sabendo para quem vender.  Poderá auxiliar na diminuição do êxodo rural, uma vez que as famílias terão maiores  condições de manutenção de sua produção e o campo pode voltar a ser atrativo para a  juventude, na ampliação das possibilidade de sucessão na agricultura familiar e no  desenvolvimento local.       Referências   FLACH, A. B.; MARCHIORO, G. Comercialização e Agroindustrialização. In:  Primeiro Encontro Brasileiro de Agricultura Familiar & Desenvolvimento    Sustentável, 2002, Brasília. Anais eletrônicos... Brasília: 2002. Disponível em: http://  www. pronaf.gov.br / Encontro / textos / APACO.doc. Acesso em 14 de junho de  2003.   WILKINSON, J. Agroindústria e perspectivas para a produção familiar no Brasil.  Políticas Agrícolas. v. 2, n. 1, 1996.     
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   291        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 291-294 Nov/2015     Mineração de Dados a partir do Currículo Lattes com a  Ferramenta WEKA     Un Hee Schiefelbein1, Igor Camargo Moiano1, Tairone Livinalli1, Milene   Santos Teixeira1, Matheus Ricalde de Souza1, Juçara Salete Gubiani1     1 Universidade Federal de Santa Maria (UFSM) – 97.105-900 – Santa Maria – RS   – Brasil     {peace.unhee, milene.tsi, matheusricaldee}@gmail.com, {igor.moiano,  taironelivinalli}@hotmail.com, jucara@ufsm.br     Abstract. Data mining aims to mine or extract knowledge in large volumes of  data using tools and techniques that, by the use of learning algorithms, are  able to explore a data set extracting or highlighting patterns to assist in  knowledge discovery. This paper makes a review on data mining and shows  the result of the processing of the algorithm J48, which is implemented in the  WEKA tool. The data were extracted from the base of the Lattes curriculum of  a set of professors from the Federal University of Santa Maria.     Resumo. A mineração de dados tem como objetivo minerar ou extrair  conhecimento em grandes volumes de dados usando ferramentas e técnicas,  que por meio de algoritmos de aprendizagem, são capazes de explorar um  conjunto de dados, extraindo ou evidenciando padrões para auxiliar na  descoberta de conhecimento. O presente trabalho faz uma revisão sobre  mineração de dados e mostra o resultado do processamento do algoritmo J48  implementado na ferramenta WEKA. Os dados foram extraídos da base do  currículo Lattes de um conjunto de professores da Universidade Federal de  Santa Maria.     1. Introdução    Segundo Tan (2009), ao longo dos últimos anos com avanço da tecnologia,  organizações começam a armazenar uma grande quantidade de dados, estes que já não  possuem a mesma dimensionalidade e complexidade de décadas anteriores, dificultando  a filtragem de informações úteis. Surge então a mineração de dados, uma tecnologia que  combina métodos tradicionais de análises de dados com algoritmos sofisticados para  processamento de grandes volumes de dados.     Para Cios et al. (2007) desde o surgimento de sistemas computacionais, o  principal objetivo das organizações tem sido o armazenamento de dados. Nas últimas  décadas essa tendência ficou ainda mais evidente com a queda nos custos e a facilidade  da aquisição de hardware, tornando assim, possível armazenar quantidades cada vez  maiores de dados. Estruturas de armazenamento novas e mais complexas foram  desenvolvidas, tais como: banco de dados, data warehouses, bibliotecas virtuais, web e  outras.     O artigo inicia com a metodologia usada para o desenvolvimento do trabalho na     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   292        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 291-294 Nov/2015     seção 2, seguindo na seção 3 com a fundamentação teórica da Mineração de Dados. Na  seção 4 é apresentada a ferramenta WEKA, assim como o seu funcionamento, seguida  pela seção 5 onde é apresentado o uso do Lattes com a Mineração de Dados. Após,  tem‐se a seção 6 com os resultados e discussões sobre o trabalho e por fim, na seção 7  apresentam-se as conclusões sobre o estudo.    2. Metodologia    O trabalho faz um estudo bibliográfico sobre mineração de dados e a partir deste é  realizado um estudo de caso utilizando a ferramenta WEKA. Por fim, são feitas algumas  considerações.    3. Mineração de Dados    De acordo com Fayyad et al. (1996), a definição de mineração é dada da perspectiva do  aprendizado de máquina: "Mineração de Dados é um passo no processo de descoberta  de conhecimento que consiste na realização da análise dos dados e na aplicação de  algoritmos de descoberta que, sob certas limitações computacionais, produzem um  conjunto de padrões de certos dados."     A mineração de dados é uma parte integral da descoberta de conhecimento em  banco de dados (KDD- Knowledge Discovery in Databases), que é processo geral de  conversão de dados brutos em informações úteis. O processo consiste em vários passos  de transformação: pré-processamento, mineração e o pós-processamento dos resultados  da mineração de dados. Fayyad et al. (1996).    4. Software para Mineração de Dados: WEKA    A ferramenta Waikato Environment for Knowledge Analysis – WEKA foi desenvolvida  pela Universidade de Waikato na Nova Zelândia, utilizando linguagem de programação  Java e possuindo código aberto emitido sob a GNU General Public License. WEKA   possui um conjunto de algoritmos de aprendizado de máquina para tarefas de mineração  de dados um conjunto de algoritmos de aprendizado de máquina para tarefas de  mineração de dados onde, os algoritmos podem ser aplicados diretamente a um conjunto  de dados ou chamado a partir de seu próprio código Java. WEKA contém ferramentas  para pré-processamento de dados, classificação, regressão, clustering, regras de  associação, e visualização. É também bem adequada para o desenvolvimento de novos  sistemas de aprendizagem máquina. (Hall, et al. 2009).    5. Mineração de Dados a Partir dos Resumos do Currículo Lattes (CNPq)    O trabalho foi desenvolvido com base nas etapas processamento dos dados, préprocessamento, mineração e pós-processamento dos dados.     Para o pré-processamento dos dados, ocorre a extração de somente o resumo do  currículo Lattes de 67 professores de uma universidade, o qual foi obtido  automaticamente por meio do uso de um script desenvolvido para este fim. Após isto,  as informações foram estruturadas no padrão do WEKA (.arff). O nome do conjunto de  dados é especificado através da marcação @RELATION areadoconhecimento,  @atribute resumo string e @atribute area {computação, outraArea} para os atributos e  os dados definidos por meio da marcação @data, como apresentados na figura 1.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   293        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 291-294 Nov/2015                                                  Figura 1. Dados no padrão WEKA (.arff)     Com o arquivo já no formato é possível fazer uma a limpeza dos dados  transformando as Strings em vetores, podendo então remover palavras que não  contribuirão com mineração, como demonstrado na figura 1.     Para a mineração dos dados optou-se pela escolha do algoritmo J48, que permite  gerar uma árvore de decisão, sendo assim, possível entender a relação entre as palavras  do resumo dos atributos e a classe “área” procurada. A ferramenta WEKA extrai os  classificadores (ou modelo de classificação) para identificar a classe à qual pertence  uma determinada observação de uma base de dados, a partir de suas características (seus  atributos).     O atributo “área” representa o atributo classe, ele é utilizado para indicar se a  área do professor pertence a “informática” ou “outraArea”, enquanto o atributo  “resumo” é preditivo, seus valores serão analisados para que seja descoberto o modo  como eles se relacionam com o atributo classe.    6. Análise e Discussão dos Resultados    A árvore de decisão gerada por meio do algoritmo J48 apresenta a palavra Computação  como nó raiz (figura 2), pois foi considerado pelo algoritmo classificador como o  atributo mais importante para determinar se o professor pertencia a área de informática  ou outra.                             Figura 2. Árvore de Decisão formada pelo algoritmo J48     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   294        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 291-294 Nov/2015          Os  resumos  analisados  pelo  algoritmo  que  continham  então  a  palavra   Computação foram selecionados como ‘> 0’, determinado assim qual classe eles  pertencem, no caso informática, como exemplificado na figura 3.                         Figura 3. Determinação das classes por meio da palavra selecionada pelo  algoritmo J48     A árvore de decisão determinou palavras chaves relacionando as mesmas aos   professores da área de informática. O algoritmo realizou uma seleção semelhante ao mundo  real através da mineração de dados realizada. Portanto através do estudo de caso realizado é  possível implementar a mineração de dados através da ferramenta WEKA para realizar uma  otimização na busca de professores da área de informática através do currículo lattes.     7. Conclusões    O algoritmo selecionou a palavra Computação, pois esta é a palavra que melhor pode  identificar o resumo como sendo da área da informática. Esta análise tornou evidente a  importância do uso de palavras objetivas na descrição dos resumos do currículo Lattes, para  que os mecanismos de buscas encontrem cada vez mais resultados com precisão. O trabalho  proposto demonstrou ser possível realizar a mineração de dados do currículo lattes e  pretende se futuramente realizar a implementação de um sistema utilizando a mineração de  dados proposta.    Referências   Cios, K. J., Pedrycz, W., Swiniarski, R. W. e Kurgan, L. A. (2007). Data Mining - A  Knowledge Discovery Approach. Springer.   CNPq. Plaforma Lattes. Disponível em: http://lattes.cnpq.br/   Fayyad, U., Piatetsky-Shapiro, G. e Smyth, P. (1996). From Data Mining to Knowledge  Discovery in Databases. American Association for Artificial Intelligence.   Han, J. e Kamber, M. (2006). Data Mining: Concepts and Techniques. Elsevier.   Larose, D. T. (2005) Discovering Knowledge in Data: An Introduction to Data Mining.  John Wiley and Sons, Inc.   Hall, M., Frank, E., Holmes, G., Pfahringer, B., Reutemann, P., & Witten, I. H. (2009).    The WEKA data mining software: an update. ACM SIGKDD explorations  newsletter, 11(1), 10-18.   Tan, P.N., Michael, S. e Vipin, K. (2009). “Introdução ao datamining: mineração de  dados”. Ciência Moderna.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   258           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 258-261 Nov/2015     O uso computacional interativo como recurso virtual didático no  ensino de Ciências - Física   Silva da L.S.S1, Souza, F. A1, Silva, E.M1, Olekszyzen, D. N1, Frey, R1   1Instituto Federal do Paraná – (IFPR) – União da Vitória, PR – Brazil   luiz.silva@ifpr.edu.br, Fabiane.silva@ifpr.edu.br,  ederson.silva@ifpr.edu.br, drielly.salin@ifpr.edu.br,   rosana.frey@ifpr.edu.br  Abstract. These days make computer use in educational settings is essential for  strengthening a road of no return with regard to an educational modernization,  which is directly linked to the ability of educators who seek increasingly, be  prepared for new pedagogical practices arise day morning. This article presents  a survey of computer use as pedagogical teaching tool, through educational  programs freely found on the World Wide Web. These simulators help in building  the abstract, which involves the teaching of sciences in general, and more  specifically in the study of physics.   Keywords: Education; sciences; Virtual simulations, physical   Resumo. Atualmente fazer uso do computador nos locais de ensino é  imprescindível para o fortalecimento de uma via sem volta no que diz respeito a  uma modernização pedagógica, que está diretamente ligada a capacidade de  educadores que buscam cada vez mais estarem preparados para novas práticas  pedagógicas  que surgem dia a dia. Este artigo apresenta uma pesquisa do uso  computacional como ferramenta didática pedagógica, através de programas  educacionais encontrados livremente na rede mundial de computadores. Esses  simuladores auxiliam na construção do abstrato que envolve o ensino de ciências  em geral e mais especificamente no estudo da física.    Palavras-chave: Educação; Ciências; Simulações Virtuais, física.   1. Introdução  Visto que uma das finalidades do IF (s) -Institutos Federais é a oferta de cursos técnicos  integrados, bem como de licenciaturas, esta pesquisa busca proporcionar a preparação de  um espaço de apoio às atividades e disciplinas direcionadas para esses cursos na área de  ciências. O objetivo é a integração das atividades de pesquisa, ensino e extensão,  contribuindo para formação educacional de qualidade dos discentes. Nesta pesquisa é  utilizado os simuladores virtuais Phet, desenvolvidos na Universidade do Colorado sitiada  na cidade Bouldere, Estados Unidos. Com a preparação de roteiros norteadores para cada  experimento virtual, o discente tem a oportunidade de vislumbrar a teoria vista em sala de  aula em um ambiente de grandezas físicas manipuláveis. Desta forma, este trabalho  constitui-se em elemento capaz de operacionalizar a união entre teoria formal, a construção  e visualização do abstrato inerente ao ensino de ciências e em especial no estudo da física,  contribuindo com uma melhor compreensão do saber por parte dos alunos e da comunidade  de forma geral.   2. Referencial Teórico  De forma geral no ensino a grande dificuldade que se evidencia no cotidiano do  aprendizado dos discentes é o fato de se lidar com conceitos abstratos e de difíceis     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   259           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 258-261 Nov/2015     modelagens mentais, por não estarem evidentes no mundo macroscópico que vivemos. Em  consequência, muitos deles não conseguem fazer a relação dos conceitos estudados nas  ciências exatas com a vida real. Podem-se citar como exemplo, o ensino de física, segundo  Hestenes (1998), “Os métodos tradicionais de ensinar Física são inadequados”. O que  corrobora com que afirmam Lawson e McDermott (1987), “não serão de admirar falhas na  aprendizagem se conceitos complexos e difíceis de visualizar só forem apresentados de  uma forma verbal ou textual”. Ainda, segundo C. Fiolhais e J. Trindade (1999) “A  necessidade de diversificar métodos de ensino para contrariar o insucesso escolar ajudou ao  uso crescente do computador no ensino de Física”. Proporcionar alternativas que possam  ajudar a diminuir as dificuldades no ensino das exatas é de responsabilidade dos docentes,  para tanto o computador como ferramenta educacional, passa a ser uma ótima alternativa  visto que é uma forma atrativa e de fácil acesso.              Partindo destes pressupostos, este projeto de pesquisa tem como objetivo o uso do  computador através de programas educacionais encontrados livremente na rede mundial de  computadores (Campos, 2009).    3. Metodologia  Esta é uma proposta cuja natureza da pesquisa é aplicada tal como descrito por Barros e  Lehfeld (2000, p. 78), pois objetiva gerar conhecimento para aplicação prática nos cursos  do Instituto Federal do paraná - IFPR- campus União da Vitória. A abordagem dada à  pesquisa será qualitativa, pois tem ênfase na melhora da qualidade da interação dinâmica  entre o sujeito e o objeto em estudo. Corroborando com que evidencia Apolinário (2004, p.  152), de que pesquisas aplicadas objetiva “resolver problemas ou necessidades concretas e  imediatas”. Desta forma, foi analisado nesse trabalho, entender melhor, como ocorre a  interação didática- pedagógica entre o conteúdo abstrato, educando e o experimento virtual,  buscando avanços na educação das ciências exatas com o uso de “novas” tecnologias da  educação.              As simulações virtuais desenvolvidas na Phet (2015) inicialmente eram focadas para  as simulações de Física, e foi por isso chamado de *Ph*ysics (Física) *E*ducation  (Educação) *T*echnology (Tecnologia), ou *PHET*. Quando se ramificou para a química,  biologia, matemática e outras áreas, onde os criadores do projeto decidiram manter o nome.  Todas as simulações são de código aberto e tem como finalidade assessorar o aprendizado  na busca de uma eficácia educacional.  No site dos simuladores Phet (2015), existem vários  roteiros preparados por diversos professores e pesquisadores do mundo todo que os  enviaram em forma de colaboração, para uso público. Existem roteiros para os níveis de  ensino, desde o fundamental até a graduação. Entretanto, os roteiros que se encontram no  site fogem de forma acentuada da realidade da compreensão de grande parte dos alunos que  encontramos em sala de aula, no Brasil. Nesse sentido, esse artigo é fruto de um projeto que  busca estudar o conteúdo desses softwares educativos específicos para o ensino de ciências  Phet e preparar roteiros próprios para cada simulação, que irão ancorar ações tal como a  implantação de um laboratório virtual didático, que no primeiro momento será focado na  disciplina de física.              Para a confecção de cada roteiro, após a escolha do simulador a ser usado, foi  realizada uma pesquisa bibliográfica para levantar toda a teórica sobre os conceitos  envolvidos, procurando identificar as potencialidades acerca da visualização, manipulação  e comprovação das teorias da física que os discentes viram de forma conceitual em sala de  aula. O roteiro foi confeccionado em forma de um relatório de procedimentos, no qual os  alunos se auto dirigem durante toda atividade executando os comandos pré-determinados,  fazendo suas observações e anotando-as e finalmente respondendo às questões através de  suas conclusões. Para realizar os ajustes, o roteiro foi executado várias vezes por alunos e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   260           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 258-261 Nov/2015     professores voluntários. Os principais fatores verificados e corrigidos foram, clareza nos  procedimentos, funcionalidade do simulador, compreensão da situação simulada e  visualização da teoria através do simulador. O primeiro roteiro pronto foi aplicado no  laboratório de informática do campus, para uma turma de técnico em informática integrado  ao ensino médio do IFPR. A parte teórica contemplada nesse roteiro foi direcionada para os  conceitos sobre a 1ª e 2ª Leis de Newton com e sem a presença do atrito, envolvendo de  forma geral os conceitos de vetor e força resultante. O simulador para abordar esses  conceitos intitula-se “Forces and Motion Basics” versão: 1.02 - 2013 onde sua interface  gráfica é mostrada na figura 1 abaixo.                                               Figura 12. Interface do experimento virtual “Forces and Motion Basics”.                    Na figura 1 é mostrado quatro abas dentro do mesmo simulador que retratam  situações distintas respectivamente a se saber:  o quadro A cabo de guerra envolvendo o  conceito de vetores, o quadro B o movimento sem atrito envolvendo a 1ª Lei de Newton, o  quadro C movimento com atrito envolvendo as duas leis de Newton, e o quadro D  movimento acelerado.   4. Conclusões Parciais  No IFPR os alunos são avaliados por conceitos que vão de D insuficiente até A  aprendizagem plena. No primeiro bimestre os conteúdos vistos pela turma foram  ministrados de forma teórica. Da turma de 40 alunos 60% apresentou um aproveitamento  negativo D no bimestre. No segundo bimestre antecedendo a primeira avaliação, os alunos  utilizaram o simulador virtual conduzidos pelo roteiro de procedimentos preparado e  tiveram a oportunidade de vislumbrar o conteúdo visto em sala, abrindo possíveis elos entre  o conceito formal e a formulação do abstrato para as situações apresentadas na teoria. Após  a utilização do experimento virtual foi aplicado um questionário com os alunos  participantes com respostas fechadas do tipo, excelente, bom, regular e Ruim, onde se  levantou as seguintes questões, 1) O simulador auxiliou no aprendizado da teoria  relacionada?  2) conseguiu visualizar a relação entre a teoria vista em sala de aula e o  experimento apresentado no simulador?  3) como considera o nível das questões     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   261           Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 258-261 Nov/2015     apresentadas no roteiro?  Os alunos considerarão entre excelente e bom para as questões 1,2  e 3 respectivamente, 77,5%, 67,5% e 75%.                Após a atividade com o simulador junto aos alunos foram realizados as avaliações  teóricas formais e o índice de conceitos insuficientes D baixou para 36.84% no segundo  bimestre, representando aproximadamente um quarto da turma. Pode-se concluir assim que,  no primeiro momento essa ferramenta pedagógica apresenta ser de fato uma boa alternativa  na visualização e construção do abstrato essencial para o entendimento do ensino de  ciências e em especial no estudo da física.      5. Referências bibliográficas  D. Hestenes (1987). Toward a modeling theory of Physics instruction. American Journal of   Physics 55, 440-449.   R. Lawson e L. McDermott (1987). Student understanding of the work-energy andimpulsemomentum theorems. American Journal of Physics 55, 811-818.   C. Fiolhais e J. Trindade (1999). “Física para todos: concepções erradas em Mecânica e  estratégias computacionais”. In A. Pires da Silva (Eds.), “A Física no Ensino na Arte e  na Engenharia”, Instituto Politécnico de Tomar, Tomar, 195-202.   Campos, A. O que é um software livre. Disponível em: http://br-linux.org/2008/01/faqsoftwarelivre.html.  Acesso em 11. Set. 2015.   Barros, A. J. S. e Lehfeld, N. A. S. Fundamentos de Metodologia: Um Guia para a  Iniciação Científica. 2 Ed. São Paulo: Makron Books, 2000.   Appolinário, F. Dicionário de metodologia científica: um guia para a produção do  conhecimento científico. São Paulo: Atlas, 2004. Phet. Disponível em:  https://phet.colorado.edu/pt_BR/, acessado em: Setembro/2015.                  
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   295        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 295-298 Nov/2015     PerguntasIFF: Aplicativo móvel para ensino e aprendizagem  multidisciplinar      Garibaldi da Silveira Júnior¹, Daniela do Amaral Friggi¹      ¹Campus de Panambi   Instituto Federal de Educação, Ciência e Tecnologia Farroupilha   Panambi – RS     {garibaldi.junior,daniela.friggi}@iffarroupilha.edu.br      Abstract. The use of smartphones in Educational Scope, although it is still  considered restricted, their potential and evidenced in use does not regard the  interaction and mobility. The present article introduces the development of the  application for mobile devices PerguntasIFF, which aims to encourage students  to pursue knowledge responding multidisciplinary issues. The Purpose of the  application is to promote the challenge and competition between students,  through the accumulation of points for each question answered correctly, and  the possibility to share your score in the social networks. The application is  being developed in Android Studio and is in the testing phase, for the future, is  planned modules separated by levels and knowledge areas.       Resumo. O uso de smartphones em âmbito educacional, embora ainda seja  considerado restrito, seu potencial é evidente na utilização no que diz respeito  a interação e mobilidade. O presente artigo, introduz o desenvolvimento da  aplicação para dispositivos móveis PerguntasIFF, que tem por finalidade  estimular os alunos a buscar o conhecimento respondendo questões  multidisciplinares. O objetivo da aplicação é promover o desafio e a  competição entre os alunos, através do acumulo de pontos a cada questão  respondida corretamente, e a possibilidade de compartilhar sua pontuação nas  redes sociais. O aplicativo está sendo desenvolvido com a ferramenta Android  Studio e está em fase de testes, e para o futuro são planejados módulos  separados por níveis e áreas de conhecimento.     1. Introdução   Na atual era da informação, onde a comunicação é essencial, é difícil imaginar  alguma inovação tecnológica que não possua conexão a internet. As tecnologias da  comunicação e informação (TIC’s) já são faladas a algum tempo, e constituem do uso de  equipamentos, em sua maioria computadores, para a aplicação de recursos alternativos em  uma metodologia de ensino, como vídeos interativos, simulações e até mesmo jogos  educativos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   296        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 295-298 Nov/2015     O uso das TICs como uma ferramenta didática pode contribuir para auxiliar  professores na sua tarefa de transmitir o conhecimento e adquirir uma nova maneira de  ensinar cada vez mais criativa, dinâmica, auxiliando novas descobertas, investigações e  levado sempre em cona o diálogo. E, para o aluno, pode contribuir para motivar a sua  aprendizagem e aprender, passando assim, a ser mais um instrumento de apoio no processo  ensino-aprendizagem [...] (MERCADO, 2002, p. 131).     Com o crescente mercado dos dispositivos móveis, e a popularização dos mesmo, é  visto a necessidade de adaptar esse tipo de tecnologia para essa nova gama de aparelhos.  Como dito por Yordova (2007), o m-learning (mobile learning) é o conceito criado para  definir a utilização de aparelhos capazes de trazer mobilidade e flexibilidade a educação,  como smartphones e tablets. Da mesma forma, Franciscato (2008) define que o processo de  educação a distancia não acontece mais em um lugar fixo, sendo o principio do m-learning.    O objetivo desse artigo é apresentar o desenvolvimento do aplicativo PerguntasIFF,  que constitui de um sistema de perguntas, onde o aluno pontua após responder corretamente  cada questão, gerando assim uma nova e dando continuidade ao jogo, até o mesmo errar,  quando isso acontece, ele pode compartilhar o resultado em suas redes sociais. Essa  interação com as redes sociais traz uma experiência nova ao aprendizado do aluno, e ao  mesmo tempo gera competição entre os mesmos. O aplicativo em questão será  desenvolvido para ser aplicado junto as turmas dos cursos integrados ao ensino médio do  Instituto Federal Farroupilha Campus Panambi.   A escolha do desenvolvimento voltado para dispositivos moveis que utilizam o  sistema android foi baseada na popularidade do mesmo, além disso, o aplicativo também  servirá como referência para os alunos do curso de Sistemas para a Internet da instituição,  já que os mesmos possuem uma disciplina que aborda o desenvolvimento para android. O  presente artigo está dividido da seguinte forma, na seção II são mostradas as tecnologias  utilizadas nas etapas de desenvolvimento do aplicativo e na seção III é dada a conclusão ,  seguido da apresentação dos trabalhos futuros.   2. PerguntasIFF   O aplicativo, em sua versão atual, está sendo desenvolvido utilizando o ambiente Android  Studio, criado pela própria google. O motivo da escolha dessa plataforma de  desenvolvimento se deu pela popularidade e quantidade de recursos da mesma. Os recursos  visuais presentes no ambiente permitem uma maior abstração do conhecimento necessário  no desenvolvimento, visto que a aplicação de muitos elementos é simplificada. Onde seria  necessário a implementação de várias linhas de código, os mesmos são substituidos por  componentes gráficos, que quando selecionados, ou arrastados, implementam aquele  código a aplicação.   2.1 Servidor Remoto   O desenvolvimento do aplicativo foi dividido em três partes, que utilizam de tecnologias  distintas, mas que trabalham em conjunto. Para que as questões sejam armazenadas em um  ponto centralizado, e independente do espaço em disco do aparelho, foi necessário a criação  de um banco de dados remoto para o armazenamento das mesmas. A linguagem escolhida  para o desenvolvimento do banco de dados foi a SQL, devido a sua versatilidade em  trabalhar com diversos tipos de ambientes. O banco de dados foi armazenado em um  servidor remoto, disponibilizado pelo serviço hostinger, onde o mesmo possui as  ferramentas necessárias para o desenvolvimento da base de dados dessa aplicação.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   297        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 295-298 Nov/2015      Para a criação do protótipo inicial, foi feita apenas uma tabela, que cadastra as  questões, visto que os objetivos iniciais do aplicativo não englobam o controle de usuário  ou armazenamento de informações por parte do mesmo, mas somente a apresentação das  questões e o controle da pontuação do usuário.    Para a segunda etapa do desenvolvimento, foi necessária a criação de um web  service, que trata as informações que o aplicativo ira requisitar ao banco de dados. Devido a  distinção das tecnologias, é necessário uma ponte entre elas para a troca de informação,  tanto o envio quando a busca de dados são feitas através dessa mediação. O web service foi  desenvolvido utilizando a linguagem de scripts web PHP, foi criada uma página que  apresenta todos os dados contidos na tabela, codificados no formato JSON, possibilitando o  tratamento dos mesmos quando forem requisitados pela aplicação. Além disso, foi criada  uma página para o cadastro de questões.   2.2 Desenvolvimento da aplicação   A terceira etapa foi o desenvolvimento da aplicação em sua forma, utilizando recursos e  elementos padrões do Android Studio, foi criado um protótipo da interface. Contando com  três telas, a aplicação em seu estado atual busca uma questão aleatória do banco de dados  citado anteriormente e a apresenta ao usuário, o mesmo possui quatro opções de resposta,  como pode ser visto na fígura 1, após selecionar a alternativa desejada e clicar no botão  enviar, será feita a análise da questão, caso o aluno acerte, sera somado 10 a pontuação  atual, e mostrado acima da pergunta, e uma nova pergunta será carregada do banco de  dados, caso o aluno erre, o mesmo será levado a uma nova tela, contendo sua pontuação e a  possibilidade de compartilhar seus pontos nas redes sociais facebook e twitter.       Figura 1 - Telas da aplicação   3. Conclusão   O PerguntasIFF é um aplicativo com intuito educacional, desenvolvido para incentivar o  aprendizado dos alunos através da competição. O aplicativo ainda está em fase de  desenvolvimento e testes, mas já possui seu núcleo principal em pleno funcionamento, onde  o usuário já consegue responder perguntas aleatórias, previamente cadastradas pelos  professores em um banco de dados remoto, e compartilhar a pontuação obtida em suas  redes sociais.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   298        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 295-298 Nov/2015      As próximas etapas do desenvolvimento envolvem a inserção de testes separados  por disciplinas, e também multidisciplinares, divididos por níveis de ensino e dificuldade.  Para tal, além da inserção de novas telas ao aplicativo, também será necessário modificar a  estrutura do banco de dados. Além disso, também é pretendido a inserção de um ranking,  onde as maiores pontuações de cada categoria estarão disponíveis para a visualização no  aplicativo.     Referências  FRANCISCATO, F. Teixeira, MEDINA, R. Duarte.M-Learning e Android: um novo   paradigma?. RENOTE 6.1 ,2008.   MERCADO, Luis Paulo Leopoldo. Formação continuada de professores e novas  tecnologias. Maceió. EDUFAL, 2002.   YORDOVA, Korneliya. Mobile learning and integration of advanced technologies in  education. Proceedings of the 2007 international conference on Computer systems and  technologies. ACM, 2007.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   282        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 282-285 Nov/2015     Projeto de Extensão BIT de Inserção Social   Fernanda Piecha Ludwig1, Gustavo Silveira Ramos1, Jefferson Vantuir Behling1,  Larissa Monteiro Lanes1, Marcele Turchetti1, Patrícia Pires Lopes1,               Alecson Milton Almeida dos Santos1, Alex Marin1 , Fabieli de Conti1   1 - Instituto Federal de Educação Ciência e Tecnologia Farroupilha - Campus São  Vicente do Sul – Rua vinte de setembro – s/n° RS – Brasil   1-fernandaludwig95@gmail.com, jeffersonbehling@hotmail.com,  alex.marin@iffarroupilha.edu.br      Abstract Currently we live in a world where it is becoming increasingly  necessary in the pursuit of technology insertion in the Middle. Besides much of  the socialization of knowledge is given by the media and social networks,  causing the exclusion of less fortunate technologically. Thus, develops the  project of SOCIAL INCLUSION (Inclusive Social insertion Technological  Search) in municipal public schools of the city of São Vicente do Sul and two  special education schools (APAEs), the cities of São Vicente do Sul and  Jaguari, seeking social interaction and school with computers, using computer  tools for the development of activities.    Resumo Atualmente vivemos em um mundo onde torna-se cada vez mais  necessária a busca da inserção tecnológica no meio educacional. Além do  mais grande parte da socialização do conhecimento se dá por meios de  comunicação e redes sociais, causando a exclusão dos menos favorecidos  tecnologicamente. Assim, desenvolve-se o projeto BIT DE INSERÇÃO  SOCIAL (Busca Inclusiva Tecnológica de Inserção Social) em escolas da rede  pública municipal da cidade de São Vicente do Sul e em duas escolas de  Educação Especial(APAEs), das cidades de Jaguari e São Vicente do Sul,  buscando a interação social e escolar com a informática, utilizando-se de  ferramentas da computação para o desenvolvimento de atividades.      1.Introdução   A tecnologia começou a fazer parte do cotidiano do ser humano no século XXI, tanto no  meio pessoal como profissional é indispensável a importância de se atualizar aos  acontecimentos de fora do cotidiano. As escolas necessitam introduzir o conhecimento  da informática em suas atividades, porém não há pessoal com capacitação suficiente  para este trabalho. O professor muitas vezes encontra dificuldades para trabalhar com a  nova Era Tecnológica, afastando-se da realidade do discente. Porém, surge a  necessidade de estimular a aprendizagem com metodologias diferenciadas e lúdicas.    Percebe-se hoje uma nova forma de processamento do conhecimento, onde o  aluno não busca mais a aprendizagem em livros, revistas ou jornais impressos. Na  educação especial isso pode se tornar uma barreira devido à falta de acessibilidade nos  meios midiáticos. Nas escolas públicas percebe-se o difícil acesso à tecnologia,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   283        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 282-285 Nov/2015     sentindo-se assim, a importância de projetos que possibilitem a inclusão informacional  no meio educacional.   Conforme apontam Neves e Gomes (2008), as classes menos favorecidas  economicamente ficam excluídas da utilização da tecnologia, comprometendo o  desenvolvimento de questões pessoais e profissionais dos mesmos.    Também vemos em Vygotsky(1992), que a relação entre o desenvolvimento e a  aprendizagem da criança está associada ao meio social em que vive, as interações  sociais propiciam uma melhora no processo de ensino-aprendizagem, desta forma  espera-se que o uso das tecnologias sirvam como estímulo para a busca e apropriação do  conhecimento.    Sente-se assim, a importância de projetos que possibilitem a inclusão  informacional no meio educacional.   2.Objetivos   Os objetivos do projeto apesentados neste artigo baseiam-se em contribuir no processo  de ensino-aprendizagem, bem como promover autonomia e capacitação para trabalhos  que necessitem a utilização da informática. Para os bolsistas busca-se uma melhoria no  modo de se expressar, um maior contato com a realidade social e compreensão da  necessidade de inclusão.    3.Metodologia   Semanalmente planeja-se as atividades, de acordo com o tema apresentado pelo  professor, preenchendo-se uma ficha de planejamento conforme figura 1. Após  selecionado o tema a equipe reúne-se para pesquisar e estudar ferramentas e técnicas  para facilitar a aprendizagem através de aplicativos computacionais, bem como as  metodologias de ensino que serão aplicadas de acordo com o tema. São utilizados jogos,  textos, apresentações em slides, materiais adaptados, softwares, entre outros. Com um  aluno que possui deficiência visual utiliza-se softwares leitores de tela, que auxiliam na  formação social e cognitiva do estudante.      Figura 13. Modelo de planejamento para controle das atividades desenvolvidas   As atividades do projeto desenvolvidas nas escolas consistem em encontros semanais  com duração de quarenta e cinco minutos por turma, sendo atendidas três turmas de  cada escola por semana. Com as APAEs realiza-se semanalmente um encontro com  duração de duas horas. Participam como monitores do projeto quatro alunos do curso  Técnico em Informática, uma aluna do curso Superior em Licenciatura em Ciências  Biológicas e uma aluna do curso Superior em Licenciatura em Química, todos do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   284        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 282-285 Nov/2015     Instituto Federal de Educação Ciência e Tecnologia Farroupilha Campus São Vicente  do Sul.     Para validação da importância das atividades desenvolvidas aplicou-se um  questionário contendo três perguntas para respostas abertas, com retorno de três  docentes. As perguntas faziam referência à importância do projeto para os processos de  ensino-aprendizagem e desenvolvimento cognitivo de discentes e docentes.       4.Resultados   Percebeu-se uma melhoria dos discentes na forma em que o mesmos interagem  com o computador, aprendendo diversas formas de utilizá-lo para meios de  aprendizagem. Percebeu-se a melhoria no aprendizado das pessoas participantes do  projeto, bem como no conhecimento acerca da informática. O desenvolvimento do  projeto foi importante para o crescimento pessoal e profissional dos envolvidos, onde as  licenciandas puderam ter maior contato com a realidade das escolas, e os estudantes do  curso de informática utilizaram os conhecimentos adquiridos nas aulas para a  construção de objetos de aprendizagem.    Temos o exemplo de um aluno com deficiência visual onde aplicou-se a  atividade de desenvolver desenhos no programa Paint em tamanhos ampliados, de modo  que o mesmo conseguisse desenhar sozinho com a utilização do computador. Na Figura  2 podemos ver o desenho do aluno abordando o tema animais. Pôde-se perceber que o  mesmo aplicou o tema a desenhos de animais que considerava importante e de interesse  ao seu cotidiano.   Salientamos também, conforme relatos de professores, que o projeto está  contribuindo muito em prol da aprendizagem, pois retoma as atividades já trabalhadas  em sala de aula de maneira diferente, ajudando assim a reforçar o conteúdo. Posto isso,  a aplicação do projeto auxiliou o professor no momento da explicação do conteúdo para  o aluno.       Figura 2. Desenho no programa Paint de aluno com deficiência visual     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   285        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 282-285 Nov/2015     5.Considerações finais   O projeto atua desde o ano de 2004, surgindo como uma parceria entre o Instituto  Federal Farroupilha e a APAE/SVS, se ampliando para escolas públicas da rede  municipal. Durante os onze anos de atuação o projeto sempre teve grande procura, bem  como o reconhecimento da importância do mesmo, por parte do público frequentador,  pais, professores, alunos do Instituto e colegas de trabalho. Sendo assim, pode-se ver  sob a ótica da informática uma forma de contribuir para a formação das pessoas  envolvidas no projeto.   6.Referências   BRASIL. Secretaria de Educação Média e Tecnológica. Programa Nacional de  informática educativa/MEC/ SEMTEC. Brasília: PRONINFE, 1994. Disponível em:  http://www.dominiopublico.gov.br/download/texto/me002415.pdf. Acesso em:   13/09/15   FREIRE, Paulo. Pedagogia do Oprimido. Rio de Janeiro: Paz e Terra, 1987.   La Taille, Yves de, 1951-.Piaget, Vygotsky, Wallon: Teorias psicogenéticas em  discussão- Yves de La Taille, Marta Kohl de Oliveira, Heloysa Dantas. – São Paulo:  Summus, 1992.   NEVES, Barbara Coelho; GOMES, Henriette Ferreira. A inclusão digital e o contexto  brasileiro: uma experiência nos domínios de uma universidade. BiD: textos  universitaris de biblioteconomia i documentació, desembre, núm. 21. 2008. ISSN  1575-5886. Disponível em: http://bid.ub.edu/21/coelh2.htm . Consulta em : 13 de  setembro de 2015.       
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   303        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 303-306 Nov/2015     Tô Dentro: concepção de um aplicativo para os calouros do  IFSul   Julian Silva da Cunha¹, Rafael Cunha Cardoso¹   ¹Curso Superior Tecnologia em Sistemas para Internet - Instituto Federal Sul-rio-grandense  (IFSul) Pelotas – RS – Brasil   juliancunha2010@hotmail.com, rafaelcardoso@pelotas.ifsul.edu.br  Abstract. Nowadays with the different ways to access the information, the  organization of information, and the way it is available to its audience, are vital  to the success or failure of a institucional website. This article presents the  development of an application for Android platform, for improving dissemination  of information of the IFSul, with a focus on their freshmen.     Resumo. Atualmente com os diferentes meios de acesso as informações, a  organização da informação, e a maneira como ela é disponibilizada ao seu  público, são vitais para o sucesso ou não de um website institucional. Este artigo  apresenta o desenvolvimento de um aplicativo para plataforma Android para a  melhoria da divulgação das informações do IFSul, com foco em seus alunos  calouros.   1. INTRODUÇÃO  Atualmente com a evolução da internet, somos cada vez mais sobrecarregados com imensa  quantidade de informações. Na internet, a maneira que a informação é organizada para seu  público alvo, é essencial para definir o sucesso ou não de um website.   Na área da educação esse problema também pode ser rapidamente percebido, uma  vez que grande parte da comunicação entre instituições de ensino e seu público alvo  (alunos, professores, funcionários e comunidade externa) é realizada através de seu website  institucional. Analisando especificamente o website do Instituto Federal Sul Rio-grandense  (IFSul), ao se realizar algumas buscas por informações, percebe-se facilmente a maneira  confusa com que a informação é disponibilizada e organizada visualmente, dificultando a  busca do usuário.   Considerando apenas os alunos da instituição, a dificuldade ao acesso as principais  informações da instituição é ainda maior para os calouros da instituição, pois estes ainda  não estão familiarizados nem com o funcionamento do website e muito menos com os  diversos setores e coordenadorias que compõe o universo do IFSul.   Com o objetivo de minimizar este problema, este projeto realizou um levantamento  sobre as informações básicas relevantes para a vida acadêmica dos alunos ingressantes do  IFSul. A partir deste estudo, foi iniciada a concepção de um aplicativo para smartphones,  que disponibilize as principais informações de interesse dos calouros e demais alunos. Após  finalizado, este aplicativo também será adicionado a campanha de recepção aos alunos do  IFSul, evento denominado “Tô Dentro”, como uma forma de recepcionar os seus novos  alunos, além de passar as primeiras orientações sobre o funcionamento da instituição.  Evento este que utiliza-se de uma linguagem informal buscando estreitar a relação do  estudante com a instituição, estimulando relações de respeito e cooperação entre alunos e  servidores. O evento conta com a realização de gincanas culturais envolvendo os calouros e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   304        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 303-306 Nov/2015     os veteranos, realizações de passeios, oficinas literárias, apresentações musicais, entre  outras atividades (De La Rocha, 2014).   Pretende-se que esta ferramenta apresente de forma simples, organizada e intuitiva  as informações essenciais que auxiliem estes alunos sobre os diversos serviços oferecidos  pela instituição. O restante do trabalho está organizado da seguinte forma: a seção dois  descreve o processo de levantamento de dados do projeto, junto dos resultados obtidos e  sistemas similares ao proposto. A seção três descreve a arquitetura do sistema e tecnologias  utilizadas para o desenvolvimento do projeto. Por fim são apresentadas as conclusões, o  estado atual de desenvolvimento do sistema e as perspectivas de desenvolvimento do  referido sistema.      2. LEVANTAMENTO DE DADOS  Para a realização do levantamento de dados do projeto foram realizadas algumas etapas de  pesquisa dentro do próprio IFSul, para uma melhor compreensão de quais informações são  mais importantes para os usuários finais do aplicativo. Na primeira etapa foram realizadas  entrevistas com servidores (professores e coordenadores de cursos e de técnicos  administrativos) e alunos vinculados a diretórios acadêmicos do Campus Pelotas do IFSul.  Este público foi escolhido pelo fato de já conhecerem bem a infraestrutura do instituto, e  desta forma estavam aptos a detalhar quais as informações mais buscadas pelos alunos e  comunidade geral.   Na segunda etapa do levantamento de requisitos do projeto foi realizada uma  pesquisa direcionada aos alunos da instituição. Nesta fase da pesquisa o objetivo foi  diagnosticar as necessidades que os alunos consideram importantes em sua vida acadêmica.  Para esta etapa foi elaborado um questionário, disponibilizado para a comunidade estudantil  do IFSul Campus Pelotas.   2.1.  RESULTADOS    Do universo de estudantes que respondeu ao questionário, constatou-se que:   • 51.3% dos usuários utilizam o smartphone como principal meio de acesso as  informações do site institucional do IFSul;    • 43.4% dos usuários acessam o site da instituição semanalmente;  • 48.7% dos usuários possuem dificuldades em encontrar as informações sobre   diferentes setores do IFSul;  •  58.2% dos usuários não conseguem encontrar as informações desejadas.    Outros dados interessantes são que as informações que os usuários mais buscam  são:    • Editais abertos pelo IFSul (percentual de 83,6% das respostas);   •  Vagas para estágio (percentual de 63,6%);   • E os eventos realizados pelo instituto (percentual de 61.8%).     Constatou-se também que 72.7% do público, possuí dificuldades para encontrar as  informações com rapidez e facilidade. A partir da coleta destes dados notou-se também que  as informações referentes à assistência estudantil não são bem divulgadas, pois, 65.5% do  público gostariam que estas informações possuíssem melhor divulgação pela instituição.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   305        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 303-306 Nov/2015     Neste questionário, também houve a aprovação do público a respeito da elaboração  de um aplicativo para dispositivos móveis, onde 68.4% do público considerou interessante  possuir a utilização deste aplicativo. Também ficou verificado que 72.4% dos usuários que  possuem smartphones, utilizam o sistema operacional Android.   2.2. SISTEMAS SIMILARES   Antes de começar o desenvolvimento do aplicativo, foram realizadas pesquisas por  aplicativos similares ao proposto em busca de ideias e também de verificar o que cada um  desses aplicativos possui de pontos positivos e negativos. Nesta etapa foram analisados os  aplicativos utilizados pelas seguintes instituições: UFPEL, USP e Unisinos. Com esta  pesquisa foi possível estabelecer uma série de ideias, como por exemplo a disponibilização  de uma agenda destacando os eventos do campus, informações sobre os diferentes setores  da instituição, encontrado no aplicativo da UFPEL. Um ponto negativo em um dos sistemas  analisados, mais especificamente no aplicativo da USP, era possuir problemas de  comunicação entre a instituição e o responsável pelo desenvolvimento e manutenção do  aplicativo, pois a instituição está relutante em criar uma parceria com o aplicativo, não  havendo a possibilidade para a disponibilização de algumas funcionalidades e acesso a  algumas informações solicitadas pelos seus usuários.    Relacionando as informações obtidas através da pesquisa de sistemas similares, aos  resultados obtidos com a realização de entrevistas e aplicação do questionário ao público  alvo, foi definido um conjunto de informações primordiais que devem fazer parte do  aplicativo. Sendo elas: informações sobre matrículas e rematrículas, assistência estudantil,  estágios, biblioteca, cardápio do restaurante, editais para concessão de benefícios ou bolsas,  eventos e programação do campus.    Este levantamento de dados também norteou decisões do projeto. A opção para  desenvolvimento de um aplicativo para dispositivos móveis para a plataforma Android,  passa pela grande quantidade de usuários deste sistema operacional dentro da instituição.  Para corroborar esta decisão, um estudo recente realizado na América Latina pela  comScore, líder mundial de medição do mundo digital, em associação com a Internet  Media Services (IMS), foi verificado que 82% dos entrevistados, fazem a utilização do  sistema operacional Android (IMS, 2015).   3. ARQUITETURA DO SISTEMA  Após definidas as informações essências e a plataforma do app, definiu-se também a  arquitetura do sistema junto de suas ferramentas.      Figura 14- Arquitetura do sistema   (Fonte: Elaborado pelo autor).   A arquitetura do sistema prevê o acesso de dados via aplicativo para plataforma  Android. Na outra ponta encontra-se o painel de controle, que será a ferramenta utilizada  para fornecer os dados que serão consultados pelo aplicativo. O banco de dados irá  armazenar todas as informações inseridas através do painel de controle. Por fim, para     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   306        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 303-306 Nov/2015     intermediar as buscas por informações constantes na base de dados, o projeto prevê a  utilização de Web Services Restful com JSON, o qual ficará responsável por tratar  adequadamente requisições de informações no aplicativo. A partir dos dados coletados, foi  possível definir a estrutura geral de toda aplicação, realizar também a elaboração da base de  dados contemplando todas as informações essenciais, para então, desenvolver um aplicativo  para dispositivos móveis oferecendo rápido acesso às informações essenciais para os  estudantes, criando uma solução para o problema de organização das informações  encontrado no site institucional do IFSul.   Para o desenvolvimento do projeto ficou definida a utilização do Android Studio  para o desenvolvimento do aplicativo, realizando os testes no Genymotion, emulador de  dispositivos Android. Para o desenvolvimento do painel de controle do sistema definiu-se o  Atom Text Editor, onde serão desenvolvidas para a criação do mesmo as linguagens PHP, e  utilização de Bootstrap para a parte do front-end. Será utilizado o PostgreSQL como banco  de dados da aplicação. E haverá a utilização da tecnologia RESTful para criação do Web  Service (Android Developer Tools).   4. CONCLUSÃO  Para o desenvolvimento deste projeto foram realizadas várias etapas para a verificação das  necessidades do público, verificação da aceitação do aplicativo por parte do público alvo,  para que o projeto minimize parte dos problemas que o público para acessar as informações  que necessitam. A etapa de levantamento de dados dos alunos ampliou a confirmação de  que as informações precisam ser melhor divulgadas e organizadas para o público alvo. Uma  grande parte do público confirmou que faria a utilização do aplicativo, tornando o viável a  sua criação. Além da confirmação da colaboração da área de comunicação social do  instituto, para a disponibilização das informações através do app.    Atualmente o projeto se encontra na fase de implementação dos CRUD’s do painel  de controle do sistema, implementação inicial das telas do aplicativo e realização de testes  com tecnologias para melhor auxilio na parte administrativa do projeto.   5. REFERENCIAS  De La Rocha, Camila Rodrigues. (2014) “PROJETO TÔ DENTRO IFSUL:  a construção   da  identidade  do  aluno  - As  múltiplas  linguagens  de  pertencimento  ao  meio   acadêmico”, http://xanpedsul.faed.udesc.br/arq_pdf/996-0.pdf, Outubro.    IMS.  IMS Mobile in LatAm Study. Disponível na URL:  http://www.imscorporate.com/news/Estudios-comScore/IMS-Mobile-Study.  Janeiro2015.pdf. Data de último acesso: 24/04/2015.    ANDROID DEVELOPER TOOLS. Site Oficial. Disponível na URL:  https://developer.android.com/tools/studio/index.html. Data de último acesso:  23/04/2015.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   270        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 270-273 Nov/2015     Utilização da arquitetura de segurança IPSec no modo túnel  para a implementação de uma rede VPN de baixo custo   Neustlan A. de A. Junior1, Walter C. S. Simões2, Leonardo S. Valcácio1, Anderson T.  de Araujo1   1Tecnologia em Redes de Computadores – Centro Universitário do Norte (UNINORTE)   Caixa Postal 227 – 69020-220, Rua Huascar Figueiredo, s/n, Manaus – AM – Brasil   2(ICOMP), Universidade Federal do Amazonas (UFAM)  Av. General Rodrigo. Octávio, 6200, Coroado I, Manaus, AM, Brasil   Abstract. The current public networks have a certain native security of your  provider, ensuring data delivery to your recipients. But in the matter of security it  does not guarantee that their personal or corporative data being intercepted  along the way. This paper proposes the use of a method to the problem of  reliability in a public medium. The methodology is the implementation of the  IPSec security architecture in use over a VPN in tunnel mode with PfSense tool.  The result expected by the application of the technique is to provide encryption of  data sent and a relationship of trust between points, thus providing a higher level  of confidentiality in the network formed.   Resumo. As redes públicas atuais possuem uma certa segurança nativa do seu  provedor, garantindo a entrega de dados aos seus destinatários. Porém na  questão de segurança ele não garante que seus dados pessoais ou coorporativos  sejam interceptados no meio do caminho. Este trabalho propõe a utilização de um  método para o problema de confiabilidade em um meio público de comunicação.  A metodologia aplicada é a implementação da arquitetura de segurança do IPSec  sendo utilizada sobre uma VPN no modo túnel com a ferramenta PfSense. O  Resultado esperado pela aplicação da técnica é prover a criptografia dos dados  enviados e uma relação de confiança entre pontos, proporcionando assim um  nível maior de confidencialidade na rede formada.   1. Introdução  O Internet Protocol Security Protocol (conhecido por sua sigla IPSec) é uma extensão do  protocolo IP que visa ser o método padrão de privacidade do usuário aumentando a  segurança de informações fornecidas pelo meio da internet. IPsec é uma suíte de protocolos  que provê segurança no nível da camada IP para comunicações pela Internet. Opera sob a  camada de rede (ou camada 3) do modelo OSI. Outros protocolos de segurança da internet  como SSL e TLS operam desde a camada de transporte (camada 4) até a camada de  aplicação (camada 7), segundo Frankel et al, (2011).   As pesquisas realizadas neste artigo visam apresentar um sistema de interligação  Site-to-Site através da técnica VPN, neste cenário é aplicado o protocolo de segurança  IPSec, onde o mesmo garante a confiabilidade dos dados trafegados no canal. Essa solução  propõem a utilização de um hardware de baixo custo de aquisição e um nível de  processamento aceitável onde pode-se também aproveitar um desktop já obsoleto para  atividades comuns, com a configuração de 2Gb de memória ram, processador dual core, um  HD com baixo armazenamento ambos trabalhando com uma arquitetura X64, assim como a  ferramenta PfSense, que a mesma baseasse na distribuição do sistema operacional Unix     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   271        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 270-273 Nov/2015     FreeBSD. Aliando o hardware e a ferramenta de PfSense busca-se um resultado final  satisfatório pelo tempo empenhado e o investimento financeiro necessário.   2. Trabalhos Relacionados  Segundo Kurose, (2010), é valido considerar o sigilo na camada de rede entre um par de  entidades da rede, (dois roteadores, dois hospedeiros ou roteador e um hospedeiro), as  entidades enviam informações úteis de todos os datagramas que o remetente e a entidade  destinatária. A carga enviada pode ser tanto do segmento TCP quanto do UDP ou uma  mensagem ICMP. Se ambos serviços da camada de rede estiverem em funcionamento,  todos os dados de uma entidade a outra estariam ocultos de qualquer terceira parte que  possa estar analisando essa rede. Por esta razão a segurança na camada de rede é conhecida  por prover “cobertura total”, o que justifica a utilização do IPSec.   A escolha de uma ferramenta open source segundo José, (2013), é decorrente  diretamente a fatores de recursos de investimento disponíveis pois se trata de um sistema de  código aberto, além de redução de custos traz flexibilidade e praticidade para aplicar  conhecimentos na plataforma, dessa forma o administrador pode configurar um firewall de  forma muito mais segura e também respaldado em ocasiões de auditorias.   O IP Security fornece segurança para transmissões através de redes desprotegidas  segundo Wojcik, (2014), onde proporciona confidencialidade, integridade, autenticação e  proteção de Antireplay aos dados trafegados por meio da VPN estabelecida.   Os trabalhos relacionados descrevem a utilização do IPSec em uma conexão VPN,  onde os mesmos se propõem implementar e analisar o protocolo de segurança do IPSec e  verificação de suas características, assim como realizar testes de simulação do seu  funcionamento verificando os requisitos básicos da tecnologia. Assim como a  implementação da ferramenta de firewall do PfSense, onde o mesmo possibilita a formação  do canal de comunicação e a aplicação da arquitetura de segurança do IPSec.    3. Arquitetura Proposta  A Figura 1 ilustra a arquitetura proposta neste trabalho que é composta por: dois servidores  com o PfSense instalado, ambos com duas placas de rede inserido, uma para Lan e a outra  para conexão com a internet (Wan) logo pois também com a VPN, dois links de internet  sendo recebido pelo modem da sua devida operadora, repassando apenas um Ip válido para  a porta Wan do servidor correspondente. Para devidos testes da infraestrutura, é necessário  haver um computador em cada rede lan, para poder ser feita a comunicação entre as redes  distintas. No PfSense é configurado o firewall, onde o mesmo dita as políticas da rede local  e externa, e prover a conexão VPN aliado com o seu protocolo de segurança IPSec.   Cada servidor PfSense será responsável pela administração da sua rede local,  aplicando bloqueios em portas/serviços que se achar necessário para um melhor  desempenho na conexão local e trafego externo, ele também tem a principal função de  promover o túnel VPN, que promovido pela saída da placa Wan onde o mesmo é aplicado o  protocolo IPSec. A configuração de forma rígida e padronizada é necessária para minimizar  os pontos de falhas na rede onde possam gerar instabilidades na conexão proposta.                      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   272        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 270-273 Nov/2015                               Figura 1. Cenário geral do modelo.  O IPSec integra um mecanismo de aplicações de segurança necessários para garantir   confiabilidade no tráfego de dados, encriptação, autenticação ou a combinação de ambos,  como pode-se observar na Figura 2. A encriptação ocorre entre os dois hosts quando  iniciam a sua comunicação via internet, os dados que forem trafegados na rede Lan não são  encriptados, isso porque o tráfego será encriptado na camada IP pelo roteador (PfSense)  que se encarrega de enviar esses dados não encriptados da rede local para a internet via  VPN em forma cifrada.                             Figura 2. Demonstração do funcionamento do IPSec.     Na sequência apresentada Figura 2 é possível ver as definições de segurança que são  aplicadas no pacote onde contém as informações que são destinadas a um gateway, desta  forma a arquitetura de segurança se compromete em levar e trazer os dados em segurança  encriptando e decrepitando os dados de acordo com o seu gateway de destino.   4. Testes e Resultados  Os testes propostos devem seguir alguns parâmetros segundo Boava, (2010), tais como  habilitar interfaces, desconectar equipamentos da rede ou enviar pacotes de uma estação de  teste. O propósito ao testar a conectividade entre dois pontos de uma mesma VPN é  verificar a continuidade e qualidade do sinal transmitido, isso pode ser por meio de  comandos do ICMP a partir do emissor tentar enviar mensagens de PING para os endereços  IP de loopback de outros receptores na mesma VPN podendo retornar resultado positivo ou  negativo, posteriormente pode ser trafegado arquivos de maior extensão, para fins de  aferição de performance na rede, os dados podem ser colhidos e analisados.   Parâmetros de teste que podem ser adotados são teste de vazão, atraso, perdas de  pacote e jitter que por meio desses pontos abordados pode-se verificar melhorias a serem     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   273        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 270-273 Nov/2015     feitas, assim podendo proporcionar uma melhor entrega de sinal e performance no canal de  comunicação, assim verificando se há perda ou ganho de velocidade de transmissão.    Uma ferramenta que pode ser usado para gerar trafego segundo Boava, (2010), é o  iperf onde o seu fluxo pode ser configurado para o fluxo UDP com isso ter a mensura de  dados reais passando pelos pontos de comunicação de um gerador ao seu receptor,  conforme mostrado na Figura 3.                 Figura 3. Demonstração da arquitetura de teste.   Como continuidade nos testes de transmissão é necessário que se faça um teste no  inverso das pontas, também podemos observar na Figura 3, onde o receptor se torna  gerador e o gerador se torna receptor, com isso podemos observar se haverá pontos de  congestionamento na arquitetura referida, portanto podemos dizer que desta forma os testes  serão realizados em ambos os sentidos.   5. Conclusão   Com o a expansão das redes de computadores, e divulgações de informações em nuvens  pública, se torna mais evidente a necessidade de se proteger os dados de uma corporação,  assim como a interligação de uma a outra em tempo real, pois o mercado competitivo  requer informações rápidas e prontas de imediato, a proposta visou mostrar a interligação  de dois pontos de forma mais sucinta e segura, visando os baixos custos de investimentos e  a integridade de dados ao trafegar pelo meio proposto.   Como continuidade do trabalho será desenvolvido um manual de auxílio a  implementação da solução proposta, podendo assim ser de mais fácil entendimento e de  rápida aplicação em um ambiente real e de produção, podendo contribuir diretamente com  profissionais da área que passam por problemas semelhantes.   6. Referências  WOJCIK, Eduardo. Análise e Simulação de VPN com IPSec em Roteadores Cisco.   Curitiba, 2014   LEANDRO, Jefferson Ferreira. Estudo de Caso de Soluções em VPN IPSec com  Servidores Usando Software Livre. Curitiba, 2013   JOSÉ, Fernando Simplicio. Implementação de Firewall de Alta Disponibilidade Através do  PfSense. Passo Fundo, 2013   FRANKEL, S. N. KRISHNAN, S. E. IP Security (IPsec) and Internet Key Exchange (IKE)  Document Roadmap. M aryland, 2011   BOAVA, ADÃO. Avaliação da Qualidade de Serviço das VPN IP MPLS Para Redes de  Nova Geração (NGN). Campinas, 2010   INC, Cisco System. IPsec VPN WAN Design Overview. San Jose, 2006.   TANENBAUM, Andrew S. Redes de Computadores. Rio de Janeiro, 2003.   KUROSE, James G. Redes de Computadores e a Internet: uma abordagem top-down. São  Paulo, 2010.    
                                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   307        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 307-310 Nov/2015     Utilização de um Firewall com Controle de Acesso no Instituto  Federal Farroupilha – Campus Júlio de Castilhos   Diogo Otto Kunde1, Marcos Paulo Konzen2   1Instituto Federal Farroupilha – Campus Júlio de Castilhos – RS - Brasil  Caixa Postal 38 – 98.130-000 – Júlio de Castilhos, RS – Brazil   2Instituto Federal Farroupilha – Campus Alegrete – RS - Brasil  Caixa Postal 118 – 97.555-000 – Alegrete, RS – Brazil   diogokunde@hotmail.com, marcos.konzen@iffarroupilha.edu.br   Abstract. In educational institutions, the Internet has become a great ally,  enabling a breaking down of barriers to access to information. However, despite  the benefits it can present many risks for its users as well as the user itself can  pose a risk to the system where they are connected, accessing sites with  inappropriate content or committing irregularities, for example. Considering the  academic environment, information security becomes essential, and for this you  need to determine a way to keep the network and its users safe. The adoption of a  firewall is the most widely used solution and may represent a good layer of  protection   Resumo. Dentro das instituições de ensino, a Internet tornou-se um grande  aliado, possibilitando uma quebra de barreiras para o acesso à informação.  Contudo, apesar dos benefícios, ela pode apresentar diversos riscos para seus  usuários, assim como o próprio usuário pode representar um risco para a rede  em que está conectado, acessando sites com conteúdos impróprios ou cometendo  irregularidades, por exemplo. Considerando o ambiente acadêmico, a segurança  da informação se torna indispensável e, para isso é necessário determinar uma  forma de manter a rede e seus usuários seguros. A adoção de um Firewall é a  solução mais utilizada, podendo representar uma boa camada de proteção.   1. Introdução  Tendo como base o ambiente extremamente dinâmico da Internet, Ponte e Vieira (2008)  colocam-na como um elemento-chave para educação, onde ela funciona como uma espécie  de ferramenta para igualdade entre as diferentes classes sociais, visto que a mesma  informação está ao acesso de todos.   Atualmente, o acesso à Internet pelos alunos do IF-Farroupilha JC é constituído por  dez Laboratórios de Informática e pelos pontos de acesso sem fio distribuídos pelo Campus,  em que os alunos utilizam os seus próprios dispositivos para se conectar à Internet. Esse  acesso pode ocorrer tanto através da LAN (Local Area Network), quanto pela WLAN  (Wireless Local Area Network).   Mesmo já utilizando o pfSense como Firewall para a rede acadêmica, este se mostra  pouco explorado, não atendendo certos requisitos de segurança. Dentre os requisitos não  atendidos, está a filtragem do tráfego indesejado, que pode ser definido como “[...] qualquer  tipo de tráfego de rede não requisitado e/ou inesperado, cujo único propósito é consumir  recursos computacionais da rede, desperdiçar tempo e dinheiro dos usuários e empresas  [...]” (FEITOSA; SADOK; SOUTO, 2008, p. 15). Além do tráfego indesejado, existe a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   308        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 307-310 Nov/2015     falta de mecanismos de autenticação, permitindo com que qualquer pessoa que esteja ao  alcance de uma das redes sem fio possa utilizá-la sem a necessidade de identificação.   Assim, espera-se resolver essas deficiências com a adição de uma camada de  autenticação, através do Captive Portal, e da ampliação do uso de mecanismos de filtragem  de conteúdo, através da utilização do Firewall (pfSense) em conjunto com o Squid (proxy) e  SquidGuard (filtro de conteúdo).   2. Referencial Teórico   Atualmente, a Internet funciona através do Modelo de Referência TCP/IP, que é divido nas  seguintes camadas: camada física, de enlace, de rede, de transporte e de aplicação. Este  estudo abordará, principalmente, questões relacionadas a camada de rede, transporte e de  aplicação. A camada de rede está diretamente ligada a transferência dos pacotes entre  origem e destino, incluindo os protocolos de roteamento e também o IP (Internet Protocol).  A camada de transporte permite a comunicação entre as diferentes máquinas, ou seja, faz o  transporte das mensagens enviadas por elas, de modo que o que foi enviado pelo remetente  seja entregue ao destinatário. Já a camada de aplicação contém os protocolos de níveis mais  altos, atuando diretamente nas aplicações da rede, como é o caso do HTTP, FTP, etc  (TANENBAUM; WETHERALL, 2011).    “A segurança da informação é a área do conhecimento dedicada à proteção de ativos  da informação contra acesso não autorizados, alterações indevidas ou sua disponibilidade.”  (SÊMOLA, 2014, p. 41). Quando o assunto é segurança de redes de computadores, uma  propriedade que pode ser destacada é a autenticação. No dia a dia, as pessoas realizam  autenticação de diversas formas, reconhecendo a voz e aparência física de outras pessoas,  por exemplo. No ambiente de redes, a autenticação é muito importante, pois através dela é  possível gerenciar autorizações e realizar auditorias (KUROSE; ROSS, 2013).    Para controlar o tráfego de uma rede, ferramentas como firewalls são as aplicações  mais utilizadas. Firewall é um conjunto de hardware e software que tem por objetivo  manter uma rede interna protegida da Internet (rede externa). Ele possui três princípios  básicos: todo tráfego, tanto de dentro para fora quanto de fora para dentro, da rede deve  passar por ele; o tráfego autorizado é o único que poderá passar por ele sem ser bloqueado;  o Firewall deve ser impenetrável (KUROSE; ROSS, 2013).   3. Metodologia   O presente estudo visa aplicar controles de segurança sobre a rede utilizada pelos alunos  para acesso à Internet no Instituto Federal Farroupilha – Campus Júlio de Castilhos, de  maneira que, além de fornecer maior segurança a eles a partir da adição de uma camada de  autenticação e da filtragem de conteúdos acessados, bloqueie sites considerados impróprios.  A metodologia do trabalho pode ser divida em duas fases: fase de testes e implantação.   Na fase testes foram utilizadas máquinas virtuais (VM's). As máquinas virtuais  foram criadas utilizando-se Oracle Virtualbox, ferramenta gratuita para virtualização de  sistemas. Através dela é possível simular o ambiente de rede de computadores. Utilizando  um ambiente virtual é possível realizar modificações e experimentos que não seriam  possíveis em ambiente real, pois comprometeria o funcionamento da rede, prejudicando a  conectividade dos usuários. Nesse ambiente (Figura 1) foram criadas duas máquinas  virtuais com a função de servidor, um firewall (gateway) e um servidor Radius (que  também será como servidor web), além de uma máquina para simular as ações do usuário.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   309        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 307-310 Nov/2015       Figura 15. Ambiente Virtual   O projeto pfSense é um software livre, licenciado sob a Licença BSD, baseado no  sistema operacional FreeBSD, personalizado para trabalhar como Firewall. Porém, suas  funcionalidades vão muito além das de um simples Firewall, podendo exercer o papel de  roteador, trabalhar com VPN's, Sistemas de Detecção de intrusão, e muito mais. Como  Firewall, ele pode desempenhar a função de Filtro de Pacote e Gateway de Aplicação  (proxy) (PFSENSE, 2015).    Após instalado, o pfSense pode ser configurado através de uma interface web.  Atualmente possui dezenas de pacotes de software livre de terceiros para funcionalidades  adicionais, como, por exemplo, o Squid (proxy).    Para realizar autenticação dos usuários na rede, o próprio pfSense conta com uma  ferramenta pré-instalada, o Captive Portal. O Captive Portal faz a captura da conexão  através do Firewall, com o objetivo de garantir que o usuário não possua  acesso à Internet  caso não esteja autenticado. Para isso foi utilizada a opção de servidor Radius, que  armazenará os dados de autenticação dos usuários. Para administrar os dados de usuário no  servidor Radius, foi desenvolvido um sistema web. Esse sistema é responsável pelo  cadastro de novos usuários, edição dos dados cadastrais e recuperação de senha.   O Squid e SquidGuard são responsáveis, respectivamente, pelos papéis de proxy e  filtro de conteúdo. O Squid tem o papel de servidor proxy, interceptando as conexões e  armazenando o cache das páginas acessadas. Ele foi configurado em modo transparente, o  que evita ter que configurar o navegador cliente para utilizá-lo.    Já o SquidGuard desempenhará a tarefa de filtro de conteúdo, através da criação de  ACL's (Acess Control List). A utilização do SquidGuard permite utilizar Blacklists  (metodologia onde as URLs são armazenadas em um banco de dados e relacionadas com  suas categorias, conforme seu conteúdo) em suas ACL's. A função Times permite criar  diferentes horários, conforme a necessidade, de modo que é possível determinar um período  de tempo para o funcionamento e relacioná-lo com uma ACL. Por exemplo, uma ACL que  bloqueie redes sociais pode permanecer ativa durante o período de aula, mas ficar inativa  durante os períodos de intervalo, permitindo o acesso somente nesses horários.   As regras (rules) são utilizadas para controlar o tráfego, através delas que se  gerenciam as portas e serviços acessíveis pela rede. Também podem ser utilizadas para  bloquear sites específicos, o que acaba suprindo a deficiência do pacote Squid instalado no     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação   310        Anais do EATI Frederico Westphalen - RS     Ano 5 n. 1 p. 307-310 Nov/2015     pfSense, que não realiza a filtragem de conteúdo em sites que utilizam HTTPS. Com a  criação de aliases, essa torna-se uma ótima opção.   4. Considerações Finais   O trabalho encontra-se no início de sua implantação em ambiente real. Foi realizada  a importação dos dados de autenticação dos alunos do ambiente virtual de aprendizado, o  Moodle, para o servidor Radius. Essa integração é um passo importante para que os alunos  não tenham que criar novos usuários para autenticação no Captive Portal. Futuramente,  espera-se também utilizar o servidor Radius para autenticação do próprio ambiente virtual,  de modo que ocorra a integração e unificação desses dados de usuário.   Por fim, com a implantação espera-se alcançar melhorias no acesso à Internet,  destacando-se o aumento na questão de segurança da informação para promover eficiência  na utilização das tecnologias de informação no processo de aprendizagem.   Referências   FEITOSA, E. L.; SOUTO, Eduardo; SADOK, Djamel. Tráfego Internet não Desejado:  Conceitos, Caracterização e Soluções. Livro-Texto dos Minicursos do VIII Simpósio  Brasileiro de Segurança da Informação e de Sistemas Computacionais, p. 91-137, 2008..   KUROSE, J. F.; ROSS, K. W. Redes de computadores e a Internet: uma abordagem topdown. Tradução Daniel Vieira. 6. ed. São Paulo: Pearson Education do Brasil, 2013.   PFSENSE. Disponível em:<http:///www.pfsense.org>. Acesso em: 05 set. 2015.   PONTE, C.; VIEIRA, N. Crianças e Internet, riscos e oportunidades. Um desafio para a  agenda de pesquisa nacional. In: Comunicação e Cidadania. Actas do 5º Congresso da  SOPCOM. 2008. p. 2732-2741.   SÊMOLA, M. Gestão da Segurança da informação: uma visão executiva. Elsevier Brasil,  2014.   TANENBAUM, A. S; WETHERALL, D. J. Redes de Computadores. 5. Ed. São Paulo:  Pearson Prentice Hall, 2011.    
