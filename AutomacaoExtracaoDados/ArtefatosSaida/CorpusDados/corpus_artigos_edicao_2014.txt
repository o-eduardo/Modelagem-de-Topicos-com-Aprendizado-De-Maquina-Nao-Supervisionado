                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 281-285 Nov/2014       281  Um Comparativo entre Ferramentas para o Desenvolvimento  de Jogos Educativos Computacionais   Rogério Paulo Marcon Júnior, Giani Petri   Curso de Tecnologia em Sistemas para Internet(TSI)   Universidade Federal de Santa Maria(UFSM)   Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS – Brasil  rpjunior_1@hotmail.com, gpetri@inf.ufsm.br   Abstract: In current times, the area within the disciplines of computer science,  games are being used to assist learning, these games can be computational or  not computational, but for creating a computational game, should be a  development platform. This paper presents some tools and show its  advantages and limitations in the digital educational games development.   Resumo: Nos tempos atuais, dentro das disciplinas da área de Ciência da  Computação, estão sendo utilizados jogos para auxiliar no aprendizado, estes  jogos podem ser computacionais ou não computacionais, porém para a  criação de um jogo computacional, deve haver uma plataforma de  desenvolvimento. Este trabalho objetiva apresentar algumas ferramentas e  mostrar suas vantagens e limitações no desenvolvimento de jogos  educacionais digitais.   1. Introdução  Ferramentas de desenvolvimento são de uso comum para desenvolvimento de jogos  voltados ao lazer, porém, em alguns casos, estão sendo utilizadas para desenvolvimento  de jogos computacionais voltados ao auxílio no processo de ensino e aprendizagem.  Esta prática ainda se encontra tímida, porém, aos poucos está tentando se introduzir nos  métodos de aprendizagem atuais.    No entanto, pode-se encontrar várias ferramentas que podem ser utilizadas para  estes fins, cada qual com sua característica específica que pode, ou não ser de bom uso  ao desenvolvedor. Com isso, uma boa maneira de descobrir qual seria a mais adequada  para o desenvolvimento é um estudo qualitativo de cada uma, focando em o que ela  pode fazer, identificando suas vantagens e suas limitações. Desta forma, este trabalho  objetiva apresentar os resultados de um estudo comparativo entre ferramentas  computacionais para o desenvolvimento de jogos educacionais digitais.   Os resultados preliminares deste trabalho apresentam as vantagens e as  limitações das ferramentas, podendo ser usado como referência para desenvolvedores de  jogos educacionais digitais.   2. Jogos Educativos  Dentro de algumas disciplinas da área de Ciência da Computação, mais precisamente  dentro da área de Engenharia de Software, jogos educativos são muito utilizados para o  desenvolvimento de certas habilidades (cooperação, liderança, comunicação, entre     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 281-285 Nov/2014       282  outros), os jogos utilizados hoje em dia, dividem-se em jogos computacionais e não  computacionais.   No entanto, com o uso de jogos computacionais, o educador pode facilmente  moldar o ambiente de aprendizado para se adequar ao assunto abordado, e avaliar cada  educando individualmente, testando-o para ver como reage a solução de problemas.   3. Metodologia  A metodologia que constitui este trabalho baseia-se em uma pesquisa básica qualitativa,  para identificar as plataformas de desenvolvimento com maior número de  desenvolvedores presentes em fóruns e grupos de desenvolvimento. Para identificar as  ferramentas para serem objetos de estudo, foram efetuados testes de desenvolvimento de  pequenas aplicações, assim podendo identificar se as ferramentas eram ou não próprias  para um jogo educativo, enfatizando suas vantagens e suas limitações.   4.Descrição do Experimento  Nesta seção será descrito brevemente como os experimentos foram realizados  utilizando ferramentas de desenvolvimento de jogos. Nos experimentos, jogos  plataformas (jogos onde o personagem pula entre plataformas) foram  desenvolvidos em cada ferramenta.  4.1 Cocos2D  Com a utilização da ferramenta Cocos2D [Cocos2D 2014], foi realizado um  simples experimento de desenvolvimento de um jogo plataforma utilizando a sua  versão IDE baseada em linguagem LUA. Nas Figuras 1 e 2, é apresentado o  resultado e uma parte do código principal.     Figura 1. Código Fonte Principal.     Figura 2. Resultado.   4.2 Construct2  Utilizando a ferramenta Construct2 [Construct2 2014] e o método de Drag and  Drop, o jogo plataforma foi desenvolvido com a adição de elementos sendo  arrastados e seus movimentos sendo inseridos através da inserção de eventos. As  Figuras 3 e 4 apresentam o experimento desenvolvido usando o Construct2.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 281-285 Nov/2014       283    Figura3. Eventos.     Figura 4. Resultado.   4.3 Phaser   Utilizando o framework Phaser [Phaser 2014], o jogo de teste foi desenvolvido  utilizando a IDE NetBeans com a linguagem JavaScript. As Figuras 5 e 6  apresentam o experimento desenvolvido usando o framework Phaser.     Figura 5. Código Principal.     Figura 6. Resultado.   4.4 Stencyl  Utilizando o Stencyl [Stencyl 2014], o teste foi desenvolvido com o método Drag  and Drop, com a inserção de eventos e comportamentos para os elementos do  jogo, o uso de um kit de imagens também foi utilizado. As Figuras 7 e 8  apresentam o experimento desenvolvido usando o Stencyl.     Figura 7. Desenvolvimento da cena.    Figura 8. Comportamentos.   5. Comparativo entre as Ferramentas  Nesta seção encontram-se os resultados preliminares das pesquisas referentes as  ferramentas, que serão apresentadas na Tabela 1. A tabela se estrutura da seguinte  forma: a primeira coluna apresenta um identificador de cada ferramenta, a segunda  coluna apresenta o nome da ferramenta, a terceira coluna refere-se às vantagens  encontradas, a quarta coluna apresenta as principais limitações encontradas nas  pesquisas e nos testes de desenvolvimento e a quinta coluna, apresenta o modo e  linguagem de desenvolvimento.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 281-285 Nov/2014       284  Tabela 1. Ferramentas de desenvolvimento   ID Nome Principais  Vantagens   Principais  Limitações   Modo de  Desenvolvimento   1 Construct2 [Construct2  2014]   Grande quantidade  de plataformas para  uma aplicação final   Versão free com  poucos recursos   Drag and Drop com a  inserção de eventos   2 Stencyl [Stencyl 2014] Interface  organizada,  facilidade na  inserção de objetos   Desenvolvimento  com restrição de  eventos   Drag and Drop com a  inserção de eventos   3 Cocos2d [Cocos2d 2014] Possui  crossplataform,  open source, leve,  fácil aprendizado  das APIs   Grande quantidade  de tempo exigida  para o  desenvolvimento   JavaScript e Lua   4 Phaser [Phaser 2014] Desenvolvimento  simples devido à  linguagem utilizada,  fórum de  publicações   Demanda grande de  tempo e codificação   JavaScript    Com a utilização de ferramentas como Stencyl ou Construct2, torna-se simples a  criação de uma aplicação devido ao Drag and Drop, com apenas alguns cliques, eventos  e animações já estão prontas, porém, devido a isso, algumas aplicações podem ser  prejudicadas devido a criação desses eventos, tornado-as assim, ferramentas um tanto  quanto problemáticas na hora de criar um certo evento mais complicado, já ferramentas  como Cocos2D e Phaser, que enquadram-se na categoria de frameworks, porém  Cocos2D possuindo uma versão IDE, tornam a criação de eventos mais complicadas,  simples, devido ao seu método de programação, porém com isso, o desenvolvedor  precisa demandar muito tempo para a criação da aplicação, pois, além da programação,  deve-se criar os sprites e animações com códigos.   Todos estes aspectos foram descobertos através de testes, criações de aplicações,  trabalhos acadêmicos, pesquisas e leituras de manuais. Estes testes basearam-se,  basicamente, na criação de jogos voltados ao auxilio de aprendizagem, os quais  deveriam ter elementos muito específicos, assim, identificando quais seriam suas  vantagens e limitações para o desenvolvimento de um jogo educacional.   5. Conclusão  Com a utilização de jogos computacionais em um ambiente acadêmico, o orientador  pode moldar o seu método de ensino do jeito que desejar, para tornar suas aulas mais  dinâmicas e treinar habilidades básicas exigidas dentro do próprio ambiente acadêmico,  como também habilidades exigidas fora dele. Pode-se também utilizar jogos de auxilio  em matérias básicas, incentivando a criatividade e resolução de problemas. A utilização  dos mesmos não se restringe apenas ao ambiente acadêmico, com a mobilidade hoje em  dia, os jogos educativos podem ser utilizados em qualquer lugar desejado.   Portanto, conclui-se que a escolha de uma ferramenta computacional para o  desenvolvimento de jogos educacionais digitais é uma decisão estratégica no processo  de criação de novas estratégias de ensino. Assim, este trabalho apresentou as principais  vantagens e limitações encontradas durante alguns testes básicos das ferramentas e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 281-285 Nov/2014       285  serve como apoio para auxiliar a tomada de decisão de escolha de ferramentas usadas no  desenvolvimento de novos jogos educacionais digitais construídos para auxiliar os  professores e alunos envolvidos no processo de ensino e aprendizagem.   Referências  Cocos2d. (2014). Cocos2D - Thousand of Games. Disponível em: http://www.cocos2d x.org/. Acesso em: 05 set. 2014.   Construct 2. (2014). Construct 2 - Create Games Effortlessly. Disponível em:  https://www.scirra.com/. Acesso em: 05 set. 2014.   Phaser.(2014). Phaser - Desktop and Mobile HTML5 Game Framework.Disponívelem:  http://phaser.io/.Acessoem: 05 set. 2014.   Stencyl. (2014). Stencyl - Create Amazing Games Without Code. Disponível em:  http://www.stencyl.com/. Acesso em: 05 set. 2014.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 286-289 Nov/2014     286  Sistema de Recomendação Mobile: Um Estudo de Caso para  Delivery     Marcelo Garbin, Sidnei Renato Silveira   marcelo.garbin@hotmail.com, sidneirenato.silveira@gmail.com      Universidade Federal de Santa Maria (UFSM) – Centro de Educação Superior Norte do  RS (CESNORS) – Frederico Westphalen - RS   Departamento de Tecnologia da Informação – Curso de Bacharelado em Sistemas de  Informação      Abstract. This paper presents a proposal for the development of a  recommender system for delivery mobile solution. The proposed system allows  the user to make orders, accompany, to consult historic of your order, and to  have recommendations for future purchases based on your profile. The  technologies used for the development of this system will be PHP, JavaScript,  HTML5 with CSS3, using the resources of the Phonegap framework with  integration of MySQL and SQLite.    Resumo. Este artigo apresenta uma proposta para o desenvolvimento de um  sistema de recomendação mobile para delivery. O sistema proposto possibilita  que o usuário possa realizar, acompanhar e consultar o histórico de seus  pedidos, além de receber recomendações para futuras compras de acordo com  seu perfil. As tecnologias utilizadas para o desenvolvimento deste sistema  serão PHP, JavaScript, HTML5 com CSS3, utilizando os recursos do  framework Phonegap com a integração dos bancos de dados MySQL e  SQLite.     1. Introdução  Esse trabalho tem seu objetivo motivado na modernização e utilização de sistemas de  informação no comércio local (Frederico Westphalen e região), bem como no emprego  de novas tecnologias, especialmente as que compreendem a computação móvel. Dentre  as tecnologias que estão em ascensão, tanto para uso pessoal quanto para uso  empresarial, estão às voltadas para dispositivos móveis, os quais se destacam por sua  comodidade e versatilidade, impactando assim em uma nova oportunidade de  aproximação entre clientes, empresa e serviços, tornando-se um dos principais fatores  para o acréscimo da tecnologia nos dias atuais.    A solução proposta neste artigo envolve o desenvolvimento de um sistema de  recomendação, utilizando recursos de computação móvel (plataf’’orma mobile).  Baseando-se nas preferências do usuário, os sistemas de recomendação surgem como  aliados na busca de novos itens de consumo de acordo com o interesse indicado pelo  usuário, fazendo com que estes sistemas sejam amplamente utilizados como uma  estratégia na potencialização de novos negócios (SOUZA, 2012).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 286-289 Nov/2014     287     2. Referencial Teórico  Segundo Cirilo (2007), a computação móvel consiste em sistemas computacionais  distribuídos em diferentes dispositivos que se comunicam entre si por meio de uma rede  de comunicação sem fio, o que permite a mobilidade desses aparelhos. O usuário, então,  é capaz de utilizar os serviços que um computador oferece independente de sua  localização física.   Um dos fatores relevantes para o crescimento na utilização  de dispositivos móveis está ligado à utilização da Internet, bem como games e redes  sociais, como por exemplo o Facebook (KHALAF, 2014).    As aplicações que se utilizam da tecnologia móvel propiciam a melhoria de  atividades comuns. Por exemplo, em um sistema para delivery, onde em qualquer  cenário, casa, escritório, ou até mesmo no automóvel, com a utilização de um  dispositivo móvel é possível fazer pedidos online na pizzaria mais próxima, em tempo  real na comodidade de seu ambiente e com a possibilidade de pagamento remoto e ainda  receber sua pizza em sua casa ou qualquer outro local de possível entrega, sem se quer  fazer algum esforço a mais por isso.   Sistemas de Recomendação (SR) são ferramentas de software e técnicas que  fornecem sugestões de itens para serem de utilidade de um usuário. As sugestões  referem-se a vários processos de tomada de decisão, tais como quais itens compatíveis  com o interesse estão disponíveis para se comprar, sugestão de música para ouvir, ou  quais notícias on-line são destaques e que são de interesse para ler (SOUZA, 2012).      Para que um sistema de recomendação possa recomendar  os itens mais adequados aos usuários, podem-se utilizar diferentes técnicas de  recomendação, dentre as quais destacamos a filtragem baseada em conteúdo e a  filtragem colaborativa (TORRES, 2004):    Na filtragem baseada em conteúdo, o sistema recomenda itens que são  semelhantes aos que o usuário gostou no passado. A semelhança de itens é  calculada com base nas características associadas com os itens comparados;     A filtragem colaborativa consiste na recomendação de itens que pessoas com  gosto semelhante preferiram no passado. Analisa-se a vizinhança do usuário a  partir da regra: "Se um usuário gostou de A e de B, um outro usuário que gostou  de A também pode gostar de B".     3. Solução Proposta  A solução proposta neste trabalho tem por finalidade a implementação de um aplicativo  de delivery para dispositivos móveis. Com o crescimento da utilização de dispositivos  móveis e o uso cada vez maior da Internet, a modernização e utilização de sistemas  gerenciais no comércio local, cedo ou tarde, tende a ser inevitável.   A Figura 1 apresenta uma arquitetura proposta para a implementação do  protótipo do sistema de recomendação.   Para que seja possível um melhor conhecimento de perfil de cada usuário do  sistema, os dados serão coletados de forma explícita. Quando um novo usuário efetuar  seu cadastro no sistema, será solicitado que o mesmo entre com suas preferências de  sabores das pizzas. Após efetuar o cadastro, caso as recomendações oferecidas pelo     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 286-289 Nov/2014     288  sistema não forem mais compatíveis com as preferências do usuário, o mesmo poderá  editá-las em seu perfil.     Figura 1. Arquitetura do Sistema Proposto (Fonte: Do autor)      Os tipos de filtragem que serão empregadas neste sistema são a baseada em  conteúdo e a colaborativa. Na filtragem baseada em conteúdo, serão utilizadas as  avaliações dos produtos que o usuário fez anteriormente como base. Na filtragem  colaborativa, se um usuário possuir as preferências semelhantes a outros, será  demonstrada uma lista das pizzas que foram bem avaliadas e também das piores  avaliadas pelos demais usuários. As avaliações de itens proposta neste trabalho será  feita da seguinte forma: após o usuário efetuar o pedido e a entrega ser concluída no  sistema, o usuário poderá dar uma nota de 1 a 5, para o serviço de entrega como  também para os itens/produtos comprados. Sendo a nota 1 ruim, 2 regular, 3 bom, 4  muito bom e nota 5 excelente. Assim será possível gerar uma lista de melhores e piores  itens avaliados.   Algumas das tecnologias empregadas para o desenvolvimento para dispositivos  mobile foram estudadas e selecionadas para o desenvolvimento desta proposta. A  linguagem de programação atualmente mais utilizada para desenvolver aplicativos para  sistema Android é o Java. O sistema operacional Android é um dos mais utilizados em  dispositivos móveis (IDC, 2014).    A aplicação a ser desenvolvida será dividida nos seguintes módulos:  Implementação do Banco de Dados: será utilizado o banco de dados SQLite para o  aplicativo mobile, sendo que o banco de dados principal será o MySQL. O banco de  dados principal servirá para gerenciar os cadastros, consultas e relatórios de acordo com  a proposta do trabalho; Administração do Sistema: criação de um módulo de  administração do sistema. Neste módulo será possível cadastrar e gerenciar informações  dos produtos, gerenciar pedidos, gerenciar usuários, visualizar relatórios; Aplicativo  Mobile: criação de um aplicativo mobile utilizando o framework Phonegap. Neste  aplicativo poderá ser feito o cadastro de um novo usuário, configuração de perfil,  escolha de produtos para efetuar um pedido, recomendações de produtos,  acompanhamento do pedido; Web Site: criação de um web site utilizando frameworks     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 286-289 Nov/2014     289  para o auxílio no desenvolvimento da aplicação. Este web site visa o atendimento de  usuários que não possuem um dispositivo móvel.   Uma das tecnologias empregadas neste trabalho envolve o framework  Phonegap. Esta tecnologia é Open Source que tem como principal característica  desenvolver aplicativos webapp, que são web sites similares a aplicativos nativos e que  utilizam de funcionalidades das plataformas móveis. O desenvolvimento com o  Phonegap pode gerar aplicativos funcionais para ambientes tanto online como off-line  (AMBROS, 2013).  Após o desenvolvimento do sistema, será feita a validação do  mesmo junto ao gerente do comércio escolhido. O gerente poderá acompanhar o  funcionamento do sistema e efetuar um relatório de quais os prós e contras após a  implementação do sistema para o seu negócio.     4. Considerações Parciais  Na continuidade do trabalho proposto, será realizado um estudo mais detalhado sobre as  tecnologias que serão utilizadas para o desenvolvimento do sistema. Tal estudo abordará  as linguagens, sintaxes e banco de dados que serão utilizadas para a implementação do  mesmo. Será feita a implementação na plataforma web e mobile através do uso de  frameworks como CodeIgniter, Bootstrap, Jquery Mobile e Phonegap. Após a  implementação do sistema serão realizados testes e a validação do mesmo.     Referências  Ambros, Luisa (2014). “Diferença entre Aplicativos Nativos, Híbridos e Mobile Web   Apps”. Disponível em: <http://luisaambros.com/blog/diferenca-entre-aplicativos-  nativos-hibridos-e-mobile-web-apps>. Acesso em 23 jun. 2014.  Cirilo, Carlos Eduardo (2007). “Computação Ubíqua: definição, princípios e   tecnologias”. 2007. Disponível em:  <https://www.academia.edu/1733697/Computacao_Ubiqua_definicao_principios_e _tecnologias>. Acesso em: 18 abr. 2014.   IDC, International Data Corporation (2014). “Android and iOS Continue to Dominate  the Worldwide Smartphone Market with Android Shipments Just Shy of 800  Million in 2013, According to IDC”. Disponível em:  <http://www.idc.com/getdoc.jsp?containerId=prUS24676414>. Acesso em: 10 abr.  2014.   Khalaf, Simon (2014). “Apps Solidify Leadership Six Years into the Mobile  Revolution”. Disponível em: <http://www.flurry.com/bid/109749/Apps-SolidifyLeadership-Six-Years-into-the-Mobile-Revolution#.U6libkAelGN>. Acesso em: 18  abr. 2014.   Souza, Renata Ghisloti Duarte (2014). “Sistemas de Recomendação: Aplicando  Sistemas de Recomendação em Situações Práticas”.  <http://www.ibm.com/developerworks/br/local/data/sistemas_recomendacao>.  Acesso em: 10 abr. 2014.   Torres, R. (2004) “Personalização na Internet: como descobrir os hábitos de consumo  de seus clientes, fidelizá-los e aumentar o lucro de seu negócio”. São Paulo:  Novatec.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 290-294 Nov/2014       290  Questionário Eletrônico em Ambiente Android Para Coleta  de Dados   Leonildo José de Melo de Azevedo1, Mauro Miazaki1, Andres Jesse Porfirio2   1Departamento de Ciência da Computação – Universidade Estadual do Centro-Oeste  (UNICENTRO) Caixa Postal 85.040-080 – Guarapuava – PR – Brasil   2Departamento de Tecnologia em Sistemas para Internet – Universidade Tecnológica  Federal do Paraná (UTFPR) Caixa Postal 85.053-510 – Guarapuava – PR – Brasil   leonildo.azevedo@hotmail.com, maurom@unicentro.br,  andresjesse@yahoo.com.br   Abstract. Despite the importance and wide use of questionnaires, both in  socio-economic and scientific fields, little has been invested. Currently, the  physical questionnaires (in paper) require lots of time at the interview process  and analysis of the results. In this context, electronic questionnaires are  promising solutions. However, the available electronic questionnaires usually  have limitations in accessibility, usability and portability. In order to solve or  at least minimize such problems, the e-Form is proposed in this work, an  Android application for data acquisition. In the performed test case, the eForm solution obtained a time reduction of more than two times, as well as the  elimination of human error in the process.  Resumo. Apesar da importância e da vasta utilização de questionários, nos  campos socioeconômico e científico pouco se tem investido. Atualmente, os  questionários físicos (em papel) demandam muito tempo para aplicação e  análise dos resultados. Neste contexto, questionários eletrônicos se  apresentam como soluções promissoras. Contudo, os questionários  eletrônicos disponíveis geralmente possuem limitações de acesso, utilização e  portabilidade. Visando solucionar ou, pelo menos, minimizar esses problemas,  neste trabalho é proposto o e-Form, um software em ambiente Android para  coleta de dados. Nos testes realizados, o e-Form gerou uma redução de tempo  de mais de duas vezes, além da eliminação de erro humano no processo.   1. Introdução  Muitas pesquisas são conduzidas e planejadas, tanto em meio socioeconômico como em  meio científico, utilizando-se de questionários como um dos principais instrumentos de  investigação. Sua vasta utilização ocorre devido a sua versatilidade, além de sua relativa  facilidade de aplicação (Omote, Prado, Carrara, 2005); (Vasconcellos & Guedes, 2007);  (Goode & Hatt, 1972). Atualmente, ainda são muito utilizados questionários impressos  em papel. O processo inicia-se com a elaboração de um questionário ou a reutilização  de um já pronto. Com os questionários impressos, é feita a coleta de dados em campo.  Em seguida, os dados são digitados, tabulados e, armazenados em planilhas eletrônicas  ou utilizando outros softwares, para uma análise posterior. Por fim, os dados são  validados e estatisticamente analisados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 290-294 Nov/2014       291   As etapas de digitação e tabulação de dados podem levar semanas, além de  serem bastante suscetíveis a erros. Em um processo totalmente eletrônico, a etapa de  digitação é eliminada, pois a aquisição do dado já é em formato eletrônico. Além disso,  a tabulação é automaticamente realizada, de forma instantânea, eliminando erros  decorrentes do processo manual. Com a redução de erros também se facilita e reduz o  tempo necessário para validação e realização de possíveis correções nos dados. Outro  problema é referente à persistência dos dados, que em sua maioria não são confiáveis e  muito menos possuem sistemas de backup.   Além disso, os questionários eletrônicos possuem várias vantagens: facilidade,  flexibilidade e diversidade na elaboração de questões; questões multimídia, com  imagens, sons e vídeos; agilidade na aplicação e controle de respostas; possibilidade de  se exigir resposta de algumas questões específicas ou do questionário completo;  facilidade de se utilizar e gerenciar maiores amostras; entre outras (Evans & Mathur,  2005); (Hipólito et al, 1996). Apesar de todas essas vantagens, a grande maioria dos  questionários eletrônicos está disponível apenas em meio online, ou seja, são acessados  apenas pela internet, possuem formulários pouco atrativos e ainda possuem certas  limitações, que prendem o investigador a criar apenas determinados tipos de questões  ou ainda feito apenas para uma determinada plataforma (Vasconcellos & Guedes,  2007); (Omote, Prado, Carrara, 2005).    Nesse contexto, o objetivo deste projeto é o desenvolvimento do e-Form, um  sistema eletrônico offline de criação e gerenciamento de questionários para coleta de  dados através de dispositivos móveis. Assim, pretende-se resolver ou pelo menos  minimizar os problemas encontrados em questionários impressos e em questionários  eletrônicos disponíveis no mercado. Este é um projeto em andamento. Neste artigo,  serão abordados o protótipo do aplicativo para coleta de dados, desenvolvido para  Android (Android Open Source, 2014), e os resultados preliminares obtidos em testes  realizados.    Na Seção 2, são apresentados os materiais e métodos utilizados. Na Seção 3, são  apresentados os testes de coleta de dados realizados, que permitiram avaliar as  vantagens da abordagem de uso do questionário eletrônico desenvolvido em relação ao  processo em papel. Finalmente, na Seção 4, são abordadas as conclusões do trabalho.   2. Materiais e Métodos   2.1. Questionários  Os questionários são uma técnica de investigação que têm sido largamente utilizados  como ferramentas em pesquisas. Tanto em pesquisas socioeconômicas como em  pesquisas científicas, os questionários são aplicados como uma maneira de coletar  informações para investigar uma determinada população sobre um determinado assunto,  auxiliar no acesso a eventos ocorridos, definir perfis socioeconômicos, caracterizar  hábitos e comportamentos, entre outros fins. Portanto, os questionários são utilizados  como recursos instrumentais em pesquisas sobre um assunto específico, com o objetivo  de auxiliar o pesquisador em diversos diagnósticos (Omote, Prado, Carrara, 2005);  (Vasconcellos & Guedes, 2007).    Além de sua utilização em pesquisas, os questionários têm diferentes  características, podendo ter perguntas subjetivas (abertas), perguntas objetivas     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 290-294 Nov/2014       292  (fechadas), perguntas híbridas (ambas), ou ainda perguntas derivadas dos tipos  supracitados. Cada um dos principais tipos de perguntas (abertas ou fechadas) possui  sua complexidade, seja na elaboração (objetivas) ou na análise de dados (subjetivas).  Contudo, ambas podem gerar resultados confiáveis, desde que sigam uma metodologia  adequada (Converse & Presser, 1986).   2.2. e-Form  O e-Form será composto de: um assistente gerador de questões, a partir de tipos de  questões pré-definidos; um assistente gerador de questionários, que se utiliza do  gerador de questões para compor um questionário; um sistema de coleta de dados em  Android (Android Open Source, 2014); um gerenciador de dados, responsável por  unificar e armazenar os dados coletados em dispositivos móveis; e um assistente  gerador de tabelas, que permitirá exportar tabelas com os dados selecionados.   No estágio atual deste projeto, encontra-se desenvolvido em Android o sistema  de coleta de dados, que permite exibir questionários, preenchê-los, e armazenar as  respostas provisoriamente no dispositivo móvel (que posteriormente deverão ser  exportadas para o gerenciador de dados, em fase de desenvolvimento). Para as  execuções dos testes neste trabalho, os questionários foram montados manualmente em  um arquivo xml (que futuramente será criado pelo gerador de questionários). Este  arquivo é lido pela aplicação Android, que gera as telas de visualização das questões  para preenchimento.    O sistema de coleta de dados é composto por apenas uma Activity (janela), nessa  Activity são acoplados vários Fragments (equivalentes a uma Acticity), cada Fragment  corresponde a uma questão do questionário ou telas iniciais. Os dados são armazenados  no dispositivo utilizando SQLite (uma biblioteca que implementa um banco de dados  SQL), na aplicação foi implementada uma funcionalidade, que permite que os dados  sejam exportados para arquivos, o que facilita a importação dos dados na aplicação  desktop.    Até o momento, o software deste trabalho criado para o preenchimento de  questionários eletrônicos na modalidade offline permite o preenchimento de três tipos de  questões: subjetivas, objetivas com uma única resposta e objetivas com múltiplas  respostas. Questões utilizando recursos multimídia, serão implementados em trabalhos  posteriores, assim como a geração de gráficos (para melhor análise dos resultados).  Apesar de funcional, este software ainda está em desenvolvimento, ou seja, até a  conclusão pretende-se que o software permita o preenchimento de mais tipos de  questões, possibilitando que o software seja o mais flexível possível. Contudo, com os  tipos de questões já disponíveis, foi possível a execução de alguns testes.   3. Resultados e Discussão  A fim de comprovar a eficácia do software proposto foram executados alguns testes. Os  testes procederam-se da seguinte maneira: foi criado um questionário impresso e um  eletrônico, ambos com as mesmas nove questões de caráter socioeconômico (com  questões do tipo: qual sua idade, com quantas pessoas mora, qual sua cidade natal, entre  outras); foi selecionada uma população de 34 indivíduos, entre 17 a 35 anos, onde  metade preencheu o questionário impresso e a outra metade preencheu o questionário  eletrônico em um tablet. A análise dos resultados se concentrou no tempo de aplicação     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 290-294 Nov/2014       293  dos questionários (entrevista) e no tempo de tabulação e validação dos resultados. Na  Tabela 1, pode-se visualizar que o tempo total necessário em todo o processo para o  questionário impresso é mais que o dobro do tempo para o questionário eletrônico.   Tabela 1. Tempo gasto com os questionários impresso e eletrônico   Questionário Entrevista Validação/Tabulação Total   Impresso 54min 42min 44s 96min 44s   Eletrônico 44min 9s 24s 44min 33s    Durante a tabulação dos resultados do questionário impresso, houve a  necessidade de uma revisão das respostas (o que exigiu mais tempo), na qual se  averiguou que algumas respostas foram tabuladas erroneamente. Assim, verificou-se  neste caso a possibilidade de ocorrer falha humana no processo manual, enquanto que  no processo eletrônico este tipo de erro não ocorre devido ao processo automatizado de  tabulação, sem intervenção humana.   4. Conclusões  Apesar de muito empregado, pouco se tem investido na automatização dos processos  envolvidos na utilização de questionários, como elaboração, entrevista e tabulação dos  resultados. Assim, foi proposto neste trabalho o e-Form, um software para elaboração  de questionários, com visualização e preenchimento offline na plataforma Android. A  abordagem offline permitiu a realização das entrevistas sem a necessidade de conexão à  internet.   A aplicação Android para coleta de dados foi testada para comprovar a eficácia  da utilização de questionários eletrônicos e os resultados obtidos foram apresentados na  Seção 3. Esses resultados se apresentaram promissores, mesmo considerando um teste  com um questionário pequeno, no qual chegou a reduzir em mais de duas vezes o tempo  de aplicação e análise das respostas. Também foi observada a existência de erro  humano, o qual foi evitado com a utilização do questionário eletrônico proposto neste  trabalho.    Na sequência deste trabalho, pretende-se concluir o restante da aplicação  proposta, testar questionários maiores e com mais entrevistados, além de realizar  comparações com questionários eletrônicos já existentes, como Google Forms, Survey  Monkey, Wondershare, entre outros. Tal comparação terá o objetivo de avaliar as  vantagens da aplicação offline, uma vez que a maioria das ferramentas desse gênero são  disponibilizadas apenas a versão online.   Referencias  Android Open Source. (2014) “Android developers”.   http://developer.android.com/index.html, september.  Converse, J. M.; Presser, S. (1986), Survey questions: handcrafting the standardized   questionnaire. Thousand Oaks: Sage.  Goode, W. J.; Hatt, P. K. (1972), Métodos em pesquisa social, São Paulo: Nacional, 4ª   ed.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 290-294 Nov/2014       294  Evans, J. R.; Mathur, A. (2005), The value of online surveys. In: Internet Research, v.  15, n. 2.   Hipólito, J. A. M. et al. (1996) “Como usar a internet em pesquisa”, In: I SemeAd –  Seminários em Administração, São Paulo: FEA-USP.   Omote, S.; Prado, P. S. T.; Carrara, K. (2005), Versão eletrônica de questionário e o  controle de erros de resposta. In: Estudo de Psicologia, v. 10, n. 3.   Vasconcellos, L.; Guedes, L. F. A. (2007) “E-Surveys: vantagens e limitações dos  questionários eletrônicos via internet no contexto da pesquisa científica”, In: X  SemeAd – Seminários em Administração, São Paulo: FEA-USP       
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 295-298 Nov/2014     295  Jogos Cognitivos Eletrônicos para a Aprendizagem de  Conceitos Nutricionais e Coleta de Dados   Gabriel R. de Albuquerque1,  Guilherme C. Mattos1, Karina M. Martinez1, Geiza  M. H. da Silva1, Édira C. B. A. Gonçalves2, Anderson J. Teodoro2   1 Departamento de Informática Aplicada – Universidade Federal do Estado do Rio de  Janeiro (UNIRIO)   Caixa Postal 22290-240 - Rio de Janeiro - RJ - Brasil   2 Departamento de Nutrição – Universidade Federal do Estado do Rio de Janeiro  (UNIRIO)   Caixa Postal 22290-240 - Rio de Janeiro - RJ - Brasil   {gabriel.albuquerque, guilherme.mattos, karina.martinez,  geiza.hamazaki}@uniriotec.br, ediracba@analisedealimentos.com.br,  atteodoro@gmail.com   Abstract. The healthy and balanced diet is vital for a better quality of life and  the correct nutrition must be ensured from infancy. Digital games can help  with the process of nutrition education in a playful way. However, through the  analysis of some games available on the internet, it was realized that these  were restricted to issues such as the classification of foods according to their  amount of vitamins. Many of them do not seem to implement store data  mechanisms. In this context was developed a game that will relate the correct  nutritional habits and its influences on daily activities beyond the development  of students reasoning and thinking. The data arising from the users actions  will be stored enabling the analysis of their possible changes in behavior.   Resumo. A alimentação saudável e balanceada é essencial para uma boa  qualidade de vida e bons hábitos devem ser desenvolvidos desde a infância.  Jogos digitais podem ajudar no processo de educação alimentar de forma  lúdica. Porém, através da análise de alguns jogos disponíveis na internet, foi  notado que estes se restringiam a questões como a classificação de alimentos  de acordo com a sua quantidade de vitaminas. Muitos deles não aparentam  possuir mecanismos de captação de dados. Neste contexto foi desenvolvido um  jogo que irá relacionar bons hábitos alimentares e seus reflexos em atividades  do dia-a-dia, além do desenvolvimento do raciocínio e reflexão dos alunos.  Dados gerados pelas ações dos usuários serão coletados possibilitando a  análise das suas possíveis modificações comportamentais.      1. Introdução   Muitas crianças optam por uma alimentação que não é saudável ou balanceada  devido a inúmeros motivos [Oliveira, 2003]. Entre eles pode-se citar: a mídia  televisionada, a mídia impressa, alguns meios de comunicação em geral como a  internet, a falta de recursos financeiros, e a falta de esclarecimento de como obter uma  alimentação saudável [Crivelaro, 2006].     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 295-298 Nov/2014     296   Percebe-se também que, no Brasil, cada vez mais cedo, as crianças passam a  desenvolver suas habilidades com o computador, com a internet e com os jogos  eletrônicos, inclusive nas classes de baixa renda dado que, com os projetos para redução  da exclusão digital, a maioria das escolas públicas possuem laboratórios de informática.   Vários estudos têm sido realizados com o objetivo de comprovar os benefícios  cognitivos dos jogos em tarefas de aprendizados e reflexão em crianças e adolescentes   [Blumber et al., 2013] [Ramos, 2013] [Blumberg et al., 2011] [Jaeggi et al.,2011], bem  como quais características devem ter os jogos de forma a garantir esses benefícios  levando em consideração as diferenças individuais como: atenção, memória,  coordenação motora, controle e o engajamento do jogador [Deater-Deckard et al., 2013]  sem perder as características de ser lúdico e prazeroso.   Neste cenário, surgiu a proposta deste trabalho que objetiva o desenvolvimento  do protótipo de um jogo para crianças. Inicialmente o público alvo são crianças de 5  (cinco) a 8 (oito) anos que estudam em escolas públicas brasileiras.   2. Metodologia   Para estudar a conceituação do jogador, no caso o aluno, e compreender seu  papel no jogo, foram realizadas visitas em duas escolas públicas brasileiras. Nestas os  professores foram entrevistados sobre o dia-a-dia na escola e foi aplicado um  questionário, no computador, nas turmas de alfabetização das escolas. No total 131  (cento e trinta e uma) crianças responderam.   Com estes dados foi possível determinar as características do jogador/aluno em  relação a habilidade no computador, aos hábitos alimentares e as atividades físicas  praticadas pelas crianças, bem como a elaboração do plano nutricional pela equipe de  Nutrição. Estas informações são fundamentais para a modelagem do jogo.   Reuniões com as equipes do curso de Sistema de Informação e de Nutrição  possibilitaram o desenvolvimento da arquitetura e dos modelos do jogo.   3. Caracterização do Jogo Proposto   O trabalho de conclusão de curso “Jogo Virtual de Reeducação Alimentar  Infantil” [Jardim, 2013], cita inúmeros jogos na web, porém em se tratando de educação  alimentar, foram encontrados jogos que ensinavam a classificar os alimentos de acordo  com a quantidade de proteínas, carboidratos e quais vitaminas que estes possuem e não  ensinavam como deveria ser uma boa alimentação e quais os efeitos que esta pode ter.    O jogo proposto é composto de um conjunto de “mini-jogos” e tem  como  enredo a rotina nas escolas. Na versão inicial são apresentados alguns dos alimentos  presentes no dia-a-dia dos alunos.   No jogo, a partir da tela inicial (Figura 1) é possível inserir o nome do jogador e  escolher um dos quatro personagens. Em seguida é executada uma animação onde a  criança se arruma no quarto e vai para a cozinha, onde poderá escolher o café da manhã  (Figura 2). Depois de escolher o que comer, podendo optar por não se alimentar, poderá  sair da cozinha e ir para a escola onde haverá um refeitório para a realização da colagem  (Figura 4) e dois “mini-jogos” (Figuras 3 e 5). Estes têm o objetivo de estimular o  raciocínio e a importância de atividades físicas no dia-a-dia. O jogo termina com a tela  do pódio (Figura 6), onde o jogador recebe a colocação no “mini-jogo”.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 295-298 Nov/2014     297            Figura 1. Tela de Início do jogo     Figura 2. Cozinha        Figura 3. “Mini-jogo” da memória                 Figura 4. Refeitório da escola             Figura 5. “Mini-jogo” de corrida                  Figura 6. Pódio   Foi possível definir quais alimentos deverão estar presentes na versão final do  jogo baseado nas respostas dadas pelos alunos no questionário aplicado nas escolas.  Para isso, foram utilizadas perguntas como: “O que você comeu no café da manhã?” e o  mesmo para as outras refeições. No jogo, esses alimentos possuem dados que foram  fornecidos pela equipe de Nutrição sobre suas quantidades de quilocalorias, proteínas,  glicídios e lipídios. Quando o jogador escolhe um desses alimentos, esses dados são  armazenados no banco de dados e são atribuídos ao seu personagem.   No “mini-jogo de corrida”, a velocidade com que o personagem do usuário se  move é definida pelos alimentos que ele escolheu. O valor calórico ideal foi fornecido  pela equipe de Nutrição. Quando o valor calórico do personagem fica distante do valor  ideal, a sua velocidade é proporcionalmente reduzida. Assim, as ações do jogador, os  alimentos ingeridos, afetam o seu desempenho no jogo influenciando as crianças e  adolescentes em suas escolhas por uma dieta mais saudável e balanceada.   Para desenvolver o jogo, optou-se pela utilização da linguagem ActionScript 3.0,  em conjunto com o ambiente de desenvolvimento integrado da Adobe, o Flash.   5. Conclusão e Trabalhos Futuros   A utilização de jogos eletrônicos, para a aquisição de conhecimento sobre uma  dieta mais saudável e balanceada, em crianças, tem apresentado resultados melhores do  que o ensino através dos métodos convencionais (palestras, vídeos e leituras) [Mellecker  et al., 2013]. Este resultado estimula o desenvolvimento e aplicação deste que além dos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 295-298 Nov/2014     298  conhecimentos sobre uma dieta saudável visa desenvolver a prática de atividades  físicas.   Outro ponto interessante é que a aplicação desta tecnologia é sem custo dado  que as escolas de modo geral possuem laboratórios de informática.    Na continuação do trabalho serão realizados testes qualitativos e quantitativos  nas classes de alfabetização das escolas nas quais foram realizadas as pesquisas,  seguindo a análise proposta em [Ramos, 2013]. Além disso, vale ressaltar: a extensão  do jogo para outras faixas etárias, o desenvolvimento de novos “mini-jogos”, o retorno  dos dados sobre as escolhas realizadas pelos usuários e sobre a quantidade de alimentos  ingeridos, que serão utilizados para o estudo e análise dos nutricionistas.   6. Referências Bibliográficas  Blumberg, F. C., Altschuler, E. A., Almonte D. E. e Maxwell I. Mileaf (2013) "The   Impact of Recreational Video Game Play on Children's and Adolescents' Cognition",  New Directions for Child and Adolescent Development. Special Issue: Digital  Games: A Context for Cognitive Development, Vol. 2013, p. 41–50.   Blumberg, F. C. e Altschuler, E. A. (2011). "From the playroom to the classroom:  Children’s views of video game play and academic learning", Child Development  Perspectives, p. 99–103.   Crivelaro, L. P., Sibinelli, E. C., Ibarra, J. A. e Silva, R. (2006) "A publicidade na TV e  sua influência na obesidade infantil". UNIrevista, Metrocamp, SP, Vol. 1, nº 3. Julho  2006, p. 1-7.   Deater-Deckard, K., Chang, M. e Evans M. E. (2013) "Engagement States and Learning  from Educational Games", New Directions for Child and Adolescent Development.  Special Issue: Digital Games: A Context for Cognitive Development, Vol. 2013, p.  21–30.   Jaeggi, S. M., Buschkuehl, M., Jonides, J. e Shah, P. (2011). "Short and long-term  benefits of cognitive training", Psychological and Cognitive Sciences, Vol. 108, p.  10081–10086.   Jardim, R. S. (2013), "Jogo Virtual de Reeducação Alimentar Infantil". 78 p. Trabalho  de conclusão de curso (Bacharelado em Sistemas de Informação) - Escola de  Informática Aplicada, Universidade Federal do Estado do Rio de Janeiro, Rio de  Janeiro, 2013. Disponível em:  <http://bsi.uniriotec.br/tcc/201308Jardim.pdf>.  Acesso em: 17 de jun. 2014   Mellecker, R. R., Withespoon, L. e Watterson, T., (2013) "Active Learning: Educational  Experiences Enhanced ThroughTechnology-Driven Active Game Play", The Journal  of Educational Research, Vol. 106, p. 352–359.   Oliveira, C. L. de e Fisber, M. (2003) "Obesidade na Infância e Adolescência – Uma  Verdadeira Epidemia". Disponível em:   <http://www.scielo.br/pdf/abem/v47n2/a01v47n2.pdf>. Acesso em: 20 de jun. 2014.   Ramos. D. K., (2013), "Jogos cognitivos eletrônicos: contribuições à aprendizagem no  contexto escolar", Ciências & Cognição 2013, Vol. 18 (1), p. 19-32.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 299-303 Nov/2014     299  Redes Sociais na Educação – Contextos, Cases e Frameworks   Vitor Hugo Lopes¹, Karina Wiechork¹, Adriana Soares Pereira¹, Roberto  Franciscatto¹   1Colégio Agrícola de Frederico Westphalen (CAFW) - Universidade Federal de Santa  Maria (UFSM).   vhugo_l@hotmail.com, karina@cafw.ufsm.br, adriana.pereira@ufsm.br,  roberto@cafw.ufsm.br   Abstract. The work in question aims to address the role of social networks in  the teaching-learning process through the use of free social networking  frameworks and their effective educational contribution. The article discusses  the views of educators regarding the use of social networks in the educational  context, the main frameworks used, as well as future work and expected  results with the completion of this research, a comparison between the use of  social networks and free networks adapted private social in the the  educational process.   Resumo. O trabalho em questão visa abordar o papel das redes sociais no  processo de ensino-aprendizagem, através da utilização de frameworks de  redes sociais livres e sua efetiva contribuição educacional. O artigo aborda  ainda a opinião de educadores quanto a utilização de redes sociais no  contexto educacional, os principais frameworks utilizados, bem como os  trabalhos futuros e resultados esperados com a conclusão desta pesquisa, em  um comparativo entre a utilização de redes sociais livres adaptadas e redes  sociais privadas, no processo educacional.   1. Introdução   O uso das redes sociais tornou-se um fenômeno tão usual nos dias atuais, quanto o  acesso a internet por si só. Pensar o modelo atual de sociedade em que vivemos sem  levar em consideração esse fenômeno é negar seu potencial, uma vez que essas  ferramentas conseguem envolver um enorme número de pessoas em socializar, trabalhar  e aprender.    Capra (2008) complementa, através dos estudos de Calstells (2004), afirmando  que redes sociais são redes de comunicação que envolvem linguagem simbólica,   restrições culturais, relação de poder e assim por diante. Embora essa compreensão e  todo seu potencial de aplicação para o contexto educacional, esta integração de  inovação na educação é um processo lento, que ainda encontra muitas barreiras que a  tornam não efetivamente explorada.   De acordo com Richardson (2006) “estamos no início de uma relação  radicalmente diferente com a internet, que tem implicações duradouras para educadores  e alunos”, isto por que avançamos no modelo educacional no que refere-se ao uso de  tecnologias no aprendizado e ensino. Partindo desta ideia, este artigo tem como objetivo  abordar os principais frameworks livres para a criação e configuração de redes sociais  no contexto educacional, elencando suas facilidades e dificuldades, bem como  adaptações para o contexto sugerido e posteriormente validar sua aplicabilidade junto a  disciplinas de graduação avaliando o processo de aprendizagem dos alunos com auxílio  destas ferramentas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 299-303 Nov/2014     300  2. Redes Sociais na Educação – Contexto e Cases   Professores e educadores acreditam que o conhecimento é construído socialmente  através de processos educacionais facilitados por cooperação, colaboração e interações  sociais [Molina e Sales 2008], e que é uma habilidade social que deve ser  continuamente melhorada [Hodgins 2007]. Seguindo por este viés, as redes sociais  surgem como uma ferramenta que possibilita que o estudante explore as características  sociais do aprendizado, uma vez que oferecem diversas formas de interação, facilitando  a comunicação entre diversos segmentos, avançando para além do modelo tecnicista de  ensino-aprendizagem que vivenciam em sala de aula.   Os sites de redes sociais são uma ótima ferramenta para engajar pessoas,  promovendo facilmente a comunicação. Por esse motivo, tem sido proposta de pesquisa  de diversos autores, baseando-se no contexto educacional. Entre outros benefícios  destacados, temos: a participação (motiva os alunos a serem mais participativos no  processo de ensino); a colaboração (permitem aos alunos construírem coletivamente o  conhecimento); a mobilidade (oferecem acesso direto de qualquer lugar e dispositivo) e  a comunicação (proporciona uma comunicação clara e efetiva entre professores, alunos,  pais e funcionários).    Apesar de todos esses benefícios, existem diversos educadores que ainda  acreditam que o uso de redes sociais é prejudicial [Clunie, 2011] uma vez que permitem  uma invasão a privacidade (exposição pessoal) e ainda ao termo de propriedade  intelectual, visto que uma informação discutida nos sites de redes sociais pertencem ao  dono da ferramenta e não a instituição promotora.    Recuero (2009) afirma que embora os sites de redes sociais atuem como suporte  para as interações que constituirão as redes sociais, elas não são, por si, redes sociais.  Eles podem apresentá-las, auxiliar a percebê-las, mas é muito importante salientar que  são, em si, apenas sistemas. São os atores sociais que utilizam essas redes que  constituem-nas. As redes sociais impulsionam a aprendizagem informal [Marsick e  Watkins, 1997], que é uma forma de enriquecimento dos conhecimentos e competências  através do cotidiano e dos acontecimentos ao longo dele (podendo ser considerado o  acesso a uma rede social), não necessariamente intencional.    3. Frameworks livres para implementação de Redes Sociais   Com o avanço da Web 2.0, surgiram diversas ferramentas disponíveis na rede de  forma gratuita, os famosos softwares open-source, que permitem alteração e adaptação  para o contexto necessário. São exemplos destes softwares: JomSocial, BuddyPress,  Elgg, Oxwall, entre outros. Nesta seção, será descrito sobre dois deles (mais usuais),  que serão adaptados para o propósito educacional, o Elgg e o Oxwall.   O Elgg é uma aplicação para criação de redes sociais que permite o  compartilhamento de texto, fotografias, músicas, vídeos, filmes, entre outros. Pode ser  adquirido de forma gratuita na internet através de seu site oficial (elgg.org) e sua  instalação é de nível intermediário (necessita conhecimentos técnicos). Para sua correta  instalação e configuração requer banco de dados SQL (com a tabela previamente criada)  e suporte a linguagem PHP. Seu desempenho é melhor quando instalado em um  servidor Linux.    Elgg é um framework por padrão em inglês. A ferramenta oferece suporte a  pacotes adicionais de idiomas. Para isso, pode ser feito o download de um plugin     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 299-303 Nov/2014     301  diretamente do site da comunidade ou com a duplicação do idioma atual e tradução  através da alteração do arquivo /mod/lenguages/idioma.php. Para alterar sua aparência é  necessária a criação de um plugin. Os plugins são ferramentas adicionais que podem ser  incluídas através de arquivos php inseridos nas pastas do framework, neste sentido, um  plugin pode ser desenvolvido ou encontrado e baixado das comunidades online de Elgg.  O plugin pode funcionar como um tema, adaptando o Elgg para suas necessidades.    O Oxwall é uma plataforma de rede social de código fonte aberto. Foi  desenvolvido usando PHP/MySQL para criar comunidades online. Para que a instalação  ocorra com sucesso é necessário contar com PHP e MySQL executando de forma  correta. Esse framework, destaca-se por conta da sua interface mais arejada e limpa, e  por ter sido alvo de diversas pesquisas na área de usabilidade [Lindnier, 2014].   Sua língua padrão é o inglês. O mesmo acontece com o CSS e com os elementos  gráficos, onde no Admin Dashboard (painel administrativo), o programador pode alterar  diretamente em uma interface mais fácil os códigos e ícones da rede social. Por ser mais  recente que o Elgg, oferece um número maior de plugins e atualizações para atual  versão, mantendo sempre o framework atualizado e funcionando da melhor forma. Seu  processo de instalação é muito semelhante ao Elgg, diferenciado apenas no momento  em que é necessário remover a pasta de instalação (o primeiro faz isso de forma  automática), embora o próprio sistema avise quando isso é necessário. Na figura 1, é  possível visualizar a interface dos frameworks abordados, bem como seus painéis  adminsitrativos.            Figura 1: (a) framework Elgg interface inicial; (b) framework Elgg interface administrativa; (c)  framework Oxwall interface inicial; (d) framework Oxwall interface administrativa   4. Resultados Esperados e Trabalhos Futuros   A partir das pesquisas realizadas até o momento, entendemos que há a necessidade da   (a) (b)   (c) (d)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 299-303 Nov/2014     302  realização de testes de usabilidade com as duas redes sociais já instaladas e devidamente  configuradas. Além disso, é necessária a criação de plugins que cumpram a demanda do  atendimento aos estudantes, colocando-os em testes em turmas de graduação, para que  seja possível avaliar posteriormente, seguindo a metodologia de usabilidade proposta  por Preece e Schneiderman (2009).   Ainda, faz-se necessário um estudo comparativo com estas turmas, entre redes  sociais livres adaptadas ao contexto social e redes sociais privadas (como o Facebook),  como forma de comparar e analisar a efetividade dos dois casos.    Por fim pretende-se ainda aplicar questionários on-line como forma de obter os  dados dos alunos que participarão da pequisa e sua real opinião a respeito do uso de  diferente redes sociais na educação, como ferramenta no processo de ensinoaprendizagem.   5. Conclusões   Consideramos que, ao inicio de uma nova era para a educação, as redes sociais são um  forte indício de tendência para os processos educativos e que se tem disponível hoje na  grande rede diversas ferramentas para o desenvolvimento de novas redes sociais ou o  acesso a já existentes. Conclui-se que as opções de frameworks gratuitos disponíveis e  estudados nesse trabalho, podem ser de fácil adaptação para o contexto educacional,  além de fácil instalação e manutenção. Por fim, destacamos que ambos os frameworks  já são usados hoje em contextos distintos e funcionais, demonstrando assim seu  funcionamento.   6.  Referências   BRAZ, L.; CLUNIE, G.; PINTO, C.; SERRÃO, T. Construção Automática de Redes  Sociais Online no Ambiente Moodle. Disponível em: <http://www.brie.org/pub/index.php/sbie/article/view/1647> Acessado em: 18 de agosto de 2014.   CALSTELLS, M. (2004) “A Internet e Sociedade em Rede” p.225-231. Rio de  Janeiro, RJ – Brasil.   CAPRA, F. (2008) As conexões ocultas. São Paulo, SP – Brasil.   RECUERO, R.(2009)  Redes Sociais na Internet. Porto Alegre, RS – Brasil.   HODGINS, H. W. Into the future a vision paper. Disponível em:  <http://onlineschool.cusd.com/calonline/programinfo/reports/2000IntotheFutureVision NatGovs.pdf>. Acessado em: 19 de setembro de 2014.   LINDNIER, H. L.; ULBRICTH, V.; Análise da interface padrão do Oxwall como  plataforma de rede social. Disponível em:  <http://www.infodesign.org.br/infodesign/article/view/249> Acessado em: 25 de  setembro de 2014.    MARCON, K.; MACHADO, B.J.; CARVALHO, M.; Arquiteturas Pedagógicas e  Redes Sociais: Uma Experiencia no Facebook. Disponível em: <http://www.brie.org/pub/index.php/sbie/article/view/1693> Acessado em: 19 de setembro de 2014.   MOLINA, M. P. AND SALES, D. (2008). Knowledge transfer and information skills  for student- centered learning in spain. Estados Unidos.   PREECE, J., ROGERS, I., SHARP, H. (2009). Design de Interação - além da     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 299-303 Nov/2014     303  Interação homem-computador. Porto Alegre, RS – Brasil   RICHARDSON, W. (2006) Blogs, Wikis, Podcasts and other Powerful Web Tools  for Classrooms. Thousand Oaks, CA.   WATKINS, K. E., & MARSICK, V. J. (1997). Sculpting the learning organization.  San Francisco.           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 304-307 Nov/2014     304  Uma proposta de aplicativo de vídeo depoimentos integrado  ao Facebook   David S. Carvalho, Juliano P. Sales, Roger J.V. Fernandes, Alexandre T. Silva,  Glauber R. Balthazar   Faculdade de Tecnologia de Carapicuíba - Avenida Francisco Pignatari, 650 - Vila  Gustavo Correia, Carapicuíba - SP - CEP: 06310-390   {david.snt.carvalho,tzdesing,roger.fernandezv}@gmail.com,  {tavares_alexandre,glauber_rochab}@yahoo.com.br   Abstract. The article explores the concept of video testimonials to honor  birthdays on the social network Facebook. Therefore, it is proposed to build an  application that will allow users to enroll events to honor a birthday by  participating guests. Guests will record videos that serve as testimonials to be  displayed on the anniversary of the honoree.   Resumo. O artigo explora o conceito de vídeo depoimentos para homenagear  aniversariantes na rede social Facebook. Para tanto, é proposto a construção  de um aplicativo que permitirá que usuários cadastrem eventos para  homenagear um aniversariante através da participação de convidados. Os  convidados irão gravar vídeos que servirão de depoimentos para serem  exibidos no dia do aniversário do homenageado.   1. Introdução   Atualmente observa-se a utilização massiva das tecnologias da informação e da  comunicação na sociedade moderna (SILVA, 2010) que viabilizam um alto volume de  interações, através de trocas de mensagens e relacionamentos nos ambientes virtuais.  Por exemplo, em 2010 vídeos na internet atingiram 40% do tráfego total prevendo-se  que em 2015 atinja aproximadamente 62% de todo o tráfego consumido(CISCO, 2010).    Neste contexto, as mídias sociais mudaram a forma como as pessoas se  socializam e se mantém em contato. Os vídeos na internet traduzem bem esse  fenômeno, tanto que as grandes redes sociais estão atentas a este fato. A FORBES  (2013) divulgou recentemente uma lista com as 07 tendências que poderão dominar as  mídias sociais em 2014. Dentre elas pode-se destacar o surgimento de aplicativos para o  compartilhamento do chamado “micro vídeo” como o “Vine” desenvolvido para o  Twitter e o “Video Sharing Feature” desenvolvido para o Instagram.    A proposta deste trabalho é explorar o conceito de vídeos em redes sociais  através da construção de um aplicativo integrado as redes sociais.  O aplicativo proposto  irá utilizar uma funcionalidade do Facebook que é a notificação de aniversário dos  usuários. A partir disso, o usuário do aplicativo poderá criar uma homenagem ao  aniversariante e convidar outros usuários para criar e enviar vídeos ao homenageado.   2. Objetivo   O objetivo deste trabalho é o desenvolvimento de um aplicativo integrado ao Facebook,  denominado Projeto Emociona, que permita homenagear uma pessoa, em seu  aniversário por meio de vídeos depoimentos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 304-307 Nov/2014     305  3. Metodologia   Este projeto será realizado em 04 etapas: 1º protótipo, 2º coleta e análise dos dados, 3º  desenvolvimento e 4º testes e implantação. Sendo: "1º protótipo", consiste no  desenvolvimento de um protótipo de um aplicativo que permita a criação de eventos por  parte dos usuários do Facebook; "2º coleta e análise de dados", será iniciada com a  disponibilização no Facebook do protótipo do aplicativo de vídeo depoimentos. Uma  base de dados será constituída para manter registros de todos os eventos criados,  usuários envolvidos e vídeos utilizados; "3º desenvolvimento", será constituída da  execução do processo de desenvolvimento do projeto e será adotado o paradigma  interativo-incremental.  O desenvolvimento será dividido em três fases: 1) Criação  de eventos; 2) Gerenciamento de vídeos; e 3)  Notificação de usuários; por último,  "4º Testes e Implantação", será norteada tanto por testes funcionais e de usabilidade.   4. Trabalhos Similares   Existem dois aplicativos do próprio Facebook que possuem funções similares as do  Emociona. São eles: "Eventos no Facebook": o Facebook utilizando esse serviço é  possível criar eventos, definir data e hora, convidar amigos para participar, confirmar  presença ou ausência; e, o outro, "Aniversários": no Facebook é possível encontrar  diversos aplicativos que auxiliam no gerenciamento das datas de aniversário de amigos  do usuário, entre eles, o aplicativo “Aniversário”. Porém, nenhum destes aplicativos  permitem a inserção de vídeos depoimentos para homenagear o aniversariante.   5. Análise Funcional e Técnica   5.1. Tecnologias utilizadas no projeto   Para a construção do aplicativo será utilizada a linguagem de programação PHP e a  JWPlatform que é uma plataforma que fornece o armazenamento e a entrega de vídeos.  Com uso dela toda a complexidade do gerenciamento de vídeos torna-se transparente  para aplicação e permite ter compatibilidade com os principais navegadores existentes  (JWPlayer, 2014).   5.2. Atores Envolvidos   Os usuários do aplicativo serão referenciados de acordo com sua relação aos eventos  sendo eles:  Organizador (responsável pela criação da homenagem e moderação de  vídeos);  Convidado (participante do evento, habilitado a enviar vídeo para  compor a homenagem); e  Homenageado (usuário que receberá o vídeo depoimento).   5.3. Requisitos de Negócio   O aplicativo tem a finalidade de realizar um evento para homenagear aniversariantes.  Isso será feito pelo organizador da homenagem que será o responsável por convidar os  participantes do evento. A homenagem será composta de vídeos gravados pelos  participantes e estes devem enviar os vídeos ao evento. Esses vídeos serão moderados  pelo organizador que poderá aprová-los ou rejeitá-los. O organizador estará submetido  aos termos de uso do aplicativo e será responsável pelo conteúdo dos vídeos veiculados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 304-307 Nov/2014     306  5.4. Diagrama de Casos de Uso   Na figura 1 são apresentados os principais casos de uso que constituem o projeto.     Figura 5. Diagrama de Casos de Uso   5.5. Prototipação   Para melhor compreensão do aplicativo foi desenvolvido um protótipo para explicitar as  funcionalidades envolvidas. Na figura 2 a tela inicial do sistema é demonstrada em  conjunto com um vídeo explicativo ao lado de um botão "Entrar".     Figura 6. Protótipo: Tela Inicial do Aplicativo "Emociona"    Uma vez que o usuário pressione o botão "Entrar", ele é direcionado para a tela  de criação do evento (figura 3), na qual poderá selecionar a pessoa que deseja  homenagear. Para tanto ele definirá o título e data do evento. Existe ainda um botão  "Continuar" que abre uma página que permite selecionar os convidados para o evento.    Neste momento o usuário é direcionado ao painel de controle (figura 3). Neste  local existem três botões no lado esquerdo da tela: o botão "Criar", que redireciona para  tela anterior; o botão "Meus Eventos", seguido por uma lista de eventos no qual o  usuário está participando, seja como Organizador ou como Convidado; e por fim o  botão "Enviar Vídeo" que possibilitará o envio de vídeos depoimentos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 304-307 Nov/2014     307     Figura 7. Protótipo: Tela de Criação de Eventos e Painel de Controle   6. Desenvolvimento   O processo de desenvolvimento adotado na implementação do projeto é o IterativoIncremental sendo dividido em três fases: a) Criação de Evento: possibilitar que o  usuário crie, exclua ou visualize um evento. b) Gerenciamento de Vídeos: criação,  exclusão e visualização de vídeos enviados pelos usuários e aprovação ou rejeição dos  vídeos; e c) Notificação de Usuários: envio de convites, notificações sobre alterações no  evento e notificação ao homenageado. Assim, para cada iteração, uma das três fases será  desenvolvida obtendo um protótipo funcional da aplicação e a cada protótipo ocorre o  incremento de funcionalidades, iniciando uma nova iteração até que o objetivo final seja  alcançado.   7. Aplicabilidade do Projeto   Para mensurar a aplicabilidade este projeto será executado dois tipos de testes  diferentes, sendo eles: funcionais (serão produzidos cenários de testes para verificar se  as funcionalidades estão corretas) e de usabilidade (será criado uma pesquisa com  perguntas e respostas, Likert, que será aplicada às pessoas que utilizarem o Emociona).   8. Considerações Finais   O atual projeto de TCC encontra-se em processo de desenvolvimento. As duas  primeiras etapas propostas na metodologia encontram-se prontas existindo atualmente  duas das três funcionalidades já implementadas. Pretende-se até o final do ano de 2014  terminar o desenvolvimento e iniciar a última etapa previsto na metodologia que são  testes e implantação para utilização no ambiente real do Facebook.   9. Referências Bibliográficas  CISCO.  “Cisco  visual  networking  index:  Forecast  and methodology, 2010–2015”, 2011.   FORBES. The Top 7 Social Media Marketing Trends That Will Dominate 2014. 2013.  Disponível em:    <http://www.forbes.com/sites/jaysondemers/2013/09/24/the-top-7-social-media-marketingtrends-that-will-dominate-2014/ > Acesso em: 04 mar. 2014.   JWPLAYER. Host and Stream with JW Platform. 2014. Disponível em:  <http://www.jwplayer.com/hosting-and-streaming> Acesso em: 25 mar 2014.   SILVA, Maurício Samy. HTML5 A linguagem de Marcação que revolucionou a Web. São  Paulo: Novatec, 2011, p. 20-36.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 308-311 Nov/2014     308  Segurança da Informação: Proposta de arquitetura de alta  disponibilidade para aplicações web   Marco Antoni1, Gláucio R. Vivian1, Evandro Preuss1    1Colégio Agrícola de Frederico Westphalen (CAFW)   Universidade Federal de Santa Maria (UFSM)   98.400-000 – Frederico Westphalen – RS – Brasil     marquinho9.10@gmail.com, {glaucio,evandro}@cafw.ufsm.br   Abstract. This short paper discusses the context of high availability within the  information security in web applications presenting a proposal for  development of an infrastructure cluster with load balancing. For  development of same personal computers will be used, Linux operating system  and software for high availability, server will be used to provide access to web  pages, databases and distributed file system, and all free tools.   Resumo. Este artigo aborda o contexto da alta disponibilidade dentro da  segurança da informação em aplicações para web apresentando uma  proposta de desenvolvimento de uma infraestrutura de cluster com  balanceamento de carga. Para desenvolvimento da mesma serão utilizados  computadores pessoais, sistema operacional Linux e softwares de alta  disponibilidade, servidor para prover ao acesso a páginas da web, banco de  dados e sistema de arquivos distribuídos, sendo todas as ferramentas livres.   1.  Introdução  Devido ao constante crescimento no uso da Internet motivado pelo barateamento de  equipamentos como computadores, notebooks, smartphones, etc e a conexão com a  Internet tornando-se cada vez mais barata e rápida, as organizações estão cada vez mais  utilizando a web como uma solução eficaz de comunicação, marketing e comércio  eletrônico. Uma empresa que trabalha com comércio eletrônico pode ter inúmeros  prejuízos se o seus serviços web ficarem indisponíveis por qualquer período de tempo,  não importando a origem do problema, seja ele por ataques de negação de serviço,  congestionamento na rede, falhas na infraestrutura do datacenter como hardware  defeituoso, erros de software ou paradas de manutenção programada. Esses são  problemas que além de prejudicar a imagem da empresa irão comprometer sua  confiabilidade.   Segundo [LAUREANO 2012], a segurança da informação é um ponto chave em  qualquer sistema, para o mesmo ser dito seguro ele deve prover três aspectos que são a  integridade, confiabilidade e disponibilidade.   O objetivo desse trabalho é propor a criação de um ambiente totalmente  tolerante a falhas como acontece em datacenters de grande porte, utilizando apenas  computadores pessoais e softwares open source visando garantir a disponibilidade  contínua de 99,999% do sistema, ou seja ter a garantia que o sistema poderá ficar  inoperante por um período máximo de aproximadamente cinco minutos durante um ano.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 308-311 Nov/2014     309  2.  Segurança da Informação  A tecnologia da informação vem se tornando cada vez mais utilizada pelo ser humano  que busca sempre utilizá-la para agilizar as tarefas do cotidiano fazendo-as de maneira  rápida e eficiente produzindo melhores resultados. A web é a tecnologia mais usada  permitindo que haja comunicação entre todos os elementos permitindo hospedar  websites, sistemas de gestão empresarial, etc. Esses recursos disponibilizados  representam a era da informação.   No que tange a segurança da informação, segundo [LAUREANO 2012], temos  três aspectos que são essenciais para o bom funcionamento das organizações que são: a)  Integridade: Deve garantir que a informação esteja sempre em estado consiste não  podendo ter valores perdidos ou alterados por qualquer entidade não autorizada pelo  dono da mesma. b) Confiabilidade: Deve garantir o acesso à informação apenas ao dono  e entidades previamente autorizadas. c) Disponibilidade: Deve garantir que a  informação permaneça acessível por todos que tenham autorização para acessá-la  independe de qualquer problema de nível técnico ou desastres naturais.    2.1.  Ferramentas Open Source para Alta Disponibilidade  Algumas ferramentas open source disponíveis para implementar alta disponibilidade  são: a) DRBD: É um software licenciado sob a licença GPL, atualmente é mantido pela  empresa austríaca LINBIT HA-Solutions GmbH [HA-Solutions 2014]. Ele é usado para  a construção de clusters de alta disponibilidade de armazenamento através da replicação  de blocos de mais baixo nível do HD. b) Heatbeat: O [Heartbeat 2014] é um daemon  disponível para Linux que fornece a infraestrutura de cluster, fazendo o gerenciamento  do mesmo, permitindo fazer a verificação dos serviços do cluster. c) MySQL com  Replicação: O MySQL tem suporte a replicação permitindo que dois ou mais servidores  tenham conteúdos idênticos. A arquitetura de replicação pode ser master/master ou  master/slave.   3.  Trabalhos Relacionados  Nesta seção serão analisados alguns trabalhos relacionados com a proposta. No trabalho  de [Caciato 2012] propôs-se uma arquitetura de duas camadas, composta pela camada  de virtualização e camada de aplicação. Essa arquitetura consiste basicamente em um  servidor principal e outro reserva. Quando ocorrer um erro no servidor físico, a camada  de virtualização realizará a migração da máquina virtual para outro servidor. Falhas nos  serviços do servidor principal farão a migração do serviço para o servidor reserva. A  maior desvantagem dessa estratégia é a necessidade de duplicação do número de  servidores e a ociosidade do servidor reserva.   Nos trabalhos de [Chi et al. 2012] e [Li et al. 2009] propõem-se arquiteturas para  alta disponibilidade com distribuição de carga e utilização de cache. O aplicativo  utilizado para tal foi o software [Nginx 2014] trabalhando como proxy reverso. Os  resultados apresentados comprovaram o aumento de disponibilidade e o número de  acessos simultâneos e evitam a ociosidade de servidores reserva.   A detecção de falhas de um serviço é implementada no trabalho de [Li et al.  2009] através do uso do software heartbeat.   Um problema encontrado em sistemas CMS é o grande uso do banco de dados  para armazenamento de configurações e dos dados própriamente ditos. Nos trabalhos de  [Li et al. 2009] e [Chi et al. 2012] não ha preocupação com a replicação da base de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 308-311 Nov/2014     310  dados. Já em [Caciato 2012] utiliza-se uma instância do DRBD[HA-Solutions 2014],  porem não ha detalhes sobre a implementação.   4.  Proposta da Arquitetura  Com base nos trabalhos relatados, propõem-se uma arquitetura utilizando o Nginx como  Proxy reverso para realizar a distribuição de carga entre dois servidores HTTP,  replicando esse serviço em outra instancia gerenciada pelo [Heartbeat 2014]. Os outros  dois servidores HTTP trabalham usando o Nginx, e usam o sistema de arquivos OCFS  sobre o DRBD, permitindo que a escrita seja feito em ambos. O banco de dados  Mysql[Dubois 2005] estará rodando em duas máquinas distintas, utilizando mecanismos  próprios de replicação Master/Master para garantir a consistência das informações entre  as duas base dados. O objetivo dessa configuração é garantir que a informação  armazenada em uma base seja replicada para a outra base de dados. Finalmente  pretende-se utilizar o software heartbeat para detectar falhas e redistribuir os serviços a  fim de garantir a alta disponibilidade. Na figura a seguir pode-se visualizar a arquitetura  proposta.          Figura 1: Proposta da arquitetura de alta disponibilidade   Esta proposta de arquitetura foi elaborada com base nos tecnologias apresentadas na  secao 3. Procurou-se corrigir a ociosidade do servidor relatada no trabalho de [Caciato 2012]  bem como melhorar a sua implementacao atravez do uso de outras solucoes utilizadas  como o heartbeat, DRBD e a replicacao do banco de dados.   5.  Resultados Esperados  Espera-se obter a comprovação da arquitetura proposta através da análise do aumento  do número de acessos simultâneos bem como a obtenção de 99,999% de disponibilidade  dos serviços. Para tanto, serão mensurados a disponibilidade do serviço na web por  meio da ferramenta Sentinela Web[Web 2014] durante o período de um ano e  comparada com um servidor simples. A análise do aumento do número de acessos  simultâneos será realizada através do aplicativo apache benchmarking tool[Foundantion  2014], método também utilizado por [Caciato 2012] para avaliar a performance.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 308-311 Nov/2014     311  6.  Considerações finais  Com base nos estudos das soluções já existentes e visando manter os três princípios da  segurança da informação, principalmente a disponibilidade, propôs-se um modelo de  arquitetura de alta disponibilidade visando corrigir as deficiências apontadas pelas  soluções estudadas. Espera-se constatar a viabilidade da solução apresentada através do  monitoramento da disponibilidade e testes de acesso simultâneos, comprovando a  utilização do Ngnix como proxy reverso, DRBD como replicador de sistema de arquivos  e a replicação master/master do SGBD.   Referências  [Caciato 2012] Caciato, L. E. (2012). High avaliability for critical services using   open software and virtualization. In Brazilian Symposium on Computing System  Engineering, pages 214–217. IEEE.   [Chi et al. 2012] Chi, X., Liu, B., Niu, Q., and Wu, Q. (2012). Web load balance  and cache optimization design based nginx under high-concurrency environment. In  Digital Manufacturing and Automation (ICDMA), 2012 Third International  Conference on, pages 1029–1032. IEEE.   [Dubois 2005] Dubois, P. (2005). MySQL : guia de estudo para certificação. Ciência  Moderna - Rio de Janeiro, 1ª edition.   [Foundantion 2014] Foundantion, A. (2014). Apache http server project. Disponível  em: http://httpd.apache.org/.   [HA-Solutions 2014] HA-Solutions, L. (2014). Drbd. Disponível em: http://drbd.org/.   [Heartbeat 2014] Heartbeat (2014). Disponível em: http://linuxha.org/wiki/Heartbeat/.   [LAUREANO 2012] LAUREANO, M. (2012). Segurança da Informação. Editora LT -  Curitiba, 1ª edition.   [Li et al. 2009] Li, F.-f., Xiang-zhan, Y., and Wu, G. (2009). Design and  implementation of high avaliability distributed system based on multi-level heartbeat  protocol. In IITA International Conference on Control, Automation and System  Engineering, pages 83–87. IEEE.   [Nginx 2014] Nginx (2014). Disponível em: http://nginx.org/.   [Web 2014] Web, S. (2014). Disponível em: http://www.sentinelaweb.com.br/.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 312-316 Nov/2014     312  Algoritmo K-Means Paralelo com base no MapReduce para  Mineração de dados agrícolas   Lays Helena Lopes Veloso1, Luciano José Senger1   1Departamento de Informática – Universidade Estadual de Ponta Grossa (UEPG)  Caixa Postal 84030-900 – Ponta Grossa – PR – Brazil   lays.veloso@gmail.com, ljsenger@uepg.br   Abstract. Clustering techniques are employed in applications in various fields  of knowledge. The K-Means clustering algorithm is the most commonly used.  However, the time spent in performing K-means can be considerable when  large amounts of data are used. The aim of this work is to implement a  MapReduce based parallel K-Means algorithm to run on a Hadoop cluster and  improve the response time of data mining in agriculture. This algorithm will  address deficiencies identified in other parallel implementations of K-Means.  Its performance will be evaluated with respect to SpeedUp and ScaleUp by  using large flux datasets from agricultural regions.   Resumo. Técnicas de agrupamento são empregadas em aplicações nas  diversas áreas do conhecimento. O K-Means é o algoritmo de agrupamento  mais comumente usado. No entanto, o tempo gasto para a execução do KMeans pode ser considerável quando grandes quantidades de dados são  usadas. O objetivo deste trabalho é implementar o algorimo K-Means  paralelo baseado no modelo MapReduce para ser executado em um cluster  Hadoop e melhorar o tempo de resposta da mineração de dados agrícolas.  Este irá tratar falhas identificadas em outras implementações paralelas do KMeans. Seu desempenho será avaliado com relação ao SpeedUp e ao ScaleUp  a partir de experimentos usando grandes conjuntos de dados de fluxo de  regiões agrícolas.   1. Introdução   Com a modernização dos equipamentos de aquisição e transmissão de dados, as  organizações têm investido em coletar uma massa de dados diária de observações, tais  como medições de torres de fluxo e redes de sensores. Essa massa de dados vem sendo  tratada pelo termo Big Data e traz como desafios, armazenar e processar os dados com  tempo de resposta aceitável e com baixo custo.    A Mineração de Dados (MD) é um conjunto de técnicas que através do uso de  algoritmos de Aprendizado de Máquina (AM), permitem extrair conhecimento a partir  da identificação de padrões desconhecidos em dados e auxiliar à tomada de decisão  [Witten e Frank 2005]. Conforme [Kudyba 2014] o uso de Big Data na MD pode  melhorar à tomada de decisão, a partir do uso de todos os dados disponíveis, em vez de  se limitar a pequenas parcelas dos dados. O MapReduce é o framework distribuído mais  popular para a análise de Big Data [Sakr e Gaber 2014]. O Hadoop é um projeto Open  Source para processamento distribuído que implementa o modelo MapReduce.    O objetivo deste trabalho é implementar o algoritmo K-Means paralelo com base  no modelo MapReduce para ser executado em um cluster Hadoop e melhorar o tempo     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 312-316 Nov/2014     313  de resposta da mineração de dados agrícolas. O algoritmo irá tratar falhas identificadas  em outras implementações paralelas do K-Means que serão discutidas a seguir. O KMeans paralelo será avaliado com relação ao SpeedUp6 e ao ScaleUp7 a partir de  experimentos usando grandes conjuntos de dados de fluxo de regiões agrícolas. Com  essa tarefa se busca obter informações para o planejamento agrícola para controlar as  emissões de gás carbônico (CO2) na atmosfera, determinando o potencial de sequestro  de carbono (C) do solo, e sua relação com as variáveis climáticas.    Os resultados encontrados serão avaliados com base na literatura e juntamente  com um profissional da área da Agricultura Orgânica. A qualidade do agrupamento será  avaliada utilizando os métodos intra-cluster e inter-cluster, como em [de Mello e  Senger 2005].   2. K-Means   O K-Means consiste em reunir n amostras de dados em k grupos de maneira que as  amostras em um mesmo grupo sejam similares entre si e diferentes daquelas em outros  grupos [Sakr e Gaber 2014]. O algoritmo K-Means sequencial pode ser descrito em 4  passos:   1. Seleção de k amostras como centróides iniciais;  2. Atribuição de cada amostra ao centróide mais próximo com base em um critério   de distância;  3. Cálculo de novos centróides através da média das amostras pertencentes ao   mesmo centróide;  4. Os passos 2 e 3 são repetidos até convergir para uma solução ótima.    O K-Means pode tirar vantagem do paralelismo. As amostras podem ser  distribuídas em cada processador e então atribuídas ao centróide mais próximo em  paralelo [Dean 2014]. Algumas implementações paralelas do K-Means foram propostas,  baseadas no MapReduce [ZHOU et al. 2011, Golghate e Shende 2014]. Em tais  implementações, foram identificadas 2 falhas:    Ausência de tratamento de falta de dados: É comum nas bases de dados  sequenciais casos em que as medidas não são realizadas por algum problema com os  mecanismos de coleta ou gravação. Nosso algoritmo descarta as instâncias que  apresentarem mais de 30% dos seus valores perdidos para evitar que esses registros  prejudiquem o resultado final.    Falta de um método eficiente para a seleção dos centróides iniciais - A solução  do K-Means é sensível aos centróides iniciais, que são geralmente selecionados de  maneira aleatória. Nós iremos paralelizar uma técnica mais eficiente para a inicialização  dos centróides de forma a melhorar a qualidade dos grupos finais.   3. Torres de Fluxo   Torres de fluxo utilizam a técnica de covariância de vórtices turbulentos ou Eddy  Covariance (EC) para medir em longo prazo os fluxos de CO2, água e outros nutrientes                                                    6 SpeedUp - Medida de ganho de desempenho de um algoritmo paralelo com relação a um algoritmo  sequencial equivalente.  7 ScaleUp - Medida da escalabilidade de um algoritmo, ou seja, a capacidade de um algoritmo lidar com  porções crescentes de trabalho quando mais recursos estão disponíveis, de forma uniforme.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 312-316 Nov/2014     314  entre a atmosfera e os ecossistemas, florestais e agrícolas. Essas quantificações  começaram a ser feitas em 1996 a fim de entender os controles sobre os fluxos de C  [Cihlar et al. 2002]. O Fluxo pode ser definido como a quantidade de uma grandeza que  passa através de uma superfície por unidade de tempo. O princípio geral das medições  de EC é a covariância entre a concentração da grandeza de interesse e a velocidade  vertical do vento [Burba 2013].    Para [Lichtfouse et al. 2011] a perda de carbono do solo merece uma atenção  particular na Agricultura, pois controla diferentes fatores a longo prazo, tais como o  CO2 atmosférico, erosão e abastecimento de água e nutrientes. Com as descobertas de  práticas agrícolas que podem diminuir os níveis de CO2 na atmosfera, têm surgido  diferentes estudos para observar a dinâmica do C a fim de descobrir o potencial de  sequestro de C do solo em áreas com diferentes tratamentos [FAO 2011].   4. Implementação   4.1 Base de Dados   A base de dados a ser utilizada nos experimentos contém medições contínuas de fluxo  do período de 2004 à 2011 coletadas em áreas agrícolas submetidas à diferentes  tratamentos. Os dados pertencem a rede AmeriFlux8 e foram obtidos em  (http://ameriflux.ornl.gov/).   4.2 K-Means Paralelo   No modelo MapReduce o processamento é dividido em duas fases: map e reduce. Para  isso é necessário especificar os passos da computação em duas funções respectivas.  Desta maneira, o sistema de execução automaticamente paraleliza a aplicação através do  cluster de computadores e cada iteração do K-Means é executada como um job  MapReduce.    A aplicação inicia submetendo o job. Desta forma a base de dados é segmentada  e suas partes são distribuídas em Mappers que são executados em paralelo. Os Mappers  executam instâncias da função map em cada nó no cluster computacional. No K-Means  os Mappers fazem a leitura dos centróides atuais, calculam a distância euclidiana entre  os centróides e as amostras e atribuem cada amostra ao grupo com o centro mais  próximo.    Como em [Zhao et al. 2009], uma função combine foi implementada para  melhorar o desempenho do algoritmo. A função combine é executada no mesmo nó que  a função map respectiva e tem como objetivo agrupar localmente as saídas da fase map.  No K-Means implementado, a função combine faz a soma parcial das amostras  atribuídas ao mesmo grupo na respectiva função map antes que a função reduce faça a  soma total.    Por fim, a função reduce calcula e emite os valores dos novos centróides e o  número de amostras atribuídas ao mesmo grupo para serem usados na próxima iteração  do K-Means.                                                    8 AmeriFlux - Rede de torres de fluxo das Américas     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 312-316 Nov/2014     315  4.3 Cluster Hadoop   O cluster Hadoop configurado para os experimentos possui uma máquina mestre com  um processador Intel core i7-3537 de 2,50 GHZ com 2 núcleos, 4 processadores lógicos  e 8,0 GB de memória RAM e seis máquinas escravas com processador Intel core i72600 de 3,4 GHz com 4 núcleos, 4 processadores lógicos e 4,0 GB de memória RAM.   5. Conclusões   Com este trabalho foi implementado o algoritmo de agrupamento K-Means paralelo  com base no modelo MapReduce a fim de melhorar o tempo de resposta da mineração  de dados agrícolas quando grandes conjuntos de dados são usados. A aplicação será  executada em um cluster Hadoop com recursos computacionais de baixo custo. Será  paralelizado um método eficiente para seleção dos centróides iniciais, que atualmente é  feita de maneira aleatória. Além disso, a qualidade do agrupamento será avaliada com  diferentes quantidades de grupos, para encontrar o número de grupos que minimiza as  distâncias intra-cluster e maximiza as distâncias inter-cluster. O desempenho do  algoritmo será avaliado e deverá apresentar SpeedUp e ScaleUp lineares. Desta maneira  será possível fornecer resultados que efetivamente auxiliem a tomada de decisão  agrícola para baixa emissão de CO2 com alta velocidade de resposta.   Referências   Burba, G. (2013). Eddy Covariance Method for Scientific, Industrial, Agricultural and  Regulatory Applications: A Field Book on Measuring Ecosystem Gas Exchange and  Areal Emission Rates. LI-COR Biosciences.   Cihlar, J., Denning, A. S., and Gosz, J. R., editors (2002). Terrestrial Carbon  Observation: The Ottawa Assessment of Requirements, Status and Next Steps.  Number 2 in Environment and natural resources series. Food & Agriculture Org.   de Mello, R. F. and Senger, L. J. (2005). Automatic text classification using an artificial  neural network. IFIP Advances in Information and Communication Technology,  172:215–238.   Dean, J. (2014). Big Data, Data Mining, and Machine Learning: Value Creation for  Business Leaders and Practitioners. John Wiley & Sons.   FAO (2011). Organic agriculture and climate change mitigation. Technical report, FAO.   Golghate, A. A. and Shende, S. W. (2014). Parallel k-means clustering based on hadoop  and hama. International Journal of Computing and Technology, 1.   Kudyba, S. (2014). Big Data, Mining, and Analytics: Components of Strategic Decision  Making. CRC Press.   Lichtfouse, E., Hamelin, M., Navarrete, M., and Debaeke, P. (2011). Sustainable  Agriculture, volume 2. Springer.   Sakr, S. and Gaber, M. (2014). Large Scale and Big Data: Processing and Management.  CRC Press.   Witten, I. H. and Frank, E. (2005). Data Mining: Practical Machine Learning Tools and  Techniques. Morgan Kaufmann series in data management systems, 2nd edition.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 312-316 Nov/2014     316  Zhao, W., Ma, H., and He, Q. (2009). Parallel k-means clustering based on mapreduce.  In CloudCom 2009, volume 5931, pages 674–679. LNCS.   ZHOU, P., LEI, J., and YE, W. (2011). Large-scale data sets clustering based on  mapreduce and hadoop. Journal of Computational Information Systems, 7:5956– 5963.           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 317-320 Nov/2014     317   Uso da Ferramenta Mantis para apoio ao processo Garantia  da Qualidade do MPS.BR    Emanuel Dantas Filho1, Osmar Leandro Dantas da Silva1   1Instituto Federal do Ceará – Campus Crato (IFCE)  Caixa Postal 63115-500 – Crato – CE – Brasil.   emanuel.filho@ifce.edu.br, Ls.siddis@gmail.com   Abstract. The MPS.BR (Improvement of Brazilian Software Process) has  frequently been followed by companies to get maturity in software  development. One of the most important processes in the model is the Quality  Assurance (GQA), which focuses on ensuring that products and processes are  working in accordance with the plans predefined by the company. When this  complex process is done manually, it can become a costly and impractical  activity to follow. The Mantis is the most popular open source bugs/issues  tracking systems, that can be used to automate this process. In this context, the  objective of the article is to assess the scope of Mantis on the expected results  of GQA process of MPS.BR.   Resumo. O MPS.BR (Melhoria de Processo do Software Brasileiro) vem  sendo seguido frequentemente pelas empresas para obter maturidade no  desenvolvimento de software. Um dos processos mais importantes do modelo é  a Garantia da Qualidade (GQA), que tem como foco assegurar que os  produtos e a execução dos processos estejam em conformidade com os planos  predefinidos pela empresa. Quando este processo complexo é realizado de  forma manual, pode se tornar uma atividade custosa e inviável de seguir. O  Mantis é um sistema de gestão de defeitos/casos de código aberto (open  source) que pode ser utilizado para automatizar este processo. Neste cenário,  o objetivo do artigo é avaliar a abrangência do Mantis sobre os resultados  esperados do processo GQA do MPS.BR.   1. Apresentação   Para auxiliar as organizações que desejam obter melhoria em seus processos, existem  guias e modelos que representam um conjunto de boas práticas a serem adotadas pelas  empresas. Dentre eles, pode-se listar o Capability Maturity Model Integration (CMMI),  Project Management Body of Knowledge (PMBOK) e o programa para Melhoria de  Processo do Software Brasileiro (MPS.BR).    Todos esses guias são compostos por um conjunto de processos que devem ser  seguidos para que as empresas alcancem um melhor nível de maturidade. Em todos  esses modelos, uma área presente consiste nos processos de qualidade. A organização é  responsável por escolher o melhor guia para se especializar, de acordo com seu perfil, a  fim de alcançar os resultados esperados por cada abordagem.    No mundo de software, em específico, os processos de qualidade tendem a  melhorar os processos organizacionais e mensurar a capacidade da organização em  gerenciar o desenvolvimento, aquisição e manutenção dos produtos e serviços de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 317-320 Nov/2014     318   software, de acordo com Softex (2012). No modelo MPS.BR, essa área é tratada no  processo de Gestão de Qualidade, conhecido como GQA.     Usar ferramentas traz facilidades na condução e gestão de qualquer  processo. Em especial, esse trabalho tem como objetivo apresentar o cenário em que o  Mantis deverá atuar e levantar os seguintes questionamentos: como a ferramenta pode  ser utilizada para alcançar os resultados esperados do processo GQA do modelo  MPS.BR? Somente a ferramenta é suficiente para suprir as necessidades do processo?   2. MPS.BR   Cada modelo de maturidade utiliza diferentes níveis para classificar o avanço  progressivo da capacidade técnica e gerencial das organizações. Essa maturidade deve  ser planejada a longo prazo e realizada de forma coordenada, ou seja, o modelo aplicado  é, de certa forma, responsável por definir o planejamento da maturidade a ser aplicado  na empresa. Porém, isso não significa o sucesso da modelo, que depende de diversos  fatores ambientais da empresa.     O modelo MPS.BR define sete níveis hierárquicos de maturidade, baseada nos  estágios de maturação do modelo internacionalmente difundido CMMI. Ambos definem  metas, os resultados esperados, para cada um dos níveis de maturação. Uma relação  entre os níveis de maturidade do CMMI e MPS.BR é definida na Figura 1 a seguir.     Figura 1: Relação entre os níveis do CMMI e MPS.BR.   3. GQA   O propósito do processo Garantia da Qualidade (GQA) é assegurar que os produtos de  trabalho e a execução dos processos estejam em conformidade com os planos,  procedimentos e padrões estabelecidos, conforme Softex (2012).    O processo GQA está presente no nível F do modelo MPS.BR. Ao todo, são  quatro os resultados esperados por esse processo. Esses resultados estão relacionados a  identificação, comunicação, gerenciamento de não-conformidades, e aderência dos  produtos de trabalho e dos processos aos padrões e procedimentos definidos.   4. Mantis   De acordo com The MantisBt Team (2014), o Mantis é uma ferramenta bug/issue  tracker desenvolvida em código aberto (PHP) e publicada em novembro de 2000. Este     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 317-320 Nov/2014     319   tipo de ferramenta auxilia no gerenciamento de defeitos/casos durante o projeto,  integrando as partes envolvidas por meio de informações centralizadas em tempo real,  desde a identificação até a correção de um caso reportado. A visão inicial do Mantis  pode ser visualizada na Figura 2.     Figura 2: Visão Inicial do Mantis. Fonte: http://www.mantisbt.org/.   Para utilizar o Mantis no processo GQA, os defeitos/casos devem ser vistos  como não-conformidades do processo. O conceito de não-conformidade relaciona-se  com o descumprimento de um requisito, enquanto que o defeito afeta o funcionamento  correto do produto final. A customização do Mantis contorna esta diferença facilmente,  no que se refere principalmente à formulários e ciclo de vida de uma não-conformidade.  Em projetos reais, a aderência da ferramenta pode (e deverá) variar. Para discutir isso, o  ideal seria utilizar um estudo de caso. Entretanto, uma avaliação inicial utilizando  conceitos de uma fábrica de software será utilizada para produzir resultados parciais  próximos do cenário real.   5. Definição do processo    Um processo pode ser definido pelos papéis, atividades e resultados gerados para cada  fase do projeto. Em especial, um processo de software é um conjunto de atividades e  resultados associados que geram um produto de software, segundo Sommerville (2011).     Para Medeiros (2014), em uma fábrica de software alguns perfis de profissionais  fazem parte do processo, inevitavelmente: gerente de projeto, analista de sistemas,  analista de qualidade, engenheiro de testes e engenheiro de software. Normalmente,  cabe ao analista de qualidade realizar o processo de Garantia de Qualidade (GQA).     As atividades do analista de qualidade consistem basicamente em auditorias  periódicas para verificar a conformidade de um processo. Caso sejam encontradas nãoconformidades, estas devem ser identificadas, comunicadas e gerenciadas,  caracterizando um resultado esperado no processo.     O Mantis utiliza um ciclo de vida predefinido para gestão de defeitos, o qual é  bastante longo se utilizado em GQA. Para garantir o resultado esperado abordado  anteriormente, o ciclo pode ser redefinido pelo analista da qualidade. Uma proposta de  organização dos estados de um processo de GQA pode ser observada na Figura 3, onde  segue a descrição de cada estado.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 317-320 Nov/2014     320     Figura 3: Diagrama de máquina de estados para o ciclo de um problema.    Analogamente, como disposto nos resultados esperados do GQA, o Mantis  permite estabelecer e acompanhar medidas corretivas para não-conformidades até a sua  conclusão, por meio da integração dos dados em tempo real. Neste ponto de vista, as  diferenças entre não-conformidades e defeitos são mínimas, já que os métodos de  correção poderão ser os mesmos em ambos os casos.   6. Conclusão   O processo Garantia de Qualidade possui quatro resultados esperados. Por meio deste  trabalho, foi verificado que a ferramenta Mantis pode ser utilizada para: identificar,  registrar, comunicar e acompanhar as não-conformidades. Dessa forma, o Mantis tornase um bom facilitador para alcançar alguns dos resultados esperados neste processo do  MPS.BR.    Teoricamente, delimitar o ciclo de um processo ajuda a realizar o gerenciamento  de não-conformidades, de forma a alcançar parcialmente os resultados esperados pelo  GQA. A aderência dos produtos de trabalho e dos processos executados não são  atendidos pela ferramenta, sendo uma proposta de customização do Mantis. Dessa  forma, para o trabalho completo, pretende-se aplicar este processo, customizado por  meio da ferramenta, em um cenário real de uma fábrica de software, a fim de analisar a  aderência do processo e colher indicadores para avaliar a solução proposta.   Referências   Medeiros, V. N.; Andrade, C. A. R.. Construindo uma Fábrica de Software: da  Concepção às Lições Aprendidas. XL Conferencia Latinoamericana en Informática  (CLEI 2014), Jul. 2014, Montevideo, Uruguay.   Softex. MPS.BR: Guia Geral MPS de Software. Associação para promoção da  excelência do software brasileiro – SOFTEX. [S.l.], 2012.   Sommerville, Ian. Engenharia de software. 9. ed. São Paulo: Pearson, 2011. p. 544.   The MantisBt Team. Mantis Bug Tracker Administration Guide. Disponível em:  <http://www.mantisbt.org/>. Acesso em: 4 ago. 2014.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 321-324 Nov/2014     321   Uma Linha do Tempo Digital Interativa na Forma de  Objeto de Aprendizagem para a Disciplina de Sociologia     Luís Guilherme Eich, Vinicius Hartmann Ferreira, Vanessa Petró     Instituto Federal de Educação, Ciência e Tecnologia do Rio Grande do Sul – Campus   Feliz  95770-000 – Feliz – RS – Brasil    gui.eich@hotmail.com, {vinihf,vanessapetro}@gmail.com     Abstract. This paper presents a Learning Object (LO) to the discipline of  sociology, developed due to the lack of interactive features for this area, since  this discipline is still emerging in school curriculum of high school and has few  teaching materials. The proposed LO aims to facilitate the understanding of  theoretical concepts related to classical sociology. The dynamics of LO  involves a timeline in which the student must associate chronologically thinker  with certain fundamental ideas related to his theory. We intend to develop it in  two versions, one to be used as a practical activity in the classroom and the  other being an evaluative instrument. In order to evaluate the reception of  students and its impact on class dynamics, the resource will be used in classes  on the sociology of high school and after use it students will answer a  questionnaire.  Resumo. Este artigo apresenta um Objeto de Aprendizagem (OA) para a  disciplina de Sociologia, desenvolvido devido à carência de recursos  interativos para esta área, visto que esta disciplina está ainda se consolidando  no currículo escolar do Ensino Médio e tem poucos materiais didáticos. O OA  proposto tem por objetivo facilitar a compreensão de conteúdos teóricos  relacionados à Sociologia clássica. A dinâmica do OA envolve uma linha do  tempo, na qual o estudante deve associar de forma cronológica determinado  pensador com ideias fundamentais relacionadas a sua teoria. Pretende-se  desenvolvê-lo em duas versões, uma para ser utilizada como atividade prática  em sala de aula e a outra sendo um instrumento avaliativo. Com o fim de  avaliar a recepção dos aluno e seu impacto na dinâmica das aulas, o recurso  será utilizado em aulas de sociologia do Ensino Médio e após o seu uso os  alunos responderão a um questionário.     1. Introdução   A disciplina de Sociologia ainda está se consolidando no currículo do Ensino  Médio e carece de materiais didáticos e também de recursos didáticos digitais  interativos, visto que os alunos do Ensino Médio têm um perfil diferente dos alunos do  Ensino Superior e materiais interativos podem tornar os conteúdos teóricos um pouco  mais acessíveis. Ainda que existam alguns recursos digitais para esta disciplina nos  principais repositórios, todos envolvem vídeos ou sugestões de textos [Leite, Hubler e  Junior, 2013; Pereira, 2009].    Tendo em vista que se trata de uma disciplina com muitos conteúdos teóricos,  utilizar-se dos benefícios que os recursos digitais interativos proporcionam para a  motivação dos alunos é de grande relevância [Silva e Melo 2013], pois os alunos  sentem-se mais atraídos por este tipo de recurso e com isso eles também têm a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 321-324 Nov/2014     322   possibilidade de interagir mais ao realizar exercícios a partir desta forma que está sendo  proposta.   Sendo assim, este artigo apresenta o desenvolvimento de um Objeto de  Aprendizagem (OA) para a disciplina de Sociologia do Ensino Médio, descrito através  do padrão OBAA. O OA que será apresentado baseia-se na ação de relacionar em uma  linha do tempo um conjunto de teóricos importantes para a Sociologia com aspectos de  suas teorias. Pretende-se desenvolver duas modalidades de utilização do OA, uma com  opções mais limitadas para servir como instrumento avaliativo, e outra para ser utilizada  como atividade prática a ser desenvolvida durante as aulas.      2. Objetos de Aprendizagem, Repositórios e Metadados   Objetos de Aprendizagem são recursos que podem ser utilizados pelos  professores e alunos no processo de ensino e de aprendizagem, podendo ser digitais ou  não. Como Objetos de Aprendizagem digitais, podem ser citados vídeos, imagens, jogos  e etc [Wiley 2000].    Para que seja possível disponibilizar e organizar os OAs, estes são armazenados  em repositórios digitais. Neste contexto, para que os OAs possam ser referenciados e  localizados nos repositórios, é necessário descrevê-los através de metadados. Essas  informações sobre os OAs são determinadas por certos padrões de referências, dentre os  quais se pode citar o padrão OBAA, uma proposta brasileira para referenciar Objetos de  Aprendizagem [Vicari et al. 2010].   Após construídos os OAs, eles são armazenados em repositórios. Pode-se  entender os repositórios como bibliotecas que armazenam e gerenciam os OAs através  de etiquetas, os metadados, facilitando a referência de um objeto para outro. Os  metadados podem ser entendidos como uma informação que descreve outra informação,  ou como uma etiqueta de um livro usado em uma biblioteca, isto é, os repositórios. Para  padronizar as informações (metadados), são criadas especificações sobre quais  informações um OA precisa conter para poder ser referenciado. Dentre estes padrões  podemos destacar o Dublin Core, o IEEE LOM e o OBAA.    O padrão OBAA é uma proposta brasileira de metadados para Objetos de  Aprendizagem Baseados em Agentes [Vicari et al. 2010]. O padrão OBAA herda várias  especificações do IEEE LOM, como a flexibilidade de plataforma, por exemplo, além  de outras especificações de outros padrões, criando uma ampla gama de informações  sobre o OA.   A construção do aplicativo na forma de OA se vale dos benefícios  proporcionados por ele, como reusabilidade e portabilidade, e isto justifica a escolha do  desenvolvimento deste recurso como tal. Ainda, a opção pelo padrão de metadados  OBAA ocorreu pelo fato de este se adequar melhor à realidade escolar brasileira,  sobretudo do Ensino Médio.     3. O Objeto de Aprendizagem em desenvolvimento   A equipe responsável pelo desenvolvimento deste projeto é multidisciplinar,  sendo composta por professores da área de Ciência da Computação e de Sociologia.  Após várias pesquisas por Objetos de Aprendizagem para a área de Sociologia,  percebeu-se que os que estavam disponíveis eram apenas vídeos, textos e imagens. Não  foi encontrado nenhum que fosse interativo.    Neste contexto, o OA está sendo desenvolvido com o intuito de criar um  ambiente que desperte o interesse do aluno e que o estimule ao aprendizado mais prático     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 321-324 Nov/2014     323   de uma disciplina com conteúdos considerados essencialmente teóricos. Concebeu-se  como proposta para um OA uma linha do tempo interativa, cujo objetivo do aluno é  organizar cronologicamente os conteúdos estudados. Um dos conteúdos que os  estudantes apresentam maiores dificuldades é aquele relacionado ao estudo da  Sociologia clássica, incluindo a história do surgimento da Sociologia. Sendo assim,  optou-se por este tema para o desenvolvimento deste OA.    Selecionado o conteúdo, este foi organizado de forma a disponibilizar aos  estudantes uma linha do tempo com os séculos marcados, a qual deve ser preenchida de  forma cronológica com um conjunto de informações sobre pensadores e aspectos  fundamentais das suas teorias, conforme ilustrado na Figura 1. No início do aplicativo,  várias caixas são disponibilizadas para o aluno, sendo que cada caixa representa um  pensador (caixa branca) e uma informação chave (caixa amarela) (Figura 1).        Figura 1. Pensadores e informações, não relacionadas na linha do tempo      O objetivo do aluno é arrastar as caixas referentes aos autores até os pontos   correspondentes na linha. Abaixo da caixa do autor devem ser associadas as  informações correspondentes (Figura 2).     Figura 2. Pensadores e informações relacionados na linha do tempo.   O OA será desenvolvido em duas versões. Em uma delas, ao finalizar o recurso,  o usuário receberá uma pontuação por seu desempenho e esta pontuação poderá ser  utilizada na disciplina de Sociologia como avaliação do aluno. A segunda versão será  em forma de atividade que corrigirá os erros do aluno ao finalizar, atribuindo ao seu     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 321-324 Nov/2014     324   desempenho uma pontuação diferenciada, permitindo que com isso os alunos possam  comparar seus resultados com o dos colegas.   É importante ressaltar que como o OA está sendo desenvolvido na linguagem de  programação Java, haverá portabilidade de plataforma, ou seja, será possível utilizá-lo  independente do Sistema Operacional do computador. Além disso, será possível  disponibilizá-lo através de repositórios de OAs no padrão OBAA.    4. Conclusão   O recurso que está sendo desenvolvido será um recurso novo para a área de  Sociologia. Pois, com as pesquisas realizadas em diferentes repositórios, constatou-se a  falta de recursos interativos para a disciplina que visam atrair a atenção do aluno,  motivá-lo e possibilitar que ele exercite o conteúdo.   O OA ainda está em desenvolvimento e novos recursos serão ainda  desenvolvidos. Pretende-se desenvolver um módulo que permita aos usuários  professores inserir novas informações, além das que já estarão disponíveis, registrandoas em arquivos XML, ampliando assim o reuso deste recurso em outras disciplinas.   Além disso, ao clicar nas caixas referentes às informações chaves serão  apresentadas informações mais detalhadas que possam auxiliar o aluno. E, por fim,  permitir que o usuário (professor ou aluno), configure qual período deseja, selecionando  um intervalo entre anos de acordo com a parte do conteúdo com a qual está trabalhando.    Após a conclusão do OA, este será utilizado nas aulas de sociologia do ensino  médio. Ao utilizá-lo os alunos farão uma avaliação do mesmo respondendo a um  questionário, através do qual poderá ser avaliado como os alunos receberam o  aplicativo, necessidades de adaptação, além de perceber os impactos da sua utilização.      Referências  IEEE Learning Technology Standards Committee (LTSC). Learning Objects Metadata.   Disponível em: http://www.ieeeltsc.org. Acesso em: 12 set. 2014.  LEITE, C. A. C.; HUBLER, P. N.; JUNIOR, A. C. G. R. A inovação no ensino de   sociologia com a utilização de objetos de aprendizagem. In: CONGRESSO  BRASILEIRO DE SOCIOLOGIA, 16, 2013, Salvador. Anais... Salvador: SBS.  2013.   PEREIRA, L. H. Por uma sociologia da sociologia no ensino médio. In: CONGRESSO  BRASILEIRO DE SOCIOLOGIA, 14, 2009, Rio de Janeiro. Anais... Rio de Janeiro:  SBC, 2009.   SILVA, T. S. C. e MELO, J. C. B. Cidade dos bits: um game para auxiliar no  aprendizado dos fundamentos da ciência da computação a nível médio. In:  SIMPÓSIO BRASILEIRO DE INFORMÁTICA NA EDUCAÇÃO, 24, 2013,  Campinas. Anais... Campinas: SBC, 2013. p. 915-919.   VICARI, R. M. et al. (2010). Proposta Brasileira de Metadados para Objetos de  Aprendizagem Baseados em Agentes (OBAA). RENOTE: Revista Novas  Tecnologias na Educação, Porto Alegre, v. 8, n. 2.   WILEY, D. A. Connecting learning objects to instructional design theory: a definition, a  metaphor, and a taxonomy. Disponível em: http://reusability.org. Acesso em: 12 set.  2014.          
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 325-328 Nov/2014     325   Mapeamento de Processos Utilizando a Metodologia BPM  Uma ferramenta de suporte estratégico no desenvolvimento  de sistemas em uma Instituição Federal de Ensino Superior   Evandro G. Flores, Marisa M. Amaral   Divisão de Análise e Desenvolvimento de Sistemas  Universidade Federal de Santa Maria (UFSM) - Santa Maria, RS - Brasil   evandro.flores@.ufsm.br, amarisa@cpd.ufsm.br   Abstract: This article briefly describes the good performance that the Division  of Systems Analysis and Development of the Data Processing Center of the  Federal University of Santa Maria has achieved with the inclusion of the  methodology of process management in the process of systems development.   Resumo. Este artigo tem a finalidade de descrever de forma sucinta o bom  desempenho que a Divisão de Análise e Desenvolvimento de Sistemas do  Centro de Processamento de Dados da Universidade Federal de Santa Maria  tem alcançado com a inclusão da metodologia de gestão de processos em seu  processo de desenvolvimento de sistemas.   Introdução  As instituições de forma geral tem sofrido pressão por resultados mais eficientes,  principalmente as organizações públicas, e isso faz com que as áreas de Tecnologia da  Informação (TI) tenham um papel extremamente importante no planejamento  estratégico e organizacional. Diante deste contexto, as áreas de TI tem buscado cada vez  mais seguir as boas práticas da gestão, e uma delas é o uso de metodologias específicas  como a BPM (Business Proccess Management) que integra um conjunto de tecnologias  de informação e comunicação para relacionar as pessoas e os sistemas dentro das  organizações, permitindo integração e compartilhamento de dados, regras, informações  e um direcionamento estratégico único, além do monitoramento e controle dos  processos (Brodbeck & Gallina, 2008).   Com o gerenciamento dos processos é possível mapear e descrever de maneira  simples os papéis de cada pessoa envolvida e também o comportamento de cada tarefa  do processo. Isso auxilia o desenvolvimento do sistema, pois fica mais claro para o  analista entender como funciona o processo. Para a área de desenvolvimento este  gerenciamento se torna muito eficiente no momento de desenvolver novas aplicações ou  até mesmo no momento das manutenções de sistemas, pois com a visão detalhada dos  processos é possível analisar os impactos de possíveis mudanças e definir estratégias.   Solução Adotada  Para um melhor entendimento sobre gestão de processos, faz-se necessário compreender  o conceito de “processos de negócio”. Sendo assim, “um processo é um conjunto  definido de atividades ou comportamentos executados por humanos ou máquinas para  alcançar uma ou mais metas” e ainda “(...) são compostos por várias tarefas ou  atividades inter-relacionadas que solucionam uma questão específica” (ANTONUCCI,  2009, p. 23).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 325-328 Nov/2014     326   A gestão de processos nas Instituições Federais de Ensino Superior (IFES) é  uma metodologia relativamente nova e que vem ganhando seu espaço devido aos bons  resultados que tem proporcionado para a instituição como um todo.   Na UFSM, o ponto de partida para uso dessa metodologia foi através da Divisão  de Análise e Desenvolvimento de Sistemas do CPD, que em um primeiro momento já  tinha os processos definidos e mapeados pelo analista de TI responsável pelo projeto.  Entretanto, esse mapeamento era elaborado somente para auxiliar no processo de  desenvolvimento, após o término do projeto o processo mapeado era esquecido.    Com o objetivo de auxiliar não somente o processo de desenvolvimento, mas  também beneficiar o usuário final para que ele tenha acesso ao seu processo de trabalho  mapeado, surgiu a ideia de criar um “Portal de Processos” e disponibilizar para toda a  comunidade acadêmica. Assim, os processos mapeados estariam disponíveis não  somente para um grupo restrito da instituição, mas sim para todos aqueles que  desejassem visualizá-los.   Desta forma, para tornar este processo de mapeamento como uma prática dentro  do setor, foi designada uma pessoa responsável somente para isso, que chamamos de  “Analista de Processo”. Com esse papel bem definido, torna-se possível gerenciar  melhor os processos que estão sendo mapeados.  O principal motivo de centralizar em  uma ou mais pessoas o mapeamento dos processos permite identificar, entre outros  aspectos, os riscos operacionais para que estes possam ser tratados. Além de mapear os  processos que serão informatizados pela equipe do CPD, o Analista de Processo  também auxilia a instituição nos demais processos que necessitam de melhoria ou  otimização.    Metodologia Utilizada  Diante do exposto e da necessidade contínua de melhorias em suas rotinas, gerenciar  esses processos é mais difícil do que se imagina, pois vários deles interagem e não  acontecem isoladamente. Para que este gerenciamento se torne possível, a metodologia  BPM se encaixou adequadamente às necessidades, pois ela alinha a Gestão de Negócios  com a TI, promovendo uma visão estratégica que possibilita a otimização e integração  dos processos. Cabe destacar que para desenvolver esta gestão e colocar em prática o  uso da metodologia BPM, a Divisão de Análise e Desenvolvimento de Sistemas elegeu  como ferramenta de trabalho o Software BizAgi que é uma ferramenta livre, específica  para o mapeamento de processos  e que utiliza como base a notação BPMN,  possibilitando que o analista desenvolva o desenho do processo e detalhe todas as  tarefas pertencentes aos processos, podendo inclusive gerar a partir dela relatórios e  páginas web para publicação.   O uso da metodologia BPM em conjunto com o software BizAgi, permitiu  a  elaboração e mapeamento dos processos, com geração das páginas para web. Desta  forma, as páginas foram agrupadas em um “Portal de Processos” e disponibilizadas para  toda a comunidade acadêmica.    A forma utilizada para organizar os processos mapeados neste portal foi vincular  os processos às pró-reitorias ao qual ele pertence. Como ainda temos poucos processos  mapeados esta estrutura está atendendo perfeitamente, entretanto, a longo prazo, será  necessário um estudo mais detalhado de como organizar melhor este Portal de  Processos.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 325-328 Nov/2014     327     Figura 1. Tamplate do Software BizAgi     Figura 2. Portal de Processos   A facilidade de navegação pelos processos mapeados e a visualização detalhada  do fluxo, além da descrição de cada tarefa contribuiu para auxiliar o usuário final, mas  também dar suporte à tomada de decisão em nível estratégico.   Resultados alcançados  Embora o número de processos mapeados e publicados no Portal de Processos ainda  seja reduzido, já é possível perceber alguns resultados positivos em relação à adoção do  uso da metodologia BPM como ferramenta de gestão dos processos.   Atualmente, grande parte dos processos de negócios estão somente na cabeça de  algumas pessoas em diferentes setores da instituição. O problema dessa cultura é que  todo o conhecimento acaba perdendo-se quando essas pessoas se aposentam ou por     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 325-328 Nov/2014     328   algum outro motivo saem da instituição. Desta forma, mapear os processos  institucionais é uma forma de evitar que isso aconteça.    A área de TI da UFSM tem sido pioneira neste levantamento de processos  justamente por esta metodologia auxiliar no desenvolvimento dos sistemas.  Desta  forma, a interação entre a equipe de TI e os usuários conhecedores do processo tem  contribuído de forma significativa no desempenho do processo de desenvolvimento dos  sistemas, pois com o processo bem definido e mapeado há um entendimento maior entre  ambas as partes, o que influencia diretamente na agilidade de entrega do sistema.   Outro fator importante a destacar é a visibilidade que o Portal de Processos  trouxe para os sistemas desenvolvidos, pois o processo também é utilizado como help  do sistema e auxilia os usuários a entender o processo como um todo.   Considerações Finais  A implantação da gestão de processos em uma instituição não é um projeto que possa  ser executado à curto prazo, pois o seu sucesso depende de um elevado grau de  maturidade e aprendizagem que só será atingido com uma mudança na cultura  organizacional. Além disso, este processo deve envolver todos os segmentos da  instituição e estar alinhado com o planejamento estratégico.   A gestão dos processos deve ter um foco inovador que proponha mudanças, que  agregue valor às atividades da instituição, como a otimização dos resultados, do tempo e  dos custos, promovendo transparência e facilidade de acesso às informações pertinentes  aos processos organizacionais.    Finalizando, acreditamos que a gestão dos processos é uma maneira simples e  inteligente de desenvolver a integração dos diferentes processos dentro da universidade  e é um importante mecanismo para promover melhorias e inovações nas rotinas de  trabalho de seus servidores.   Referências  ALBUQUERQUE, Alan; ROCHA, Paulo. (2006) Sincronismo organizacional: como   alinhar a estratégia, os processos e as pessoas. São Paulo: Saraiva.   ANTONUCCI, Y. L.; BARIFF, M.; BENEDICT, T.; CHAMPLIN, B.; DOWNING, B.  D.; FRANZEN, J.; MADISON, D. J.; LUSK, S.; SPANYI, A.; TREATt, M.; ZHAO,  L.; RASCHKE, R. L. (2009), “Business process management common body of  knowledge”, Terre Haute: ABPMP.   BRODBECK, A.F.; GALLINA, D.B. (2008) Practices of the Project Management to  Redesign Business Critical Process: The Case of a Multinational Electronic  Company. In: Anais do IV CONTECSI, CD-ROM, São Paulo.           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 329-333 Nov/2014     329   Desenvolvimento de um Plugin para o Moodle voltado ao  Ensino de Programação utilizando a API Davit   Karina Wiechork, Bruno Batista Boniati   Graduação Tecnológica em Sistemas para Internet – Universidade Federal de Santa  Maria (UFSM)   Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS  {karinawiechrok, brunoboniati}@gmail.com   Resumo. O Moodle é uma plataforma de aprendizagem a distância baseada  em software livre que vem ganhando espaços em universidades e empresas.  Tal plataforma oferece mecanismos para compartilhamento de conteúdo  digital bem como ferramentas para comunicação. Pretende-se por meio deste  trabalho desenvolver um módulo (plugin) para o Moodle na tentativa de  disponibilizar uma ferramenta para correção de atividades ligadas a área de  programação. Para tanto o trabalho pretende estudar a API Davit para  ensino de programação baseado em desafios propostos pelo professor  formador que são resolvidos por meio de código.   Abstract. Moodle is a distance learning platform based on the free software  that is gaining spaces in universities and companies away. Such platform  provides mechanisms for digital content sharing as well as tools for  communication. The purpose of this work is to develop a module (plugin) for  Moodle in an attempt to provide a tool for correction of activities related to  programming area. For that, this work aims to study the Davit API for  teaching programming based on challenges posed by the teacher trainer that  are solved through code.   1. Introdução   Educação à distância tem se consolidado como uma modalidade alternativa de  aprendizagem, que se apoia fortemente em tecnologias de comunicação e informação  como possibilidades de interação no espaço virtual (Carvalho, J. M. A., Moraes, V. e  Vellasquez, F. S., 2005). Um dos pontos fortes do EAD é evitar a necessidade de  deslocamento do aluno até o local do curso, tal característica potencializa essa  modalidade de ensino.     No ano de 2012 o Colégio Agrícola de Frederico Westphalen (unidade de ensino  vinculada à UFSM) ingressou no programa eTec (Escola Técnica Aberta do Brasil) do  Ministério da Educação objetivando oferecer um curso técnico em Informática para  Internet na modalidade EAD. Observaram-se, no entanto, durante a execução da  primeira edição do curso algumas dificuldades para propor e corrigir atividades ligadas  à codificação (disciplinas de algoritmos, introdução à programação, linguagem de  programação, etc.).     Este trabalho descreve os resultados parciais do desenvolvimento de um plugin  para o Moodle com o objetivo de possibilitar a definição e correção de atividades  relacionadas à área de programação. Entende-se que os resultados deste trabalho  poderão qualificar as atividades de ensino desenvolvidas em cursos da área de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 329-333 Nov/2014     330   computação que utilizam o ambiente Moodle. O plugin será desenvolvido e ficará  disponível em: https://github.com/karinawie/DavitMoodle/ sobre a licença GLP para ser  utilizado e adaptado livremente por instituições que adotam o Moodle como ferramenta  de apoio ao ensino.   2. Moodle   Acrônimo de Modular Object Oriented Distance Learning Environment – MOODLE é  um sistema modular de ensino à distância orientado a objetos (Nakamura, 2008).  Segundo o site oficial “O Moodle é uma plataforma de aprendizagem projetada para  fornecer educadores, administradores e alunos com um único sistema robusto, seguro e  integrado para criar ambientes de aprendizagem personalizados” (Moodle, 2014). O  Moodle é um framework de construcionismo social da educação e foi desenvolvido na  linguagem PHP e pode ser executado em qualquer computador que possua um Sistema  de Gerenciamento de Banco de Dados (SGBD) compatível com SQL (Structured Query  Language). Segundo o site Moodle.net existem 54.713 locais atualmente ativos que  foram registrados a partir de 229 países. No Brasil são 3932 sites no total (Moodle.net,  2014).    3. Davit API   Davit é uma implementação em JavaScript, e adaptação livre do Robô Karel9 do  professor Mehran Sahami de Stanford. O Davit é um pequeno Robô virtual, um robô  triangular, que pode ser programado por estudantes de programação. Davit vive num  mundo dividido por linhas e colunas, que além do próprio Davit, pode conter discos de  várias cores e muros. (Louro, 2010).  A Figura 1 ilustra o ambiente de desenvolvimento  conhecido como “Mundo de Davit”, utilizado pelo site  www.aprenderprogramar.com.br.     Figura 1. O ambiente de programação do “Mundo de Davit”                                                    9  https://jinkchak.wordpress.com/tag/mehran-sahami/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 329-333 Nov/2014     331    A quantidade de linhas e colunas do “Mundo de Davit” é definida pelo próprio  exercício e no Moodle pretende-se implementar uma forma do professor inserir cenários  diferentes para os alunos. A interação de Davit com o mundo e seus objetos também são  inicialmente simples. Davit anda pra frente, gira no sentido horário, pega e solta os  discos e eventualmente bate com a cabeça nos muros e bordas do mundo. O vocabulário  básico da linguagem que o Davit entende é:    move(); - anda uma posição para frente.   turn(); - gira uma posição no sentido horário, ou seja, para a direita do robô.   getDisc(); - faz Davit pegar o disco no qual ele está pisando.   putDisc(); - faz Davit largar o último disco pego.   4. Trabalhos Relacionados   Por meio de pesquisas, especialmente em fóruns relacionado ao Moodle, até mesmo nos  fóruns mantidos pelo do site oficial é possível encontrar diferentes usuários procurando  pela existência de módulos que simulem exercícios de lógica de programação.    Dentre os trabalhos relacionados mais relevantes, destaca-se o plugin VPL –  Virtual Programming Lab for Moodle. O qual é definido como sendo um sistema de  gerenciamento de trabalhos de programação que permite editar e executar programas e  avaliar de forma automática e contínua (VPL, 2014). Com ele é possível editar o  código-fonte de programas no navegador, executar testes para rever os programas,  procurar similaridade entre arquivos e permite definir restrições de edição evitando a  colagem de texto externo.    Outro trabalho relacionado é o CodeMonkey, semelhante a API Davit. O  CodeMonkey é um jogo online, que ensina programação de computador real para  crianças a partir dos 9 anos (Mottes, Pinchover, Schor, Schor, 2014). Seu objetivo é  criar e compartilhar desafios para os outros usuários. O objetivo do CodeMonkey é  programar o Monkey (personagem) de forma que ele alcance seu objetivo que é de pegar  uma banana. É um jogo desenvolvido em JavaScript com HTML5.      5. Resultados Preliminares   As Figuras 2 e 3 ilustram a versão atual do plugin que está sendo testado na versão 2.7  do Moodle. Na Figura 2 é possível visualizar que o cenário está vazio e o aluno pode  escolher o nível de dificuldade (fácil, médio, difícil).          Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 329-333 Nov/2014     332     Figura 2.  Plugin 1.0 instalado no Moodle 2.7, cenário ainda não selecionado.       Na Figura 3 o cenário é carregado, neste caso o aluno deverá alterar as linhas do  código e depois de concluído deve clicar em executar. Se tudo der certo aparecerá uma  mensagem o parabenizando e caso contrário ele poderá tentar novamente.    Terminado a atividade, o aluno deverá enviar a resposta para o professor via  Moodle. Até o presente momento é possível instalar o plugin no Moodle e programar o  Davit com um cenário fixo.  Ainda faltam configurações a serem desenvolvidas entre o  plugin Davit e o Moodle, como a alteração do cenário que os professores poderão fazer,  habilitar a opção do aluno enviar a atividade, configurar um período para ficar  disponível a atividade. Tais requisitos estão sendo projetados e implementados.        Figura 3.  Cenário carregado com a opção difícil selecionado.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 329-333 Nov/2014     333   6. Conclusões e Trabalhos Futuros   A avaliação na modalidade a distância é muito importante no decorrer do processo de  ensino-aprendizagem. Com o plugin Davit para Moodle entende-se que será possível  colocar a disposição de professores da área de programação uma excelente ferramenta,  permitindo ao mesmo definir, propor e corrigir atividades de forma integrada às demais  ferramentas existentes no Moodle.     Os resultados deste trabalho poderão qualificar as atividades de ensino  desenvolvidas em cursos na área de programação que utilizam o ambiente Moodle. Com  adaptações no trabalho, o mesmo pode ser utilizado em outros ambientes virtuais de  ensino.   Referências   Carvalho, J. M. A., Moraes, V. e Vellasquez, F. S. (2005) “Aprendizagem na Educação  a Distância”. Disponível em: http://www.ricesu.com.br/ciqead2005/trabalhos/07.pdf.  Pesquisa de projeto, Universidade do Estado do Rio de Janeiro. Acesso em setembro  de 2014.   Louro, R. “Davit: Uma ferramenta Javascript para aprender a programar”. Disponível  em: http://blog.renatolouro.com.br/2010/12/davit-uma-ferramenta-javascript-paraaprender-a-programar/. Acesso em setembro de 2014.   Moodle. (2014) “About Moodle”. Disponível em:  https://docs.moodle.org/27/en/About_Moodle.  Acesso em setembro de 2014.   Moodle.net. (2014) “Registered Moodle Sites”. Disponível em: http://moodle.net/sites/.  Acesso em setembro de 2014.   Mottes, M., Pinchover, Y., Schor, I. e Schor, J. “CodeMonkey”. Disponível em:  http://www.playcodemonkey.com/. Acesso em setembro de 2014.   Nakamura, R. (2008) “MOODLE: Como criar um curso usando a plataforma de Ensino  à Distância”, 1ª Ed. - São Paulo: Farol do Forte.   VPL. (2014) “VLP – Virtual Programming Lab”. Disponível em:   http://vpl.dis.ulpgc.es/. Acesso em 14/09/2014.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 334-337 Nov/2014     334   Refatoração de Aplicações Web: Um Estudo de Caso   Jean Carlos Dalcero, Bruno Batista Boniati   Tecnologia em Sistemas para Internet – Universidade Federal de Santa Maria (UFSM)  Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS   {jeandalcero, brunoboniati}@gmail.com   Resumo. Constantemente os sistemas de software estão em evolução, há quem  diga que o código de uma aplicação é orgânico, ou seja, se deteriora  naturalmente com o passar do tempo em função de novas técnicas e  ferramentas. Refatoração é uma técnica que consiste em alterar a estrutura do  código de uma aplicação sem que isso afete necessariamente seu  funcionamento, trata-se de melhorias internas. Por meio deste trabalho  objetiva-se estudar técnicas de refatoração para aplicações web. Através de  um estudo de caso pretende-se identificar falhas relacionadas à segurança,  leiaute, acessibilidade e desempenho de uma aplicação, realizando a  reestruturação do código com técnicas de Refatoração de Aplicações Web.   Abstract. Constantly software systems are evolving, some say that the code of  an application is organic, in other words, it naturally deteriorates over time  due to new techniques and tools. Refactoring is a technique that consists in  changing the structure of an application without necessarily affecting its  functioning, just like internal improvements. This paper aims to study  refactoring techniques for web applications. Through a case study it is  intended to identify failures related to security, layout, accessibility and  performance of an application, performing the restructuring of the code using  refactoring techniques for Web Applications.   1. Introdução   Com a evolução da Internet, a importância e demanda das aplicações Web aumentou  muito, em especial nos últimos anos. Os sistemas defasados ou não planejados podem  possuir inúmeras falhas e limitações. Porém essas características podem ser melhoradas  através de técnicas e normas padronizadas que surgiram para o melhoramento dessas  aplicações, fazendo com que os sistemas possam ser desenvolvidos com facilidade no  entendimento e inclusão de novas funcionalidades por parte dos desenvolvedores.    De acordo com Flores (2011), quando citamos aplicações Web, uma das áreas  mais abordadas é a camada de apresentação. Nestas, a boa formatação do código é  essencial para maior qualidade de segurança, leiaute, acessibilidade e desempenho do  sistema.  Sabendo-se que os sistemas mais antigos ou pouco planejados podem  apresentar problemas estruturais na criação dos códigos-fonte de suas páginas, o  trabalho tem como proposta através de um estudo de caso, identificar falhas  relacionadas à segurança, leiaute, acessibilidade e desempenho de uma aplicação Web,  realizando a reestruturação do código utilizando técnicas de Refatoração de Aplicações  Web citadas por Harold (2010).      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 334-337 Nov/2014     335   2. Refatoração   O conceito de refatoração vem originalmente da comunidade de programação orientada  a objetos, datando do ínicio dos anos 90, mas sendo popularizada por Martin Fowler em  1999 com o livro "Refactoring" (Addison-Wesley, 1999). Fowler (1999) define  refatoração como o processo de aperfeiçoamento do código-fonte de um sistema de  software, tornando-o mais bem entendido, menos custoso na modificação e sem  mudanças no comportamento externo.     Outro conceito abordado por Harold (2010) cita que a refatoração é a melhoria  gradual de uma base de código por meio de pequenas mudanças que não modificam o  comportamento de um programa, normalmente com ajuda de ferramentas  automatizadas. O objetivo da refatoração é remover problemas de código - muitas vezes  legado, produzindo código mais claro, mais fácil de manter, depurar e adicionar  funcionalidades.    Baseando-se nesses conceitos pode-se dizer que refatoração é o emprego de  técnicas para melhorar o projeto do software auxiliando na reestruturação do códigofonte, visando promover atributos não funcionais de software, tais como  extensibilidade, modularidade, reusabilidade, complexidade e eficiência.   3. Refatoração para Aplicações Web   Técnicas de refatoração são amplamente utilizadas em linguagens de programação  como Java e C. Porém, não é só código orientado a objetos ou linguagens orientadas a  objetos que podem produzir código ruim e com necessidade de refatoração. Pode-se  dizer que não somente linguagens de programação, mas qualquer sistema  suficientemente complexo e mantido ao longo do tempo pode se beneficiar de  refatoração.    Em um sistema Web o lado servidor de uma grande aplicação distribuída,  funciona geralmente sobre uma base de dados relacional, enquanto que o lado cliente é  uma ou mais páginas web, quase sempre construídas com códigos HTML (HyperText  Markup Language), CSS (Cascading Style Sheets) e JavaScript. O HTML tornou o  desenvolvimento dessas aplicações mais rápidas, mas não as tornou mais fáceis, mais  simples ou menos complexas. Vários desses sistemas, tal como qualquer outra aplicação  de vida suficientemente longa podem acumular problemas de código. As novas  tecnologias não se adaptam perfeitamente com as antigas, tornam os sistemas mais  lentos, abrem brechas de segurança e deixam a alteração ou implementação de  funcionalidades comprometida. Em muitos casos não é possível jogar a aplicação fora e  criar uma nova, portanto a importância de aplicar as técnicas de refatoração é visível.      Harold (2010) aborda mais de 60 sugestões de refatoração para códigos HTML.  As técnicas são subdivididas em Documentos bem formados, Validade, Leiaute,  Acessibilidade, Aplicações Web e Conteúdo. As técnicas abordadas nas subseções  seguintes foram escolhidas, pois se adequam ao que se foi proposto para a melhoria das  aplicações estudadas.    3.1. Validade   A validade garante que somente elementos e atributos especificados no HTML  apareçam, mostrando o mesmo conteúdo para usuários de diversos navegadores. Para  Harold (2010), adicionar atributos alt em imagens é uma técnica de refatoração     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 334-337 Nov/2014     336   essencial, uma vez que dá assistência para usuários com deficiências de visão à medida  que navegadores de áudio vierem embarcados em celulares, carros e outros dispositivos  direcionados a esse público.   3.2. Leiaute   Harold (2010) cita que usar a semântica adequada para cada elemento torna as páginas  inteligíveis para leitores de tela e faz com que sejam mostradas apropriadamente para  diferentes plataformas. Muitos elementos, como o table são usados abusivamente para  tornar as páginas com aparência agradável. Atualmente, tem-se trabalhado bastante com  o desenvolvimento de páginas Web utilizando o conceito "tableless", ou seja, sem  tabelas. O padrão de desenvolvimento com o CSS e tags div permite a separação da  camada de apresentação, tornando a manutenção das páginas mais fácil, dentre outros  benefícios.   3.3. Acessibilidade   A web tem o poder de integrar à sociedade as pessoas com necessidades especiais. As  páginas Web devem ser projetadas de modo que não precisem saber qual o tipo de  dispositivo o usuário está utilizando, seja ele um monitor de vídeo ou um leitor de tela.  Harold (2010) lembra que os usuários com limitações visuais que utilizam leitores de  tela não podem usar o leiaute visual de uma página para determinar quais rótulos estão  associados a quais campos. É preciso rotular, deixar explícito cada um dos campos não  ocultos, de forma que eles sejam facilmente identificados pelos dispositivos. Para cada  elemento visível do tipo input, textarea ou select, deve existir ao menos um elemento do  tipo label associado.   3.4. Aplicações Web   Atualmente, muitos sites não são mais apenas estáticos, são aplicações completas para  entrada de dados, processamento de texto, jogos e muito mais. Com a evolução das  aplicações vem também a necessidade de tornar as páginas mais rápidas e seguras, de  modo que o usuário passe a utilizar essas ferramentas sem medo de que seus dados  sejam expostos e que o sistema suporte toda a demanda requerida.    Um exemplo de refatoração é a substituição de requisições GET inseguras por  POST. As requisições GET utilizam a própria URL para enviar os dados para o  servidor, essas requisições podem ser navegadas por robôs, pré-carregadas,  armazenadas em cache, repetidas ou acessadas automaticamente. Operações inseguras  como, por exemplo, cadastrar, alterar ou excluir um cliente, devem ser realizadas apenas  via POST, evitando que os dados sejam manipulados sem o consentimento do usuário.     Outro exemplo de refatoração é adicionar tipos de formulários Web 2.0, eles  trazem novos campos de entrada fortemente tipados (email, date, time, datetime,  datetime-local, month, week, number, tel e url), novos atributos para restrições, novas  interfaces e novos eventos DOM (Document Object Model) para validação e  acompanhamento de dependências. Eles permitem que os navegadores forneçam  componentes mais apropriados de interface gráfica para a entrada de dados.     Na questão segurança, usar sequência de escape para as entradas de usuário é  fundamental. Atualmente, a fonte mais comum de falhas de segurança na Web é a  injeção de código SQL (Structured Query Language). Harold (2010) cita que é     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 334-337 Nov/2014     337   provavelmente mais fácil encontrar um site baseado em banco de dados com uma  vulnerabilidade de injeção de código SQL que um site que não possua uma. Harold  (2010) ainda diz que a injeção de código SQL tem levado ao roubo de dados  confidenciais de clientes, fraudes de cartão de crédito, phishing, spams e a quase todos  os outros tipos de crimes auxiliados por computador que possamos imaginar.   4. Trabalhos Relacionados   Nesta seção serão analisados alguns trabalhos relacionados com a proposta. O trabalho  de graduação de Flores (2011) objetivou a busca de oportunidades de Refatoração em  Aplicações Web através da criação de buscas XQuery em páginas codificadas XHTML,  visando melhorar a estrutura do código fonte, bem como o desempenho de aplicações  Web.    Na dissertação de mestrado Boniati (2009) propõe identificar, automatizar e  aplicar técnicas de refatoração em aplicações de alto desempenho escritas em linguagem  Fortran (não orientadas a objetos) com vistas ao ganho de desempenho em relação a  suas construções originais. A tese de doutorado de Piveta (2009) trabalha com muitos  conceitos relacionados à refatoração, em especial a busca de oportunidades para  refatoração, de um contexto mais amplo, tendo como objetivo prover um processo  detalhado para refatoração.   5. Resultados Esperados e Considerações Finais   O presente trabalho apresentou as motivações para a realização de um estudo de caso  com o objetivo de aplicar técnicas de refatoração para aplicações Web. Trata-se de um  trabalho em andamento do qual, por meio de sua continuidade, pretende-se aprofundar o  estudo das principais técnicas para refatoração de aplicações Web citadas por Harold  (2010) e por meio de um estudo de caso aplica-las em sistemas legados na tentativa de  reestruturar seus códigos-fonte sem que isso interfira em seu funcionamento.     A refatoração vem sendo utilizada há anos e demonstra ser uma excelente  prática quanto referimos a reestruturação do código de aplicações legadas e/ou mal  planejadas ao longo do tempo. Espera-se por meio da continuidade deste trabalho  documentar o  processo de aplicação das técnicas escolhidas bem como demonstrar os  resultados e benefícios alcançados (segurança, leiaute, acessibilidade, desempenho, etc.)    Referências   Boniati, B. B. (2009), Refatoração de Programas Fortran de Alto Desempenho.  Universidade Federal de Santa Maria, Dissertação de Mestrado.   Flores, P. L (2011), Busca de Oportunidades de Refatoração em Aplicações Web.  Universidade Federal de Santa Maria, Trabalho de Graduação.   Fowler, M (1999), Refatoração: Aperfeiçoamento e Projeto, Bookman.    Harold, E. R. (2010), Refatorando HTML, Bookman.    Piveta, E. K. (2009), Improving the Search for Refactoring Opportunities on ObjectOriented and Aspect-Oriented Software, Universidade Federal do Rio Grande do Sul.  Tese de Doutorado.       
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 338-341 Nov/2014     338   Provendo Acessibilidade em Sites com WAI-ARIA   Andressa Vergutz, Bruno Batista Boniati   Universidade Federal de Santa Maria (UFSM)  Caixa Postal 54 – 98.400-000 –  Frederico Westphalen – RS – Brasil   {andressavergutz,brunoboniati}@gmail.com   Resumo. Observa-se que nos últimos anos houve um grande crescimento na  utilização da Web como plataforma de trabalho e comunicação. Em função  disso, os sites têm utilizado muitos recursos para prover interfaces ricas.  Porém, quanto mais rica é a interface, mais difícil ela pode se tornar para  usuários com necessidades especiais. A partir do HTML5 existe uma  especificação para prover acessibilidade na Web, trata-se da WAI-ARIA (Web  Accessibility Initiative - Accessible Rich Internet Applications). Por meio deste  trabalho, pretende-se estudar tal especificação e desenvolver um site que  apresente requisitos de acessibilidade.   Abstract. It is observed that in last years, there was a large growth in the use  of the Web as a working and communication platform. For this reason, the  websites have used many resources for provide rich interfaces. However, the  richer the interface is, the more difficult it can become for users with special  needs. From the HTML5 exists a specification to provide Web accessibility, it  is the WAI-ARIA (Web Accessibility Initiative - Accessible Rich Internet  Applications). Through this work, it is intended to study such specification and  to develop a website that presents accessibility requirements.   1. Introdução   A WEB como se apresenta hoje, é uma das ferramentas mais revolucionárias de nossa  sociedade. Além de ser um espaço livre e democrático, tem permitido uma revolução  em nossas relações, tanto pessoais, como profissionais e até mesmo econômicas. Não é  desejável que toda essa revolução seja acessível apenas a uma parcela da população,  desse modo, é essencial a acessibilidade estar presente na Web a fim de proporcionar  igualdade de acesso e oportunidades para todas as pessoas [W3C 2014].    Considerando tal realidade, desenvolvedores e organizações procuram achar  soluções para atender o maior número possível de usuários que possuam algum tipo de  deficiência. Pode-se citar a W3C que durante anos cria padrões acessíveis a serem  seguidos pelos desenvolvedores web. Dessa forma, o objetivo deste trabalho é estudar a  especificação WAI-ARIA da W3C, a fim de desenvolver um site web acessível. Este  site, que no momento se encontra em fase de desenvolvimento, abordará o conteúdo do  projeto de extensão cujo nome é "Capacitação para o Uso de Tablets Educacionais em  Espaços Escolares" e objetiva compartilhar materiais que venham auxiliar docentes na  utilização do tablet. Como o conteúdo da aplicação web será acessível, pretende-se  utilizar a ARIA e outras recomendações da W3C conforme necessidades.    2. Web e Acessibilidade   Quando a Web foi concebida por Tim Berners-Lee sua intenção principal propunha uma  forma de navegação em documentos de texto. Com o passar do tempo, percebeu-se que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 338-341 Nov/2014     339   a Web era uma ótima forma de distribuição de informações e sua evolução foi  exponencial. Hoje, além de textos, é comum encontrar grande quantidade de imagens,  sons e vídeos. A forma de interação também evoluiu bastante, não são mais apenas links  para navegar entre as páginas de textos, hoje é possível realizar operações como:  arrastar e soltar , duplo clique, parar sobre algum componente, e, além disso, a forma  como os dados são apresentados também pode ser diferente [Watanabe 2014].    Atualmente, as aplicações Web 2.0 passaram a apresentar maior interatividade,  permitindo que o usuário influencie na forma como o conteúdo é apresentado  [Watanabe 2014]. Não há dúvidas de que tais aplicações, conhecidas como Rich  Internet Applications (RIA), podem melhorar a experiência dos usuários na web. No  entanto, o aumento da interatividade apresenta uma série de barreiras de acessibilidade  para usuários que interagem com o navegador utilizando Tecnologias Assistivas, como  leitores de tela [Merayo 2011]. Para criar essa interatividade e obter um visual mais  sofisticado as aplicações da Web 2.0 utilizam linguagem de script e outras tecnologias  avançadas. Porém, grande parte dessas características exige percepção visual do usuário  e requerem interações do mouse para que possam ser operadas, resultando num impacto  negativo na acessibilidade da aplicação [Watanabe 2014].    RIA e componentes de interface Ajax alteram e atualizam dinamicamente a  estrutura DOM (Document Object Model) de uma página web sem a necessidade de  gerar uma atualização completa da página [Watanabe 2014]. As Tecnologias Assistivas,  em grande parte, não estão preparadas para que novos conteúdos apareçam em lugares  arbitrários da estrutura da página. Para tais tecnologias não é possível ler o código fonte  e descrever seu comportamento antes que a interação seja realizada.   3. WAI-ARIA   A W3C por meio da WAI (Web Acessibility Iniative) trabalha em diversos padrões e  recomendações que tem por objetivo melhorar a acessibilidade dos sites [Grillo 2014].  A especificação WAI-ARIA, Accessible Rich Internet Applications Suite, é umas dessas  recomendações que trata da acessibilidade em interfaces ricas. A ARIA ajuda  especialmente em conteúdos dinâmicos e controles avançados de interface de usuários,  focando principalmente em usuários dependentes de leitores de tela e pessoas que não  podem utilizar o mouse [W3C 2014].      ARIA define um conjunto de atributos para serem incluídos nos elementos  HTML. Esses atributos compreendem as seguintes extensões: estado (states),  propriedade (property) e papel (role).  Estados e propriedades são usadas para  declarar atributos importantes de um elemento e informam a descrição e interação do  mesmo. Os papéis indicam o tipo de elemento, ou seja, informará como o elemento se  comportará, por exemplo, no elemento LI do MENU o role (papel) informará que esta  lista se comportará como um item de menu (<li role="menuitem">). A Figura 1  permite observar que o atributo role informa que essa DIV se comporta como um slider,  e os outros atributos estão informando propriedades importantes para o elemento que  são os valores máximo, mínimo e atual do elemento slider. Desse modo, a tecnologia  assistiva receberá esses atributos e o usuário com deficiência conseguirá manipular o  elemento pelo teclado [Merayo 2011].     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 338-341 Nov/2014     340     Figura 8. Exemplo de utilização da especificação WAI-ARIA.   4. Trabalhos Relacionados   Analisando trabalhos na área de acessibilidade Web com estudos de casos sobre ARIA,  podemos identificar algumas iniciativas de pesquisa parecidas com o presente trabalho.     Watanabe (2014) propõe melhoria no processo de avaliação automática de  aplicações web ricas (RIA). Assim, elabora diferentes estratégias para avaliar  automaticamente a acessibilidade considerando a utilização de leitores de tela para a  navegação. Após estudos e testes realizados, conclui que para avaliar a acessibilidade  dessas aplicações Web é necessário não avaliar apenas o conteúdo HTML, mas também  o seu comportamento implementado utilizando JavaScript e CSS.  Conclui também, que  as ferramentas de avaliação automáticas se sobressaem das ferramentas de avaliação de  conteúdo estático HTML [Watanabe 2014].    Ghelardi (2012) apresenta impactos da especificação ARIA na construção de  aplicações web ricas, baseando-se no desenvolvimento de um player de mídia acessível.  Concluiu que a partir da utilização de especificações Web como o HTML5 e ARIA é  perfeitamente possível a construção de soluções acessíveis, sem sacrificar a aparência e  a interatividade das mesmas [Ghelardi 2012].   5. Resultados Parciais   Salienta-se que o presente trabalho se encontra em fase de desenvolvimento. Entretanto,  já foram determinados alguns requisitos da ARIA que serão utilizados no site web, três  deles serão descritos abaixo.     Um destes requisitos trata da forma de como avisar o usuário de algum erro  ocorrido durante o preenchimento de formulários. Geralmente, quando algum campo é  preenchido de forma incorreta o usuário é notificado disso com a alteração da  apresentação dos campos (por exemplo, muda a cor). Porém, estas práticas não são  acessíveis. A fim de resolver estes problemas, ARIA introduz as propriedades ariarequired e aria-invalid para marcar os campos que são obrigatórios e caso  houver algum erro de preenchimento deverá avisar o usuário, respectivamente, onde  esse aviso será através da tecnologia assistiva. Um exemplo de tais propriedades é  ilustrado na figura 2.     Figura 2. Exemplo de propriedades da especificação WAI-ARIA.    Outro requisito que será utilizado são as Roles Landmarks que marcam as  principais estruturas da aplicação web de forma a facilitar a navegação do usuário com o  teclado. As landmarks descrevem e marcam estruturas comuns da web como menus  (navigation), conteúdo principal (main), rodapés (contentinfo), caixa de pesquisa  (search), entre outros. Com isso, o usuário não precisa ficar pressionando a tecla TAB  muitas vezes. A figura 3 ilustra a utilização das roles citadas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 338-341 Nov/2014     341     Figura 3. Exemplo do atributo Roles Landmarks da ARIA.    A propriedade aria-describedby também será utilizada na implementação  da aplicação web. Esta propriedade tem como função passar alguma informação  importante sobre o elemento, essa informação pode estar relacionada à função do  elemento por exemplo. Através dela o usuário dependente de leitores de tela conseguirá  saber o que o elemento fará e para que ele serve.  A figura 4 abaixo possui um exemplo  da utilização desta propriedade.     Figura 4. Propriedade aria-describedby da WAI-ARIA.   6. Considerações Finais   A partir do estudo e testes sobre WAI-ARIA, a especificação se mostrou útil e eficiente,  através dela é possível resolver vários problemas de acessibilidade tanto em interfaces  ricas quanto em aplicações web não tão sofisticadas. A utilização da ARIA não afeta  muito a implementação, o tempo gasto utilizando ou não a especificação é praticamente  o mesmo. Outro ponto relevante é que sua documentação no site da W3C é muito rica,  possui exemplos e descrições de cada propriedade e atributo da especificação. Desse  modo, conclui-se que é de extrema importância abordar essas recomendações e utilizálas para tornar a Web um mundo mais acessível para que todos possam contribuir de  alguma forma.   Referências   Ghelardi, A., Otsuka, J. L. and Kawakami, C. (2012). Acessibilidade na Educação a  distância: desenvolvimento de um player de mídia acessível utilizando html5 e waiaria e sua integração com o moodle.  In Anais do Simpósio Brasileiro de Informática  na Educação, volume 23.   Grillo, F. D. N. (2014). Uma ferramenta acessível de apoio à modelagem de software  na web.  PhD thesis, Universidade de São Paulo.   Merayo, R. V. N. (2011). Rich internet applications (RIA) and web accessibility.   http://www.upf.edu/hipertextnet/en/numero-9/ria-and-webaccessibility.html. Set/2014.   W3C (2014). Wai-aria oreview. http://www.w3.org/WAI/intro/aria.  Set/2014.   Watanabe, W. M. (2014). Avaliação automática de acessibilidade em RIA.  PhD thesis,  Universidade de São Paulo.       
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 342-346 Nov/2014     342   Uma proposta de Experimento da Combinação de Técnicas de  Vendas com a Técnica de Entrevista em Engª de Requisitos   Carlos A. Paiva, Kelvin M. F. Firmino, Glauber R. Balthazar   Faculdade de Tecnologia de Carapicuíba - Avenida Francisco Pignatari, 650 - Vila  Gustavo Correia, Carapicuíba - SP - CEP: 06310-390   {beto.fatec,kelvinmatheus}@gmail.com, glauber_rochab@yahoo.com.br   Abstract. In this work the possibility of applying the techniques of sales is  presented in conjunction with the activity requirements elicitation. Based on  this proposed approach is the development and implementation of an  experiment on a software engineering project. For both qualitative and  quantitative approaches are used, based on participant observation, ie, the  researcher immersed in the experiment.   Resumo. Neste trabalho é apresentada a hipótese da aplicação das técnicas  de vendas em conjunto com a atividade de levantamento de requisitos. Com  base nessa abordagem é proposta a elaboração e a aplicação de um  experimento em um projeto de engenharia de software. Para tanto são  utilizadas a abordagem qualitativa e quantitativa, tendo como base a  observação participante, ou seja, o pesquisador imerso no experimento.   1. Introdução    Simpatia, gentileza e cordialidade são quesitos que podem referenciar uma  relação social entre duas ou mais pessoas. Shakespeare (1564-1616) dizia que "É mais  fácil obter o que se deseja com um sorriso do que com a ponta da espada.". Assim, mais  do que apenas comercializar um produto, existe hoje a preocupação em satisfazer e  agradar o cliente. Isso objetiva a fidelização, para que novas vendas de produtos e  serviços sejam realizadas. Técnicas de vendas são aplicadas no comércio com esse foco  (MARTINS et al., 2009). Sorrir ao receber um cliente, um atendimento cordial  (ALVES, 2010) ou mesmo a premiação através de uma promoção (HSM, 2003) são  estratégias que objetivam fazer com que o cliente se sinta bem ao comprar, ou satisfeito  com o serviço que adquiriu, aumentando assim sua fidelização (MARTINS et al., 2009).    Dentro do processo de engenharia de software, no estágio de levantamento de  requisitos, a equipe técnica trabalha para descobrir informações sobre o domínio de  aplicações. Essa atividade envolve clientes e usuários finais de um sistema, e torna-se  particularmente difícil captar essas informações (SOMERVILLE, 2007). Falta de  cooperação, omissão de informações ou mesmo o simples fato do usuário não saber de  forma exata o que deseja em um sistema, estão entre as principais dificuldades  apontadas. Santiago (2011) defende que um dos princípios fundamentais da Engenharia  de Software é a boa comunicação entre os usuários e engenheiros de software.    Baseado nessas premissas, e com o intuito de oferecer uma possível resposta à  pergunta-problema: “Como modificar a interação entre os envolvidos em um projeto de  TI (Tecnologia da Informação) de forma a otimizar a captação de informações durante o  levantamento de requisitos?”, este projeto propõe como hipótese, a conjugação de  Técnicas de Vendas com a Técnica de Entrevista durante o levantamento de requisitos,  com o intuito de analisar a interação e, por consequência, a captação de informações.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 342-346 Nov/2014     343   2. Objetivo    Este trabalho objetiva elaborar e efetuar um experimento conjugando as técnicas  citadas, de forma a apresentar resultados quantitativos e qualitativos sobre o processo.   3. Metodologia    A estrutura usada para definir a metodologia empregada no experimento é uma  adaptação das etapas descritas por Martins (2009) em sua obra “Técnicas de Vendas”,  com a técnica de levantamento de requisitos “Entrevista” Moraes (2009). Essa  adaptação propõe a divisão sequencial do experimento, conforme etapas (Figura 1).          Na parte Atividades e Técnicas selecionam-se as técnicas que melhor se  adaptam ao experimento, detalhando-se cada uma. Assim, optou-se pela técnica de  entrevista por esta se adequar de forma mais satisfatória, a este projeto acadêmico. A  possibilidade de aplicação em um número limitado de pessoas, em um reduzido espaço  físico e de tempo, Moraes (2009) propõe que essa seja a técnica mais indicada ao  experimento proposto. Esse experimento será aplicado sobre uma equipe de alunos  voluntários da Fatec Carapicuíba, dividida em dois grupos: alunos analistas - com  sólidos conhecimentos na área de TI, e alunos usuários – com nenhum conhecimento no  processo de construção de um software. Na parte Preparação e Aplicação, os grupos  passarão por treinamento específico, e as técnicas de venda e entrevista serão  efetivamente aplicadas. Na última parte Resultados os dados obtidos na segunda parte  serão coletados e, em seguida, analisados segundo métricas expressas nesta pesquisa.   4. Material e Método    A pesquisa apresentada neste projeto é predominantemente qualitativa, isto é, a  interpretação dos fenômenos e a atribuição de significados são básicas, e não requerem  o uso de métodos e técnicas estatísticas. O ambiente natural onde ocorre (local onde  acontece o processo in natura) é a fonte direta para coleta de dados e o pesquisador é o  instrumento chave.  O experimento proposto projeto se divide em três partes, onde  cada uma possui um conjunto de processos (Figura 2), e são descritos a seguir.        Figura 9. Detalhamento da Metodologia do Experimento.   Fonte: autores do projeto   Figura 1. Metodologia de Criação do Experimento. Fonte: autores do projeto       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 342-346 Nov/2014     344   4.1. Atividades: Criação    Antes de iniciar-se o experimento, serão tomados cuidados específicos a fim de  se evitar possíveis ameaças que possam invalidar os resultados obtidos através do  método “duplo-cego de dois grupos”. Segundo Wainer (2007), esse é o método que  proporciona maior redução de ameaças que possam invalidar resultados experimentais.    4.2. Atividades: Detalhamento    O experimento foi dividido em etapas, sendo elas: Etapa 1: serão formados dois  grupos (T1 e T2). T1 será formado por duas pessoas da área de TI e T2 por seis pessoas,  com nenhum ou com poucos conhecimentos em TI (T1 e T2 serão alunos da FATEC  Carapicuíba); Etapa 2: T1 será dividido em T1A e T1B. Ambos receberão treinamentos  em levantamento de requisitos, mas apenas T1A receberá instruções sobre técnicas de  vendas; Etapa 3: T2 receberá treinamento sobre o funcionamento de um negócio  (Faturamento e Emissão de Notas Fiscais), para que possam fornecer informações  solicitadas pelos analistas durante a entrevista; Etapa 4: serão formados novos grupos,  chamados de G1 e G2, onde: G1 será o Grupo Experimental - aquele que sofre a  intervenção referente à aplicação das técnicas de venda em conjunto com a técnica de  entrevista, e G2 será Grupo de Controle – aquele não sofrerá intervenção; Etapa 5: será  efetuado o experimento aplicando-se os conhecimentos adquiridos nos treinamentos  (Figura 3) e, na sequência, serão coletados os requisitos levantados no processo e  aplicados questionários para geração de dados. Etapa 6: Na conclusão do projeto serão  apresentados relatórios apontando os resultados qualitativos e quantitativos obtidos.   4.3. Preparação e Aplicação: Preparar o ambiente para experimentação    Para a aplicação do experimento serão usadas 3 salas que, isoladamente,  receberão: T1A, T1B e T2; material de apoio (folders, lápis e papel) e gravador de som.   4.4. Preparação e Aplicação: Iniciar o treinamento das equipes    A equipe de apoio (T1A e T1B) será treinada nos conceitos de: requisitos,  técnicas de levantamento de requisitos, entrevista, preparação, condução e finalização  da entrevista; T1A receberá o treinamento diferenciado, conjugado com as técnicas de  vendas abordando os tópicos: técnicas e fases de venda, Fase 1: Pré-Abordagem, Fase 2:  Abordagem, Fase 3: Levantamento das necessidades. Por fim, o grupo T2 receberá o  treinamento sobre o funcionamento do negócio, que abordará: definição do negócio,  apresentação do material, atividades e técnicas para o bom desenvolvimento do negócio.   Figura 3. Divisão de Grupos, Aplicação do Experimento e Coleta de Resultados. Fonte: autores do projeto     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 342-346 Nov/2014     345   4.5. Preparação e Aplicação: Aplicar o experimento    Uma vez reunidos os participantes do experimento, será efetuada a divisão dos  grupos. G1 será formado pelo analista do grupo T1A e por 3 integrantes de T2 (seleção  aleatória). G2 será formado pelo analista do grupo T1B e por outros 3 integrantes de T2.    4.6. Resultados: Coletar e efetuar a análise    Para análise do experimento serão gerados relatórios, que indicarão os resultados  qualitativos e quantitativos do grupo G1 - Experimental e G2 - Controle.  Para mensurar  os dados quantitativos serão usados questionários, que indicam o grau de interação em  uma escala Likert. Para os dados qualitativos, serão apresentados os requisitos  coletados, transcrições (parciais) de gravações e anotações efetuadas no experimento.   5. Trabalhos Relacionados    Podem-se destacar alguns trabalhos de suma importância neste projeto, que  estão relacionados ao tema do experimento. Dentre eles: Metodologia da Pesquisa  Qualitativa e Quantitativa (WAINER, 2007), Técnicas de Elicitação de Requisitos  (WAGNER, 2011), Análise da Interação Social de Analistas de Requisitos e Usuários  (BALTHAZAR, 2012), Engenharia de Requisitos - Técnicas (BRUM, 2011), e demais  autores indicados nas referências bibliográficas.   6. Considerações Finais e Cronograma   O atual projeto de TCC encontra-se qualificado e em desenvolvimento. Na atual fase, as  autorizações da FATEC Carapicuíba para recrutamento dos alunos participantes já  foram obtidas. Pretende-se como próxima fase (Figura 4) realizar o treinamento dos  alunos, aplicar o experimento e apresentar a análise dos resultados obtidos.  DATAS TAREFAS 27.09 Preparação do Treinamento: Requisitos, Técnica de Entrevista, Técnica de Vendas, Funcionamento de Negócio 01.10 Entrega do Plano de Aula(Requisitos / Técnica de Entrevista) e Treinamento do Analista 1  Entrega do Plano de Aula (Func. Negócio) e Treinamento dos Usuários. Entrega do Plano de Aula (Técnicas de Vendas e de Entrevista) e Treinamento do Analista 2 (Técnicas Conjugadas)  11.10 Aplicação do Experimento - Preparação dos Relatórios Sintéticos e inclusão dos resultados no documento final 18.10 Preparação PPT  para Defesa e Entrega do documento Final à Banca  04.10.     Referências Bibliográficas   ALVES, José Roberto. A Importância do Vendedor Frente à Globalização. 2010.  Disponível em: <http://www.techoje.com.br/site/techoje/categoria/detalhe_artigo/834>.    BALTHAZAR, Glauber da R. Análise da Interação Social de Analistas de Requisitos e  Usuários na Etapa de Levantamento de Requisitos. 2012. 163 f. Dissertação (Mestrado  Profissional em Engenharia da Computação do IPT), SP 2012.   BRUM, Bruno C.P.; PENA, Leandro. Engenharia de Requisitos – Técnicas. 2011.  Disponível em: <http://brunobrum.wordpress.com/2011/04/27/principais-tecnicas-delevantamento-de-requisitos-de-sistemas>   HSM Management. As Melhores Práticas em Vendas. 2003. Disponível em: <http://  www.techoje.com.br/site/techoje/categoria/detalhe_artigo/322>   Figura 4. Cronograma de Preparação e Aplicação do Experimento. Fonte: autores do projeto     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 342-346 Nov/2014     346   MARTINS, Carlos A.; SCHVARTEZEER, Arnaldo; RIBEIRO, Pedro H. A. Técnicas  de Vendas. Rio de Janeiro, RJ: Editora FGV, 2009.   MORAES, Janaina B. D. Técnicas para Levantamento de Requisitos. Revista  Engenharia de Software 2.  2009. Disponível em: <http://www.devmedia.com.br  /engenharia-de-software-2-tecnicas-para-levantamento-de-requisitos/9151>.    SANTIAGO, Marcos R. Ensaio do SWEBOK – Software Engineering Body of  Knowledge. Goiânia, GO, 2011 (Trabalho Conclusão Curso). Universidade Gama Filho   SOMMERVILLE, Ian. Engenharia de Software. São Paulo: Ed Pearson, 2007.   WAINER, Jacques. Metodologia de Pesquisa Quantitativa e Qualitativa para a Ciência  da Computação. In: Tomasz Kowaltowski ; Karin Breitman. Atualização em  informática 2007. Soc. Brasileira de Computação e Editora PUC rio, 2007, p. 221-262.    WAGNER, Rosana. Técnicas de Elicitação / Extração de Requisitos. 2011 Disponível  em: <http://www.profs.iffca.edu.br/~rosana/Pos-gradua%E7%E3o/3%20-%20Tecnicas  %20de%20Elicita%E7%E3o%20de%20Requisitos.pdf>    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 347-351 Nov/2014     347   Análise de Performance de Frameworks de Desenvolvimento  Mobile Multiplataforma   Kamile A. Wahlbrinck, Bruno B. Boniati   Universidade Federal de Santa Maria – (UFSM)  Caixa Postal  54 – 98.400-000 – Frederico Westphalen – RS – Brasil   {kamilewahlbrinck,brunoboniati}@gmail.com   Resumo. Desenvolver aplicações mobile não é tarefa fácil devido as várias  plataformas móveis existentes. Para facilitar o desenvolvimento dessas  aplicações existem frameworks de desenvolvimento multiplataforma, que  permitem que se escreva um único código que funcione em mais de uma  plataforma móvel, o que torna o desenvolvimento mais rápido e fácil. Este  trabalho tem como objetivo analisar a performance desses frameworks  comparada à de aplicativos nativos. Serão abordados diferentes frameworks  (que utilizam diferentes linguagens de programação) e partindo-se de uma  aplicação nativa com uso intenso de CPU pretende-se mapear as diferenças  no tempo de execução de tal aplicativo utilizando-se o mesmo hardware e  diferentes frameworks.   Abstract. Developing mobile applications is not a easy task because of the  several existing mobile platforms. In order to facilitate the development of  these applications there are cross-platform development frameworks which  allow the user to enter a unique code that works on more than one mobile  platform making it a faster and easy development. This paper aims to analyze  the performance of these frameworks compared to native applications. It will  be addressed different frameworks (ones that use different programming  languages) and starting from a native application with intensive CPU usage it  is intended to track differences in performance time as such application using  the same hardware and different frameworks.   1. Introdução  Com a crescente evolução das tecnologias, os dispositivos inteligentes estão cada vez  mais presentes no dia a dia das pessoas. A utilização de dispositivos móveis é bastante  variada, profissionalmente pode ser utilizado para ler e-mails, realizar transações  bancárias e utilizar ferramentas de comunicação providas pela internet [PREZOTTO   2014]. O fato de a tecnologia estar cada vez mais acessível a diferentes perfis de  consumidores torna esses dispositivos ferramentas de trabalho, lazer e aprendizagem e  um grande mercado consumidor para quem tiver interessado em oferecer serviço e  softwares.     O advento do conceito de sistemas operacionais ou plataformas para dispositivos  móveis é um dos fatores que possibilitou o crescimento na oferta de aplicativos para tais  plataformas [LECHETA 2013]. Observa-se, no entanto, que não há um padrão de  mercado em relação à plataforma de desenvolvimento a ser adotada e dependendo da  escolha do profissional de Tecnologia da Informação (TI) o software desenvolvido será  incompatível para ser executado em uma plataforma diferente daquela para o qual foi  projetado [CARVALHO 2014].      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 347-351 Nov/2014     348    Diante de tal realidade programadores procuram uma forma fácil e rápida para  atender as necessidades do maior número possível de plataformas, pois desenvolver um  aplicativo para cada dispositivo é uma tarefa economicamente desgastante. A solução é  recorrer a frameworks de desenvolvimento multiplataforma, que a partir de um único  código tornam possível que sua aplicação funcione em mais de uma plataforma.   A intenção deste trabalho é estudar diferentes frameworks para desenvolvimento  mobile e realizar um teste de performance com os mesmos. Entende-se que o fato de os  frameworks utilizarem diferentes linguagens e tecnologias é natural que se comportem  de forma diferenciada. Para tanto a próxima seção conceitualiza os frameworks  multiplataforma e descreve alguns que estão sendo utilizados para os testes. A seção 3  apresenta os resultados parciais obtidos com os testes e na seção 4 são feitas as  considerações finais.   2. Frameworks de Desenvolvimento Multiplataforma  Segundo Fayad e Schmidt (1997), um Framework é uma aplicação semi-completa,  reusável que pode ser especializada para produzir aplicações customizadas. No contexto  do desenvolvimento de aplicações multiplataforma, os frameworks podem ser  entendidos como blocos de códigos pré-implementados que serão reutilizados no  momento da compilação do código escrito pelo desenvolvedor para gerar a aplicação  final [FAYAD e SCHMIDT 1997].    Resumidamente, frameworks de desenvolvimento multiplataforma nos permitem  escrever um único código que poderá ser executado em mais de uma plataforma móvel.  Durante o desenvolvimento desse trabalho são utilizadas as seguintes ferramentas:  Phonegap, AppGyver e Corona SDK. Para fins de comparação, uma aplicação nativa,  que executa o mesmo algoritmo também será implementada, neste caso será utilizada a  linguagem de programação Java com SDK para Android.   2.1. PhoneGap  Open-source e gratuito, o PhoneGap provê um container web no qual você constrói suas  aplicações multiplataforma usando apenas o básico da web: HTML5 + JavaScript e  CSS. Ele provê APIs JavaScript para que o desenvolvedor tenha acesso aos recursos de  hardware do dispositivo móvel e exige apenas que os dispositivos tenham browsers que  suportem esses recursos básicos e padrões da web [PHONEGAP 2014].   2.2. AppGyver  AppGyver utiliza linguagens web (HTML5 e JavaScript) para desenvolvimento de  aplicativos móveis. É conhecido principalmente por suas ferramentas de prototipagem e  por usar Steroids.js, uma ferramenta de linha de comando que permite criar rapidamente  aplicativos HTML5. Um recurso muito interessante do serviço é que pode-se gerar um  código QRCode e digitalizá-lo no aplicativo móvel do AppGyver para acompanhar as  alterações feitas no desenvolvimento em seu telefone em tempo real [APPGYVER  2014].   2.3. Corona SDK  Baseia-se na linguagem Lua e em frameworks consolidados de desenvolvimento como  OpenGL ES, OpenAL, Box2D, entre outros. Muito bom para desenvolvimento de jogos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 347-351 Nov/2014     349   2D, deixa a desejar um pouco quando a assunto são apps com look-and-feel nativo dos  frameworks tradicionais. Possui uma versão trial ilimitad mas um preço de  licenciamento alto quando se deseja publicar a aplicação nas lojas de aplicativos   [CORONA 2014].   2.4. Algoritmo Implementado  Para realizar os testes com os diferentes frameworks multiplataforma foi utilizado um  algoritmo que calcula a soma dos números primos no intervalo de 1 a 50000. O mesmo  algoritmo foi escrito em JavaScript para as ferramentas PhoneGap e AppGyver, em  Linguagem Lua, para o Corona SDK e em JAVA para o aplicativo nativo. A figura 1  mostra o algoritmo utilizado, escrito em pseudo-código.     Figura 1. Algoritmo Implementado   3. Resultados Parciais  Com base na pesquisa feita sobre cada framework construiu-se uma tabela comparativa  onde são listados os frameworks estudados (PhoneGap, AppGyver, Corona SDK)  apresentando algumas de suas características. O resultado pode ser visualizado na tab. 1.   Tabela 1. Tabela Comparativa – Frameworks de Desenvolvimento Mobile    PhoneGap AppGyver Corona   Plataformas  Suportadas   Android, iOS, Windows Phone,  Black Barry, Symbiam, Bada,  Kindle Fire e Nook Color   Android, iOS Android,  iOS   Linguagens HTML, JavaScript, CSS JavaScript, HTML5 Lua   Acesso a recursos de  Hardware   Sim Sim Sim    Conforme apresentado na tabela 1, percebe-se que o PhoneGap é o framework  que abrange maior número de plataformas e assim como o AppGyver utiliza umas das  linguagens mais conhecidas entre os programadores. É importante ressaltar que o  PhoneGap e o AppGyver, executam os aplicativos usando WebViews, que se utilizam  do browser para rodar o aplicativo, tanto online quanto off-line. Já o framework Corona  utiliza interpretadores ou compiladores incorporados nas aplicações ou nos sistemas  operacionais para executar o mesmo código fonte em mais de uma plataforma.    Os testes para análise de performance das ferramentas foram realizados em um  mesmo hardware, um celular da Samsung, modelo Galaxy SIII mini aparelho GT18190L com processador Dual Core 1GHz e 1GB de memória RAM, com sistema     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 347-351 Nov/2014     350   operacional Android 4.1 Jelly Bean.  A partir dos testes realizados, chegou-se a um  tempo médio de execução para cada ferramenta, divisão da soma do tempo de cada  execução dos dez testes realizados com o aplicativo desenvolvido em cada framework,  apresentados na tabela 2.   Tabela 2. Tabela Comparativa – Tempo de execução dos algortimos    PhoneGap AppGyver Corona Android   Máximo 104,96s 112s 989,7s 72s   Mínimo 89,21s 90,15s 600s 62s   Médio 92,39s 95,77s 900,5s 63,7s   Percentual 47% 50,3% 1313% -    Com base nas informações da tabela 2 pode-se observar que o aplicativo com  melhor performance foi o nativo, seguido dos aplicativos desenvolvidos com linguagens  web e por último, com pior desempenho, o aplicativo desenvolvido em Lua.  Comparados ao tempo de execução do aplicativo nativo, os aplicativos desenvolvidos  usando frameworks em HTML foram, em média, 48,65% mais lentos que o nativo,  enquanto o app desenvolvido com linguagem Lua foi 1313% mais lento que o nativo.   4. Conclusão  O trabalho de pesquisa realizado, permitiu-nos identificar a existência de algumas  iniciativas no sentido de oferecer ao profissional de TI um conjunto de ferramentas e  bibliotecas para desenvolver uma única versão do software e portá-la para diferentes  plataformas. Observa-se, no entanto, que tais ferramentas apresentam significativas  diferenças que vão desde a linguagem utilizada para codificar até a forma de  disponibilizar o software desenvolvido para instalação. Os recursos oferecidos pelos  frameworks estudados também são distintos e não há uma homogeneidade em relação  às plataformas suportadas.    As próximas etapas do projeto visam desenvolver um novo algoritmo para testar   a performance dos frameworks quanto a memória e testar como funciona o acesso aos  recursos nativos do hardware.   Referências  AppGyver. (2014) “Create beautiful mobile apps with”, http://www.appgyver.com/,   acesso em setembro/2014.   Carvalho, M. S. (2014) “Titanium Mobile: Aplicações multiplataforma”,  http://www.devmedia.com.br/titanium-mobile-aplicacoes-multiplataforma-revistamobile-magazine-41/24055, acesso em setembro/2014.   Corona, S. (2014) “Develop cross platform mobile apps em games”,  http://coronalabs.com/products/corona-sdk/, acesso em setembro/2014.   Fayad, E. M. e Schmidt, D. C. (1997) “Object-oriented application frameworks”, In:  Communications of the ACM, Editora Guest, p. 32-38.   Lecheta, R. R. (2013), Aprenda a criar aplicações para dispositivos móveis com  Android SDK, 3ª edição.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 347-351 Nov/2014     351   PhoneGap, (2014) “Easily create apps using the web technologies you know and love:  Html, css and javascript”, phonegap.com/, acesso em setembro/2014.   Prezotto, E. D.. (2014), Estudo de frameworks multiplataforma para desenvolvimento  de aplicações mobile híbridas. Universidade Federal de Santa Maria, Trabalho de  Conclusão de Curso.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 352-355 Nov/2014     352   Micuim: Uma proposta de Sistema de Gerenciamento de  Atividades Desportivas   Marcelo Kunz, Antônio Augusto Foletto, Joel da Silva   Departamento Graduação, Pós-Graduação e Pesquisa – Colégio Agrícola de Frederico  Westphalen (CAFW) - Universidade Federal de Santa Maria (UFSM)    98400-000 – Frederico Westphalen – RS – Brasil   {marcelo.kunz92,gutofoletto,joeldasilva}@gmail.com   Abstract. This paper presents the context of management of sports  competitions in a Web application, presenting a proposal to develop a tool for  managing sports championships. The prototype comes to complement the  sports activities system management taking its particularities geolocation  athletes. For development of the system will be based on the case study of a  particular municipality. Finally are addressed in this article the proposals and  the solutions expected by the application.   Resumo. O presente trabalho objetiva apresentar o contexto de gerencia de  competições esportivas em uma aplicação Web, apresentando uma proposta  de desenvolvimento de uma ferramenta para gerenciamento de campeonatos  esportivos. O protótipo vem para complementar o sistema de gerencia de  atividades esportivas tendo suas particularidades a geolocalização dos  atletas. Para desenvolvimento do sistema será baseado no estudo de caso de  um determinado município. Por fim são contemplados no presente artigo as  propostas e soluções esperadas pela aplicação.      1. Introdução  Novas tecnologias voltadas ao gerenciamento de eventos esportivos estão sendo  disponibilizadas na Web algumas delas sendo ferramentas pagas. Por algumas dessas  ferramentas serem pagas causam um impasse na utilização das mesmas ocasionando  certa carência tecnológica para seu segmento, como no caso o gerenciamento de  atividades desportivas.   Desta forma o Micuim pode vir a ser uma ferramenta que tornará possível a  organização de uma competição e poderá reduzir erros humanos durante as fases de um  campeonato tornando o mesmo mais preciso entre esses erros seria a falta de  documentação obrigatória de um determinado atleta ou problemas que impeçam o atleta  de atuar na competição.     2. Objetivo  O objetivo de desenvolver o sistema foi à necessidade de ter um software que fizesse o  gerenciamento de atividades desportivas sendo o mesmo livre e de código aberto e  tendo inúmeros recursos essenciais para gerenciamento de campeonatos e competidores,  podendo ser flexível para real necessidade de determinado município ou localidade, o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 352-355 Nov/2014     353   mesmo possui uma particularidade que é a geolocalização do competidor, assim tendo  finalidades como relatórios finais com endereço exato do mesmo.      3. Trabalhos Relacionados   Na fase de revisão bibliográfica, foram pesquisados e serviram de referência para o  mesmo os seguintes sistemas.    O Campeonato Online, ferramenta de uso simples e fácil que permite a gestão de  campeonatos de futebol pela internet (Campeonato Online, 2014), é sistema que possui  um plano Free, mas com seus recursos limitados, possui também plano expresso em  reais que dão acesso a seus recursos.   Campeonato de Verão é um portal Web que oferece um serviço avançado para  gerenciamento de campeonatos, desenvolvido por Dallas Websites que é uma empresa  de tecnologia da informação (Dallas Websites, 2014). O mesmo possui planos de  assinatura possuindo planos Free com recursos limitados e planos Rubi com todos os  recursos disponíveis sendo esses recursos pagos (Campeonato de Verão, 2014).     4. Micuim  O Micuim é um sistema cujo objetivo é cadastrar atletas adquirindo informações  relevantes a seu vinculo com determinado esporte fazendo a geolocalização do mesmo.   Além de parte administrativa de cadastrar e gerenciar equipes, modalidades,  realizar sorteio de chaves e grupos de um determinado campeonato.     4.1 Arquitetura  O Micuim vem obedecendo à estrutura MVC (model, view, controller), forma onde o  código está sendo separado de acordo com o papel que desempenha na sua aplicação. O  padrão MVC é uma solução para desacoplar as camadas de regras de negócio da  camada de visualização. Implementa três camadas distintas, sendo elas Model View  Controller, cada qual com suas características e atribuições em uma aplicação.  (GABARDO, 2012)   Quanto sistema gerenciador de banco de dados vem utilizando - se o modelo  relacional, fazendo assim o acesso facilitado dos dados, armazenando seus dados em  tabelas.     4.2 Tecnologias  O sistema está sendo desenvolvido com a linguagem PHP. É uma linguagem de  programação open source, muito utilizada e especialmente guarnecida para o  desenvolvimento de aplicações Web embutidas dentro do HTML, importante  característica dessa linguagem é fato de ser extremamente simples para iniciantes, e ao  mesmo tempo oferece muitos recursos para o programador profissional. (Manual do  PHP, 2013).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 352-355 Nov/2014     354   Para o gerenciamento e armazenagem de dados foi adotado o Mysql como base  de dados. O Mysql, sistema gerenciador de banco de dados (SGBD) relacional,  existindo uma versão com licença comercial e outra de código aberto com licença  (GPL) General Public License (MYSQL, online), o desempenho deste banco colabora  na sua grande fama, sendo considerado por grandes empresas o banco de dados mais  popular existente (VIDEIRO, 2008).    Também, se utiliza Ajax, que é uma tecnologia que utiliza recursos de scripts  executando no lado do cliente, buscando e carregando dados sem a necessidade de  recarregar a página. O objetivo do Ajax é evitar cada solicitação enviada pelo cliente ao  servidor e não seja necessário carregar toda a página (MORONI, 2007).   Para produzir páginas Web está sendo utilizado o Framework para front-end  Bootstrap, ferramenta para criação de sites e aplicações Web, contém HTML5, CSS3 e  JavaScript em sua composição (BOOTSTRAP, 2014). O HTML5 é uma linguagem de  marcação utilizada para produzir páginas web onde os documentos podem ser  interpretados pelos navegadores (W3C - HTML5, 2014). O CSS3 Cascading Style  Sheets (folhas de estilo em cascata) é utilizado para definir aparência em páginas web,  permitindo que as marcações de uma página sejam apresentadas em diferentes estilos  (W3C, 2011).   Completando a parte de front-end, o JavaScript que tem a funcionalidade de  complementar a criação de páginas Web as tornando mais dinâmicas e interativas. O  JavaScript é uma linguagem de programação interpretada e executada do lado cliente,  ou seja, a interpretação e o funcionamento da linguagem dependem de funcionalidades  hospedada no navegador do usuário (SILVA, 2010).     4.3 Desenvolvimento  Na camada de persistência está sendo utilizada a classe PDO do PHP tornando a  conexão com banco de dados flexível sem ficar dependente da tecnologia podendo ser  alterado o tipo de (SGBD) de acordo com a necessidade sem alterar grande número de  arquivos.   Na criação dos arquivos de da camada de persistência estão seguindo a estrutura  MVC sendo criados os arquivos da camada de modelo, camada de controle e os  arquivos da camada de visualização assim sendo construído um Framework pessoal.     4.4 Funcionamento  O funcionamento do sistema vem sendo disponibilizado em uma versão de teste ainda  não estando disponível para cadastros oficiais de atletas.    Após concluída a fase de prototipação o mesmo será disponibilizado junto com a  entidade promotora do campeonato esportivo, assim sendo disponibilizado em um  formulário para o cadastramento de competidores sendo os mesmo vinculados a suas  equipes e sendo geolocalizados para fim de relatórios aprimorados dos mesmos.   Uma vez que o cadastro foi realizado o mesmo passa por uma avaliação feita  pelo administrador do sistema podendo ser aceito caso as informações estão sendo  fornecidas de forma correta, ou podendo ficar pendente e não ser aprovado por falta de  informações fornecidas pelo usuário.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 352-355 Nov/2014     355           A parte de gerência feita pelo administrador do sistema é restrita assim tornando  os dados seguros apenas sendo disponibilizados dados para geração de relatórios e  podendo ser manipulados ou notificados pelo próprio administrador do mesmo. Além  de possuir inúmeras funcionalidades o mesmo tem que seguir rigorosamente o que está  descrito na documentação do sistema, pois o mesmo disponibiliza recursos essências  além de cadastros, gerencia de dados e relatórios finais.      5. Considerações Finais  Diante de um cenário complexo, possuindo ferramentas limitadas e possuindo recursos  pagos para gerenciamento de campeonatos esportivos, será disponibilizado um sistema  livre, podendo ser modularizado de acordo com a necessidade do cliente, contendo  inúmeras funcionalidades básicas e funcionalidades especificas do sistema, tendo  comprometimento na forma segura a armazenagem de dados.      Referências   ABOUT CURRENTLY v3.2.0. Disponível em: http://getbootstrap.com/about/. Acesso  dia 17 de setembro de 2014   CASCADING STYLE SHEETS (CSS) Snapshot 2010 - 2011. Disponível em:  http://www.w3.org/TR/CSS/. Acesso dia 18 de setembro de 2014   CAMPEONATO DE VERÃO, 2014. Disponível em:  http://www.campeonatodeverao.com.br/index.php. Acesso dia 18 de setembro de 2014   CAMPEONATOS ONLINE, 2009-2014 v2.49. Disponível em:  http://www.campeonatosonline.com.br/sobre. Acesso dia 19 de setembro de 2014   DALLAS WEBSITES. Disponível em:  http://www.dallaswebsites.com.br/?pg=empresa. Acesso dia 18 de setembro de 2014  GABARDO A.C. PHP e MVC com Codeigniter. Editora Novatec, 2012.  MANUAL DO PHP 2013. Disponível em: http://www.php.net/manual/pt_BR. Acesso  em: 18 de setembro de 2014   MYSQL 2014. Disponível em: http://www.mysql.com/why-mysql/. Acesso dia 18 de  setembro de 2014   MORONI, Herbert. Criação de Sites em Ajax. São Paulo: Digeratti Books, 2007.  128p.   SILVA, Mauricio S. JavaScript Guia do Programador. Editora Novatec Lita. 2010.  Disponível em:  https://www.novatec.com.br/livros/javascriptguia/capitulo9788575222485.pdf Acesso  dia 18 de setembro de 2014   VIDEIRO, Rafael, Criação de base de dados em linguagem SQL. Disponível em:  http://mysql.softonic.com.br/. Acesso dia 18 de setembro de 2014   VISÃO GERAL DO HTML5. Disponível em:  http://www.w3c.br/cursos/html5/conteudo/capitulo1.html. Acesso dia 17 de setembro  de 2014   
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 356-359 Nov/2014     356   Implementação de uma Ferramenta de Integração de Dados  Aplicado a Dados Meteorológicos    Marcelo L. Gross, José E. C. Soares, Alexandre T. Lazzaretti   IFSUL – Instituto Federal Sul-rio-grandense Campus Passo Fundo   Estrada Perimetral Leste, 150 – CEP: 99064-440 Passo Fundo (RS)  {marcelolgross, joseericosoares}@gmail.com,  alexandre.lazzaretti@passofundo.ifsul.edu.br   Abstract. Some contexts of human society, there is data stored and available  in various forms and formats. The use of data is not easy, because they need to  be transformed and integrated, to after to be manipulated. The agricultural  sector is very important in global economic and social context and is strongly  influenced by meteorological variables. Thus, this work aims to show the  implementation and design a tool to integrate weather data with the database.   Resumo Em diversos contextos da sociedade humana, existem dados  armazenados e disponíveis em diversas formas e formatos. A utilização desses  dados é extremamente trabalhosa, pois precisam ser transformados e  integrados para poderem ser manipulados. O setor agrícola possui  considerável importância no contexto econômico e social mundial e é  influenciado fortemente por variáveis meteorológicas. Nesse sentido, esse  trabalho tem por objetivo mostrar a implementação e o projeto uma  ferramenta para integração de dados meteorológicos com banco de dados.   1. Introdução   O processo de integração de dados é importante pelo fato de dados oriundos de  diferentes fontes poderem ser manipulados de forma única dentro de um determinado  domínio de aplicação (ALVARO, 2001).    Na agricultura os modelos de simulação de culturas são capazes de predizer o  rendimento final de grãos e também representar a simulação da dinâmica do  crescimento das culturas através da integração numérica (GRAVES et al., 2002). A  utilização de modelos de simulação tenta prever riscos e estimar tendências, e tem se  tornado um importante aliado para a tomada de decisão (DONATELLI et al., 2002;  SINCLAIR & SELIGMAN, 1996). Para a comunidade científica, tais modelos têm  auxiliado na organização do conhecimento e em testes de hipóteses. Os modelos de  simulação de culturas necessitam de dados meteorológicos de entrada e após a execução  do simulador, geram dados de saída. Dependendo do tipo de simulação executada, fazse necessário trabalhar com uma grande quantidade de dados em diversos formatos,  tanto de entrada quanto de saída. Sem os mecanismos adequados de manipulação e  armazenamento, esse trabalho torna-se difícil, ou até mesmo impossível de ser  realizado.   No entanto, atualmente poucas ferramentas deste cunho estão disponíveis para  realizar este trabalho de integração dos dados e estas normalmente, possuem limitações  quanto ao seu uso. Um exemplo é a ferramenta BPEL Process Manager, desenvolvida  pela empresa Oracle. Essa ferramenta possui integração com as ferramentas da mesma     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 356-359 Nov/2014     357   empresa, e apresenta empecilhos quando aplicada a outros ambientes.   Algumas ferramentas realizam a integração de dados através do mapeamento de  esquemas XML (HARA et. al.). Também existem ferramentas de integração num  contexto ETL (Extract Transform and Load). Elas recebem dados de diferentes  formatos nas etapas de extração, e realizam mapeamentos semânticos, cálculos de  valores, uniões, agregação, validação de dados dentre outras atividades na etapa de  transformação. Geralmente os dados de saída na etapa de carga dessas ferramentas é  feita por uma aplicação de data warehouse.   Dentre as ferramentas de ETL open source se destacam a Pentaho BI Suite e a  Talend Data Integration. Essas ferramentas possuem uma arquitetura semelhante a  proposta nesse trabalho principalmente na etapa de transformação. Entretanto, não se  adaptam ao contexto agrícola aqui proposto, pois nesse caso pretende-se usar as  instruções de regras de mapeamento geradas em processos batch, além de gerar diversos  formatos de saída, inclusive com conexão com banco de dados.     Assim sendo, este trabalho tem por objetivo apresentar o protótipo de uma  ferramenta para integração genérica de dados meteorológicos, apresentando a sua  arquitetura de funcionamento, pois já foi parcialmente implementado.   2. Materiais e Métodos   2. 1 Dados Meteorológicos   O DSSAT (Decision Suport System for Agrotechnology Transfer) é um modelo de  simulação do desenvolvimento e crescimento de culturas (DSSAT, 2014), e entre os  dados usados como entrada pelos modelos de simulação de culturas está este tipo. As  variáveis meteorológicas diárias usadas no arquivo são: radiação solar (SRAD),  temperatura máxima do ar (TMAX), temperatura mínima do ar (TMIN) e precipitação  pluvial (RAIN).    2. 2 Tecnologias   Desejava-se cria uma ferramenta Web, por isso foi escolhida a linguagem PHP (PHP  Hypertext Preprocessor) como linguagem de desenvolvimento, a qual gera um código  HTML (HyperText Markup Language) para apresentação ao usuário. Também foi usada  a linguagem Javascript para interações com o usuário dentro da interface da ferramenta.    Para o tratamento dos metadados foi utilizada a tecnologia XML (eXtensible  Markup Language). De acordo com o World Wide Web Consortium (W3C), XML foi  originalmente projetado para vir ao encontro dos desafios da publicação eletrônica em  larga escala e tem um importante papel na exportação e troca de dados. Desta forma,  num documento XML são armazenados os metadados que correspondem aos arquivos  de entrada e saída gerados pela ferramenta implementada.   3. Resultados e Discussão   A ferramenta de integração desenvolvida tem o propósito de ser genérica, porém devido  ao escopo do projeto, inicialmente realizou-se à integração somente com dados  meteorológicos no padrão do sistema DSSAT.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 356-359 Nov/2014     358    Foi desenvolvido um assistente na linguagem PHP, na qual o usuário apenas  comunicaria os detalhes e a aplicação faria a geração automatizada dos metadados em  XML, e as validações da interface gráfica seriam feitas com auxílio de Javascript e  Jquery. Na interface gráfica da ferramenta inicialmente é feito um pedido ao usuário se  ele já possui um arquivo XML com os metadados salvos, e se o usuário não o possuir,  ele poderá entrar no modo assistente para fazer a geração.     O assistente gráfico por sua vez ficou dividido em 3 partes: “Dados de Entrada”,  “Metadados e Arquivos”, e “Dados de saída”, e as partes são de livre navegação. Para a  criação correta dos metadados, o usuário informa corretamente o número de tabelas e o  número de campos de cada tabela envolvida no armazenamento dos dados, e é gerada  uma janela modal personalizada para o pedido, com todas as tabelas e seus respectivos  campos informados, que basta serem preenchidos com informações sobre cada  campo.Ao pedir a geração dos XML com os metadados, todos os dados temporários são  enviados por meio de um array pelo método POST para os arquivos do motor XML,  que cria o documento XML com todos os metadados para a conversão dos arquivos de  origem para a saída desejada.    Para o armazenamento dos metadados (dados sobre as entradas e saídas da  ferramenta), foi criado um template XML, onde é possível armazenar dados sobre o  formato, cabeçalho, escolher o tipo de saída (CSV ou na linguagem SQL) dos dados de  entrada.    Na Figura 1 é mostrado um exemplo do documento XML gerado pela  ferramenta, com base no arquivo de dados meteorológicos armazenados no arquivo  WTH do modelo DSSAT.   <root>    <cabecalho>      <numeroLinhas>5</numeroLinhas>      <indicador>@</indicador>    </cabecalho>    <arquivo>      <nomeProfile>dados_meteorologicos</nomeProfile>      <delimitador></delimitador>      <nomeSaida>Insert</nomeSaida>      <formatoSaida>sql</formatoSaida>    </arquivo>    <tabelas>      <tabela sequence="0" generator="Y" name="weather_data_variable" pk="id">        <campo sequence="0" type="double" value="" notNull="Y">id</campo>        <campo sequence="1" type="double" value="" notNull="Y">weather_data</campo>        <campo sequence="2" type="integer" value="" notNull="Y">variable</campo>        <campo sequence="3" type="char(1)" value="" notNull="Y">data_type</campo>        <campo sequence="4" type="date" value="" notNull="Y">data</campo>        <campo sequence="5" type="time" value="" notNull="Y">time</campo>        <campo sequence="6" type="tp_data" value="" notNull="Y">data_value</campo>      </tabela>      <tabela sequence="1" generator="Y" name="weather_data" pk="id">        <campo sequence="0" type="double" value="" notNull="Y">id</campo>        <campo sequence="1" type="double" value="" notNull="Y">date_import</campo>        <campo sequence="2" type="time" value="" notNull="Y">time_import</campo>        <campo sequence="3" type="integer" value="" notNull="Y">io</campo>        <campo sequence="4" type="integer" value="" notNull="Y">station</campo>      </tabela>    </tabelas>  </root>   Figura 1 - Exemplo de documento XML, gerado pelo framework, com os  metadados do arquivo WTH de entrada.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 356-359 Nov/2014     359    A tag “cabeçalho” armazena informações sobre o cabeçalho do arquivo de  entrada, neste caso informando o número de linhas do cabeçalho e qual o caractere  identificador do mesmo, pois num mesmo arquivo podem existir diversos cabeçalhos. A   tag “arquivo” contém informações necessárias para a geração dos arquivos de saída da  ferramenta, como o nome do arquivo a ser gerado, o delimitador de dados e o formato  de saída dos dados.    A tag “tabelas” descreve os metadados referente as tabelas do banco de dados,  para onde serão feitas as importações, e pode conter uma ou várias tag “tabela”. Cada  uma descreve como serão mapeados os campos da tabela do banco de dados para os  campos do arquivo de entrada, que é feito pela tag campo.    4. Conclusões   Com toda uma base operacional já pronta, e com o domínio de várias tecnologias, foi  criada uma interface gráfica no formato de assistente, que salva os metadados  escolhidos no XML, para a posterior execução. No entanto, a ferramenta não está  pronta. Como trabalhos futuros, falta a geração dos arquivos de saída, fazendo a leitura  dos arquivos de dados na memória para a interpretação e geração da saída. Também  faltam testes com outros formatos de arquivos.   Referências   Consortium, World Wide Web. XML: Extensible Markup Language. Massachusetts,  2011. Disponível em: < http://www.w3.org/XML/>.    Dssat. Decision Support System for Agrotechnology Transfer. Disponível em:  <http://dssat.net>. Acesso em 04/09/2014.   Donatelli, M.; Ittersum, V.; Bindi M.; Porter, J. R.; Modelling cropping systems:  Highlights of the symposium and preface to the special issues. Eur. J. Agron., v 18:111. 2002.   Graves, A.R.; Mathheus, H.T.; Stephens, R.B.; Middleton, W.T. Crop simulation  models as tools in computer laboratory and classroom-based education. J. Nat.  Resour. Life Sci. Educ., 31:48-54. 2002 .    Hara, Carmem Satie, Ruthes, Eduardo da Rocha, Scopim, Kemmel da Silva, Sunyé,  Marcos Sfair. Jintegrator: A Heterogeneous Database Integration Tool. International  Conference on Information Systems and Technology Management, CONTECSI. 2006   Sinclair, T. R.; Seligman, N.G.; Crop modeling: From infancy to maturity. Agron. J.  88:698-704. 1996.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 360-363 Nov/2014     360   Totem Informativo para o Centro de Informática   Maurício S. Oliveira1, Iverton A. Santos¹   1Instituto Federal de Educação, Ciência e Tecnologia Farroupilha - Câmpus Alegrete   RS 377 Km 27 – Passo Novo – CEP 97.555-000 – Alegrete – RS – Brasil   mauricio_oliveira13@hotmail.com, iverton.santos@iffarroupilha.edu.br   Abstract. In Instituto Federal Farroupilha Câmpus Alegrete updating  information on the buildings is carried out through posters attached murals.  However, this manual activity hampers the simultaneous update and is not  always attractive to students. Therefore, the aim of this work is the use of an  informative totem for the Informatics Center of the Institution. The  methodology provides requirements analysis and coding of a web page.  Preliminary results show prototypes have already been developed.   Resumo. No Instituto Federal Farroupilha Câmpus Alegrete a atualização de  informações nos prédios é realizada através de cartazes anexados em murais.  No entanto, essa atividade manual dificulta a atualização simultânea e, nem  sempre é atrativa aos alunos. Portanto, o objetivo deste trabalho é a  utilização de um totem informativo para o Centro de Informática da  Instituição. A metodologia prevê análise de requisitos e codificação de uma  página web. Os resultados preliminares apresentam os protótipos já  desenvolvidos.   1. Introdução   Ishisaki (2008) salienta que os artefatos tecnológicos contribuem consideravelmente na  mudança social e cultural da humanidade. Os sistemas informatizados já atingiram  diversos seguimentos e estão cada vez mais presentes nas atividades cotidianas,  propiciando novas formas de relação do indivíduo com a informação.     Um recurso facilitador para acesso a informação é a tecnologia touch screen  (sensível ao toque). A sua proposta facilita o autoatendimento em muitos setores, como  nos caixas eletrônicos e emissores de senhas.     Totens informativos tem uma importância fundamental em ambientes onde  informações precisam ser disponibilizadas de forma que induza o indivíduo a ler seu  conteúdo, uma vez que meios tradicionais, tais como os murais, estão perdendo a sua  finalidade por não serem tão atrativos (ISHISAKI, 2008).    Esta ferramenta para informação pode apresentar produtos e prestar atendimento  automático aos usuários rapidamente. Está presente em lojas, aeroportos, universidades,  shoppings, cidades como meio de informação para turistas em lugares com determinado  volume de público, entre outros (ALVEZ; JUNIOR, 2009).    O Centro de Informática do Instituto Federal Farroupilha Câmpus Alegrete  possui uma deficiência na forma de informar os estudantes a respeito de seus horários  de aula e notícias escolares atualizadas, este processo é feito através da impressão dos  horários ou no aviso de eventos por parte dos professores. Esse processo manual  demanda muito tempo e por isso várias notificações deixam de ser feitas, dificultando o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 360-363 Nov/2014     361   acesso a informação sobre eventos, reuniões e liberação de editais da instituição para os  alunos.    Portanto, o principal objetivo deste trabalho é a criação de um sistema web para  notificações, que será implantado em um equipamento touch screen.    2.  Metodologia   O desenvolvimento do trabalho foi dividido em etapas para melhor organização.  Inicialmente foi necessário um levantamento de requisitos, consultas a alunos e  professores e pesquisas sobre como funcionam estes tipos de sistema para delimitação  do escopo do trabalho. Assim, decidiu-se criar uma página web com interface intuitiva,  preferencialmente em formato de botões para fácil navegação. Nesta página serão  organizadas as seções:     Horários professores: será informado o horário individual de cada professor,  facilitando para o aluno a localização do docente.    Horários das aulas: será informado o horário de cada turma.   Ensalamento: será informado as salas e laboratórios para desenvolvimento das   atividades de cada disciplina.    Notícias: será informado as notícias que estão no site principal do Câmpus  Alegrete.    Através da criação de protótipos, a avaliação com usuários será contínua, não  somente no final da codificação. Com a ajuda de formulários, os usuários poderão  opinar sobre o layout da página, cores, conteúdo, interatividade e usabilidade. A versão  final será implantada na recepção do prédio do Centro de Informática em um  equipamento com tela touch screen para ser usado por professores e alunos.    Será desenvolvido em forma de uma página web como já mencionado  anteriormente, utilizando PHP, HTML, CSS, entre outras ferramentas que sejam  necessárias para a construção.      3. Resultados preliminares    Atualmente o projeto está na fase de desenvolvimento dos códigos e será testado com o  auxílio de colegas que também serão usuários do sistema. O resultado que se espera  com este projeto é que a carência de informações que os alunos possuem sobre avisos  gerais, editais, horários dos professores seja reduzida após a implantação do sistema,  com um meio de comunicação e organização entre o centro de informática e os alunos.     A Figura 1 apresenta o protótipo inicial (baixa fidelidade). Após consulta aos  professores, foi codificado o segundo protótipo (média fidelidade), conforme telas  apresentadas nas Figuras 2 e 3, incluindo botões de navegação.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 360-363 Nov/2014     362        Figura 10. Protótipo de baixa fidelidade        Figura 11. Tela inicial do segundo protótipo        Figura 12. Tela Horário das aulas do segundo protótipo              Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 360-363 Nov/2014     363   4. Considerações finais e trabalhos futuros   O objetivo deste trabalho foi apresentar o projeto de um totem informativo para auxiliar  alunos do IFF – CA a manterem-se informados sobre aquilo que diz respeito à  instituição e o seu dia a dia, como: ensalamento de turmas, horários de disciplinas,  professores presentes na instituição, eventos, notícias, entre outros visando a otimização  de informações à comunidade escolar. Acredita-se que este projeto seja viável por suas  características simples e de alta utilização institucional.   O projeto ainda conta com a ideia de ser implantado em todos os cursos da instituição,  contendo um administrador geral e um administrador de cada coordenação dos cursos  para que sejam postadas informações mais rápido no sistema.       5. Referências   ALVES, Thais Mahara; JUNIOR, Oswaldo Dias dos Santos. A utilização de totens  multimídia como canais de divulgação para turistas em Curitiba. Caderno da  Escola de Negócios, UNIBRASIL, Nº 07, 17p, 2009. Disponível em:  <http://apps.unibrasil.com.br/revista/index.php/negociosonline/article/view/291>.  Acesso em: 14 set. 2014.      ISHISAKI, Jane Matie. O design de interação dos equipamentos informatizados: A  usabilidade da máquina de auto-atendimento de informações sobre serviços  públicos. 2008. 147p. Dissertação (Mestrado – Área de Concentração: Design e  Arquitetura) – FAUUSP, São Paulo, 2008.   Disponível em: <http://www.teses.usp.br/teses/disponiveis/16/16134/tde-20012010112915/pt-br.php>. Acesso em: 15 set. 2014.                
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 364-367 Nov/2014     364   Inclusão da Melhor Idade no Meio Digital: Cursos Para a  Melhor Idade    Matias Lazarotto1, Evandro Preuss1   1 Universidade Federal de Santa Maria/Colégio Agrícola de Frederico Westphalen  mathsettung@hotmail.com, evandro.preuss@cafw.ufsm.br   Abstract. This paper presents an initial study of an experience with a digital  inclusion project for the elderly, conducted with a group of ten volunteers. The  increase in the elderly population due to longer life expectancy brings with it  the need to rethink what is proposed for this new society so that they can  interact and make use of information and communication technologies. The  Internet allows the elderly expand their knowledge remains up to date and  increase your circle of relationships. This extension project funded by the  Municipality of Caiçara-RS provided the digital inclusion of seniors,  facilitating communication, created new possibilities and proving that older  people can indeed acquire knowledge and keep pace with technological  advances needed in everyone's life.   Resumo. Este trabalho apresenta um estudo inicial sobre uma experiência  com um projeto de inclusão digital do idoso, realizado com um grupo de dez  voluntários. O aumento da população idosa devido à maior expectativa de  vida traz consigo a necessidade de se repensar o que será proposto para esta  nova sociedade a fim de que consigam interagir e usufruir das tecnologias de  informação e de comunicação. A Internet permite que o idoso amplie seus  conhecimentos, permaneça atualizado e aumente o seu circulo de  relacionamentos. Este projeto de extensão financiado pela Prefeitura  Municipal de Caiçara-RS proporcionou a inclusão digital da terceira idade,  facilitando a comunicação, criou novas possibilidades e provando que  pessoas idosas podem, sim, adquirir conhecimentos e acompanhar o avanço  tecnológico necessário na vida de todos.   1. Introdução   O crescimento da expectativa de vida vem modificando o retrato da população  brasileira e também do mundo. O aumento da população idosa comparado ao declínio  das taxas de natalidade são um forte indicativo de que a sociedade precisa se adaptar a  estas mudanças para que não se perca a qualidade de vida dessa grande massa  populacional.   De acordo com Rocha (2003), idoso pode ser considerado como a pessoa que  possui sessenta anos ou mais. Assim, no Brasil, conforme as leis vigentes a pessoa idosa  tem prioridade nas formulações de politicas sociais, destinação de recursos, acesso à  saúde e a meios que possibilitem a comunicação e integração dos idosos na sociedade.   As pessoas idosas, atualmente, apresentam uma grande vitalidade, participam de  muitos projetos, contribuem em relação à produção e intervenção nas mudanças sociais  e políticas e ainda constituem parte muito valorizada pela experiência profissional e de  vida no mercado de trabalho atual. Neste sentido, é muito importante o conhecimento a     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 364-367 Nov/2014     365   respeito da utilização do computador e da Internet de forma segura, e que possa  melhorar a vida dessas pessoas e também sirva de fonte de informações para auxiliar os  idosos a gozarem de seus direitos.   Este trabalho apresenta um estudo inicial sobre uma experiência com um projeto  de inclusão digital do idoso, realizado com um grupo de dez voluntários, buscando  tornar possível o acompanhamento do mundo virtual por essas pessoas e, ao mesmo  tempo, estabelecer relações de ajuda e cooperação com vistas a desenvolver suas  potencialidades a fim de contribuir para a sua autonomia, propondo uma troca de  experiências entre gerações.   2. Inclusão Digital para a Melhor Idade   O idoso com mais tempo para usufruir da vida e o que ela oferece, vem se  tornando mais participativo na família e na sociedade, deixando de ser meramente um  agente passivo para se constituir como agente ativo, com potencialidades para serem  desenvolvidas. Demonstrando cada vez mais interesse nas mudanças e inovações  tecnológicas, de comunicação como uma maneira de estar incluído e ser valorizado.    É fundamental que a sociedade compreenda que o processo de envelhecimento  não é sinônimo de inutilidade, de que a vida está chegando ao final e então não vale a  pena fazer planos nem se dedicar a aprender algo novo. Lima (2000) aponta que  prevalece na atualidade a visão do idoso como alguém inútil, isolado, em declínio  biológico e mental, com problemas de saúde e que provavelmente é dependente  econômica e fisicamente de alguém.   Existe uma grande preocupação com o aprendizado de crianças e jovens,  esquecendo-se que o processo de aprendizado ocorre por toda a vida. Então se faz  necessário direcionar o olhar para os idosos e desenvolver ações que sejam voltadas  para enriquecer e continuar o seu processo de aprendizado.   Conforme Delors (2004): "A educação ao longo da vida é uma construção  contínua da pessoa humana, do seu saber e das suas aptidões, mas também da sua  capacidade de discernir e agir" (Delors, 2004, P.103).   No que diz respeito à relação da atual geração de idosos com as novas  tecnologias, percebe-se que estes enfrentam algumas dificuldades em entender,  manusear e ter acesso aos avanços tecnológicos. Este fator contribui significativamente  para que estes indivíduos fiquem à margem da sociedade.    Conforme Oliveira (2006), o uso da Internet pelo idoso ainda é cercado de  dificuldades, contudo aprender a usar essa ferramenta acarreta em ganhos para estas  pessoas, pois favorece a expansão do círculo social, ajuda na inserção social e aumenta  significativamente as possibilidades de comunicação através da rede.   O uso das tecnologias pela melhor idade é vantajoso pois vêm atender os anseios  de se manter ocupado, se comunicar com pessoas diferentes, fazer novas amizades,  buscar informações e se manter atualizado e principalmente mostrar que é capaz e pode  superar dificuldades. Para os idosos que ainda estão contribuindo no mercado de  trabalho o manuseio das tecnologias é fundamental para acompanhar o progresso do  trabalho e as necessidades de cada profissão.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 364-367 Nov/2014     366   Dessa forma é fundamental que se possibilite a essas pessoas condições e acesso  às tecnologias de informação e comunicação para que conforme a sua necessidade e  capacidade vão descobrindo que são capazes de aprender e acompanhar a seu modo as  inovações tecnológicas e sociais.   De acordo com Pasqualotti et al (2007), ao entrar em contato com novas  tecnologias cada ser humano apresenta diferentes necessidades, expectativas,  habilidades e conhecimento prévio. Sendo assim é importante que a inclusão digital leve  em consideração as diferenças individuais, facilidades e dificuldades para se apropriar  de novas formas de usar as tecnologias de informação.   Neste sentido, é fundamental que se utilize uma metodologia simples, que  motive o idoso perder o medo e buscar ampliar seus conhecimentos sobre as  tecnologias, para que dessa forma, ele aprenda e possa estar incluído em uma sociedade  que já não vive mais sem a tecnologia.   3. Desenvolvimento   Para viabilizar a execução deste projeto foram realizados encontros semanais  com duração de uma hora no Laboratório de Informática pertencente ao Telecentro  municipal com 10 idosos do Município de Caiçara-RS, que manifestaram interesse em  participar das aulas.     As temáticas abordadas foram: internet, digitação e informática. Na  oportunidade também foi desenvolvido um Website, hospedado no servidor do  Telecentro Municipal de Caiçara, visando o controle de frequência, construção de  cadastros e acompanhamento do desempenho dos participantes.   Após apresentação do projeto em uma conversa informal com os participantes  foi realizado o primeiro encontro. O segundo encontro abordou o tema a Informática  Atual por meio de uma dinâmica grupal onde os participantes puderam tirar dúvidas e  discutir sobre o assunto. O terceiro encontro tratou da relação entre internet e  informática por meio de uma dinâmica. O quarto encontro teve como discussão as  formas de prevenção contra vírus e um folder foi construído em grupo. O quinto  encontro foi sobre digitação, então os participantes foram convidados a digitarem a sua  história de vida. O sexto encontro teve a Internet como tema central, foram abordados  os benefícios e malefícios do uso dessa ferramenta. O sétimo e último encontro teve a  dinâmica da Caixa Surpresa, que continha perguntas para serem discutidas como uma  avaliação final das atividades, sempre envolvendo o computador e a Internet.   As atividades foram desenvolvidas pelos idosos no decorrer dos encontros  através do sistema operacional disponibilizado pela rede de Tele centros, Linux  Educacional 4.0, navegador Mozilla Firefox, Tutorial para digitação Klavaro e o pacote  Libre Office 3.0.    Dessa forma, as atividades foram preparadas e adaptadas respeitando o nível de  conhecimento e as limitações de cada um. Utilizou-se uma linguagem simples associada  à visualização de imagens no projetor, contribuindo para uma melhor aprendizagem. Ao  final de cada encontro era realizada uma avaliação em forma de conversa destacando  pontos positivos e negativos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 364-367 Nov/2014     367   4. Considerações finais   Este projeto ressalta que de fato se faz necessário para o idoso interagir com o  mundo digital, tendo em vista que essas pessoas poderão encontrar na interação com o  computador e a internet uma forma de sentirem-se úteis, de realmente se divertirem,  trocar conhecimento e diminuir as diferenças culturais, afinal, uma pessoa conectada  indiferente qual seja sua idade tem a possibilidade de se comunicar com qualquer  pessoa em qualquer parte do mundo. Da mesma forma é imprescindível que se ofereçam  oportunidades de acesso às tecnologias que atendam os anseios e respeitem as  necessidades e limitações das pessoas da melhor idade.     Por ser uma atividade nova, os participantes demonstraram ter muita  insegurança com o computador e somente depois de algumas aulas, é que se sentem a  vontade e percebem o quanto isso é interessante. Inicialmente eles demonstraram  timidez e receio de manusear os computadores e até de tirar dúvidas no grande grupo.  Alguns tinham conhecimento sobre Internet, computador e outras ferramentas  tecnológicas, mas a maioria só tinha ouvido falar sobre os mesmos.   Foi possível perceber o quanto é importante para o idoso aprender a lidar com as  novas tecnologias para resgatar a autoestima e valorizar a capacidade dessas pessoas. A  informática na terceira idade impulsionou a capacidade superação, o auto desafio, a  manutenção de uma memória saudável e consequentemente uma melhor qualidade de  vida dos participantes através do processo digital viabilizado pela educação.   O desenvolvimento de habilidades técnicas e a construção de novos  conhecimentos permitiu que estes idosos se tornassem mais ativos, mais participativos e  capazes, autovalorizando-se e percebendo que não há limites para o aprendizado.   Referências  DELORS, J. Educação: um tesouro a descobrir. 9 edição. São Paulo, Cortez, 2004.   LIMA, M. P. Gerontologia educacional: uma nova concepção de velhice. São Paulo:  Editora LTR, 2000.   OLIVEIRA, F. S. Aprendizagem por idosos na utilização da Internet. Dissertação de  Mestrado em Psicologia Social e da Personalidade, Pontifícia Universidade Católica  do Rio Grande do Sul – PUCRS, Porto Alegre, Rio Grande do Sul, Brasil, 2006.   PASQUALOTTI, A. et al. Inclusão Digital para Terceira Idade: Oportunidades,  Possibilidades e Propostas Inovadoras. Centro Universitário Feevale - Instituto de  Ciências Exatas e Tecnológicas, 2007. Disponível em:  http://www.niee.ufrgs.br/eventos/CIIEE/2007/pdf/CP-310.pdf. Acessado em 15 de  outubro de 2011.   ROCHA, E. G. Estatuto do Idoso: Um avanço Legal. Revista Online da Universidade  Federal de Goiás, v.5, nº2, dez, 2003. Disponível em: www.proec.ufg.br Acessado  em 15 de outubro de 2011.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 368-371 Nov/2014     368   Uma Proposta de Sistema de Informação para o  Gerenciamento Eletrônico de Documentos   Douglas Rocha, Talles Brito Viana   Instituto Federal de Educação, Ciência e Tecnologia do Ceará (IFCE)   Resumo. O Gerenciamento Eletrônico de Documentos (GED) surge como um  conjunto de tecnologias para o processamento de documentos como  informação eletrônica digital. Neste contexto, este artigo apresenta uma  proposta de Sistema de Informação para o Gerenciamento Eletrônico de  Documentos que possibilita tratar os requisitos de Distribuição, Segurança e  Gerenciamento de Ciclo de Vida dos documentos de uma forma integrada.    Abstract. Electronic Document Management (EDM) systems emerge as a set  of technologies for processing documents as digital electronic information. In  such a context, this paper presents a proposal of Information System for  Electronic Document Management that handles document’s Distribution,  Security and Workflow Management requirements in an integrated way.    1. Introdução  No cotidiano, empresas e organizações emitem um volume significativo de documentos  que necessitam ser armazenados para acesso posterior. Neste cenário ocorre uma série  de problemas relacionados com o espaço físico de armazenamento, a dificuldade de  acesso às informações armazenadas, bem como em relação ao modo tal que os  documentos são gerenciados dentro da organização. Com o objetivo de minimizar estes  problemas, conforme definido por Andrade (ANDRADE, 2002), o Gerenciamento  Eletrônico de Documentos (GED) surge como um conjunto de técnicas e tecnologias  para a conversão e processamento de documentos como informação eletrônica digital.    Apesar disso, em geral, as propostas existentes na literatura de soluções para o  Gerenciamento Eletrônico de Documentos não atendem aos requisitos de Distribuição,  Segurança e Gerenciamento de Ciclo de Vida dos documentos de forma integrada. Dado  este problema, este artigo apresenta uma proposta de Sistema de Informação para o  Gerenciamento Eletrônico de Documentos que possibilita tratar os requisitos  anteriormente citados. O restante deste artigo está organizado da seguinte forma: na  Seção 2 uma análise comparativa de trabalhos correlatos em função de requisitos  funcionais e não funcionais considerados recorrentes em sistemas de Gerenciamento  Eletrônico de Documento é apresentada. Após isso, na Seção 3, baseado nos requisitos  apresentados, uma proposta de Sistema de Informação para o Gerenciamento Eletrônico  de Documentos é discutida. Por fim, considerações finais são apresentadas na Seção 4.    2. Trabalhos Relacionados  Com o objetivo de obter uma classificação dos trabalhos relacionados, características  recorrentes dos trabalhos analisados são discutidas nesta seção. Assim, a seguir é  apresentada uma análise de trabalhos em função dos requisitos de a. Distribuição,  b. Controle de Acesso, c. Autenticação e d. Gerenciamento de Ciclo de Vida.    a. Distribuição: No contexto dos sistemas de Gerenciamento Eletrônico de  Documentos, a distribuição fornece meios para que grupos de usuários do sistema     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 368-371 Nov/2014     369   possam ter acesso aos documentos de forma descentralizada. No trabalho de  (KLEMANN, 2006) é apresentado um modelo de distribuição cliente-servidor que  emprega uma interface Web tanto para recuperação quanto para cadastramento dos  documentos . Uma alternativa ao uso de interfaces Web é apresentada no trabalho de  (PINTO, 2005), em que a distribuição de documentos é realizada através de protocolos  de compartilhamento de arquivos em sistemas operacionais de redes.    b. Controle de Acesso: O controle de acesso consiste em configurar permissões  de acesso para determinadas áreas do sistema de Gerenciamento Eletrônico de  Documento. Nos sistema de Gerenciamento Eletrônico de Documentos propostos por  (KLEMANN, 2006) e (REZENDE, 2013), o administrador tem total acesso ao sistema  enquanto que os demais usuários têm limitações de acesso customizadas, de forma que  determinadas funções do sistema (tais como o gerenciamento de usuários, visualização,  recuperação, inserção e exclusão de documentos) são atribuídas somente para os  usuários que têm permissão de execução das mesmas.    c. Autenticação: A autenticação é um procedimento de segurança que permite  verificar se a identidade do usuário do sistema é legítima. No sistema de Gerenciamento  Eletrônico de Documentos proposto por (BARBIERI, 2002) a autenticação é baseada  em senhas de acesso, isto garante que os usuários que fazem alterações nos documentos  são realmente os usuários que têm permissão para isto.    d. Gerenciamento de Ciclo de Vida:  Uma tecnologia de gerenciamento  do ciclo de vida (workflow) de documentos permite controlar e gerenciar o fluxo de  documentos em uma organização.  Em (CENCI, 2002) é discutido um método de  gerenciamento do ciclo de vida em que os documentos devem percorrer um fluxo de  trabalho construído através de uma interface gráfica. Elos de decisão podem ser  utilizados, criando caminhos alternativos aos documentos dependendo da situação.  Enquanto o documento movimenta-se pelo fluxo de trabalho, o sistema envia e-mails  aos usuários reportando o estado atual do documento na execução do fluxo de trabalho.   O Quadro 1 resume os trabalhos analisados em função dos requisitos  enumerados. Pode-se observar que, em geral, as propostas de soluções para o  Gerenciamento Eletrônico de Documentos não atendem a todos os requisitos ou pelo  menos a maioria deles. Ao contrário, os trabalhos correlatos priorizam determinados  requisitos em detrimento dos demais, causados pela forma ineficiente tal como o  problema é tratado ou por ênfase demasiada ao tratar somente alguns dos requisitos.    Quadro 1. Comparação entre os trabalhos analisados   a b c d    (BARBIERI, 2002)   X    (CENCI, 2002) X   X   (KLEMANN, 2006) X X     (PINTO, 2005) X      (REZENDE, 2013)  X  X   3. Uma Proposta de Sistema de Informação para o GED  Desta forma, ainda existem desafios para a elaboração de um sistema de Gerenciamento  Eletrônico que contemple o tratamento dos requisitos discutidos de uma forma  integrada. Para alcançar isso, este trabalho propõe uma nova direção para tratar cada um  dos requisitos apresentados anteriormente da seguinte forma:      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 368-371 Nov/2014     370    Distribuição: Para alcançar a distribuição dos documentos em um sistema de  GED é proposta uma arquitetura de sistema distribuído baseado em um espaço de dados  compartilhado. Um espaço de dados compartilhado consiste em um repositório comum  no qual os documentos estão disponíveis para acesso por pessoas de departamentos  distintos de organizações distintas. Do ponto de vista lógico, na arquitetura proposta,  temos que os departamentos são vistos como setores, e os setores pertencem a uma  organização. O espaço de dados compartilhado trata-se de um repositório global que  possibilita que usuários de diferentes setores da mesma organização ou de organizações  diferentes possam acessar um mesmo documento, caso possuam permissão para isto.    Já do ponto de vista físico, cada setor pode ter um dispositivo físico de  armazenamento privado (servidor local) para armazenar os documentos, bem como cada  organização tem um servidor central que serve para comunicação e compartilhamento  entre diferentes organizações através da Web. Por exemplo, o Instituto Federal do  Ceará (IFCE) é uma organização que tem um setor de Pró-Reitoria de Pesquisa (PRPI)  e um setor de Pró-Reitoria de Ensino (PROEN). Neste caso, dois servidores locais são  instalados para armazenar os documentos da PRPI e PROEN. E, além disso, um  servidor global do IFCE é instalado e configurado de forma que reconheça os endereços  físicos dos servidores locais da própria instituição. É importante ressaltar que o servidor  global do IFCE pode recuperar documentos de outras organizações externas, tal como  da Universidade Federal de Santa Maria (UFSM) através do acesso ao servidor global  da UFSM via Web. Este cenário é ilustrado na Figura 16.    PRPI prpi.ifce.edu.br  PROEN proen.ifce.edu.br  IFCE ifce.edu.br  UFSM ufsm.br  Web  Setor  (Serviço Local)  Organização (Serviço Global)  LEGENDA:    Figura 16. Arquitetura do sistema proposto    Autenticação: É proposto um modelo de autenticação via senhas. O nome de  usuário é empregado juntamente com a senha para autenticar se um determinado usuário  é realmente quem dita ser. O nome de usuário obedece a um esquema de organização de  nomes hierárquico que facilita a identificação do usuário em relação ao setor e a  organização que o mesmo pertence. Assim, o nome de usuário obedece ao seguinte  formato usuário@setor.organização. Por exemplo, o usuário Pró-Reitor do setor PRPI  pertencente à organização IFCE deve ser identificado por próreitor@prpi.ifce.edu.br.    Controle de Acesso: O controle de acesso é definido em função dos  documentos. Cada documento possui um nome que o identifica de maneira global, bem  como, possui um arquivo de configuração de controle de acesso que delimita: i) Quais  são os usuários que podem acessá-lo. ii) Quais operações podem ser executadas sob o  documento em relação a cada usuário que tem acesso ao mesmo. As operações incluem  a visualização, criação, edição, exclusão ou manipulação do documento.  Por exemplo,  um documento identificado globalmente por documento.prpi.ifce.edu.br criado pelo  usuário próreitor@prpi.ifce.edu.br (nome de usuário do Pró-Reitor de Pesquisa do  IFCE) pode ser configurado para ser manipulado pelo usuário reitor@ufsm.br (nome de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 368-371 Nov/2014     371   usuário do Reitor da UFSM) via arquivo de configuração de controle de acesso do  documento.    Gerenciamento do Ciclo de Vida: No sistema proposto, o ciclo de vida dos  documentos é gerenciado através de um modelo de workflow colaborativo com recursos  de aprovação e rejeição do documento no fluxo de um processo. Cada documento  possui um arquivo de configuração e montagem de fluxo de processo. Com isto, de  acordo com o fluxo especificado para o documento, o sistema se encarregar de notificar  aos usuários a chegada de novos documentos para edição, visualização ou aprovação.    Por exemplo, suponha o cenário em que um determinado documento deve ser  visualizado e editado pelo Pró-Reitor de Pesquisa do IFCE e, em seguida, editado e  aprovado pelo Reitor da UFSM. Para alcançar isto, um arquivo de configuração de  fluxo do documento define que as operações de edição e visualização devem ser  habilitadas no documento inicialmente a partir do usuário próreitor@prpi.ifce.edu.br, e  na sequência, pelo usuário reitor@ufsm.br. Com isto, o sistema gerenciará o fluxo do  documento ao registrar modificação no processo e notificará aos setores envolvidos em  que situação do fluxo de trabalho o documento se encontra. Além disso, é importante  ressaltar que neste caso, o usuário externo reitor@ufsm.br pode editar o documento  criado pelo usuário próreitor@prpi.ifce.edu.br, mas sem necessitar replicar cópias do  documento original entre os usuários, pois modificações no documento alteram o  armazenamento no servidor original do arquivo, o qual é acessado de forma global.    4. Considerações Finais  Como principal contribuição, este trabalho apresenta uma forma de tratamento dos  requisitos de Distribuição, Segurança e Gerenciamento de Ciclo de Vida de documentos  de uma forma integrada. Especificamente, esta proposta define uma infraestrutura  global distribuída de repositório de documentos, em que os usuários autenticados  podem recuperar, com segurança, documentos fornecidos através de um fluxo de  trabalho. A proposta atualmente se encontra em fase de análise e especificação. Vale  ressaltar que as tecnologias atuais para construção de Serviços Web (WebServices)  possibilitam concretizar as ideias propostas neste trabalho. Assim, a implementação de  Serviços Web constituem etapas futuras na geração de um protótipo de prova de  conceito da proposta.    5. Referências  ANDRADE, M., “Gerenciamento eletrônico da informação: ferramenta para a gerência   eficiente dos processos de trabalho”. Seminário Nacional de Bibliotecas Universitárias, PE,  2002.    BARBIERI, Cristina Correia Dias. “Gerenciamento eletrônico de documentos: criação de um  banco de informações e imagens no Arquivo Permanente da UNICAMP”, São Paulo, 2002.   CENCI, Jackson Antônio. “Gerenciamento eletrônico de documentos: Um estudo teórico para  definição do projeto Openged”. Monografia. Lages, 2002.    KLEMANN, Jean Wilhelm. “Desenvolvimento de um sistema de gerenciamento eletrônico de  documentos na secretaria da educação e cultura de Pomerode”. Monografia, Blumenau, 2006.   PINTO, Daniel Dias. “Sistema de Operações de GED”. Monografia. São Judas Tadeu, 2005.  REZENDE, Laura Vilela Rodrigues. “Levantamento de requisitos para a implantação de um   sistema de gerenciamento eletrônico de documentos em um software de gestão de  processos”, Florianópolis, 2013.     
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 372-375 Nov/2014     372   Sistema para Visualização das Notificações dos Casos de  Malária no Brasil   Juliano B. Prettz, Kelvin S. do Prado, Luciano R. de Almeida, Maik Frizon, Mauro  Murari, Cristiano Bertolini   Sistemas de Informação – Universidade Federal de Santa Maria (UFSM)  Frederico Westphalen – RS – Brasil   prettzb@gmail.com, kelvinfw@hotmail.com, lucralm@gmail.com,  mfrizon@fredon.com.br, mauro_murari@hotmail.com,   cristiano_bertoloni@ufsm.br   Abstract. This paper proposes a web system for data visualization of malaria  notifications cases based on an open data bases provided by the Brazilian  government. The application presents general information about the malaria, a  mapping of the epidemic regions and comparison graphs, which can be  customized to a better understanding of the malaria incidence in different  Brazilian regions. In this way, the tool support provided by this work will be an  efficient way to monitor and establish new policies to prevent malaria.   Resumo. Este artigo propõem um sistema web para visualização das  notificações dos casos de malária utilizando as bases de dados abertas do  Governo Brasileiro. A aplicação apresenta informações gerais sobre a  malária, um mapeamento das regiões epidêmicas e gráficos comparativos que  podem ser customizados por meio de diversos filtros para um melhor  entendimento da malária nas diferentes regiões do Brasil. Desta forma, o  aplicativo fornece uma maneira eficiente para monitorar e estabelecer novas  politicas para a prevenção na malária.   1. Introdução   Segundo Martins [MARTINS, 2013], a malária é uma doença infecciosa potencialmente  grave, causada por parasitas do tipo Plasmodium, que são transmitidos de uma pessoa  para outra pela picada de mosquitos do gênero Anopheles. A malária é uma doença  bastante preocupante, principalmente para viajantes em áreas de risco de transmissão, e  é transmitida pela picada das fêmeas do mosquito, por transfusão de sangue ou por  compartilhamento de agulhas e seringas infectadas pelo vírus.    O objetivo geral deste trabalho é visualização das notificações de forma  dinâmica através de filtros os dados sobre à malária no Brasil. As informações são  extraídas de uma base de dados disponibilizada pelo Governo Brasileiro, através do  DATASUS [DATASUS, 2014]. O presente trabalho propõe o desenvolvimento de uma  aplicação web, usando informações da incidência da malária no Brasil. A aplicação em  desenvolvimento apresenta informações sobre os casos de malária registrados no Brasil  dos anos de 2008 a 2013, com o intuito de beneficiar estudantes, cidadãos e  profissionais da área da saúde que buscam estatísticas e dados sobre a doença de forma  simples e objetiva.    As principais contribuições deste projeto são: (i) a visualização dos números de  notificações casos da malária por regiões do Brasil; e (ii) comparação dos casos de  malária utilizando filtros dinâmicos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 372-375 Nov/2014     373   2. Solução Proposta   A aplicação é uma importante ferramenta em processos de controle e prevenção da  doença, já que a compreensão das informações torna-se mais simples e acessível pela  população e profissionais da área da saúde. A aplicação pode ser acessada em  200.132.38.210:8000/dados/.     A aplicação consiste em um mapa, onde mostra as regiões endêmicas. Para cada  estado com casos de malária, é possível visualizar no mapa a quantidade de casos de  malária por cidade. A aplicação web foi desenvolvida utilizando Django que é um  framework para desenvolvimento rápido web usando a linguagem de programação  Python. Foi utilizado uma base de dados MySQL, criado a partir de dados obtidos junto  ao DATASUS [DATASUS, 2014].       3. Resultados Preliminares   A aplicação apresenta uma interface gráfica para navegação e visualização das  informações sobre a malária, onde o usuário pode utilizar gráficos comparativos e um  mapa no qual são buscadas todas as cidades brasileiras com casos registrados de  malária. Também é possível realizar buscas através do nome da cidade ou estado.  Os  gráficos da aplicação irão apresentar comparativos tais como: comparativo entre  estados, comparativo do crescimento da malária no decorrer dos anos, etc.     Figura 1. Mapa com a quantidade das notificações dos casos de malária.    A Figura 1 apresenta os registros de notificações de malária no Brasil. O mapa  apresenta um ponto de referência para cada cidade, no qual é possível clicar e visualizar  o nome da cidade, do estado e o total de notificações de malária. O aplicativo agrupa  automaticamente os pontos de referência próximos criando um circulo colorido de  acordo com a quantidade de casos de malária, sendo as regiões com menores números  de casos da cor azul e as regiões com maiores números de casos da cor vermelha.  Observa-se na Figura 1 as três cidades com grandes índices da doença. É o caso de Boa     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 372-375 Nov/2014     374   Vista em Roraima que tem um total de 147.887 notificações de malária registrados pelo  DATASUS entre os anos de 2008 a 2013.      Figura 2. Percentagem de casos de malária por sexo       Na aplicação é possível visualizar gráficos referentes à doença, como por  exemplo, na Figura 2 podemos ver a percentagem de casos de malária por sexo, onde  ele automaticamente carrega as informações da base de dados e filtra as informações em  forma de gráfico, no mesmo apresentado acima mais da metade da porcentagem é de  dados não informados pela população. O processo de coleta das informações sobre a  malária atualmente é realizado de forma manual pelos agentes, ocasionando no não  preenchimento completo das informações do formulário.   4. Trabalhos Relacionados   No contexto da informatização da saúde, existem outros projetos que se relacionam ao  tema proposto por este trabalho. O primeiro trabalho relacionado é o site Consulta de  Aconselhamento ao Viajante [Hospital Escola Universidade Fernando Pessoa, 2014]. O  site é destinado para viajantes e tem como principal intuito informar regiões com  maiores números de casos de várias doenças, incluindo a malária, os sintomas das  doenças, prevenções e algumas medicações que podem ser usadas para controlar e  combater as doenças.     O site Consulta de Aconselhamento ao Viajante mostra em mapas estáticos as  áreas mundiais de risco de transmissão de malária, que conforme a legenda, quanto mais  avermelhado, maior o risco. A principal diferença é que no sistema proposto a busca dos  dados ocorre de forma dinâmica através de formulários preenchidos pelos usuários,  enquanto o trabalho relacionado apenas apresenta links para informações sobre as  doenças em alguns países, citados como, destinos frequentes. Outro ponto bastante  importante é que o sistema proposto tem o foco apenas na doença da malária nos  estados brasileiros, enquanto a Consulta de Aconselhamento ao Viajante apresenta os  dados de forma bastante genérica visando apenas informar sobre as doenças em alguns  países.    Segundo o site da CDC [CDC, 2014], que fornece informações de diversas  fontes do mundo onde há casos de malária. Ele apresenta informativos com tópicos de  interesse de viajantes, como tipos de malária, história da doença, diagnósticos, entre  outras informações. Apresenta uma sessão com links rápidos para as principais  informações, uma sessão de artigos relacionados, programas e campanhas de  erradicação da malária. O usuário poderá inscrever-se para receber informações ou     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 372-375 Nov/2014     375   entrar em contato diretamente pelos formulários disponibilizados, além de possuir o  recurso de mapa, onde é possível pesquisar por países e visualizar estados com casos de  malária e alguns tipos da doença.     A principal diferença é que o sistema proposto apresenta dados comparativos e  estatísticos como lugares com maior incidência, gráficos e visualização em mapa das  informações sobre a malária no Brasil, enquanto o CDC Malária Map Application  oferece somente um mapa onde é possível pesquisar pelo país, o qual irá apresentar os  estados com casos de malária encontrados no país.    Existem diversos sistema web para visualização de diferentes dados e temas. O  projeto aqui desenvolvido vem somar a comunidade como um todo, sendo mais uma  ferramenta web com um tema diferenciado dos demais. Dentre os dados coletados  atraves de uma base de dados aberta, muitos dos dados podem ser empregados em  pesquisa cientifica.      5. Conclusões   Este trabalho apresentou uma aplicação Web com índices de malária no Brasil  utilizando dados extraídos de uma base de dados aberta do DATASUS, mostram que o a  malária está controlada em algumas partes do Brasil, porém ainda o número de casos é  muito alto, principalmente na região norte.  Os dados também apontam que a maior  parte dos casos de malária ocorrem em regiões da floresta amazônica. Ao realizarmos  este trabalho, foi possível criar gráficos e visualizar estatísticas sobre a doença.    Como trabalhos futuros, pretende-se: continuação na geração dos gráficos  comparativos e estatísticos, bem como os possíveis filtros por ano, sexo e faixa etária  dos mesmos, juntamente com correlações entre os dados pertinentes em cada região,  permitindo uma possivel tomada de decisão em diferentes regiões do Brasil.       6. Referências   CDC, Centers for Disease Control and Prevention. Malaria Map Application. Atlanta  – Geórgia. Estados Unidos. Disponível em: <http://cdc-malaria.ncsa.uiuc.edu/> -  Acesso em: 15 de setembro de 2014.   Hospital-Escola. Universidade Fernando Pessoa. Gondomar-Portugal. Consulta de  Aconselhamento ao Viajante. Disponível em: <http://consultaviajante.ufp.edu.pt/>  - Acesso em: 15 de setembro de 2014.   DATASUS, Departamento de Informatica do SUS. Disponível em:  <http://www2.datasus.gov.br/DATASUS/index.php?area=01> Acesso em: 15 de  setembro de 2014.   MARTINS, Fernando S. V.; CASTIÑERAS, Terezinha Marta P. P. & PEDRO, Luciana  G. F. Malária: Centro de Informação em Saúde para Viajantes. Universidade  Federal do Rio de Janeiro. 2013. Disponível em:  <http://www.cives.ufrj.br/informacao/malaria/mal-iv.html> Acesso em: 17 de  setembro de 2014.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 376-380 Nov/2014     376   Análise psicológica das cores no contexto do design de  interação sob a visão da Psicologia Analítica   Brenda Ludovico Vieira Nascimento1, Cleomar de Souza Rocha2   1Faculdade de Educação – Universidade Federal de Goiás (UFG)  Caixa Postal 131 – Goiânia – GO – Brasil   2Faculdade de Artes Visuais – Universidade Federal de Goiás (UFG)  Caixa Postal 131 – Goiânia – GO – Brasil   {brendaludovico,cleomarrocha}@gmail.com   Abstract. The psychological analysis of colors occupies an important space in  the context of Interaction Design and justifies the need of investigative efforts  that best relate these two areas of knowledge. This article is based on  Analytical Psychology and aims to make an initial investigation about  influences provoked by colors, present in web pages interfaces, on users  experiences. Thus, studies were performed on interfaces of some social  networks and of Universidade Federal de Goiás web portal. This analysis  benefits scientific literature as it deepens psychology knowledge applied to  Human-Computer Interaction.   Resumo. A análise psicológica de cores ocupa um importante espaço no  contexto do Design de Interação e justifica a necessidade de esforços  investigativos que melhor relacionem essas duas áreas de conhecimento. Este  artigo fundamenta-se na Psicologia Analítica e tem como objetivo fazer uma  investigação inicial sobre a influência de cores, presentes em interfaces de  páginas web, na experiência do usuário. Para tanto, são analisadas as  interfaces de algumas redes sociais e do portal web da Universidade Federal  de Goiás. Tal análise beneficia a produção científica à medida que aprofunda  os conhecimentos da Psicologia aplicados à Interação Humano-Computador.   1. Introdução   A Psicologia e a Informática são áreas com um relacionamento significativo, as  conectividades entre elas estão cada vez maiores, primeiramente  pela presentificação  da tecnologia na vida diária, estando em constante relação com as pessoas (objeto de  estudo da Psicologia) e também pelas preocupações em entender o homem no sentido  de beneficiá-lo com essa tecnologia. No que se refere às aplicações da Informática na  Psicologia, os estudos predominantes são os relacionados a produção de testes,  instrumentos informatizados e softwares para a Psicologia. Na aplicação da Psicologia à  Informática predominam estudos relacionados à inteligência artificial, inclusão digital e  interação humano-computador [Prado, Fortim e Cosentino 2006].    A Interação Humano-Computador tem como componente o design de  interação, cuja especificidade de estudo são os sistemas interativos em seu  funcionamento e aparência. De acordo com Preece, Rogers e Sharp (2005) o design de  interação pode ser definido como a criação de determinadas formas de comunicar  ideias, conceitos, funcionalidades e outras informações que sejam interativas e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 376-380 Nov/2014     377   melhorem a experiência do usuário, de forma que as páginas virtuais ou máquinas sejam  fáceis e agradáveis de se utilizar.    Mais do que a usabilidade de um sistema interativo, isto é, a eficiência em  atender às necessidades objetivas do usuário, é necessário melhorar a qualidade de sua  experiência, provocar nele emoções que capturem seu olhar. As imagens podem  provocar toda uma gama de emoções na subjetividade das pessoas, desde uma emoção  negativa até o fascínio, ou o simples conforto [Heller 2013]. Nem sempre o sistema  mais eficiente é preferido pelo usuário, ele pode selecionar um sistema de desempenho  inferior, mas com o qual se sente mais confortável. Nesse contexto se faz necessário o  estudo da Psicologia, para tentar compreender como as interfaces afetam os usuários.  Mais importante ainda, é o foco na análise das cores, seu papel provocador dos valores e  dos sentimentos humanos e dos benefícios que podem trazer para esses sistemas  informativos.   Diante disso, o objetivo deste artigo é iniciar uma observação do design de  algumas redes sociais e do portal web da Universidade Federal de Goiás (UFG),  realizando uma análise introdutória das cores e as implicações psicológicas que elas  causam nos usuários. A abordagem psicológica usada é a Psicologia Analítica, que  configura-se como ideal por fazer um estudo da relação do homem com os símbolos e  por considerar os aspectos inconscientes que determinam essa relação. Esses aspectos  podem enriquecer muito os estudos da relação Humano-Computador, haja visto que a  maioria dos estudos na área encontram-se restritos aos aspectos da consciência. De  acordo com o citado objetivo, a metodologia escolhida para a realização deste estudo é a  abordagem qualitativa. Segundo Mucchielli (1991) os métodos qualitativos são  característicos às ciências humanas pois são destinados ao estudo de “fatos humanos” e  pesquisam, explicitam ou analisam fenômenos, sejam estes visíveis ou ocultos. Tais  fenômenos não são passíveis de serem medidos em sua essência, até porque se  relacionam a objetos de estudo muito abstratos. Por exemplo: uma representação e uma  reação face a uma cor.   2. As abordagens psicológicas dentro do design de interação   As abordagens psicológicas mais utilizadas nos trabalhos correlatos são a Cognitiva e a  Gestalt, as quais estão mais relacionadas com o estudo das percepções, das sensações,  da atenção, da memória, etc.; em outras palavras, têm seu foco em processos  conscientes. O design de interação herda da Psicologia Cognitiva, por exemplo, o  entendimento do usuário como um processador de informações humano e os  melhoramentos de design são feitos no sentido de provocar o menor gasto cognitivo  possível. Dentre as preocupações estão: evitar sobrecarga de informação, empilhar itens  e criar lembretes que auxiliem memória do usuário. As cores aparecem como mais um  elemento de sobrecarga ou redução de carga. [Preece, Rogers e Sharp 2005].     3. As cores e o inconsciente   O inconsciente é uma instância psíquica estudada principalmente por Sigmund Freud.  Tal inconsciente, além de alheio à consciência, tem um funcionamento autônomo,  totalmente independente dessa consciência. Seu conteúdo é irrepresentável pela nossa  razão, não pode ser acessível pela linguagem e não pode ser compreendido em sua  essência, mas somente pelas diversas simbolizações feitas pela consciência [Bennet  1985]. Carl Gustav Jung defende que além do inconsciente freudiano, puramente     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 376-380 Nov/2014     378   individual, existe um inconsciente mais amplo e universal cuja origem se encontra na  hereditariedade. Esse inconsciente, denominado inconsciente coletivo, é um registro das  experiências instintuais vivenciadas pela humanidade. Seu conteúdo é mais ou menos o  mesmo em todos os lugares e indivíduos, tem um caráter transpessoal e ao mesmo  tempo presente em cada pessoa e suas pequenas diferenciações provém da influência do  inconsciente pessoal [Bennet 1985].    O inconsciente coletivo é composto por aquilo que Jung denomina “arquétipos”,  isto é, imagens padronizadas que constituem a linguagem própria, o substrato deste  inconsciente coletivo [Cloninger 1999] e que se manifestam através dos símbolos. Os  arquétipos são dotados de uma expressividade “numinosa”, ou seja, que provoca o  campo dos valores e dos sentimentos [Jung 1962]. Essas representações numinosas são  extremamente ativas para os indivíduos, tornando-os sensíveis aos símbolos. Os  símbolos são representados na linguagem formal mas podem aparecer isolados dela, em  cores e formas [Cloninger 1999]. Para ser um considerada um símbolo, uma palavra,  imagem ou cor deve implicar em algo além do seu significado manifesto e imediato,  portando um aspecto inconsciente mais amplo que não pode ser precisamente explicado   [Jung 2008].   4. Análise das cores em redes e portais web    A maior parte das redes sociais opta por um design minimalista, isto é, um design com  poucas cores e que não corre o risco de “agredir” o usuário com cores que possam não  ser tão agradáveis e prejudicar sua experiência. A única cor configurada como principal  nessas redes sociais é o azul, geralmente mesclado com a cor branca. Bons exemplos  desse padrão são o Facebook, o Twitter, o Tumblr e o MySpace. Toda essa imponência  do azul se explica no fato dele trazer para quem o vê uma sensação de confiabilidade,  segurança e harmonia [Heller 2013].     A porcentagem de pessoas que não gostam de azul é baixíssima (cerca de 1%),  porque ele adquiriu um significado universal de calma e transparência. Quanto mais  claro é o azul mais ele se relaciona com a transparência, inclusive, frequentemente são  feitas pinturas (por artistas ou não) onde a água é colorida de azul [Heller 2013]. Isso  explica o fato de muitas dessas redes sociais, por exemplo o Facebook, também usarem  o azul bem claro sobreposto à neutralidade do branco. Além disso, quanto mais clara é  uma cor, mais ela está relacionada à um caráter introspectivo [Jung 2010], típico dos  momentos em que as pessoas passam navegando nas redes sociais.    Em 2014 foi realizada uma grande reforma no portal da UFG. O portal anterior  não se preocupava com usabilidade ou acessibilidade e nem em ter uma identidade  visual para referenciá-lo. As mudanças, portanto, objetivaram melhorar esses aspectos.  Com as mudanças perdeu-se o excesso de informações e ganhou-se maior  horizontalidade. Além disso, a interface passou a ter algumas poucas imagens, todas em  preto e branco até o momento em que se passa o cursor do mouse por cima e elas se  tornam coloridas (Figura 1). Em virtude do preto e branco, as informações ficam sempre  objetivas no site e só ganham “vida” (cor) quando o usuário demonstra interesse por  elas.    A cor predominante no portal é o branco, vazio, que transmite leveza a quem o  vê e que, pela sua qualidade de “não cor”, não desvia a atenção e dá ainda mais ênfase  àquilo que tem cor. Pode-se perceber, dessa forma, que o site foi aperfeiçoado não     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 376-380 Nov/2014     379   somente por se tornar mais fácil de usar, mas também por ter um componente atrativo  ao inconsciente. Esses componentes atrativos correspondem, em alguns momentos, à  calma e objetividade das cores preto e branco e, em outros momentos, à diversidade de  sentimentos causados pelas cores que se revelam nas pequenas imagens, antes coloridas  em preto e branco. Como, por exemplo, o vermelho e sua chamatividade, o amarelo e  seu caráter enérgico e o azul e o seu equilíbrio [Heller 2013].     Figura 1. Página inicial do portal web da UFG. Somente a imagem central (na qual se   encontra o cursor) está colorida.   5. Considerações finais e Trabalhos Futuros   Com esse artigo podemos perceber o quão significativo pode ser o inconsciente na  forma com que visualizamos os ambientes interativos. Mesmo quando informações  estão sendo processadas pela consciência elas sofrem uma grande influência  inconsciente. Nesse sentido, as cores se constituem num componente importante à  medida que são bastante abstratas e mais próximas deste inconsciente. Todas as  discussões aqui presentes pretendem apenas iniciar os estudos deste tema, servindo de  base para um estudo posterior mais aprofundado, onde a intenção é fazer uma análise  mais completa de cores em design, discorrendo a respeito de todas elas. Também é  pretendida uma análise conjunta das formas que contornam essas cores e que, como já  teorizado por Jung, também podem conter um caráter simbólico. Além disso, aponta-se  aqui para a necessidade de mais estudos nessa direção, visando integrar ainda mais as  áreas de conhecimento da Psicologia e da Informática, principalmente no que se refere à  Relação Humano-Computador e dos aspectos psicológicos humanos que são ao mesmo  tempo influenciados e influenciadores da relação com os ambientes interativos.   Referências   Bennet E. A. (1985). O que Jung disse realmente. Rio de Janeiro: Jorge Zahar Editor.   Cloninger, S. C. (1999) Teorias da Personalidade. São Paulo: Martins Fontes.   Heller, E. (2013) A psicologia das cores: como as cores afetam a emoção e a razão. São  Paulo: Gustavo Gilli.   Jung, C. G. (1962) Um mito moderno. Lisboa: Editorial Minotauro.   Jung, C. G. (2008) O homem e seus símbolos. Rio de Janeiro: Nova Fronteira.   Jung. C. G (2010) Livro vermelho. Petrópolis: Editora Vozes.   Mucchielli, R. (1991). Les Méthodes Qualitatives. Paris: Presses Universitaires de  France.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 376-380 Nov/2014     380   Prado, O. Z., Fortim, I. e Cosentino, L. (Org.). (2006) Psicologia & Informática:  produções do III Psicoinfo II Jornada do NPPI. São Paulo: CRP/SP.   Preece, J., Rogers, Y. e Sharp H. (2005). Design de interação: além da interação  homem-computador. Porto Alegre: Bookman.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 381-384 Nov/2014     381   Visualização de Dados sobre Acidentes de Trabalho   Cássio M. Teixeira, Daniel Prediger, Iulisloi Zacarias, Júlio Moerschbacher,  Rafael A. Vitalli, Cristiano Bertolini   Departamento de Tecnologia da Informação – Centro de Educação Superior Norte – RS  – Universidade Federal de Santa Maria (UFSM)   Caixa Postal 54 – 98400-000 – Frederico Westphalen – RS – Brasil  {cassiomichels,iuli.zacarias,rafavitalli}@gmail.com,   {daniel_prediger,juliowm}@hotmail.com, cristiano_bertolini@ufsm.br   Abstract. This paper aims to analyze open databases about occupational  accident by the Brazilian government. In this way, this paper presents  organized information of the main index of occupational accidents in the  country. In the end, we intend to develop an application for data visualization  of occupational accidents, which are available by the Brazilian government.   Resumo. O presente artigo tem como objetivo analisar bases de dados abertas  sobre acidentes de trabalhado disponíveis pelo governo brasileiro. Desta  forma, este trabalho apresenta um demonstrativo dos principais índices de  acidentes de trabalho do país. Como resultado procura-se desenvolver uma  aplicação capaz de realizar a visualização gráfica dos dados de acidentes de  trabalho que estão disponíveis no portal brasileiro de dados abertos.   1. Introdução   Os acidentes de trabalho no Brasil possuem uma baixa taxa de registros nos órgãos  reguladores além da falta de informações consolidadas. Foi possível identificar tal  problema após o acesso e verificação dos dados disponibilizados pelo governo que, sem  nenhuma aplicação ou ferramenta que possibilite a visualização gráfica desses dados de  acidentes de trabalho, os mesmos se tornam irrelevantes.    Segundo o Portal do Ministério da Previdência Social [Previdência, 2014],  “define-se como acidente do trabalho aquele que ocorre pelo exercício do trabalho a  serviço da empresa ou pelo exercício do trabalho dos segurados especiais, provocando  lesão corporal ou perturbação funcional, permanente ou temporária, que cause a morte,  a perda ou a redução da capacidade para o trabalho”.    O principal objetivo deste trabalho é implementar um aplicativo que facilite a  visualização dos dados publicados no Portal Brasileiro de Dados Abertos [Portal, 2014],  pois no referido portal os dados são fornecidos em forma de arquivo texto ou formato  XML o que dificulta a interpretação dos dados. Traina [Traina et. al., 2007] enfatiza que  os seres humanos não são eficientes para “interpretar” grandes volumes de dados em  forma numérica ou textual, especialmente em espaços de altas dimensões, mas têm uma  percepção muito boa quando esses dados são apresentados de forma gráfica. A  visualização gráfica nos permite fazer inferências sobre os dados e além de possibilitar a  comparação entre fontes diferentes.    O trabalho apresenta como possíveis benefícios a visualização dos dados de  forma intuitiva sendo possível utilizar a aplicação para visualizar de forma gráfica os  dados que primeiramente foram disponibilizados em tabelas e sem modelagem. Outro     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 381-384 Nov/2014     382   benefício do trabalho é proporcionar aos usuários a possibilidade de comparar os índices  de acidentes referentes aos estados, regiões e municípios, podendo identificar em quais  regiões ocorreram mais acidentes de trabalho.    Neste contexto, este artigo está assim estruturado: a seção 2 apresenta os  trabalhos relacionados; a seção 3 apresenta o referencial teórico; a seção 4 apresenta a  solução proposta; a seção 5, resultados parciais do trabalho e para finalizar a seção 6, as  referências.   2. Trabalhos relacionados   A recente iniciativa do Governo Federal em disponibilizar dados referentes a vários  serviços, incluindo dados da saúde do trabalhador, cria várias possibilidades para  visualizações de informações e planejamento de políticas públicas [Portal, 2014]. No  entanto esses dados são disponibilizados de forma bruta e demandam um grande esforço  para compreensão e relacionamento dos mesmos com outros dados.    O trabalho Visualização de Dados Estatísticos Representados como Dados  Abertos Ligados [Palazzi et. al., 2012],  faz referência ao crescimento e movimento de  diversos governos em todo o mundo na direção da criação de plataformas de dados  abertos, que tem impulsionado a pesquisa de formas de representação adequadas para  estes.   3. Referencial Teórico   Segundo Oswaldo Michel [Michel 2001] acidente do trabalho é o que ocorre pelo  exercício do trabalho a serviço da empresa, ou ainda pelo exercício do trabalho dos  segurados especiais, provocando lesão corporal ou perturbação funcional que cause  morte, a perda ou redução da capacidade para o trabalho permanente ou temporário.    Para Diego G. O. Budel [Budel 2012] a ocorrência de acidentes do trabalho gera  consequências traumáticas ocasionando na maioria das vezes mutilações, invalidez  permanente, entre outros danos, que não se limitam ao corpo físico do trabalhador,  afetando também sua integridade psicológica, chegando até a causar a morte do  trabalhador com repercussões também para os familiares, inclusive para a sociedade de  modo geral bem como para os cofres públicos.   4. Solução Proposta   Nesta seção são apresentadas as informações que orientaram o desenvolvimento deste  trabalho. Tem-se como solução proposta neste trabalho a criação da aplicação que  proporcionará ao usuário a visualização gráfica dos dados abertos sobre acidentes de  trabalhos que foram disponibilizados pelo governo.    A visualização dos dados no aplicativo pode ocorrer de três maneiras, sendo  elas: através de gráficos que possibilitam a comparação de dados entre municípios,  estados e regiões; a visualização da evolução no tempo dos dados através de um gráfico  de barras; e um mapa de calor, onde será possível visualizar os dados referentes aos  estados e regiões.    Para desenvolvimento do sistema foi utilizada a linguagem de programação  Python juntamente com a ferramenta Django para realizar a comunicação do banco de  dados com a aplicação. As tecnologias HTML, CSS e JavaScript foram utilizadas para     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 381-384 Nov/2014     383   realizar a criação da interface do sistema, além da API Highcharts para criação dos  gráficos, assim como bases de dados abertas fornecidas pelo governo e órgãos  regulamentadores.   5. Resultados Parciais   Foram alcançados os seguintes objetivos principais: acesso aos dados disponíveis pelo  governo, criação da aplicação, modelagem do banco e migração dos dados. Como  resultados parciais temos a visualização de alguns dos dados em forma gráfica, sendo  eles demonstrados na sequência.    Na Figura 1 pode-se visualizar o índice de acidentes de trabalho através do mapa  de calor do Brasil, podendo ser por estados ou por região, de acordo com o que o  usuário selecionar. O mapa apresentado na Figura 1 mostra os índices de acidentes de  trabalho das principais regiões para o ano de 2008. Observa-se que a região nordeste  registrou a maior incidência de acidentes de trabalho no ano de 2008.     Figura 1. Mapa de calor que apresenta os índices de acidentes de trabalho por  estados ou região.    A Figura 2 apresenta o gráfico comparando os acidentes de trabalho entre os  anos de 1997 a 2008, mostrando em barras a quantidade de acidentes (por 1.000  segurados), podendo mostrar o país, uma região, o estado ou município selecionado.  Observa-se, por exemplo, que houve uma redução no índice de acidentes de trabalho no  Brasil entre os anos de 1997 à 2008.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 381-384 Nov/2014     384     Figura 2. Dados referentes aos acidentes de trabalho no Brasil.    A aplicação desenvolvida até o momento pode ser acessada através do endereço  http://avdat.herokuapp.com/acidentes/.    Como trabalhos futuros, será realizado refinamentos e ajustes da versão atual da  aplicação, assim como a implementação de novas funcionalidades na aplicação, como  novos filtros e comparações de mais bases de dados, além da utilização de outras novas  bases de dados relacionadas a acidentes de trabalho.   6. Referências   Budel, Diego G. O. (2012). Acidente do trabalho: Caracterização, conceito e  competência, http://www.revistas.unifacs.br/index.php/redu/article/view/1930/1466/  Acesso em 18 Set. 2014.   Palazzi, D., Tygel A. (2012). Visualização de Dados Estatísticos Representados  como Dados Abertos Ligados, http://cirandas.net/alantygel/academico/relatoriovisualizacao-de-dados-estatisticos-representados-como-dados-abertos-ligados.pdf,  Acesso em 16 Out. 2014.   Michel, Oswaldo. (2001). Acidentes do Trabalho e Doenças Ocupacionais, 2. ed. rev.  e ampl. São Paulo: Ltr, p. 29.   Portal Brasileiro de Dados Abertos. Sobre o Dados.gov.br, http://dados.gov.br/sobre/,  Acesso em 10 Set. 2014.   Previdência Social. Estatísticas. Seção IV - Acidentes de Trabalho – Texto,  http://www.previdencia.gov.br/estatisticas/secao-iv-acidentes-do-trabalho-texto/,  Acesso em 10 Set. 2014.   Traina, A. J. M., Traina, C. J., Botelho, E., Barione, M. C. N. e Bueno, R. (2007).  Visualização de Dados em Sistemas de Bases de Dados  Relacionais, http://www.lbd.dcc.ufmg.br/colecoes/sbbd/2001/007.pdf, Acesso em 26  Set. 2014.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 385-388 Nov/2014     385   Análise de ondas eletroencefalográficas aplicada a  Tecnologias Assistivas de Controle de Ambiente   Matheus Hentges Ferreira, Prof. Alexandre dos Santos Roque   Universidade Regional Integrada do Alto Uruguai e das Missões   DECC – Departamento de Engenharias e Ciência da Computação – Santo Ângelo, RS -  Brazil      matheushfer@hotmail.com, ale.roque@gmail.com   Abstract. This paper presents a model of the control system applied to  Assistive Technologies control environment. The system performs analysis of  EEG waves (EEG) of an individual and is able to interpret and command  actions by concentration levels, such coupled with sensors and actuators in  the environment actions will be to enhance communication of individuals with  physical limitations within a certain space where it is inserted.   Resumo. Este trabalho apresenta um modelo de sistema de controle  embarcado aplicado a Tecnologias Assistivas de controle de ambiente. O  sistema efetua análise de ondas eletroencefalográficas (EEG) de um indivíduo  e é capaz de interpretar e comandar ações através de níveis de concentração,  tais ações aliadas a sensores e atuadores presentes no ambiente terão por  objetivo potencializar a comunicação do indivíduo com limitações físicas  dentro de um determinado espaço onde ele encontra-se inserido.   1. Introdução    Este artigo apresenta as possibilidades de desenvolvimento de um modelo de  sistema de controle embarcado como alternativa de implementação de Tecnologias  Assistivas (TA) de Controle de Ambiente, utilizando a análise eletroencefalográfica  (EEG) como meio de comunicação. O sistema de controle deve ser capaz de possibilitar  a interação entre o indivíduo e o ambiente onde ele encontra-se inserido,  potencializando os aspectos de comunicação existentes neste meio, assim como agregar  qualidade na execução de determinadas tarefas do dia-a-dia, sendo essa uma premissa  das TA’s de Controle de Ambiente.    O termo “análise eletroencefalográfica” mencionado no parágrafo anterior, faz  alusão à Eletroencefalografia (EEG), que de forma bastante abrangente, significa o  registro da atividade cerebral, sendo este atualmente utilizado como um mecanismo de  obtenção de dados, dados que por sua vez podem ser correlacionados a diversos estados  e sintomas dos seres humanos [Lage 2013]. As TA’s baseadas na análise de EEG,  buscam trazer ao indivíduo com deficiência novas possibilidades de interagir com o  meio, sem utilizar para isso as vias de comunicação normais como nervos e músculos.  O objetivo é utilizar sinais puramente cerebrais, transcrevendo as vontades dos  indivíduos para diferentes tipos de dispositivos [Caloti 2010].    Dentro do contexto das TA’s de controle de ambiente, através de um controle  remoto (gatilho), que no caso será a capacidade de pensar do indivíduo, as pessoas com     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 385-388 Nov/2014     386   limitações motoras, podem ligar, desligar e ajustar aparelhos eletroeletrônicos como a  luz, o som, televisores, ventiladores, executar a abertura e fechamento de portas e  janelas, receber e fazer chamadas telefônicas, acionar sistemas de segurança, entre  outros, localizados em seu quarto, sala, escritório, casa e arredores [Bersch 2013].    Temos definido que o “gatilho” que irá disparar alguma ação é um “controle  remoto”, que por sua vez consiste na interpretação de algum estado mental de um  determinado indivíduo. A interpretação do estado mental a que nos referimos, pode ser  a detecção do nível de concentração, relaxamento, piscada e outros estados detectáveis a  partir da análise eletroencefalográfica. O objetivo é transformar tais estados mentais em  comandos, onde a concentração acima de um determinado percentual indica o “power  on” para um dispositivo, por exemplo.  Porém, unicamente com o gatilho não temos  aplicabilidade alguma, precisamos que este estabeleça comunicação com alguns  sensores e atuadores no ambiente, o que possibilitaria ao sistema de controle ali presente  descobrir com qual dispositivo o indivíduo está querendo interagir e então realizar a  ação.    Portanto, a partir da união dos conceitos acima mencionados, a lacuna que este  sistema de controle pretende explorar, é a de permitir que indivíduo, independentemente  de sua(s) disfunção(ões) motora(s), possa aprimorar seus aspectos de acessibilidade ao  estabelecer comunicação com o ambiente como um todo, trabalhando na interação de  forma integrada com os diferentes tipos de dispositivos existentes naquele ambiente e  consequentemente contribuindo num processo de mitigação das limitações do indivíduo  naquele espaço, atingindo pontualmente os objetivos que tangem uma TA de Controle  de Ambiente.   2. Pesquisas relacionadas    A análise eletroencefalográfica juntamente com as TA’s, vem sendo utilizadas  em diversas áreas, como por exemplo, aplicações que auxiliam na educação de  indivíduos com paralisia cerebral [Heidrich, 2013]; estudo e desenvolvimento de  próteses robóticas neurocontroladas para utilização em indivíduos com ausência de  determinados membros [Haber & Bezerra 2010]; na criação de novas formas de  controlar meios de transporte como as cadeiras de rodas [Schuh & Heidrich, 2013]; etc.     A pesquisa envolvendo eletroencefalografia e Tecnologias Assistivas não é algo  essencialmente novo. Existem diversos projetos fazendo uso destes conceitos, porém,  como observado em seções anteriores, as Tecnologias Assistivas se dividem em  diversas categorias, e algumas delas foram e estão sendo mais exploradas, a exemplo as  de mobilidade [Schuh & Heidrich, 2013] e órteses e próteses [Haber & Bezerra 2010].   3. Arquitetura de controle    A arquitetura de controle consiste basicamente na representação formal de como  ocorrerá todo o processo de leitura, interpretação e ação dos comandos dentro do  ambiente. A Figura 1 representa basicamente um cenário de atuação, onde um  determinado indivíduo é cercado por diversos dispositivos e sensores, os sensores  detectam a proximidade do indivíduo com determinado dispositivo, e então através da  interpretação de comandos cerebrais acionamos e/ou configuramos algum tipo de  dispositivo.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 385-388 Nov/2014     387     Figura 1. A figura é um exemplo de um cenário de atuação controlado por EEG.   4. Resultados parciais    Dos estudos realizados até o momento, elencamos e analisamos três dispositivos  leitores de EEG, sendo eles:   Dispositivo Fabricante Preço Lançamento Eletrodos   MindWave NeuroSky U$79,99 2011 1   MindWave Mobile NeuroSky U$129,99 2012 1   Emotiv EPOC Emotiv Systems U$299,99 2009 14    Por questões de custo x benefício, foi selecionado o Headset MindWave Mobile  da fabricante NeuroSky como dispositivo (controle remoto) que irá efetuar a leitura das  ondas cerebrais.    O Headset MindWave Mobile consiste num fone de ouvido que possui dois  sensores de captação de sinal, o principal fica posicionado sobre a testa e o secundário  em formato de clip fica preso à orelha [Schuh 2014]. O dispositivo conta também com  conectividade bluetooth e transmissão de dados utilizando um protocolo de dados  seriais, o que o torna ideal para trabalhar com a plataforma Arduino. Outro diferencial  do MindWave Mobile é a sua possibilidade de integração com dispositivos móveis  dotados dos sistemas operacionais Android e IOS. A conectividade do MindWave já foi  testada juntamente com o arduino, e no momento estamos em fase de estudo dos  diversos estados mentais detectáveis pelo aparelho assim como suas possíveis  aplicações no que diz respeito a controle de ambientes.   5. Conclusão    O trabalho realizado até o momento demonstra as vastas possibilidades de  aplicação dos conceitos da eletroencefalografia juntamente com as tecnologias  assistivas. O estudo em questão focou na subárea das TA’s de controle de ambientes,  porém, os mesmos conceitos podem ser aplicados para outros fins, como por exemplo,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 385-388 Nov/2014     388   na área de educação de pessoas com paralisia cerebral, estudo e desenvolvimento de  próteses neurocontroladas, etc.   6. Referencias Bibliográficas    Bersch, Rita; Tonolli, J. Carlos. (2006) “Introdução ao Conceito de Tecnologia  Assistiva”, Disponível em: <http://www.bengalalegal.com/tecnologia-assistiva> Acesso  em: 13/04/2014.    Bersch, Rita. (2013) “Introdução à Tecnologia Assistiva”. Disponível em:  <http://www.assistiva.com.br/Introducao_Tecnologia_Assistiva.pdf> Acesso em:  13/04/2014.    Caloti, Thiago A.; Ferreira, André; Andreão, Rodrigo V.; Coelho, Laíza C.  (2011) “Reconhecimento de estados mentais no EEG para aplicação em tecnologias  assistivas”. Disponível em: <www.sba.org.br/rsv/SBAI/SBAI2011/86469.pdf> Acesso  em: 13/04/2014.    Haber, Átila S.; Bezerra, Johelden C. (2010) “Dispositivos de Tecnologia  Assistiva Aplicada à Mão Robótica Neurocontrolada”, Disponível em: <http://  http://www3.iesam-pa.edu.br/ojs/index.php/computacao/article/viewFile/1068/710>  Acesso em: 13/04/2014.    Schuh, Ânderson R.; Lima, Alessandro; Mossmann, João; Bez, Marta. (2014)  “Protótipo de simulador de cadeira de rodas motorizada controlada por interface  cérebro-computador não invasiva”. Disponível em:  <http://siaiweb06.univali.br/seer/index.php/acotb/article/view/5342/2799> Acesso em:  13/04/2014.    Heidrich, Regina. (2013) “A utilização de BCI por pessoas com paralisia  cerebral no contexto escolar aplicado a games”, Disponível em:  http://issuu.com/universidadefeevale/docs/jornal_feevale_setembro_2013?e=2618666/4 765898> Acesso em: 20/05/2014. Schuh, Ânderson R.; Lima, Alessandro; Heidrich,  Regina de O.; Mossmann, João; Flores, Cecilia; Bez, Marta. (2013) “Desenvolvimento  de Um Simulador Controlado por Interface Cérebro-Computador Não Invasiva para  Treinamento na Utilização de Cadeira de Rodas ”. Disponível em: <  www.um.pro.br/prod/_pdf/716.pdf> Acesso em: 13/04/2014.    Lage, Aleria Cavalcante. (2013) “Análise de novos dados linguísticos: A  eletroencefalografia em neurociência da linguagem”. Disponível em: <  http://www4.fsanet.com.br/revista/index.php/fsa/article/view/114> Acesso em:  25/04/2014.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 389-392 Nov/2014     389   Perfil dos Profissionais e das Empresas de Tecnologia da  Informação (TI) da Cidade de Frederico Westphalen - RS      Francieli Zanardi, Sidnei Renato Silveira   Curso de Bacharelado em Sistemas de Informação – Universidade Federal de Santa  Maria – Centro de Educação Superior Norte - RS – Frederico Westphalen – RS – Brasil   francielizanardi@hotmail.com, sidneirenato.silveira@gmail.com  Resumo. O objetivo principal deste trabalho é a realização de uma pesquisa  que tornará visível, para a comunidade geral e acadêmica, o perfil dos  profissionais e das empresas de Tecnologia da Informação (TI) existentes hoje  no mercado de trabalho, na cidade de Frederico Westphalen –RS, permitindo  a formação de uma base de conhecimento geral para fomentar projetos e  programas visando à inserção de novas pessoas nesse ambiente como um  melhor direcionamento da universidade para tal finalidade como também a  criação de programas eficazes de atração e retenção de talentos nas empresas  locais.    Abstract. This paper presents a research that will become apparent, for  general and academic community, the profile of Information Technology (IT)  professionals and IT companies existing in the city of Frederico Westphalen -  RS, allowing the formation of a general knowledge base to promote projects  and programs aimed at the inclusion of new people in this context as better  targeting the university for this purpose as well as creating effective programs  to attract and retain talent in local companies.       1. Introdução   As transformações tecnológicas e a crescente demanda com um aumento real e concreto  das oportunidades para profissionais de TI (Tecnologia da Informação) tornou esta área  um mercado promissor, com remunerações diferenciadas e possibilidades de aplicações  em diversos setores.  Conhecer o perfil dos profissionais que atuam em TI, bem como  as empresas da área na cidade de Frederico Westphalen – RS visa possibilitar o  direcionamento de futuras ações estratégicas dos cursos de informática ofertados pelas  IES (Instituições de Ensino Superior) da região, em especial os cursos ofertados pelo  CESNORS (Centro de Educação Superior Norte do RS), da UFSM (Universidade  Federal de Santa Maria), como também a criação de programas eficazes de atração e  retenção de talentos nas empresas locais.    O conhecimento gerado por meio deste trabalho auxiliará, também, no  mapeamento do clima organizacional das empresas. O clima organizacional tem um  papel indispensável para evitar falhas nos processos de gestão de pessoas, bem como  permitir um melhor gerenciamento dos profissionais, criando programas motivacionais  para retenção de talentos e melhoramento dos processos de recrutamento e seleção.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 389-392 Nov/2014     390   2. Estado da Arte   Schuster (2008) apresenta uma pesquisa realizada sobre o mercado de trabalho de TI,  que permitiu levantar dados relevantes, possibilitando apontar algumas das tendências  de demandas por profissionais exigidas pelo mercado de trabalho de TI de Porto Alegre  - RS, bem como indicar possíveis causas para o não preenchimento das oportunidades  em aberto.  Os dados foram coletados através de entrevistas e posteriormente  analisados através de mapas de associação de ideias. Foram apontadas características  deste mercado, dos profissionais, assim como as principais dificuldades encontradas nos  processos seletivos. Também foram levantadas possíveis causas para a dificuldade que  as empresas têm em contratar mão-de-obra especializada em TI, indicando diretamente  a pouca qualificação destes profissionais que, segundo a pesquisa, não estão preparados  para atender as demandas do mercado de trabalho (SCHUSTER 2008).    Conhecer melhor o perfil comportamental dos profissionais do setor de  Tecnologia da Informação foi o objetivo da pesquisa apresentada em Iannini (2010),  realizada por meio de questionários e entrevistas.  O trabalho envolveu uma pesquisa  para identificar o perfil das seis principais áreas de atuação dos profissionais de TI,  sendo elas: Administração de Redes, Administração de Banco de Dados, Análise de  Sistemas, Desenvolvedor, Gerência de Projetos e Web Design.  A pesquisa foi  realizada em duas fases, sendo a primeira pelo método quantitativo e a segunda pelo  método exploratório. Na implementação da primeira fase foi submetido a profissionais,  para responderem de forma voluntária, um questionário eletrônico com 23 questões das  quais 1079 respostas foram validadas. Na segunda fase 256 profissionais foram  entrevistados pessoalmente. No final desta pesquisa o autor pôde definir várias atitudes  e comportamentos envolvendo os profissionais da área de TI.     No estudo apresentado por Ferreira (2003), 12 empresas de consultoria em  recrutamento e seleção de recursos humanos foram estudadas para obter informações  acerca da demanda atual do mercado de trabalho. Foram levantadas e analisadas as  literaturas sobre o mercado de trabalho, as qualificações profissionais requeridas pelo  mercado e as informações obtidas em depoimentos de empregadores.  O estudo  trouxe quatro conclusões principais: (1) os profissionais devem desenvolver  continuamente suas habilidades técnicas típicas de ciência da informação, bem como  suas atitudes comportamentais; (2) as potencialidades desses profissionais nem sempre  são reconhecidas pelo mercado de trabalho; (3) como consequência não é comum  encontrar profissionais da informação ocupando posições superiores como analistas ou  gerentes; (4) as causas principais das deficiências são tanto a falta de desenvolvimento  dessas habilidades durante o período de formação, quanto a falta de reconhecimento do  perfil dos profissionais da informação pelo mercado e da autoimagem por eles mesmos  (FERREIRA, 2003).   3. Solução Proposta   A realização deste trabalho surge pelo aumento da demanda de profissionais da área da  Tecnologia da Informação (TI) e pela necessidade de conhecer o perfil dos profissionais  existentes hoje no mercado de trabalho da cidade de Frederico Westphalen - RS, já que  o perfil destas empresas e destes profissionais pode direcionar futuras ações estratégicas  dos cursos de informática ofertados pelas IES da região, em especial os cursos ofertados  pelo CESNORS/UFSM. Acredita-se que o resultado dessa pesquisa constituirá um     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 389-392 Nov/2014     391   documento de grande importância para as empresas de TI que necessitam também ter  estratégicas para se desenvolverem a fim de buscar aprimoramento para sua equipe  tanto nos processos de seleção, como desenvolvimento e aperfeiçoamento da equipe e  para a própria retenção de talentos quando necessário.    Neste contexto, faz-se necessário conhecer as características gerais que fazem  parte do perfil deste profissional, tais como: faixa etária, nível de escolaridade,  conhecimento de idiomas, relação com o empregador, relacionamento interpessoal,  perspectivas de melhorias e da carreira do profissional, características que formam um  conjunto de informações que serão necessárias para uma análise do perfil profissional,  bem como características dos empregadores, envolvendo remuneração, benefícios,  investimento em Educação Continuada, entre outros aspectos.     O levantamento de dados deste trabalho será realizado através de uma  pesquisa de caráter descritivo do tipo survey (RIBEIRO; ZABADAL, 2011). Esta  pesquisa será realizada em empresas de desenvolvimento e suporte de software, de  manutenção de hardware e de fornecimento de acesso e hospedagem de internet da  cidade de Frederico Westphalen - RS.  Serão realizadas entrevistas com os  responsáveis pelas empresas e pelos seus colaboradores, tentando abranger da forma  mais ampla possível o maior número de profissionais.  A pesquisa será realizada por  meio da aplicação de questionários semiestruturados a partir de dois modelos, um para  os gestores/responsáveis pelas empresas e outro para os colaboradores. A Figura 1  apresenta os instrumentos elaborados.    Frente a grande quantidade de dados e informações que serão coletadas, será  empregada a técnica de mineração se dados, para que se possam identificar padrões e  conhecimento implícito. Nesta fase do trabalho seguir-se-á a metodologia proposta por  Rezende (2003), na qual a mineração de dados é dividida em três grandes etapas: préprocessamento, extração de padrões e pós-processamento.     Na primeira etapa denominada como pré-processamento, após serem aplicados  os instrumentos de pesquisa e os dados coletados sejam tabulados, os mesmos passarão  por uma integração, que ajudará a unificar os dados deixar todos no mesmo formato.  Será realizada uma limpeza, visando garantir a qualidade dos dados, sendo verificados  erros de digitação e consistência dos dados.     A tabulação dos dados por meio de uma planilha eletrônica, além de servir como  entrada para a mineração de dados, também permitirá a construção de tabelas e gráficos,  possibilitando a análise das informações que comporão o perfil dos profissionais de TI  de Frederico Westphalen.  Na etapa seguinte ocorrerá a extração de padrões, ou  mineração de dados propriamente dita. Conforme Kasahara & Conceição (2008), esta  etapa tem como finalidade o cumprimento dos objetivos definidos na identificação do  problema, compreendendo a escolha da tarefa de Mineração de Dados a ser empregada,  a escolha do algoritmo a ser utilizado e a extração dos padrões propriamente dita. Para  tanto será empregada a ferramenta de mineração de dados Tanagra  (RAKOTOMALALA, 2014).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 389-392 Nov/2014     392   2 3  Figura 1: Roteiro de Entrevistas (Fonte: Dos autores)     4. Considerações Finais   Acredita-se que uma das principais dificuldades para realização deste trabalho será  conseguir com que as empresas forneçam todos os dados necessários. Espera-se que,  deixando claro para as empresas o quão importante será a participação delas, as mesmas  sejam sensibilizadas em contribuir para o levantamento do perfil dos profissionais de TI  da cidade de Frederico Westphalen – RS. A aplicação dos instrumentos de pesquisa está  sendo realizada durante o segundo semestre deste ano. Após a aplicação dos  instrumentos de pesquisa, será realizada a tabulação e organização dos dados para que  sejam aplicados em uma ferramenta de mineração dos dados para gerenciamento das  informações.   Referências   FERREIRA, D. T. Profissional da informação: perfil de habilidades demandadas   pelo mercado de trabalho. Universidade Estadual de Campinas. São Paulo. 2003.  IANINI, T. O. Pesquisa do Perfil dos Profissionais de Tecnologia da Informação.   Minas Gerais, 2010.  KASAHARA, C. N.; CONCEIÇÃO, F. W. S. Análise de ferramentas de mineração   de dados. Universidade Federal do Pará. Belém – PA, 2008.  RAKOTOMALALA, R. Tanagra. Disponível em: <http://eric.univ lyon2.fr/~ricco/tanagra/en/tanagra.html>. Acesso em maio, 2014.  REZENDE, S. O. Sistemas Inteligentes: fundamentos e aplicações. Manole: 2003.  RIBEIRO, V. G.; ZABADAL, J. R. S. Pesquisa em Computação: uma abordagem   metodológica para Trabalhos de Conclusão de Curso e Projetos de Iniciação  Científica. Porto Alegre: UniRitter, 2010.   SCHUSTER, M. E. Mercado de trabalho de tecnologia da informação: O perfil dos  profissionais demandado. Universidade Federal do Rio Grande do Sul. Porto  Alegre –RS, 2008.   
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 393-397 Nov/2014     393   Frameworks para criação de Web Apps para o Ensino  Mobile   Lucas Zamim1 Roberto Franciscatto1 Evandro Preuss1   1Colégio Agrícola de Frederico Westphalen (CAFW) – Universidade Federal de Santa  Maria (UFSM) 98400-000 – Frederico Westphalen – RS – Brasil   lucaszamim@hotmail.com, roberto@cafw.ufsm.br, evandro@cafw.ufsm.br   Abstract. This work aims to present the main frameworks for creating web  apps, as well as its features and functionality. The project envisages the  development of an integrated web system for teaching that offers features such  as specific materials and content to the students and making them available  through mobile applications generated from mobile frameworks. So it must be  considered in this research project leading operating systems for mobile  devices (Android, iOS and Windows Phone).   Resumo. Este trabalho tem por objetivo apresentar os principais frameworks  para a criação de web apps, bem como, seus recursos e funcionalidades. O  projeto em desenvolvimento prevê ainda a integração de um sistema web  voltado para o ensino que dispõe de recursos como materiais e conteúdos  específicos para os alunos e sua disponibilização através de aplicativos  móveis gerados a partir de frameworks mobile. Para tanto, serão  considerados neste projeto de pesquisa os principais sistemas operacionais  para dispositivos móveis (Android, iOS e Windows Phone).   1. Introdução   Atualmente os smartphones e tablets vêm substituindo os computadores tradicionais,  pelas suas vantagens de mobilidade, além dos mesmos estarem com características e  desempenho similares a esses computadores. Segundo IDC (2014) o número de  smartphones no mundo no segundo trimestre de 2014 era superior a 301 milhões de  aparelhos, desses 84,7% utilizam sistema operacional Android, seguido do iOS,  Windows Phone e BlackBerry. Além disso, a quantidade de aplicativos mobile  disponíveis é bastante grande. Apenas no Google Play, loja de aplicativos para o  Android, o número já ultrapassa a marca de um milhão de aplicativos disponíveis para  instalação (XIMENES, 2014).    Estes dados refletem o crescimento do mercado mobile, possibilitando inovação e  oportunidades de desenvolvimento. Explorar as tecnologias mais recentes como o  HTML5, CSS3 e JavaScript, possibilita desenvolver aplicações mais interativas e  multiplataforma, como exemplo, web apps que podem ser acessadas pela maioria dos  dispositivos. Assim, este trabalho em desenvolvimento tem por objetivo conhecer os  principais frameworks para criação de web apps (suas características, recursos, pontos  positivos e negativos), bem como desenvolver uma aplicação para o ensino (sistema  web) que permita através de um framework específico gerar versões deste sistema para  os principais sistemas operacionais presentes nos dispositivos móveis.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 393-397 Nov/2014     394   2. Desenvolvimento Mobile   O desenvolvimento mobile está dividido basicamente em três categorias: aplicativos  nativos, web apps e aplicativos híbridos (destinados a uma única plataforma ou  multiplataforma).   Os aplicativos nativos são descritos em uma linguagem de programação padrão  referente ao sistema operacional em questão, por exemplo, a linguagem Java para  desenvolver aplicativos Android. Estes aplicativos são instalados no dispositivo e  consomem os recursos do mesmo. A vantagem destes aplicativos está no acesso e  comunicação com os recursos e componentes do dispositivo (GASPAROTTO, 2014).   Os web apps são aplicações multiplataforma, projetadas para serem acessadas via  browser. Estas requerem conexão com a internet e o conhecimento do endereço web da  aplicação. São desenvolvidas utilizando as linguagens de desenvolvimento web e  disponibilizadas em um servidor web remoto, o qual é o responsável por processar os  dados (CHEDE, 2013).   Já os aplicativos híbridos são aplicações parcialmente nativas e parcialmente web apps.  Como os nativos são instaláveis, possibilitam aproveitar alguns componentes e  funcionalidades do dispositivo, como web apps podem ser desenvolvidos utilizando as  linguagens padrão de desenvolvimento web. A grande vantagem é que o mesmo projeto  pode ser direcionado às múltiplas plataformas mobile. (GASPAROTTO, 2014).   Tanto as aplicações nativas ou híbridas podem ter parte ou conteúdo total vindos da web  ou de outra aplicação externa. Como os dispositivos mobile não disponibilizam recursos  para acesso a aplicações externas se faz necessário o uso de webservices entre as  aplicações. Os webservices são tecnologias que permitem a comunicação entre  aplicações diferentes. Outra opção é trabalhar em modo off-line e utilizar para  armazenamento de dados um banco de dados local, o SQLite ou em aplicações híbridas  utilizar a tecnologia de armazenamento disponibilizada pela tecnologia HTML5 o  LocalStorage. Essas aplicações também podem ser disponibilizadas nas lojas de  aplicativos.   3. Ferramentas para o Desenvolvimento Mobile   As APIs (Application Programming Interface) e os frameworks são ferramentas  disponibilizadas para auxiliar no desenvolvimento de aplicações. Estas ferramentas  disponibilizam mecanismos que são comuns para todos os projetos. As APIs são mais  voltadas para o desenvolvimento de aplicativos nativos, como exemplo, o Android SDK  para o desenvolvimento Android, Windows Phone App Studio para Windows Phone,  XCode para iOS e assim por diante. Os frameworks também podem ser utilizados para o  desenvolvimento nativo, mas são mais encontrados para o desenvolvimento de web  apps. Se têm como exemplos de frameworks mais conhecidos nesta área:    jQuery Mobile - Framework que disponibiliza arquivos de CSS, JavaScript e  elementos da tecnologia HTML5 para o desenvolvimento de web apps.    Sencha Touch - Arquivos de CSS, JavaScript e diversos outros componentes  extras para o desenvolvimento de apps, com a vantagem de poder ter controle  exclusivo sobre alguns componentes do dispositivo, como o touch.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 393-397 Nov/2014     395   Ainda, pode ser citado o Bootstrap, Ionic, Wink Toolkit, Zepto.js, dentre outros  destinados ao desenvolvimento web. Também é possível optar por não utilizar  frameworks e desenvolver o código fonte por conta própria. Usando ou não alguma  ferramenta, deve ser levado em conta como o conteúdo apresentado se comportará em  telas diferentes (responsivo). Para o desenvolvimento híbrido também estão disponíveis  algumas ferramentas, sendo elas:    PhoneGap - Framework JavaScript que possibilita o desenvolvimento de apps  utilizando as linguagens de desenvolvimento web. Permite acessar os recursos  do dispositivo (agenda, câmera, GPS, bússola, acelerômetro, arquivos, entre  outros). Possibilita também que o mesmo código seja compilado para múltiplas  plataformas através do PhoneGap Build.   Além do PhoneGap pode ser citado o Appcelerator Titanium Mobile que utiliza  ferramentas nativas de desenvolvimento de cada plataforma para compilar o projeto,  exemplo XCode para gerar aplicativo para o iOS. E ainda, o Sencha Touch, que também  possibilita o desenvolvimento de apps híbridas. Esses são alguns exemplos dos  principais frameworks para o desenvolvimento de web apps e aplicações híbridas, os  quais associados possibilitam o desenvolvimento de aplicações mais robustas.   4. Estudo de Caso   Para testar a efetividade dos frameworks relatados neste trabalho, está sendo  desenvolvido um sistema híbrido para o ensino mobile. A ideia do sistema é  disponibilizar materiais e conteúdos que possam ser utilizados por alunos em seu tempo  livre através de seus dispositivos móveis. No exemplo abaixo, é apresentada uma tela  (interface) que permite o cadastro prévio de alunos com suas informações gerais. A  aplicação foi desenvolvida utilizando o framework PhoneGap, o jQuery Mobile e o  Bootstrap. Os dados cadastrados são gravados em um banco de dados MySQL externo,  localizado em um servidor web remoto.    Os dados preenchidos no formulário de cadastro quando enviados são testados e  encaminhados pela aplicação via Ajax para serem acessados e manipulados pelo  webservice, que neste caso, está localizado em um servidor web onde o mesmo permite  gravar os dados no banco.  Os dados que são enviados ou recebidos do webservice são  no formato Json. A figura 1 apresenta uma parte do código fonte da aplicação e também  do webservice escrito na linguagem de programação PHP (Hypertext PreProcessor).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 393-397 Nov/2014     396     Figura 17: Exemplo de uma interface inicial da aplicação (a), código de envio de dados do   formulário (b) e código de comunicação da aplicação com o banco de dados (WebService) (c).   Conforme pode ser visualizado na figura 1, o sistema foi desenvolvido utilizando as  linguagens padrão de desenvolvimento web (HTML, CSS e JavaScript), o qual foi  compilado para múltiplas plataformas utilizando o PhoneGap Build. O Build ao enviar o  projeto compactado (zip) gera os aplicativos instaláveis referentes a cada sistema  operacional mobile (Android, iOS e Windows Phone) automaticamente e os  disponibiliza para download ou instalação no dispositivo.   4.1  Resultados Esperados   Ao termino deste projeto, são esperados os seguintes resultados:    Identificar o framework que melhor se adapta a ideia de integrar um sistema web  e seu conteúdo a versões móveis (web apps) para as plataformas mais usuais  presentes nos dispositivos móveis (Android, iOS e Windows Phone).    Integrar uma aplicação web voltada ao ensino, com suas respectivas versões  móveis (web apps e híbridas) através do uso de frameworks e disponibilizá-las  nos principais repositórios para aplicativos mobile, passando pelo processo de  validação e disponibilização nas plataformas mais usuais.   5. Conclusão    O desenvolvimento mobile é uma das áreas que mais cresce e evolui atualmente, sendo  necessário ao desenvolvedor ter um conhecimento das ferramentas e técnicas  disponíveis para a criação e disponibilização de aplicativos mobile. Conhecer as  ferramentas, recursos, bem como, pontos positivos e negativos de cada framework  torna-se tão fundamental quanto o propósito para o qual o aplicativo será criado. Assim  estudar o ambiente, projetar e disponibilizar um aplicativo torna-se uma tarefa que exige  um conhecimento variado e amplo sobre o contexto mobile e seus arranjos. Em relação  ao futuro dos aplicativos móveis estudos apontam que as aplicações que mais ganharam  o mercado são as baseadas na web, ou seja, web apps.              Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 393-397 Nov/2014     397   Referências   CHEDE, C. (2013) “Desenvolvimento de apps – Parte 2: Híbrido, Nativo ou web?”,  Disponível em: https://www.ibm.com/developerworks/community/blogs  /ctaurion/entry/desenvolvimento_de_apps-parte_2_hibrido_nativo_ou_web?lang=en.  Acesso em: Julho de 2014.   GASPAROTTO, H. M. (2014) “Aplicações Móveis: Nativas ou Web?”, Disponível  em: http://www.devmedia.com.br/aplicacoes-moveis-nativas-ou-web/30392. Acesso  em:    Julho de 2014.   IDC. (2014) “Smartphone OS Market Share, Q2 2014”, Disponível em:  http://www.idc.com/prodserv/smartphone-os-market-share.jsp. Acesso em: Agosto  de 2014.   XIMENES, L. (2014) “Android supera Apple iOS em número de aplicativos”,  Disponível em: http://mobilexpert.com.br/mercado-telecom/materias/9415/androidsupera-apple-ios-em-numero-de-aplicativos. Acesso em: Agosto de 2014.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     16  Integrando a Gestão de Configuração do CMMI com o  Gerenciamento de Liberação do ITIL   Marlon Gracietti de Amorim, Cláudio Ratke   Departamento de Sistemas e Computação  Universidade Regional de Blumenal (FURB) – Blumenau, SC – Brasil   amorim.mga@gmail.com, ratke@inf.ufsc.br   Abstract. This study demonstrates the aggregation of concepts in an  application that presents information relevant to the planning and monitoring  of the release of new software releases. Using the concepts of the Capability  Maturity Model Integration (CMMI) in side of the software house and  integrates with release management of the Information Technology  Infrastructure Library (ITIL) in perspective of the customer. The results reflect  in a defined and controlled process that starts with the change request until  the safe and planned update in production environment.   Resumo. Este trabalho demonstra a agregação dos conceitos em uma  aplicação que apresenta informações relevantes ao planejamento e  acompanhamento da liberação de novos releases de software. Utilizando os  conceitos do Capability Maturity Model Iflntegration (CMMI) no lado da  software house e integra com a gestão de liberação do Information  Technology Infrastructure Library (ITIL) na perspectiva do cliente. Os  resultados obtidos refletem em um processo definido e controlado que inicia  desde a solicitação da requisição de mudança até a atualização segura e  planejada no ambiente de produção.   1. Introdução   Com o aumento da complexidade da infraestrutura de TI e da dependência das  organizações em relação aos serviços de TI, torna cada vez mais necessário o  gerenciamento detalhando a liberação de softwares para uso pela organização  (MAGALHÃES; PINHEIRO, 2007).    Por tanto, as empresas desenvolvedoras de softwares precisam adotar boas práticas para  obter o mínimo de impacto e a máxima agilidade na entrega de seus serviços de  software. Segundo Magalhães e Pinheiro (2007) são muito frequentes o emprego de  processos simplificados para o gerenciamento de liberação, muitas vezes gerando falhas  na entrega do serviço de software. Causando transtornos e desgaste ao cliente, bem  como custos e trabalhos não planejados para a equipe de desenvolvimento de software.    Nesta solução uniu-se a utilização de práticas recomendadas pelo Capability Maturity  Model Integration (CMMI) integradas as melhores práticas de Information Technology  Infrastructure Library (ITIL). A utilização destas duas metodologias resulta em um  processo que inicia com o planejamento da liberação da versão até a implantação e  integração da versão liberada no ambiente de produção do cliente.   A escolha por estas duas metodologias, deve-se ao fato de serem bastante difundidas no  âmbito de gerenciamento de serviço e deterem um reconhecimento internacional.  Freqüentemente elas são exigidas como requisitos para indicação de qualidade de  prestação de serviço.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     17  2. CMMI (Capability Maturity Model Integration)   O CMMI é um modelo de melhoria de processos e programa de avaliação de serviços.  Composto por práticas e processos recomendados durante o ciclo de vida de um  produto. No âmbito da metodologia, os processos são classificados de acordo com seus  níveis de maturidade, que são definidas como: inicial, gerenciado, definido,  quantitativamente gerenciado e otimização. O CMMI é administrado e comercializado  pela Carnegie Mellon University.   2.1. Gestão de configuração    Segundo Sommerville (2003), gestão de configuração é a utilização de modelos e  padrões para gerenciar um software em desenvolvimento. Alterações em suas  funcionalidades, correções e adaptações, geram diferentes versões do sistema. A  gerência de configuração serve para evitar conflitos nos itens de configuração  modificados.   A gestão de configuração de software pode ser entendida como uma disciplina que  permite manter a evolução de produtos de software sobre controle e contribuir para  atender as exigências de qualidade e prazo (ESTUBLIER, 2000).   Segundo Mellon (2006) os produtos de trabalho colocados sob a gestão de configuração  incluem os produtos que são entregues ao cliente, produtos de trabalho internos  selecionados, produtos adquiridos, ferramentas e outros itens que são utilizados para  criar e descrever esses produtos de trabalho.   2.2. Gerenciamento de mudanças    As necessidades e requisitos organizacionais modificam o tempo de vida útil de um  sistema. Isso requer que mudanças sejam feitas no software. Um processo definido de  gerenciamento de mudanças associado a ferramentas de apoio garantem que essas  mudanças sejam registradas e aplicadas ao sistema de maneira econômica  (SOMMERVILLE, 2003).   Os procedimentos de gerenciamento de mudança devem ser concebidos pra assegurar  que os custos e os benefícios das mudanças sejam adequadamente analisados e as  mudanças em um sistema sejam feitas de maneira controlada (SOMMERVILLE, 2003).   O primeiro estágio do processo de gerenciamento de mudanças é o preenchimento de  um formulário de solicitação de mudança Change Request Form (CRF), em que o  solicitante estabelece a mudança requerida no sistema. Tem como objetivo registrar a  solicitação da mudança, recomendações, custo estimado, aprovação. Ele pode também  incluir uma seção na qual o engenheiro de manutenção faz um esboço de como a  mudança deverá ser implementada. As solicitações de mudança devem ser registradas  no banco de dados de configuração (SOMMERVILLE, 2003).   Uma vez que o formulário de solicitação de mudança tenha sido submetido, ele é  analisado a fim de ser verificado se a mudança é válida. Algumas solicitações de  mudanças podem ocorrer em virtudes de erros de compreensão, e não de defeitos do  sistema. Outras podem se referir a defeitos já conhecidos (SOMMERVILLE, 2003, p.  555).   Quando um conjunto de mudanças é aprovado, ela é encaminhada para a equipe de  desenvolvimento ou manutenção, para implementação. À medida que os itens de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     18  configuração são modificados, deve ser mantido um registro de mudança feito em cada  um deles (SOMMERVILLE, 2003, p. 556).   3. ITIL (IT Infrastructure Library)   O ITIL consiste em uma série de documentos que são utilizados para auxiliar a  implementação de uma estrutura de ciclo de vida de serviços de TI. Este quadro  personalizável define como gerenciamento de serviço é aplicada dentro de uma  organização. Ele também alinhado com o padrão internacional, ISO 20000. (AXELOS,  2014).   3.1. Gerenciamento de liberação   O gerenciamento de liberação é o processo de planejar, compilar, testar e implantar uma  versão de distribuição de software, bem como o controle de versionamento e a sua  armazenagem. Tem como objetivo garantir a qualidade do ambiente de produção  usando procedimentos formais e verificações quando se implementam novas versões  (BON, 2006).   Um release de sistema é uma versão que é distribuída para os clientes. Cada release de  sistema deve incluir nova funcionalidade ou se destinar a uma diferente plataforma de  hardware. Há sempre muito mais versões de um sistema do que releases, uma vez que  as versões são criadas dentro de uma organização para o desenvolvimento interno ou  testes, e nunca são liberadas para clientes (SOMMERVILLE, 2003, p. 557).   Ter uma política de gerenciamento de liberação também é muito importante para o  sucesso de um projeto. Como o desenvolvimento de um projeto é bastante dinâmico,  torna-se freqüente a liberação de várias versões do produto (BECTA, 2004).   O processo de Gerenciamento de Liberação também contribui para aumentar a  eficiência da introdução das mudanças no ambiente de produção, combinando-as em  uma única liberação e realizando a implementação em conjunto (MAGALHÃES;  PINHEIRO, 2007).   3.2. Ramos de desenvolvimento (Branches)   A forma mais comum de lançamento de versões nos projetos é o “congelamento” do  código, isto é, a criação de uma linha de base. A partir disto, nenhuma funcionalidade é  adicionada ao código base, apenas os bugs são corrigidos para o lançamento de uma  versão estável. Em seguida é criada uma nova liberação que compreendem uma ou mais  mudanças autorizadas (BON, 2006, p. 96).   Segundo Sussman, Fitzpatrick e Pilato (2011) um ramo é uma linha de desenvolvimento  que existe independente de outra linha, e ainda, partilham um histórico em comum. Um  ramo sempre se inicia como cópia de outra linha de desenvolvimento e segue rumo  próprio a partir deste ponto, gerando seu próprio histórico.  Um exemplo é exibido na  Figura 1.                    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     19       Figura 1 - Ramos de desenvolvimento adaptado de Sussman, Fitzpatrick e   Pilato (2011, p. 72).   3.3. Biblioteca Definitiva de Software   A Biblioteca Definitiva de Software é o local onde todas as versões autorizadas e  definitivas de software da organização são armazenadas. Ela armazena as cópiasmestras de todos os softwares comprados (junto com os documentos de licenciamento),  assim como as dos softwares desenvolvidos internamente (MAGALHÃES; PINHEIRO,  2007).   4. Ferramentas de apoio   De acordo com Sommerville (2003) os processos de gerenciamento de configuração são  padronizados e envolvem a aplicação de procedimentos predefinidos. Eles exigem no  gerenciamento cuidados de grande quantidade de dados, e a atenção aos detalhes é  essencial. Quando se constrói uma nova versão de software, um único erro de  gerenciamento de configuração pode significar que o software não funcionará  adequadamente. Como consequência, a ferramenta de apoio é essencial para o  gerenciamento de configuração.   A seguir são exibidas algumas das ferramentas de apoio para gerência de configuração  utilizada no desenvolvimento deste trabalho.   4.1 Subversion (SVN)   O Subversion é um software livre para controle de versão. É utilizado tanto para o  desenvolvimento de software livre como para fins corporativos (SUSSMAN,  FITZPATRICK, PILATO, 2011).   Tem o objetivo de gerenciar arquivos e diretórios, e as modificações feitas neles ao  longo do tempo. Isto permite que você recupere versões antigas de seus dados, ou que  examine o histórico de suas alterações (SUSSMAN, FITZPATRICK, PILATO, 2011, p.  17).   O Subversion tem comandos para ajudar a controlar versões paralelas de um arquivo ou  diretório. Ele permite você criar ramos copiando seus dados, e ainda lembra que as  cópias têm relação entre si. Ainda é possível duplicar cópias de um ramo para outro.  Finalmente, ele pode fazer com que partes de sua cópia de trabalho reflitam ramos  diferentes, assim é possível “misturar e combinar” diferentes linhas de desenvolvimento  no trabalho de dia-a-dia (SUSSMAN, FITZPATRICK, PILATO, 2011, p. 72).   4.2 Redmine   O Redmine é um software livre, gerenciador de projetos baseados na web e ferramenta  de gerenciamento de mudança. Ele contém calendário e gráfico de Gantt para ajudar na     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     20  representação visual dos projetos e seus prazos de entrega. Ele pode também trabalhar  com múltiplos projetos (REDMINE, 2012).   5. Metodologia   Para reunir informações e automatizar o processo de liberação, o trabalho desenvolvido  faz a integração com um sistema de gestão empresarial, gerenciamento de configuração  e gerenciamento de mudança. Utilizando práticas recomendas pelo CMMI a equipe de  liberação, inicia o processo de liberação e faz a indicação dos arquivos de atualização.  Automaticamente os arquivos indicados são disponibilizados em um FTP pelo servidor  de atualizações.    O servidor ainda tem a responsabilidade de autorizar o download dos arquivos  solicitado pelos clientes via webservice. A partir do momento que a atualização é  autorizada, os clientes fazem o download automático dos arquivos. Seguindo  recomendações do processo de gerenciamento de liberação definido pelo ITIL, é dado  inicio ao processo de atualização. Primeiramente em um servidor de homologação em  seguida a atualização é enviada para o servidor de produção.  A Figura 2 exibe  uma visão geral do trabalho desenvolvido.     Figura 2 - Visão geral do trabalho desenvolvido   Foram inseridos alguns processos para ampliar o controle sobre as soluções  desenvolvidas. A Figura 3 exibe uma visão geral do ciclo de vida de uma requisição de  mudança realizada pelo cliente.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     21   act Fluxo  Usuário Chave/Membro da equipe Gerente de Projeto (PM) Responsável Gerente de Configuração (CM)  Inicio  Requisição de Mudança (Tarefa)  Av aliação  Definir Classificação  Definir Prioridade  Correção, Adaptação, Evolução  Baixa, Normal, Alta, Urgente,  Imediata  Analizar Impacto  Avaliar se a requisição é  coerente, viável  e nescessária.  Estabelacer Tempo Estimado  Atribuir a uma v ersão  Atribuir a um responsáv el  Definir Categoria  Implementa as modificações nescessárias  Realiza Testes/Validação  Atualiza tempo de trabalho  Gera uma baseline  Implementação OK?  Define Situação (Resolv ido)  Define Situação (Autorizado)  Define Situação (Reaberto)  Define Situação (Homologação)  Libera VersãoAtualiza Ambiente Homologação  Realiza Testes/Validação  Requisição atendida?  Atualiza Ambiente Produção  Define Situação (Concluído)  Fim  Util izar a tela de Gerenciamento  de Liberações.  Criação de um Branch no  Sistema de Controle de Versão  (SCM)  [Não]  [Sim]  [Não] [Sim]    Figura 3 - Fluxo proposto   A partir do momento que o cliente informa a necessidade de uma nova funcionalidade  no sistema, o Analista faz o levantamento dos requisitos e regras de negócio para a  alteração solicitada. Em seguida é realizada a estimativa de tempo e custo da alteração.  Caso a solicitação seja aprovada pelo cliente, ela é registrada no sistema de controle de  mudanças (redmine) e atribuída a uma equipe ou programador. Com o término do seu  desenvolvimento, são realizados testes unitários até que a correção esteja em condições  de ser liberada para o cliente.   O objetivo deste processo é garantir que possíveis erros possam ser corrigidos antes de  entrar para o ambiente de produção do cliente, fazendo os ajustes necessários antes da  sua liberação oficial   Após serem realizados todos os testes de integração a nova versão está pronta para ser  liberada. É neste momento que o aplicativo desenvolvido neste trabalho é utilizado. A     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     22  equipe responsável pela liberação inicia o processo de liberação através da tela de  Gerenciamento de liberações exibida na Figura 4.     Figura 4 - Tela de gerenciamento de liberações   O aplicativo desenvolvido armazena um histórico com todas as liberações realizadas e  os clientes que receberam cada atualização. Ao incluir uma nova liberação é exibida  uma lista com todos os clientes envolvidos no projeto, o sistema faz a recomendação  dos clientes aptos a receber a nova atualização exibindo-os na cor amarela, como é  exibido na Figura 4.   6. Resultados   Neste trabalho foi realizado o desenvolvimento de um aplicativo que automatiza o  processo de liberação de software. Auxiliando os membros da equipe de liberação a  identificar os clientes aptos a receber a nova atualização, monitorar a versão utilizada  por cada cliente, além de manter um histórico de todas as liberações efetuadas pela  empresa. O aplicativo ainda faz a integração com o sistema de projetos redmine,  extraindo informações utilizadas na criação de release notes de cada liberação. Para  concluir foi adicionado a possiblidade de enviar por e-mail a relação de modificações  contidas em cada liberação.   Utilizando conceitos recomendados pelas metodologias ITIL e CMMI o trabalho  alcançou todos os seus objetivos, além de auxiliar na elaboração de um novo fluxo de  trabalho, que proporciona objetividade e define responsabilidade sobre cada etapa do  processo de requisição de mudança, fornecendo um ganho de qualidade e maior  controle dos serviços prestados.   As ferramentas e tecnologias utilizadas foram adequadas, atendendo todas as exigências  para o sucesso deste projeto.    A realização deste trabalho contribuiu para a expansão dos conhecimentos sobre as  metodologias ITIL e CMMI, que foram elementos essenciais para guiar o objetivo deste  trabalho. Além disso, novas oportunidades foram identificadas, despertando o interesse  pelas demais áreas tratadas por estas metodologias.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p.16 -23  Nov/2014     23  Referências    Axelos. Axelos. [S.l.],(2014). http://www.axelos.com/.   Beca, Advice. (2012) “FITS Release Management”. [S.I.], 2004.  http://www.becta.org.uk/tsas/docs/fits_release.pdf, Agust.   Bon, Jan V. (2006) “Fundamentos do gerenciamento de serviços em TI baseado no  ITIL”. 1. ed. Tradução Van Haren Publishing. Holanda.   Couto, Ana Brasil. (2007) “CMMI: integração dos modelos de capacitação e maturidade  de sistemas”. Rio de Janeiro: Ciência Moderna, 2007. XIII, 276 p.   Estublier, J.(2000)  Software Configuration Management: Proceedings of the  Conference on The Future of Software Engineering. Ireland: Limerick,.   Magalhães, Ivan Luizio; Pinheiro, Walfrido Brito. (2007) “Gerenciamento de serviços  de TI na prática: uma abordagem com base na ITIL”. São Paulo: Novatec.   Mellon, Carnegie. (2012) “CMMI para desenvolvimento – Versão 1.2.” [S.l.], 2006.   http://www.sei.cmu.edu/library/, December.   Redmine. Redmine. [S.l.],(2012). http://www.redmine.org, may.  Sommerville, Ian.(2003) “Engenharia de software”. 6. ed. São Paulo: Addison Wesley,   2003. XVI, 592 p.  Sussman, Ben; Fitzpatrick, Brian; Pilato, C. (2011) “Version control with subversion:   For subversion” 1.7. California: TBA, 2011. 441 p.        
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     24  Analisando cenários de smart cities: Aplicando critérios de  comparação baseado em componentes arquiteturais   Maria Amélia Pessoa da Silva1, Felipe da Silva Ferraz2   1Faculdade Boa Viagem – Recife – PE – Brasil.  2Universidade Federal de Pernambuco – Recife – PE – Brasil.   m.amelia.pessoa@gmail.com, fsf3@cin.ufpe.br    Abstract. Due to population growth, city administrations begin worrying  about the shortage of finite and natural resources that are getting more  demand and also about services for their citizens such as water, energy,  transportation, health, education and security. Information technologies have  been an ally on the challenge of making most effective use of these resources.  This research seeks to achieve an objective method to classify cities based on  their technological aspects. Will be use preliminary studies to define which  criteria will use in this classification. As a result, we will have the  classification of cities by the percentage of technological knowledge.   Resumo. Devido ao crescimento populacional, as administrações das cidades  começam a se preocupar com a escassez dos recursos naturais e finitos que  estão sendo mais demandados e também serviços para os cidadãos como  água, energia, transporte, saúde, educação e segurança. As tecnologias da  informação têm sido aliadas no desafio de fazer um uso mais efetivo desses  recursos. Este trabalho busca atingir um método objetivo de categorizar  cidades com base em seus aspectos tecnológicos. Serão utilizados estudos  preliminares para definir quais critérios serão usados nessa classificação.  Como resultado, teremos a classificação das cidades por percentual de  conhecimento tecnológico.    1. Introdução   Existem atualmente cerca de 280 milhões de habitantes nas megacidades do planeta. No  ano de 2007 a população da China cresceu 11,9% enquanto a megacidade Xangai  registrou um crescimento populacional em torno de 13%. A Organização das Nações  Unidas (Unesco), afirma que até 2025 teremos 25 megacidades espalhadas pelo mundo  e muitas delas fora dos países desenvolvidos (SOUZA; AWAD, 2012).     O crescimento populacional e a migração têm exigido das cidades uma maior  oferta de água, energia, transporte, saúde, educação e segurança. Diante de recursos  finitos, as cidades têm visto nas tecnologias de informação e comunicação (TIC) a  oportunidade de melhorar a eficiência e a qualidade de seus serviços. O processo de  ampliação da inteligência das cidades exige inovação na forma de planejar, operar e  gerir (NAPHADE et al., 2011). Essa evolução traz um grande desafio tanto para os  governos quanto para toda a sociedade criando a necessidade de mudanças nos hábitos  comuns e obrigando o mundo a rever padrões da vida urbana como o uso excessivo de  automóveis, o consumo desenfreado da água e energia e a geração de grande quantidade  de lixo (SOUZA; AWAD, 2012).    Conforme Dirks e Keeling (2009), as cidades são baseadas em vários sistemas  diferentes e é a forma como eles funcionam que define o quão bem sucedido é o  funcionamento de uma cidade. Cidades inteligentes devem saber como transformar seus  sistemas e otimizar o uso de seu capital. Elas têm o dever de prover diversos recursos e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     25  serviços aos seus cidadãos e para isso elas devem olhar para os seus sistemas e torná-los  mais eficientes e eficazes, ou seja, mais inteligentes.   Posto isso, esta pesquisa busca propor uma forma objetiva de julgar e classificar  as cidades que estejam passando por um processo de adaptação a essa nova realidade,  destacando os pontos positivos e negativos para que as mesmas possam identificar onde  devem aplicar mais esforços. Para tanto, definiremos uma proposta baseada nos estudos  de Ferraz et. al (2013) que citam elementos e entidades tecnológicas necessárias nesse  processo de transição. Desta maneira, espera-se ao final da pesquisa, termos a  sistematização de uma forma de classificação objetiva das cidades em termos de  inteligência tecnológica e baseada nesta, uma análise da amostra selecionada.   2. Metodologia   Neste capítulo será descrita toda a metodologia utilizada na realização dessa pesquisa.   2.1. Critérios e Avaliação   Baseado nos conceitos de itens essenciais e entidades destacados por Ferraz et. al, foram  escolhidos 6 critérios de julgamento: Dados Abertos, Aplicações, Sensores, Atuadores,  Interoperabilidade e Sensibilidade.  Para os critérios dados abertos e aplicações foram  considerados apenas aqueles itens que se encaixavam direta ou indiretamente nos tipos  de sistemas classificados por Ferraz et. al, a saber: Educação, Energia e Água,  Governança, Saúde, Segurança e Transporte. Itens de lazer, turísticos ou ambientais, por  exemplo, não foram contabilizados. Os critérios de sensores, atuadores,  interoperabilidade e sensibilidade foram analisados com base nas aplicações  encontradas (FERRAZ et al., 2013).    Todos os critérios foram julgados agrupados com base no tipo de sistema em  que se encaixavam. A pontuação final do critério será alcançada através da média  aritmética das notas obtidas em cada tipo de sistema e os critérios medidos da seguinte  maneira:   1. Dados Abertos: Um ponto para cada conjunto de dados disponível;   2. Aplicações: Um ponto para cada aplicação encontrada. Se a mesma aplicação estiver  disponível em duas plataformas será contada apenas uma vez, mas se a mesma  aplicação se encaixar em mais de um tipo de sistema ela será contada em cada pilar.   3. Sensores: Um ponto para cada sensor utilizado nas aplicações, não computando  sensores repetidos dentro do mesmo tipo de sistema;   4. Atuadores: Um ponto para cada atuador usado nas aplicações;   5. Interoperabilidade: Um ponto para cada tipo de Interface de Programação de  Aplicativos (API) disponibilizada pelas aplicações;   6. Sensibilidade: Para cada aplicação disponível, um ponto negativo se a aplicação tiver  informação sensível, ou seja, informação privada ou um ponto positivo se não tiver. A  aplicação também pode receber zero se não houver condições de mensurar sua  sensibilidade através da descrição da mesma existente nos repositórios.   O limite da pontuação de cada pilar será de cinco pontos, a justificativa para esta  limitação é que se, por exemplo, nos depararmos com o cenário de uma cidade A com  vinte dados abertos em saúde e zero em todos os outros pilares e uma cidade B com  quatro dados abertos em cada um dos pilares. Entendemos que a cidade B tem mais  sensatez ao distribuir seu conhecimento em várias áreas do que a cidade A que parece se  importar apenas com a saúde esquecendo-se dos outros fatores fundamentais.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     26   Por fim, a nota da cidade, será a média aritmética das notas obtidas em cada  critério. Essa nota nos dará uma classificação do quão inteligente aquela cidade é  segundo nosso conceito que se baseia nas definições de Ferraz et. al: Uma cidade  inteligente em termos de recursos tecnológicos deve possuir dados abertos e aplicações  bem distribuídos entre os tipos de sistemas; essas aplicações devem ter o maior número  de sensores possíveis e incluir a participação do cidadão como sensor social; devem  atuar também da maior quantidade de formas possíveis visando atingir diferentes  públicos; devem oferecer interoperabilidade nos mais diferentes formatos e proteger os  dados usados (FERRAZ et al., 2013).  Os dados e as aplicações consideradas na  análise foram encontrados nos sites de dados abertos e catálogos de aplicações oficiais  de cada cidade.   2.3. Amostra  Foram escolhidas sete cidades como amostra para esta pesquisa. O critério de seleção  das mesmas levou em consideração a facilidade na busca por fontes de dados oficiais  disponibilizados pela própria cidade.   Várias cidades foram cogitadas e depois descartadas, pois a quantidade de  informações necessárias para o correto levantamento de dados se mostrou abaixo do  encontrado em outros locais. Também pelo fato das cidades apresentarem muitas  referências, limitamos o tamanho da amostra em sete para que pudéssemos concluir a  análise em tempo hábil para este trabalho. Por fim, as cidades selecionadas foram:  Amsterdam, Barcelona, Boston, Chicago, Londres, Recife e Rio de Janeiro.   3. Análise de Dados  Este capítulo trata da apresentação dos resultados obtidos na realização desta pesquisa.  Os dados foram coletados no mês de fevereiro de 2014 e a Tabela 1 os reúne.   Tabela 11 - Visão completa dos dados obtidos na pesquisa    Critérios Dados Abertos Aplicações Sensores   Cidades ED SE TR E/A S GO P ED SE TR E/A S GO P ED SE TR E/A S GO P   Recife 10 0 4 0 7 11 3,17 0 0 7 0 1 1 1,17 0 0 3 0 1 0 0,67   Chicago 114 39 90 13 52 546 5,00 4 2 45 1 6 18 3,67 2 0 2 0 2 1 1,17   Rio de Janeiro 0 0 18 2 0 16 2,00 4 3 15 0 9 4 3,50 0 1 2 0 2 1 1,00   Boston 1 9 2 16 0 71 3,00 0 0 1 0 0 2 0,50 0 0 3 0 0 1 0,67   Barcelona 10 0 26 0 9 238 3,33 6 0 18 2 3 5 3,33 1 0 3 0 1 1 1,00   Londres 61 39 169 0 103 457 4,17 8 3 36 1 3 4 3,50 1 0 3 0 1 1 1,00   Amsterdam 25 4 27 9 14 33 4,83 1 0 4 1 0 1 1,17 1 0 2 1 0 2 1,00   Critérios Atuadores Interoperabilidade Sensibilidade   Recife 0 0 2 0 1 1 0,67 0 0 0 0 0 0 0,00 0 0 7 0 1 1 1,17   Chicago 2 1 2 1 2 2 1,67 1 2 7 1 1 9 2,50 4 2 45 1 6 18 3,67   Rio de Janeiro 1 1 2 0 2 2 1,33 0 0 0 0 0 0 0,00 4 3 14 0 9 4 3,50   Boston 0 0 1 0 0 1 0,33 0 0 0 0 0 0 0,00 0 0 1 0 0 2 0,50   Barcelona 2 0 2 1 1 2 1,33 0 0 0 0 0 0 0,00 6 0 18 2 3 5 3,33   Londres 2 1 2 1 2 2 1,67 0 0 4 0 0 0 0,67 8 3 36 1 3 4 3,50   Amsterdam 1 0 2 2 0 1 1,00 0 0 1 0 0 0 0,17 1 0 4 1 0 1 1,17   Legenda: ED–Educação, SE–Segurança, TR–Transporte, E/A–Energia e Água, S–Saúde, GO–Governança, P–  Pontuação.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     27  3.1. Amsterdam   A cidade conquistou 96,6% da nota máxima do critério de Dados Abertos. O alcance da  nota máxima só não foi possível porque o pilar Segurança apresenta um conjunto de  dados a menos que a quantidade esperada.  Com relação às aplicações, a cidade  apresenta 23,4% da quantidade esperada. É possível ver que em dois pilares nada é  computado e em nenhum dos demais a nota máxima de cinco pontos foi atingida.   Os sensores usados foram social, GPS e câmeras. A cidade pontua 20% da  pontuação total esperada. Os atuadores usados nas aplicações são dois em sua maioria:  Internet e smartphones. Em Amsterdam apenas os pilares Educação e Governança não  tiveram ambos ficando o primeiro apenas com Internet e o segundo apenas com  smartphones.    Em termos de interoperabilidade, apenas o pilar Transporte contou uma API.  Nenhuma das aplicações analisadas apresentou dados sensíveis.  A média destas notas  conferiu à cidade uma nota equivalente a 31,2% da nota máxima definida.    3.2. Barcelona   No critério Dados Abertos pode-se ver um alcance de 66,6% da nota esperada. Chama  atenção o fato de que dois dos seis pilares pesquisados – Energia e Água e Segurança  (33,33%) não terem nenhum dado disponibilizado.  Com relação as aplicações da  cidade, pode-se observar que apenas em um pilar (Segurança) nenhuma aplicação foi  encontrada e em dois (Energia e Água e Saúde) a pontuação foi menor que a esperada.    Os sensores encontrados na cidade, que atinge 26,6% da nota esperada, são:  Social, GPS e câmera. Com relação aos Atuadores, os pilares de Energia e Água e  Saúde utilizaram apenas os smartphones. Nos demais se acrescenta o uso da Internet  com exceção do pilar Segurança que não pontou nada. Semelhante ao relatado em  Sensores, o critério de Atuadores obtêm 26,6% da nota máxima.    Não foi encontrada, na cidade de Barcelona, nenhuma aplicação que oferecesse  qualquer interface para compartilhamento de dados, portanto no critério  interoperabilidade a cidade não obtém nenhum ponto e as aplicações analisadas não  apresentaram dados sensíveis. Barcelona atinge 42,2% da nota esperada.    3.3. Boston   Apesar de apresentar apenas um pilar sem Dados Abertos (Saúde), Boston mostrou uma  pontuação abaixo do esperado em outros dois pilares (Educação e Transporte), por fim,  atingiu 60% da nota máxima. As aplicações da cidade, também estão armazenas no  portal principal desta seguidas de uma breve descrição. Verifica-se que a mesma conta  com apenas três aplicações. A cidade atingiu 10% da pontuação esperada. Encontramos  os sensores social, GPS e acelerômetro (sensor capaz de medir a aceleração sobre  objetos).    Nesta cidade, encontramos os aplicativos atuando apenas através de  smartphones. Não são encontradas aplicações interoperáveis e as aplicações não  divulgam dados sensíveis. Finalizamos a cidade de Boston com a pontuação de 16,6%  do valor esperado.    3.4. Chicago   Para Dados Abertos, Chicago atinge a nota máxima estipulada na pesquisa, pois pontua  em todos os critérios e todos eles acima do limite definido de cinco unidades. Sobre as     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     28  aplicações Chicago alcança 73,4% da nota máxima definida na pesquisa. Pode-se ver  que suas aplicações estão presentes em todos os pilares.    Em Chicago tivemos a utilização apenas de sensores GPS e sensores sociais  distribuídos nos pilares. Com 23,4% da pontuação do pilar, Chicago alcança menos de  um terço do alcançado no item anterior, pois em dois pilares (Energia e Água e  Segurança) não acumula nenhum ponto e nos demais fica abaixo de 50% da nota  esperada. Os atuadores Internet e smartphones são usados em todos os pilares com  exceção dos pilares de Energia e Água e Segurança que atuam apenas na Internet. Neste  pilar a cidade obtêm nota de 33,4%.    Nesta cidade encontramos muitas aplicações disponibilizando APIs para  interoperabilidade atingindo 50% da pontuação máxima. Nenhuma das aplicações  analisadas apresentou dados sensíveis. A cidade conquista 58,8% da nota máxima.    3.5. Londres   No critério de Dados Abertos, Londres atinge 83,4% da pontuação total esperada  apresentando uma quantidade de dados acima do limite em cada pilar com exceção do  critério Energia e Água que pelo fato de não computar nenhum ponto não permitiu a  cidade receber nota máxima. As aplicações atingem uma nota de 76,6% do total  esperado. A cidade conta com uma boa distribuição entre os pilares. A nota máxima não  foi alcançada apenas pelo fato de três pilares não contabilizarem o valor máximo de  cinco.    Os sensores encontrados foram social, GPS e câmera. A cidade pontua 20% da  pontuação total esperada. Os pilares de Energia e Água e Segurança usam apenas o  atuador Internet enquanto os demais usam também Internet. Pelo fato de não ter  apresentado nota zero em nenhum pilar, a cidade consegue melhorar seu desempenho,  com relação ao item anterior, finalizando o critério com 33,4% da pontuação obtida.    Em Londres, apenas o pilar Transporte apresentou aplicações com  interoperabilidade. A cidade atinge 13,4% da pontuação total pelo fato de computar  pontos em apenas um pilar (Transporte). Dentre as aplicações analisadas nenhuma  apresenta dados sensíveis. Por fim, Londres atinge 50,6% da nota máxima.    3.6. Recife   A pontuação acumulada pela cidade está descrita na Tabela 6. Em termos de Dados  Abertos, Recife atinge 63,4% da pontuação limite apresentando dois pilares com notas  zeradas e outro com nota abaixo no esperado. Nas aplicações, Recife atinge 23,4% da  nota máxima. Esta nota ocorre pelo fato de três pilares não alcançarem nenhuma  pontuação e apenas um deles atingir a nota esperada.    Os sensores encontrados nas aplicações da cidade foram Social, câmeras, GPS e  RFID. A cidade pontua 13,4% da nota esperada nesse critério, por contar com  pontuação apenas em dois pilares (Saúde e Transporte) e em ambos ter uma pontuação  abaixo do esperado. Na cidade do Recife o pilar Transporte atua com os canais de  smartphones e Internet. Já os pilares Saúde e Governança, atuam apenas com os  primeiros. Semelhante ao relatado no item anterior, os atuadores também conquistam  13,4% da nota esperada.    As aplicações analisadas não oferecem qualquer interface para  compartilhamento de dados e as aplicações não disponibilizaram dados sensíveis. Tudo  isso confere a Recife 22,8% da pontuação máxima.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     29  3.7. Rio de Janeiro   Em se tratando de Dados Abertos, o Rio de Janeiro obtêm 40% da nota limite por  apresentar três pilares com nota zerada e outro com nota abaixo do esperado, ou seja,  apenas as pontuações dos critérios Governança e Transporte foram satisfatórios.  O Rio  de Janeiro alcança 70% da nota total do critério Aplicações. Vê-se que em um pilar nada  é computado e em três deles a nota máxima de cinco pontos não foi atingida.    Os sensores usados na cidade foram apenas GPS e sensor social. A cidade  pontua 20% da nota esperada nesse critério, apresentando pontuação zerada em dois  pilares. Os pilares de Educação e Segurança utilizaram como atuadores apenas os  smartphones. Nos demais se acrescenta o uso da Internet com exceção do pilar de  Energia e Água que não pontua nada. Dentre as aplicações, nenhuma delas  disponibilizava qualquer API para compartilhamento de dados e não apresentaram  dados sensíveis, com exceção de uma aplicação na qual não houve condições de  mensurar sua sensibilidade. A cidade do Rio de Janeiro atinge 37,8% da nota esperada.    4. Conclusões   O objetivo desse trabalho era indicar uma forma de mensurar o quão inteligente é uma  cidade, entendendo como inteligente uma comunidade urbana que disponibiliza dados  abertos e aplicações com quantidades semelhantes entre os diferentes tipos de sistemas,  com o maior número de sensores, atuadores e formatos interoperáveis possíveis e que  não divulgue dados privados dos cidadãos (FERRAZ et al., 2013).    A pesquisa foi realizada colhendo conjuntos de dados abertos e aplicações  ofertadas nos portais oficiais de cada cidade, depois analisando cada aplicação para  catalogar seus sensores, atuadores, formatos interoperáveis e medir a sensibilidade das  informações providas por elas. O estudo foi aplicado nas cidades: Amsterdam,  Barcelona, Boston, Chicago, Londres, Recife e Rio de Janeiro. E com base nos dados  reunidos verificamos que o modelo proposto consegue objetivar uma classificação entre  a amostra selecionada. Através dos números encontrados, podemos destacar os  seguintes pontos:   a) O critério Dados Abertos foi o que obteve maior quantidade de pontos acumulados,  demonstrando um possível interesse dos gestores em prover informação acerca da  cidade e estimular a disseminação da cultura de uma cidade inteligente. Também  chamou a atenção o fato de que cinco das sete cidades pesquisadas (71,43%) não  disponibilizaram nenhum conjunto de dados com relação a algum tipo de sistema.  Ainda sobre os Dados Abertos, pode-se perceber como a quantidade de dados varia de  cidade para cidade dentro do mesmo pilar refletindo as diferentes preocupações que as  comunidades priorizam;   b) Apesar dos Dados Abertos apresentarem maior quantidade no pilar Governança  (61%), o critério Aplicações teve em seu topo, com mais da metade das aplicações  (55%) o pilar Transporte, sugerindo uma preocupação por parte da população com  relação aos congestionamentos, também provocados pelo crescimento da população;   c) Nem sempre uma maior quantidade de pontos significou uma maior nota no critério  tendo em vista que uma das regras era uma boa distribuição das notas dentre os pilares,  indicando que a cidade dá a devida importância a todos eles;    d) Contabilizamos que 49% das aplicações usam o sensor Social. Essa inclusão do  cidadão, segundo Chourabi et. al é indispensável para a implantação do modelo de  cidade inteligente (CHOURABI et al., 2012).      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     30  e) Dois sensores em especial chamam atenção por terem sido usados apenas uma vez:  RFID usado para reconhecimento de veículos em Recife e Acelerômetro usado para  mapeamento de buracos em vias públicas na cidade de Boston. Pode-se verificar que  apenas cinco tipos de sensores foram usados (Social, GPS, Câmeras, RFID e  Acelerômetro). Isso nos parece um número baixo tendo em vista a quantidade de  sensores que os smartphones, por exemplo, nos oferecem atualmente.   f) Os critérios Atuadores, Sensores e Interoperabilidade respectivamente obtiveram as  menores médias, em torno de 23, 19 e 10 pontos percentuais sinalizando uma  necessidade de maiores iniciativas nesse âmbito;    g) Em Atuadores, encontramos o uso de apenas duas opções: Internet e smartphones.  Acreditamos que estes, por serem populares conseguem alcançar uma considerável  parcela da população mas podemos ainda sugerir o uso de painéis em lugares públicos e  televisores inteligentes;   h) Em termos de Interoperabilidade, pode-se verificar que a maior nota atinge 50% da  pontuação esperada e quatro das sete não conseguiram nenhum ponto mostrando certa  deficiência nesse aspecto;   i) Com relação à sensibilidade dos dados disponibilizados, pode-se ver que as mesmas  têm tido o cuidado de não liberar acesso indevido à informações privadas;   j) Devemos enfatizar que a quantidade de aplicações tem grande influência sobre todos  os outros critérios, com exceção de Dados Abertos, pois todos eles são buscados dentro  das aplicações encontradas. Por isso é interessante para a cidade incentivar o  desenvolvimento de aplicações através de concursos, encontros etc.    Pode-se então constatar que nenhuma das cidades analisadas conseguiu atingir a  nota máxima de cinco pontos definida nesta pesquisa. A cidade que mais se aproximou  disso, Chicago, atingiu 58,9% desta nota.   4.1. Trabalhos Futuros   Com o intuito de aperfeiçoar e evoluir os resultados encontrados, sugerimos algumas  melhorias e desafios a serem abordados por trabalhos futuros:   a) Medir o uso das aplicações verificando com isso sua usabilidade, utilidade e  aceitação;   b) Aplicar a metodologia proposta em outras cidades para validar o procedimento e ao  mesmo tempo mensurar as deficiências e acertos de novas localidades;    c) Aplicar técnicas estatísticas para normalizar os dados obtidos e verificar o impacto  disso nas notas finais geradas e se esse impacto se perpetua até o ranking final;   d) Realizar um ranking colaborativo, obtendo a opinião dos usuários sobre os  aplicativos;   e) Sugerimos em nossa análise que a maior quantidade de aplicativos no pilar  Transporte se deve a preocupação dos cidadãos com o mesmo. Analisar se essa sugestão  de fato procede e a quantidade de aplicações varia conforme as necessidades da  população local;    f) Elaborar uma classificação das cidades tendo como base sua população, tendo assim  uma medida de quantidade de dados e aplicações por habitante.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 24 -31  Nov/2014     31  Referências  Amsterdam Open Data. Disponível em: <http://www.amsterdamopendata.nl/web/guest/data>.   Acesso em: 14 fev. 2014.    apps4BCN. Disponível em: <http://apps4bcn.cat/>. Acesso em: 25 jun. 2014.    CHOURABI, H. et al. Understanding Smart Cities: An Integrative Framework. 2012 45th  Hawaii International Conference on System Sciences, p. 2289–2297, jan. 2012.   City of Boston. Disponível em: <https://www.cityofboston.gov>. Acesso em: 14 fev. 2014.    City of Chicago. Disponível em: <http://www.cityofchicago.org/city/en.html>. Acesso em: 17  fev. 2014.    CTA Transit. Disponível em: <http://www.transitchicago.com>. Acesso em: 17 fev. 2014.    CycleStreets. Disponível em: <http://www.cyclestreets.net/>. Acesso em: 14 fev. 2014.    data.gov.uk. Disponível em: <http://data.gov.uk>. Acesso em: 7 fev. 2014.    Desafio Rio Apps. Disponível em: <http://rioapps.com.br>. Acesso em: 14 fev. 2014.    DIRKS, S.; KEELING, M. A vision of smarter cities: How cities can optimize their systems for  the talent-based economy. 2009.   FERRAZ, F. S. et al. Towards a Smart City Security Model: Exploring Smart Cities Elements  Based on Nowadays Solutions. n. c, p. 546–550, 2013.   London DataStore. Disponível em: <http://data.london.gov.uk/>. Acesso em: 13 fev. 2014.    NAPHADE, M. et al. Smarter cities and their innovation challenges. p. 32–39, 2011.   Open City. Disponível em: <http://www.opencityapps.org/>. Acesso em: 19 fev. 2014.    Open Data de l’Ajuntament de Barcelona. Disponível em:  <http://opendata.bcn.cat/opendata/en>. Acesso em: 4 fev. 2014.    Open Gov Hack Night. Disponível em: <http://opengovhacknight.org>. Acesso em: 12 fev.  2014.    Portal de Dados Abertos da Cidade do Recife. Disponível em: <http://dados.recife.pe.gov.br/>.  Acesso em: 12 fev. 2014.    Rio datamine. Disponível em: <http://riodatamine.com.br>. Acesso em: 14 fev. 2014.    Smart Chicago. Disponível em: <http://www.smartchicagocollaborative.org/>. Acesso em: 19  fev. 2014.    Smart Chicago Apps. Disponível em: <http://www.smartchicagoapps.org/>. Acesso em: 17 fev.  2014.    SOUZA, C. L. DE; AWAD, J. D. C. M. Cidades Sustentáveis, Cidades Inteligentes. 1. ed. São  Paulo: Bookman, 2012.            
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     32  Gestão da Segurança da Informação em ambientes BYOD:  Um mecanismo de apoio baseado nas boas práticas ITIL   I. K. B. Cunha, R. C. C. Castro   Grupo de Pesquisa em Informática Aplicada - Instituto Federal de Educação, Ciência e  Tecnologia (IFCE) – Canindé, CE - Brasil.   kariseilane@gmail.com, ritacastro@ifce.edu.br   Abstract. The complexity of environments processes supported by the  Information Technology and Communication is increasing by leaps and  bounds with the insertion of practices such as BYOD, which, on the other  hand, is driven by the proliferation of personal mobile devices in the corporate  environment. This scenario, when not controlled by strategies arising from the  IT Governance can cause the ruin of business. This paper aims to present a  mechanism to support companies or organizations wanting to join BYOD,  enables them to align the tendency to managing information security, through  the application of best practices in IT Governance Framework ITIL V3  constant.   Resumo. A complexidade dos ambientes suportados pelos processos da  Tecnologia da Informação e Comunicação vem aumentando a passos largos  com a inserção de práticas como o BYOD, que, por sua vez, é impulsionada  pela proliferação dos dispositivos móveis pessoais no ambiente corporativo.  Este cenário, quando não controlado por estratégias oriundas da Governança  de TI pode representar a ruína do negócio. O presente trabalho tem por  objetivo apresentar um mecanismo de apoio às empresas ou organizações que  pretendem aderir ao BYOD, possibilitando aos mesmos o alinhamento da  tendência à gestão da segurança da informação, através da aplicação de boas  práticas de Governança de TI constante no framework ITIL V3.   1. Introdução  Durante anos diversas empresas mantinham seus negócios com pouco ou   nenhum apoio da equipe de Tecnologia da Informação e Comunicação (TIC).  Atualmente essa realidade mudou, e não poderia ser diferente, pois a TI tornou-se um  fator crítico de sucesso para as organizações, e, em muitos casos, o principal diferencial  competitivo no mercado.   Considerando essa competitividade e a criticidade da informação para alguns  órgãos, a gestão dos ativos da informação acaba despontando como um processo dos  mais importantes. Desta forma, a gestão corporativa de TI, deve, através de um modelo  bem definido e estruturado, ser integrada e alinhada ao planejamento estratégico da  empresa, possibilitando a esta a capacidade de adaptar-se rapidamente às necessidades  de mudanças do negócio, evitando que novos serviços e alterações em serviços já  existentes sejam implantados de forma errônea ou de maneira que infrinjam os controles  da empresa, mitigando assim os riscos aos ativos de informação. Toda essa estrutura de  relações e processos encontra-se inserida na Governança de TI.    Surge atualmente no cenário corporativo uma nova tendência denominada  BYOD – Bring your own device [CIO, 2013], em português “Traga seu próprio     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     33  dispositivo”, caracterizada pela entrada dos mais variados tipos de dispositivos móveis  pessoais nas empresas trazidos pelos próprios funcionários, para ser aproveitado no  meio corporativo como ferramenta de trabalho, deixando o colaborador livre para  escolher e comprar o dispositivo que queira utilizar em suas tarefas no âmbito  organizacional.    As empresas ou organizações que desejam usufruir das vantagens do BYOD  devem estar preparadas para administrar todos os desafios relacionados à sua  implantação, possibilitando assim colocar sistemas e práticas no ambiente corporativo  de forma eficiente, garantindo serviços previsíveis, confiáveis, que não comprometam a  integridade dos ativos da informação. Visando isso, é fundamental que estejam inseridas  nas organizações aderentes à tendência, boas práticas de Governança de TI,  principalmente relacionadas à segurança da informação.   Embora pesquisadores e estudiosos da área, reconheçam a importância da  Governança de TI e seu papel nas organizações, a forma de implementá-la ainda é um  desafio, pois dependendo dos objetivos estratégicos da empresa, se faz necessário adotar  abordagens diferenciadas em cada caso. A sua aplicação em empresas ou órgãos que  aderiram à tendência BYOD torna-a ainda mais específica, uma vez que não há casos  documentados na literatura.   Este artigo vem propor a aplicação de boas práticas de Governança de TI em  ambientes coorporativos e organizacionais, que venham a aderir ao BYOD,  possibilitando que sua aplicação esteja alinhada a gestão coorporativa e a segurança da  informação da organização, através da aplicação de conceitos de Gerenciamento da  Segurança da Informação constante no framework Information Technology  Infrastructure Library Version three (ITIL V3).    2. Governança de TI – Marco Teórico             A Governança de TI adquiriu ao longo dos anos diversas definições diferenciadas  na literatura. Analisando um retrospecto, da mais remota a mais atual, pode-se perceber  que quase todas abordam a forma de autoridade da tomada de decisão de TI na  organização (estrutura) e a forma com que os recursos de TI são gerenciados e  controlados (processos), buscando sempre alinhar os investimentos realizados em TI às  estratégias corporativas.   Venkatraman, em 1991, [apud LOH, 1993] definiu-a como sendo um sistema  baseado em TI utilizado para descrever como esta media ou governava os  relacionamentos de negócios.   Em 1992, Henderson e Venkatraman [apud LOH, 1993] ampliaram a definição  anterior de forma que abrangesse escolhas de mecanismos estruturais, tais como joint  ventures, contratos de longo prazo e boas parcerias, que seriam utilizadas para obter  capacidades requisitadas da TI.    Sete anos mais tarde Sambamurthy e Zmud [1999] definiram-na como sendo a  implementação de estruturas e arquiteturas relacionadas à TI para atingir com sucesso  atividades em resposta ao ambiente e a estratégia organizacional.   Na definição proposta por Korac-Kakabadse e Kakabadse [2001] a Governança  de TI passa a se concentrar também na necessidade de definir processos e mecanismos  de relacionamento (e não apenas estruturas) para desenvolver, dirigir e controlar os  recursos de TI, de modo a atingir os objetivos da organização.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     34  Segundo Fernandes e Abreu [2008], os escândalos e fraudes corporativos, bem  como as crise financeira mundial, foram observadas pelos atentos olhos dos acionistas e  investidores, que passaram a exigir mais exatidão nas previsões orçamentárias das  empresas aos quais eram ligados, como também maior transparência no que se refere  aos gastos e retornos financeiros. Essa mudança comportamental alavancou a  Governança de TI e tornou-a um tema dominante nos negócios, devido ao impacto dos  gastos realizados na implantação de novas tecnologias no ambiente coorporativo.     3. ITIL            Toda organização enfrenta problemas relacionados à tecnologia, que causam  impactos negativos aos diversos entes envolvidos no negócio e principalmente à própria  organização, prejudicando as atividades desenvolvidas por ela. Possuir um plano para  administrar esses eventos negativos e lidar com as situações de crise de maneira  padronizada, alinhada e estruturada é um fator primordial. A equipe estratégica deve  saber como proceder antes, durante e depois de um incidente.   Magalhães e Pinheiro [2007] definem o ITIL V3 como um guia de  procedimentos e boas práticas que promove às empresas uma estrutura (framework)  abrangente e detalhada para o gerenciamento de serviços de TI. Ele aborda os serviços  de TI durante todo o seu ciclo de vida e sugere cinco fases, contendo todos os  mecanismos, para que o gerenciamento seja realizado de maneira adequada em todas as  suas fases, possuindo uma visão voltada para a alta qualidade de serviços na origem e na  entrega, bem como que estes estejam em conformidade com a legislação e ainda que se  gere um ciclo contínuo para melhorá-los.   As boas práticas sugeridas pelo ITIL podem ser utilizadas por qualquer  organização pelo fato de não se basear em nenhuma plataforma proprietária, bem como  aplicadas a qualquer tipo de empresa, do setor privado ou público, de pequeno, médio  ou grande porte, e são frutos das experiências e ideias das maiores lideranças na área de  gerenciamento de serviços de TI.    4. BYOD    Pesquisas atuais apontam que a tendência em se adotar a prática do BYOD tem  ganhado regiões como China, Índia e Oriente Médio, confirmando a abrangência do  fenômeno. Segundo o relatório da CISCO IBSG [2013], pelo menos 89% dos  departamentos de TI já permitem a sua utilização. Esse mesmo relatório afirma que a  tendência é um fenômeno crescente e de grandes proporções. Nos países analisados  (figura 1), o número de dispositivos utilizados no âmbito corporativo aumentará 105%  entre 2013 e 2016, atingindo aproximadamente 405 milhões, o que resulta uma taxa de  crescimento composto anual (CAGR) de 27%.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     35    Figura 1. Número estimado de dispositivos de consumerização de TI nos locais   de trabalho, por país.  No Brasil o fenômeno surgiu em meados de 2011, advindo da cultura   coorporativa internacional [PLÁCIDO, 2011], e notoriamente impulsionada por um  conjunto de fatores: surgimento da computação móvel, expansão dos dispositivos  móveis, facilidade na aquisição de novas tecnologias e o ingresso da população nova,  conhecida como geração digital e aficionada por novas tecnologias, no mercado.    A cada momento existe uma adequação das novas tecnologias que surgem com a  estratégia das empresas em que são inseridas. No BYOD há diversos fatores que  impulsionam a sua adoção dentro das organizações: maior produtividade, flexibilidade,  satisfação do funcionário, redução dos custos para a empresa, dentre outros.   Entretanto, apesar das inúmeras vantagens trazidas pelo efeito BYOD, há  também uma série de desafios a serem enfrentados diariamente, onde a maioria destes  está relacionada à segurança da informação.     5. Alinhamento do BYOD ao Gerenciamento da Segurança da Informação   Sendo a TI um dos principais componentes de qualquer organização, a  Governança de TI torna-se um assunto de grande relevância para a alta administração.  Os riscos referentes às tecnologias adotadas, assim como o seu desempenho, a sua  relação com as estratégias corporativas e, ainda, as políticas e responsabilidades ligadas  a TI certamente irão afetar a organização, em uma maior ou menor proporção. Uma  simples quebra de segurança, um erro ou um ataque de vírus já é suficiente para causar  um sério prejuízo financeiro, e de reputação e imagem à organização [HARDY, 2006].     A implementação de boas práticas dentro da estratégia organizacional permite  uma gestão mais profissional e transparente de modo a maximizar a criação e agregação  de valores dentro das empresas. Geralmente quando se fala em implementação de  governança, esta pode ser iniciada, em alguns casos, em virtude de um interesse  específico (como, por exemplo, definir estratégias e procedimentos que viabilizem a  adesão do BYOD dentro das empresas) ou pela presença de problemas críticos para a  organização (como os problemas decorrentes da implementação do BYOD, tais como:  lidar com diversos sistemas operacionais, segurança de dados coorporativos, controle de  acesso de usuário, dentro outros).    Diferentes pesquisadores têm respondido a essa questão sugerindo que é  necessário combinar um conjunto de práticas referentes à estrutura, processos e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     36  mecanismos de relacionamento para se obter excelência no que diz respeito a uma  implementação eficaz e de qualidade [PETERSON, 2004; VAN GREMBERGEN, DE  HAES e GULDENTOPS, 2004; WEILL e WOODHAM, 2002]. Lunardi et. al. [2007],  afirma que esses mecanismos, por sua vez, não precisam necessariamente ser utilizados  na sua totalidade ou da mesma forma pelas organizações, pois uma série de  características da própria empresa ou negócio de atuação pode exigir diferentes  configurações, evidenciando a complexidade na determinação dos mecanismos mais  indicados a serem adotados.   O Gerenciamento da Segurança da Informação tem total alinhamento à norma  ISO/IEC 17799 ou ABNT NBR ISO/IEC 27001. Esse processo visa gerenciar  efetivamente a segurança da informação em todas as atividades do serviço, abordando a  avaliação de riscos para os ativos conforme sua criticidade, o estabelecimento de  controles para garantir a segurança e a disponibilidade da informação e o tratamento de  mudanças e incidentes de segurança, em conformidade com os requisitos de segurança  exigidos pelo negócio. A norma aponta claramente quais são os controles considerados  como melhores práticas para a segurança da informação:    Documento da política da segurança da informação: tem como objetivo prover à  direção uma orientação e apoio para a segurança da informação;    Definição das responsabilidades na segurança da informação: objetivando  gerenciar a segurança da informação na organização;    Educação e treinamento em segurança da informação: com o intuito de assegurar  que usuários estejam cientes das ameaças e das preocupações de segurança da  informação e estejam equipados para apoiar a política de segurança da  organização durante a execução normal do seu trabalho;    Relatório dos incidentes de segurança: tem como objetivo minimizar os danos  originados pelos incidentes de segurança e mau funcionamento, e monitorar e  aprender com tais incidentes;    Gestão da continuidade do negócio: com o objetivo de não permitir a interrupção  das atividades do negócio e proteger os processos críticos contra efeitos de  falhas ou desastres significativos.  É importante ressaltar que mesmo com todas as melhores práticas já catalogadas   nas normas e nas bibliotecas de gerenciamento, recomenda-se que as organizações  adaptem as práticas ITIL conforme seu contexto, e defendam suas próprias melhores  práticas no âmbito da estrutura global de gerenciamento de serviço.        6. Proposta de check-list  Visando à adoção do BYOD e com o intuito de remediar possíveis vulnerabilidades no  âmbito da segurança da informação, este trabalho propõe a adoção de um check-list  (Tabela 1) baseado nas boas práticas do Gerenciamento da Segurança da Informação –  conforme apresentadas no tópico anterior – acrescentando-se, necessariamente, um  tópico, a fim de nortear a equipe de TI antes da adoção dessa nova tendência dentro do  ambiente corporativo.          Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     37  Tabela 2 - Proposta de Check-List   ITEM QUESTÃO S/N  1. Documento da Política de Segurança da Informação   1.1. A empresa/organização possui um documento de “Política de  Segurança da Informação”?      1.2. O documento contém a definição de segurança da informação,  resumo das metas e escopo e a importância da segurança como  um mecanismo que habilita o compartilhamento da informação?      1.3. O documento comtempla todas as políticas, princípios, padrões e  requisitos necessários para o bom funcionamento da  empresa/organização?      1.4. O documento está em conformidade com a legislação e todas as  clausulas contratuais que a empresa tem com os seus fornecedores  e parceiros?      1.5. O documento é fortemente implementado na empresa?   1.6. Quando um princípio é violado as consequências constantes no   documento são devidamente aplicadas?     1.7. A política da informação é acessível, compreensível e conhecida  por todos os funcionários?      1.8. Há alguma modificação que necessita ser revista na política de  segurança da informação já existente?      1.9. As modificações necessárias são aplicadas?   2. Definição de responsabilidades na segurança da informação   2.1. Há uma definição das responsabilidades gerais e específicas na  gestão da segurança da informação?      2.2. As responsabilidades pela proteção de cada ativo são claramente  definidas?      2.3. As responsabilidades pelo cumprimento de processos de segurança  são claramente definidos?      2.4. A empresa adota um processo de gestão de autorização para  utilização de novos recursos computacionais?      2.5 A empresa possui uma política de adesão e utilização de novas  tecnologias?      3. Educação e treinamento em segurança da informação  3.1. A empresa oferece uma educação suficiente aos seus funcionários   relacionada à segurança da informação?     3.2. As recomendações sobre segurança da informação estão sendo  transmitidas de forma eficaz?      3.3. A empresa adota mecanismos suficientes para que os funcionários  fiquem cientes sobre os riscos a que estão expostos quando da  utilização de novas tecnologias?      3.4. A empresa realiza treinamentos para instruir os seus profissionais  ao uso de boas práticas na utilização dos dispositivos móveis?      4. Relatórios dos incidentes de segurança  4.1. A empresa oferece uma Central de Serviços para que os usuários   possam reportar incidentes de segurança da informação?       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     38    4.2.   A Central de Serviços oferece um feedback notificando aos  usuários sobre os resultados obtidos após o incidente ser tratado e  encerrado?      5. Gestão de continuidade do negócio  5.1. A empresa/instituição identificou os eventos que podem causar   interrupções nos processos de negócio no caso da autorização de  utilização de dispositivos móveis dentro do ambiente corporativo?      5.2. A empresa/instituição entende os riscos a que está exposta quando  da adesão do BYOD?      5.3. Há algum tipo de documentação de estratégia de continuidade  consistente com objetivo e prioridades estabelecidas para o  negócio em caso de interrupções dos serviços?      6. Mecanismos de segurança BYOD   6.1. A empresa possui tecnologia que faz com que o nó realize   autenticação ao se conectar à rede?     6.2. A empresa dispõe de um controle de acesso de usuário que  abranja os dispositivos móveis?      6.3. A empresa está preparada para proteger os dados corporativos em  todos os dispositivos pessoais utilizados na prática BYOD?      6.4. A empresa adota mecanismos de controle sobre os dispositivos,  para utilização em casos de desligamento do funcionário da  empresa?        7. Conclusão  O avanço das Tecnologias da Informação e Comunicação e a importância da informação  na sociedade fazem com que práticas como o BYOD comecem a ser difundidas no meio  corporativo, garantindo a flexibilidade na utilização de dispositivos móveis e pessoais  no ambiente de trabalho.    Todos os aspectos abordados nesta pesquisa não esgotam o tema dos desafios  associados ao BYOD, já que a sua adoção e prática, aqui no Brasil, ainda está se  desenvolvendo. Por conta disso, a alta administração é constantemente indagada ao  adotar uma tendência que ainda é nova no mercado, pois a informação é tratada  atualmente como um dos ativos mais importantes dentro da estrutura organizacional.   Através do check-list proposto, o administrador, juntamente com sua equipe  estratégica e o departamento de TI, poderá adequar a empresa ou instituição a todos os  pontos que já são considerados como boas práticas para a segurança da informação. E  somente depois que todos os itens estiverem inseridos dentro da organização adotar a  nova tendência.   É importante ressaltar que o check-list proposto não se trata de um modelo  fechado e adequado para qualquer tipo de instituição, visto que a própria Governança de  TI recomenda que as organizações adaptem as práticas, conforme seu contexto, e,  também, que elas defendam suas próprias melhores práticas. Isso faz com o check-list  seja tratado de modo genérico e norteador para as instituições que o desejem utilizar.   Como proposta para trabalhos futuros, sugere-se uma avaliação sistemática dos  riscos de segurança da informação quando da adoção do BYOD. Através desta  avaliação poderão ser identificadas as ameaças e as vulnerabilidades a que estão     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 32 -39  Nov/2014     39  expostos os ativos, como também a probabilidade de ocorrência e a estimativa das  potenciais consequências do impacto nos negócios da organização.     8. Referências  CIO - BYOD to Change the Face of IT in 2013. Consumer Tech, Publicado em: 7 fev.   2013. Disponível em:  http://www.cio.com/article/728487/BYOD_to_Change_the_Face_of_IT_in_2013  Acesso em: 19 de ago. 2014.   CISCO Internet Business Solutions Group IBSG. O impacto financeiro da  consumerização de TI. Disponível em:  <http://www.cisco.com/web/about/ac79/docs/re/byod/BYOD -  Economics_Economic-Analysis_BR.pdf > Acesso em: 19 de ago. 2014.   FERNANDES, Aguinaldo Aragon; ABREU, Vladimir Ferraz de. Implantando a  governança de TI: da estratégia à gestão dos processos e serviços. 3ª ed. Rio de  Janeiro: Brasport, 2012.   HARDY, G. Using IT governance and COBIT to deliver value with IT and respond  to legal, regulatory and compliance challenges. Information Security technical  report, 2006, pp. 55-61.   KORAC-KAKABADSE, N.; KAKABADSE, A. IS/IT governance: need for an  integrated model. Corporate Governance, v. 1, n.4, 2001.   LOH, L. The economics and organizational of information technology governance:  sourcing strategies for corporate information infrastructure. Massachusetts,  1993. Tese (Doutorado em Administração) – Alfred P. Sloan School, Massachusetts  Institute of Technology, MIT.   LUNARDI, G. L.; DOLCI, P. C.; BECKER, J. L.; MAÇADA, A. C. G.; Governança  de TI no Brasil: uma análise dos mecanismos mais difundidos entre as empresas  nacionais. SEGeT – Simpósio de Excelência em Gestão e Tecnologia. 2007.   MAGALHÃES, Ivan Luizio; PINHEIRO, Walfrido Brito - Gerenciamento de serviços  de TI na prática: uma abordagem com base no ITIL. Série Gerenciamento de TI.  São Paulo: Editora Novatec, 2007.   PETERSON, R., Integration strategies and tactics for information technology  governance. In: VAN GREMBERGEN, W. Strategies for information technology  governance, Hershey: Idea group publishing, 2004.   PLÁCIDO, Daniel Gonçalves; Araújo Júnior, Edson. Consumerização e a  Continuidade do Negócio. Info Educativa. Publicado em dez, 2011. Disponível em  <http://www.infoeducativa.com.br/index.asp?page=artigo&id=929> Acesso em: 15  de ago. 2013.   SAMBAMURTHY, V.; ZMUD, R. Arrangements for information technology  governance: a theory of multiple contingencies. MIS Quarterly , v. 23, n. 2, 1997.   VAN GREMBERGEN, W.; DE HAES, S.; GULDENTOPS, E. Structures, processes  and relational mechanisms for IT governance. Strategies for information  technology governance, Hershey: Idea group publishing, 2004.   WEILL, P.; WOODHAM, R. Don’t just lead, govern: implementing effective IT  governance. Center for Information Systems Research . Working paper n. 326,  2002.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       40  O Uso da Robótica Educacional para o Ensino de Algoritmos   Eduardo Cambruzzi1, Rosemberg Mendes de Souza1   1Instituto Federal de Educação, Ciência e Tecnologia da Bahia  (IFBA)  Campus Valença – Bahia - Brazil   ec@ifba.edu.br,rosembergmendes.s@gmail.com   Abstract. The problems resolution involving logical reasoning is one of the  major obstacles to computing students. The difficulty to organize the abstract  thinking in code of program leads many students to abandon the course.  Intending reduce this obstacle on student formation, this paper presents a  learning object based on educational robotics. This object has intention to  materialize and contextualize complex and abstract concepts in ludic and  interactive activities, offering a learning environment less abstract and more  playful to students. Furthermore, results presented in this paper indicate a  significant improvement in learning of students.  Resumo. A resolução de problemas que envolvem raciocínio lógico é um dos  obstáculos enfrentados pelos alunos dos cursos de computação. A dificuldade  para organizar o pensamento abstrato em códigos de programa tem levado  inúmeros alunos a evadirem destes cursos. Buscando reduzir este obstáculo,  apresenta-se neste artigo um objeto de aprendizagem baseado na Robótica  Educacional que procura materializar e contextualizar conceitos complexos e  abstratos da computação. Ao proporcionar aos alunos um ambiente de  aprendizagem menos abstrato e mais lúdico, obteve-se significativa melhora  na aprendizagem, como indicam os resultados apresentados neste artigo.   1.  Introdução   O objetivo deste estudo é demonstrar como a Robótica Educacional pode contribuir no  desenvolvimento do raciocínio abstrato e na melhoria da relação ensino-aprendizagem  dos conteúdos algoritmos nos cursos de computação.   As dificuldades em abstrair problemas do cotidiano em um conjunto de tarefas  sequenciais a serem executas por um computador, estão entre os grandes desafios que  permeiam o desenvolvimento do chamado raciocínio lógico computacional [Ribeiro  2011].  Este tipo de raciocínio é fundamental na programação de computadores e para o  desenvolvimento de todos os tipos de dispositivos eletrônicos utilizados direta ou  indiretamente em nosso cotidiano.      No entanto, para a maior parte dos alunos dos cursos de computação, o  desenvolvimento deste tipo de raciocínio não é algo simples e requer tempo e esforço.  São muitos os problemas que podem ser atribuídos às dificuldades da construção de um  pensamento lógico por parte destes alunos. Um destes problemas é a falta de motivação  dos alunos, pois geralmente o ensino desta disciplina não estabelece uma relação entre  teoria e a prática, o abstrato e sua origem no concreto [Hinterholz Jr. 2009].    A fim de aproximar o abstrato e complexo, do concreto e lúdico, este  artigo  apresenta um objeto de aprendizagem que utiliza a Robótica Educacional como  ferramenta para o ensino de algoritmos.  Essa alternativa de aprendizagem é recente e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       41  procura integrar atividade com robôs programáveis ao cotidiano da sala de aula. O uso  da robótica permite que alunos e professores mergulhem em um ambiente de construção  coletiva e de materialização de conceitos lógicos abstratos.    2. Trabalhos Relacionados   Vários estudos indicam que o uso da Robótica Educacional é um importante  instrumento para o desenvolvimento de habilidades que necessitam de pensamento  lógico e abstrato [Leska 2004, Ribeiro 2011].   Em [Leska 2004] descreve-se um experimento no qual o autor utiliza um kit  LEGO Mindstorms como ferramenta para ensinar programação de computadores. Nas  aulas, os alunos discutem o projeto do dia e em seguida dirigem-se ao laboratório para  desenvolvê-lo. O objetivo é deixar o aluno livre para a descoberta de formas e funções  que deem suporte ao desenvolvimento das tarefas necessárias para finalizar o projeto e  ao final estabelecer uma discussão sobre suas dificuldades.   Outro trabalho é proposto por [Benetti et al. 2009]. Neste, a Robótica  Educacional serve de apoio ao ensino de Matemática, Geografia e Programação de  computadores para turmas do Ensino Médio. As atividades descritas pelos autores  foram desenvolvidas utilizando o software Robomind. Este software permite o uso de  robôs virtuais através de uma IDE programável. Para avaliar os resultados da proposta  foram realizados um pré-teste e um teste posterior ao uso do Robomind. Os resultados  obtidos indicaram que os alunos apresentaram melhora na compreensão de conceitos  computacionais abstratos e um aumento da motivação para realização das atividades  propostas.   Já em [de Souza Pio et al. 2006], uma competição de robôs foi utilizada para  estimular o interesse dos alunos pela disciplina “Robótica Móvel”, ministrada no curso  de graduação em computação. O aspecto mais relevante deste estudo são os relatos dos  alunos indicando que passaram a compreender os erros que cometiam no processo de  desenvolvimento do programa. A partir desta percepção, os erros não eram mais vistos  como um problema, mas como desafios a serem superados.   Nota-se nos trabalhos descritos anteriormente que, durante o processo de  programação dos robôs, a ludicidade da tarefa desperta nos alunos, uma nova percepção  sobre como ocorre a formalização de seus pensamentos abstratos. Outro aspecto, é que  as tarefas a eles propostas têm em sua base a ideia de um projeto prévio, sobre o qual  são discutidas a aplicação da teoria e as possíveis soluções dos problemas. Este projeto  pode ser delineado através de um objeto de aprendizagem.   3. Objetos de aprendizagem   Com a revolução tecnológica os Objetos de Aprendizagem (OA’s), principalmente os  computacionais, tornaram-se uma importante estratégia pedagógica para atrair a atenção  dos alunos. Conceitualmente, qualquer material que pode ser utilizado ou referenciado  durante o processo de ensino-aprendizagem pode ser classificado com objeto  aprendizagem [IEEE-LTSC 2014].   Estes objetos tornaram-se nas últimas décadas uma importante ferramenta de  uso educacional, não só nas disciplinas ligadas a computação, mas nas mais variadas  áreas como, matemática, química, história, etc. O principal objetivo dos OA’s é     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       42  complementar o processo de construção do conhecimento, melhorando a relação ensinoaprendizagem e expandido a sala de aula para mais próximo do contexto do aluno.   O uso dos OA’s tem colaborado com a melhora no processo de ensino-  aprendizagem, uma vez que estes tornam as aulas mais interativas e participativas,  [Santos et al. 2007]. Pode-se afirmar então que, a utilização dos objetos de  aprendizagem estimula a criatividade e a imaginação. Além disso, os OA’s favorecem o  dinamismo das aulas e a assimilação dos conhecimentos por parte dos alunos de forma  lúdica e muitas vezes imperceptível, assim como ocorre durante o brincar.   4.   Robótica Educacional   A robótica é uma área multidisciplinar que se vale dos conhecimentos de outras  ciências, como Engenharia Mecânica, Engenharia Elétrica e Inteligência Artificial para  criação de robôs. Entretanto, a maioria destas máquinas é utilizada em linhas de  produção industrial, onde repetem infinitamente e com milimétrica precisão uma série  de operações previamente programadas.    Já a Robótica Educacional tem como principal característica um ambiente de  aprendizagem no qual os alunos podem montar, programar e analisar o comportamento  de um robô ou sistema robotizado. Isto promove a socialização e a autonomia no  aprendizado, criando um ambiente que reúne ciência, tecnologia e trabalho manual.   Dada a sua grande flexibilidade, a Robótica Educacional pode ser aplicada nos  mais diversos ramos de conhecimento e, permite aos educadores apresentar de forma  lúdica e atrativa conceitos anteriormente tidos como unicamente teóricos ou de difícil  compreensão [Benetti et al. 2009].     A Robótica Educacional exige do aluno a organização de tarefas e pensamentos,  desde o planejamento, até a montagem mecânica e a programação da lógica do robô.  Com isto, a cada passo do projeto é necessário agregar conhecimentos múltiplos para  solucionar problemas, elevando gradualmente complexidade de pensamento e,  concomitantemente, o grau de atração dos alunos na resolução do problema.    É a partir de todos estes aspectos relacionados à capacidade interdisciplinar, a  ludicidade e o fascínio tecnológico que a Robótica Educacional exerce sobre os alunos,  que se pode perceber o potencial de sua utilização em sala de aula, seja para o ensino de  algoritmos, seja no ensino de outras disciplinas como física e matemática.     5.   Utilizando a Robótica Educativa para o ensino de algoritmos.   Neste artigo apresenta-se um objeto de aprendizagem para o ensino de condicionais e  laços de repetição, conceitos fundamentais para a disciplina de algoritmos. A  aprendizagem destes dois conceitos é complexa e exige dos alunos um alto grau de  abstração.  Ao materializar o uso de condicionais e laços nas ações dos robôs, conceitos  de programação antes abstratos, tornam-se ações físicas deste dispositivo, demonstrando  falhas na lógica do pensamento e colaborando no aprendizado.   Para desenvolver este objeto, utiliza-se um kit LEGO Mindstorms©. Este kit é  constituído por um conjunto de peças da linha tradicional (tijolos cheios, placas, rodas)  e da linha LEGO Technics (tijolos vazados, motores, eixos, engrenagens, polias e  correntes), acrescido de sensores de toque, de intensidade luminosa e de distância, todos  controlados por um processador programável.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       43  A programação para a robô é feita através da interface do kit LEGO. A criação  dos programas ocorre de forma simples e intuitiva através de blocos que representam  funções e testes que precisam ser realizados. À medida que estes blocos são dispostos  na linha de execução, um após o outro, o robô executará as tarefas na ordem em que  foram programadas pelo aluno.          Neste projeto utiliza-se um robô do tipo veículo, com quatro rodas, ao qual  foram acrescentados dois sensores frontais: um sensor ultrassônico na parte superior  (utilizados para medir distâncias) e um sensor que identifica cores, acoplado abaixo do  sensor ultrassônico, como mostrado na figura a seguir:      Figura 1.  Robô criado a partir do kit LEGO Mindstorms©   Durante o processo de ensino-aprendizagem são abordados os conteúdos  relacionados a noções de variáveis, operadores aritméticos e lógicos, estruturas de  condição e estruturas de repetição. Cada um destes conceitos é relacionado a um ou  mais blocos de programação do LEGO Mindstorms e para cada um destes conteúdos  são desenvolvidos programas para o robô.     O acompanhamento dos projetos deve ser constante, levando o aluno a uma  solução baseada em etapas sucessivas e incrementais. Para atingir este objetivo  apresenta-se um objeto de aprendizagem dividido em duas fases: a) aprendendo sobre  condicionais e, b) utilizando laços na programação de robôs.   5.1.   Aprendendo sobre condicionais    O objetivo desta etapa é permitir que o aluno compreenda o uso de condicionais (Se,  Então, Senão). Para isto, utiliza-se o robô mostrado na Figura 1. Este robô utiliza um  sensor ultrassônico para mediar sua distância em relação a um obstáculo à frente. Como  primeiro desafio, apresenta-se ao aluno a tarefa de criar um programa no qual o robô  anda continuamente em frente, enquanto recebe os dados do sensor ultrassônico. Caso  seja identificado um objeto à frente (ex. a 50 cm do robô) este deve parar.   Observa-se na Figura 2(a), que são utilizados apenas dois blocos, um bloco  condicional com um sensor e um bloco que aciona continuamente os motores do robô.  Assim, os motores só irão parar quando o sensor identificar um objeto à frente.  Já na  Figura 2(b), utiliza-se o mesmo bloco condicional com sensor, mas determina-se que  duas condições podem ser executadas, virar à esquerda se identificar um objeto à frente  ou continuar andando se não identificar. Esta mudança acrescenta mais um nível de  complexidade ao conteúdo abordado no desafio anterior.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       44                        (a) Condicional Simples                                      (b) Condicional Composta       Figura 2. Blocos lógicos para construção de condicionais.   Através da realização destas tarefas, os alunos podem compreender de modo  mais simples e visual, como suas escolhas de comandos nos condicionais (Se, Então,  Senão), levam o robô a executar as tarefas desejadas ou a cometerem falhas de  operação.    5.2.   Utilizando laços na programação de robôs     O objetivo deste desafio é permitir ao aluno compreender o uso de laços do tipo  “Faça” uma determinada tarefa, “Enquanto” uma condição for verdadeira. Por exemplo,  “Faça”, o robô deve andar, “Enquanto” não identificar um objeto à frente.  Uma das  importantes características dos laços computacionais é que estes têm implícito em sua  utilização, a necessidade de compreensão de condicionais, agregando, além disso, a  necessidade de abstrair a execução contínua de tarefas, até a satisfação de uma ou mais  condições de parada.    Se por um lado os laços parecem uma derivação dos condicionais, por outro, sua  compreensão pelos alunos de computação é sempre demorada e exige muitas interações  e exercícios.   Observe na Figura 3 que, o uso de laços surge de modo incremental ao  problema resolvido com os condicionais e mostrado na Figura 2(b).                           Figura 3. Blocos lógicos LEGO para construção de programas que utilizam laços.   No caso do exemplo mostrado na Figura 3, o aluno agrega de modo incremental  ao seu conhecimento anterior o conceito de laço computacional, acrescentando um laço  ao teste condicional que este já havia utilizado em outro desafio (Figura 2(b)). Assim, à   Condicional com   Sensor Ultrassônico   Acionamento   dos motores     Condicional com   Sensor Ultrassônico   Acionamento   dos motores   Acionamento  dos Motores   Laço de  Repetição  Infinita   Condicional  com Sensor  Ultrassônico     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       45  medida que o aluno avança no conteúdo de algoritmos, uma linha sequencial e  associativa é criada entre os conteúdos abordados e as tarefas ou desafios realizados por  eles.    Uma vez abordados os conteúdos e realizadas as tarefas em conjunto com os  alunos, fica a cargo do professor desenvolver outros desafios que levem estes alunos a  construir e reconstruir novos conhecimentos a partir dos conteúdos explorados, por  exemplo: criando um desafio no qual os alunos devam construir um robô que anda por  uma sala desviando de objetos.  Com isto, os alunos deverão solucionar um novo e  desafiador problema, mais complexo, mas solúvel a partir dos conteúdos abordados em  sala.   6. Metodologia    Para verificar se a utilização da robótica educativa promove melhoras nos níveis de  abstração e solução de problemas comumente apresentados aos alunos da disciplina de  algoritmos, fez-se um estudo sobre o desempenho dos alunos do Curso Técnico de  Informática do IFBA campus Valença dos últimos quatro anos. Para tanto, foram  levantadas suas notas e calculadas as médias, as medianas e a variância das notas  obtidas pelos alunos em cada um destes anos.     A média oferece um dado de desempenho global dos alunos diante dos  conteúdos, enquanto isso, a mediana permite identificar a tendência central em um  percentil de 70%, previamente adotado neste trabalho. Este valor de mediana retira da  amostra de cada uma das turmas os valores extremos, ou seja, as 15% maiores e  menores notas em cada uma delas. Isto reduz a distorção em torno do valor central  encontrado e aumenta a precisão na análise dos resultados. Por outro lado, a variância  descreve a disparidade de desempenho em cada turma, permitido analisar se a  metodologia adota conduz à homogeneidade do aprendizado.    As mesmas técnicas estatísticas foram aplicadas as notas obtidas com a turma na  qual está sendo utilizada a Robótica Educativa como ferramenta de mediação no ensino  de algoritmos. O número médio de alunos por turma é de 32 alunos, sendo que a turma  atual, ano 2014, possui 31 alunos.     O ambiente de aprendizagem de todas as turmas envolvidas é o um dos  laboratórios de informática do IFBA. Entretanto, para este experimento os alunos da  turma de Algoritmos do ano de 2014 foram divididos em grupos de quatro pessoas,  sendo que cada grupo recebeu um kit LEGO Mindstorms para construir seu robô, a  partir do modelo descrito no objeto de aprendizagem e mostrado na Figura 1.   7. Resultados    A partir da tabulação das notas dos alunos da disciplina Algoritmos dos últimos quatro  anos do Curso Técnico de Informática, foram gerados dois gráficos que permitem uma  análise da aplicação da Robótica Educacional em relação a outras turmas que não  fizeram uso desta ferramenta de ensino.    Na Figura 4, os resultados obtidos entre os anos de 2010 e 2013, dizem respeito  às turmas que não utilizaram a Robótica Educativa para o aprendizado de algoritmos.  Observa-se na mesma figura que, no ano de 2014, no qual está sendo utilizada a  Robótica Educativa como ferramenta de aprendizagem, houve uma melhora de 30% em  relação os demais anos letivos, tanto na média quanto na mediana.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       46                                                 Figura 4.  Série histórica de notas                               Figura 5. Variância das médias históricas   Entretanto, o ponto mais relevante apresentado na figura e que revelam uma  melhora no aprendizado, esta relacionado à proximidade da média e da mediana em  2014. Este dado, juntamente com a análise da variância das notas, apresentada na Figura  5, indicam que a metodologia utilizada permite um aprendizado, não só  quantitativamente melhor, mas mais homogêneo entre os alunos. Isto é, não só as notas  melhoraram, mas também houve um aumento no número de alunos com médias mais  altas, enquanto o número de alunos com notas mais baixas foi reduzido.    Observa-se também na Figura 5 que, a variância das notas em 2014 é próxima a  dois pontos, enquanto em outros anos aproxima-se do dobro disto. Isto significa uma  redução na discrepância entre alunos que estão com notas muito abaixo da média e  alunos com notas muito acima da média e, consequentemente, um aumento do número  de alunos que compreenderam os conteúdos abordados em sala.   As correlações positivas e significativas observadas entre os resultados  apresentados nas Figuras 4 e Figura 5 permitem que se identifique uma melhora no  desempenho dos alunos. Estes resultados são um forte indicativo de que o uso da  Robótica Educativa pode reduzir os problemas de aprendizagem dos conceitos abstratos  utilizados nas disciplinas que envolvem lógica de programação.  Porém, cabe destacar  que, ainda existem déficits de aprendizagem em alguns alunos, mas que estes são muito  menores que os encontrados em turmas que utilizaram metodologias tradicionais para o  ensino de Algoritmos.     Outro aspecto a ser abordado é o aumento do interesse dos alunos pela  disciplina, que fica explicito diante da pró-atividade e interesse destes em buscar novas  soluções mais elegantes para os problemas já resolvidos. Tal fato indica uma melhora  qualitativa na relação ensino-aprendizagem que transcende as questões numéricas  apresentadas neste artigo.   8. Considerações Finais   O desenvolvimento da lógica computacional exige empenho e capacidades que devem  ser estimuladas. Com a utilização da Robótica Educacional, a relação ensinoaprendizagem da disciplina de algoritmos torna-se mais lúdica, atraente e menos  abstrata.  Assim, com a construção do conhecimento através do lúdico e da prática, o  aprendizado de conceitos abstratos torna-se mais simples e compreensível para alunos  pouco acostumados a lidar com este tipo de problema em seu cotidiano, seja dentro ou  fora da sala de aula.                Os resultados obtidos neste estudo permitem visualizar o papel da Robótica  Educativa enquanto ferramenta lúdica e interativa e, ao mesmo tempo, como   2010 2011 2012 2013 2014  0 1 2 3 4 5 6 7 8 9  10 Séries Históricas de NotasMedianas e Médias  Mediana Média  N ot  as  2010 2011 2012 2013 2014  0  1  2  3  4  5  6  7  8 Variância das Notas Médias dos Alunos  V ar  iâ nc  ia    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 40 -47  Nov/2014       47  instrumento facilitador que otimiza a relação ensino-aprendizagem na disciplina de  algoritmos. Tem-se a percepção inicial das melhorias na aprendizagem, entretanto, não  apenas em termos quantitativos médios, mas também e principalmente, no aumento do  interesse dos alunos pela disciplina.     Em estudos futuros pretende-se avaliar não somente os aspectos quantitativos,  mas também aspectos qualitativos que indiquem os benefícios do uso na robótica  educativa e de objetos de aprendizagem baseados nesta tecnologia. O intuito é  identificar se realmente há aumento do interesse e melhorias da relação ensinoaprendizagem nesta disciplina tão importante para os cursos de computação.   9. Referências  Benitti, F. B. V., Vahldick, A., Urban, D. L., Krueger, M. L., and Halma, A.  (2009)   “Experimentação com Robótica Educativa no Ensino Médio:  ambiente, atividades e  resultados”. Anais do XXVII Congresso da SBC - XV Workshop de Informática na  Escola, Bento Gonçalves, RS, Brasil.   de Souza Pio, J. L., de Castro, T. H. C., de Castro Júnior, A. N. (2006) “A robótica  móvel como instrumento de apoio à aprendizagem da computação”. In XVII  Simpósio Brasileiro de Informática na Educação, Brasília, DF, Brasil.   Hinterholz Jr, O. (2009) “Tepequém: uma nova Ferramenta para o Ensino de  Algoritmos nos Cursos Superiores em Computação”.  XVII WEI, Bento Gonçalves,  RS, Brasil.        IEEE Learning Technology Standards Committee (LTSC) (2014) “Draft Standard for  Learning Object Metadata”, Institute of Electrical and Electronics Engineers, Inc.  LTSC. Learning technology standards committee website. http://ltsc.ieee.org/,  Outubro.        Leska, C. (2004) “Introducing Undergraduates to Programming using Robots in  General Education Curriculum”. ITICSE ACM 1-58113-836-9/04/0006. Leeds,  United Kingdom.   Ribeiro, Paula C., Martins, Carlos B., Bernardini, Flavia C. (2011) “A Robótica como  Ferramenta de Apoio ao Ensino de Disciplinas de Programação em Cursos de  Computação e Engenharia”. Anais do XXII SBIE – XVII WIE, UFF - Universidade  Federal Fluminense, Niterói, RJ, Brasil.   Santos, Rodrigo P. dos, Costa, Heitor A. X. (2006) “Análise de Metodologias e  Ambientes de Ensino para Algoritmos, Estruturas de Dados e Programação aos  iniciantes em Computação e Informática”, UFLA – Universidade Federal de Lavras,  Lavras, PE, Brasil.             
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     48  Proposta de Reforma Curricular do Curso de Bacharelado  em Sistemas de Informação da UFSM/CESNORS/FW: Um   Estudo de Caso     Sidnei Renato Silveira1, Fábio José Parreira1, Graciela Ló Nunes2, Laís Piovesan2,  Márcia Regina Winch2, Solange B. Kempka2     sidneirenato.silveira@gmail.com, fabiojparreira@gmail.com, napcesnors@ufsm.br     UFSM – Universidade Federal de Santa Maria – CESNORS/Frederico Westphalen   1Departamento de Tecnologia da Informação  2Núcleo de Apoio Pedagógico - NAP     Resumo: Este artigo apresenta a metodologia aplicada para compor uma  proposta de reforma da matriz curricular do Curso de Bacharelado em  Sistemas de Informação da Universidade Federal de Santa Maria –  CESNORS/Frederico Westphalen. Tendo-se em vista a atualização  necessária da matriz curricular, decorrente da constante evolução  tecnológica, aplicou-se um instrumento com os alunos, para verificar as  opiniões e sugestões dos mesmos sobre a matriz curricular.  Posteriormente, realizou-se um evento com todos os docentes do curso,  originando uma proposta de matriz curricular atualizada.    Abstract: This paper presents the methodology used to propose a new  curriculum of Information Systems Course of Federal University of Santa  Maria – CESNORS/Frederico Westphalen. According to a technology  evolution, the curriculum needs to update. We applied an instrument with  students to check your opinions and suggestions on the curriculum.  Subsequently, there was an event with all college professor of the course,  to create a proposal for updated curriculum.     1. Introdução  O Curso de Bacharelado em Sistemas de Informação da UFSM/CESNORS/Frederico  Westphalen encontra-se, atualmente, com 140 alunos matriculados. Em 2014/2 ocorreu  o ingresso da 5ª turma do curso. Recentemente, o curso passou pelo processo de  avaliação para fins de reconhecimento do curso junto ao MEC, alcançando a nota  máxima (5). De acordo com a Pró-Reitoria de Graduação da UFSM (PROGRAD), os  cursos só devem encaminhar propostas de reforma curricular após terem sido  reconhecidos. Neste sentido, acredita-se que o curso está maduro para discutir uma  proposta de reforma curricular, pensando na inovação tecnológica constante, na  adequação ao Parecer 136/2012 do CNE/CES (Ministério da Educação, 2012), na  redução da evasão e, também, na eliminação de sobreposições de conteúdos. Além  disso, a inclusão de atividades semipresenciais, de acordo com a Portaria 4059/2004 do  MEC, só pode ser realizada para os cursos já reconhecidos pelo Ministério da Educação  (Ministério da Educação, 2004).   Neste contexto, este artigo apresenta a metodologia empregada para compor uma  proposta de reformulação da matriz curricular, bem como os resultados obtidos, por  meio da participação da comunidade acadêmica (discentes e docentes), com o apoio do  NAP – Núcleo de Apoio Pedagógico.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     49    2.  Marco Teórico-Conceitual e Revisão Bibliográfica  Segundo a proposta do Ministério da Educação para os referenciais nacionais dos cursos  de graduação, o Bacharel em Sistemas de Informação (SI) “desenvolve soluções  baseadas em tecnologia da informação para os processos de negócio das organizações,  de forma que elas atinjam efetivamente seus objetivos estratégicos de negócio”. Esta  conceituação deixa claro que o Bacharel em SI atua, essencialmente, em ambientes  empresariais, aplicando a Informática como um meio para apoiar o negócio principal da  empresa. Tendo-se em vista este perfil, estabelecem-se alguns itens que devem ser  levados em conta na construção de estruturas curriculares de Bacharelados em Sistemas  de Informação (Silveira; Ribeiro, 2009):  inserção regional e perfil institucional, áreas  de abrangência da formação; sólida formação de base; emprego de tecnologias atuais;  realização de atividades práticas durante as disciplinas; realização do estágio curricular  supervisionado e/ou do trabalho de conclusão de curso; utilização de recursos de  Educação a Distância (EaD); inserção de disciplinas voltadas à gestão e ao  empreendedorismo; desenvolvimento de atividades interdisciplinares; inclusão de  atividades complementares; integração com o mercado; embasamento matemático e  formação humanística.   Além dos aspectos já mencionados no texto, é preciso estar atento à coerência do  currículo com o perfil do egresso. As disciplinas e atividades propostas estão alinhadas  ao perfil do egresso? Cabe destacar que ainda não existem diretrizes curriculares  homologadas (o Parecer 136/2012 está aguardando homologação) para a área de  Computação (Prietch; Pazeto, 2009), pois as propostas encaminhadas ainda não foram  homologadas pelo Ministério da Educação. Durante a realização do II FGCoordI  (FGCoordI, 2008), o grupo de coordenadores participantes decidiu encaminhar um  manifesto ao Conselho Nacional de Educação, solicitando a aprovação das propostas já  existentes, elaboradas pela Comissão de Especialistas de Ensino em Computação e  Informática (CEEInf, 2014). Este manifesto foi encaminhado em outubro de 2008 e  acredita-se que tenha contribuído para a elaboração do Parecer 136/2012. Outra questão  importante é a de que as disciplinas precisam estar dispostas de forma adequada, para  que os temas possam ser aprofundados a cada semestre.    A atualização constante das matrizes curriculares também é importante e precisa ser  realizada com a participação do corpo docente e discente. Um ponto importante que  precisa ser considerado é a falta de regulamentação da profissão. Como as funções que  envolvem a área de Tecnologia da Informação não são regulamentadas, muitos alunos  ingressam em cursos superiores e não os concluem, mesmo que durante o curso iniciem  sua atuação profissional. Outros trabalham na área mesmo sem terem iniciado algum  curso específico. Alguns também acreditam que, mais do que um diploma de curso  superior, o que vale são as certificações oficiais. Estas questões acabam por reduzir o  número de alunos nos Cursos de Sistemas de Informação.      3. Metodologia  Neste contexto, a Coordenação do Curso de Sistemas de Informação da  UFSM/CESNORS, em parceria com o Núcleo de Apoio Pedagógico (NAP) elaborou  um instrumento (em anexo), visando coletar a opinião dos discentes sobre propostas de  alteração da matriz curricular. Após a coleta e análise dos dados, os mesmos foram  discutidos pelos docentes do curso, por meio da realização de um workshop (Workshop  de Qualificação Docente do Curso de Sistemas de Informação). O resultado deste  workshop foi a proposta de uma nova matriz curricular para o curso, que será submetida  à aprovação do Núcleo Docente Estruturante (NDE) e do Colegiado do Curso.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     50    4. Resultados Obtidos  Os resultados aqui apresentados foram obtidos por meio da aplicação de um  instrumento (disponível em anexo), com o objetivo de colher informações e opiniões  dos discentes, visando subsidiar a proposta de atualização da matriz curricular.   O referido instrumento foi aplicado em junho deste ano, pela Coordenação do  Curso, nas turmas dos 4º e 8º semestres e nas turmas referentes aos 2º e 6º semestres,  pelo Núcleo de Apoio Pedagógico. Participaram 52 alunos, que representavam 46,84%  dos alunos que estavam matriculados no 1º semestre de 2014.   Com relação à pergunta Você conhece a grade curricular do seu curso, 25  alunos responderam afirmativamente (48% dos respondentes) e 27 responderam que  conhecem parcialmente (52%). Nenhum aluno respondeu que desconhecia a grade  curricular. Os resultados confirmam que os alunos participantes têm, pelo menos em  parte, conhecimento da grade curricular.    Com relação à pergunta sobre o número de disciplinas das áreas de  Administração e de Informática, a maioria dos alunos (39 - correspondendo a 75% dos  respondentes) acredita que o número está equilibrado (13 alunos - 25% - responderam  que não). Nesta pergunta havia um espaço para justificativa com relação à resposta  dada. Analisando as justificativas, verifica-se que 8 respondentes gostariam que  houvessem mais disciplinas da área de informática (15,38%). Entretanto, 15  respondentes (28,84%) consideram que a distribuição entre as duas áreas está adequada.    Na próxima pergunta questionou-se aos alunos quais disciplinas, relacionadas às  áreas de Administração e/ou Gestão, poderiam ser eliminadas do currículo do curso.  Nesta pergunta existia a opção NS (significando não sei ou não quero responder). 12  alunos (23,07%) responderam que nenhuma disciplina desta área, já existente no  currículo, deveria ser eliminada. 13 alunos (25%) responderam NS ou deixaram a  resposta em branco. Estes percentuais juntos somam 48,07% dos respondentes,  indicando que a maioria dos alunos considera que as disciplinas da área de  Administração e/ou Gestão ofertadas no curso estão de acordo com o perfil.    Mesmo com estes resultados, 12 alunos (23,07%) consideram que a disciplina de  Teoria Econômica poderia ser eliminada, 9 alunos (17,31%) indicaram a disciplina de  Teoria Geral de Administração, 5 alunos (9,62%) indicaram a disciplina de Gestão de  Pessoas, 4 alunos (7,69%) apontaram a disciplina de Engenharia Econômica, 3 alunos  (5,77%) apontaram a disciplina de Marketing e 1 aluno (1,92%) apontou,  separadamente, as disciplinas de Cálculo, Empreendedorismo e Matemática.    Além das disciplinas anteriormente mencionadas, os alunos relataram que a  disciplina de Marketing poderia ter seu conteúdo agregado a outra disciplina e que as  disciplinas de Custos e Engenharia Econômica têm a mesma abordagem. Como  sugestão de novas disciplinas, um aluno solicitou a inclusão de alguma disciplina  relacionada à área jurídica (relações empresariais e de trabalho).   No próximo item questionou-se aos alunos quais disciplinas, relacionadas à  Administração e/ou Gestão, poderiam ser agregadas ao currículo do curso. Nesta  pergunta existia a opção NS (significando não sei ou não quero responder). A grande  maioria dos alunos, 45 respondentes (representando 86,54%) não soube responder (35  alunos) ou não indicou nenhuma disciplina (10 alunos).   As sugestões apresentadas pelos alunos foram a inclusão de disciplinas nas  áreas de: Gerência de Tecnologia da Informação, Práticas de ITIL (Information  Technology Infrastructure Library, a junção das disciplinas de Teoria Geral da  Administração e Gestão de Pessoas (destacada por 2 alunos) e alguma disciplina que  abordasse aspectos relacionados à oratória.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     51  Na próxima pergunta questionou-se aos alunos quais disciplinas, relacionadas à  área de Informática poderiam ser eliminadas do currículo do curso. Nesta pergunta  existia a opção NS (significando não sei ou não quero responder). 49 alunos (94,23%)  responderam nenhuma ou não souberam ou quiseram responder, o que indica que os  alunos estão satisfeitos com as disciplinas da área de Informática existentes no  currículo.   As disciplinas de Computadores e Sociedade, Linguagem Comercial e  Sistemas Operacionais foram apontadas, por apenas 1 aluno, como sugestões de  disciplinas que poderiam ser eliminadas do currículo.   Seguindo o instrumento, questionou-se aos alunos quais disciplinas,  relacionadas à área de Informática poderiam ser agregadas ao currículo do curso. Nesta  pergunta existia a opção NS (significando não sei ou não quero responder).  Considerando-se os alunos que não responderam (ou não souberam responder) com os  que não fizeram nenhuma sugestão, tem-se 19 alunos (que representam 36,54%).    As sugestões apresentadas em maior número envolvem as áreas de Programação  para Dispositivos Móveis (10 alunos, 19,23%), Programação para a Web (8 alunos,  15,38%), Redes de Computadores (5 alunos, 9,62%). Outras sugestões, citadas em  menor número, envolvem as áreas de Compiladores, Computação Gráfica, Jogos e  Legislação em Informática.    Na próxima pergunta questionou-se aos alunos quais disciplinas, relacionadas a  conhecimentos sociais e humanísticos poderiam ser agregadas ao currículo do curso.  Apenas 2 alunos (3,85%) não responderam esta questão. A maioria dos alunos, com 34  respondentes (65,38%) indicaram a possibilidade de inclusão de uma disciplina na área  de acessibilidade.  15 alunos (28,85%) apontaram a área de Psicologia Organizacional,  5 alunos (9,62%) apontaram temas ligados ao meio ambiente e sustentabilidade, 4  alunos (7,69%) destacaram Filosofia e Sociologia e 2 alunos (3,85%) destacaram  questões ligadas à legislação.    Com relação à pergunta Você acha que há disciplinas com conteúdos repetidos  na grade curricular de seu curso, 21 alunos (40,38%) não responderam ou não  souberam responder, 18 alunos (34,62%) disseram que não e 13 alunos (25%)  responderam que sim.    Dos respondentes, 3 alunos (5,77%) responderam que os conteúdos se repetem  nas disciplinas de Custos e Engenharia Econômica. Para 2 alunos (3,85%) os conteúdos  se repetem nas disciplinas de Engenharia Econômica e Empreendedorismo; Teoria  Geral da Administração e Gestão de Pessoas; e nas disciplinas de Teoria Geral da  Administração e Teoria Econômica. Para 1,92% dos alunos (1 respondente para cada  uma das alternativas), as disciplinas que apresentam conteúdos repetidos são as de  Arquitetura de Computadores; Circuitos Digitais e Organização de Computadores; e  Linguagem Comercial e Programação Orientada a Objetos.   Com relação à pergunta Você gostaria que fossem incluídas atividades a  distância nas disciplinas, 32 alunos (61,54%) respondeu que sim, 17 alunos (32,69%)  disseram que não e 3 alunos (5,77%) não souberam responder ou são indiferentes a esta  possibilidade. Acredita-se que o percentual expressivo de respostas afirmativas permite  que o Núcleo Docente Estruturante, bem como o Colegiado do Curso, estudem a  possibilidade de aplicação dos recursos de EaD, de acordo com a Portaria 4059/2004 do  MEC, que permite que até 20% da carga horária dos cursos sejam ministrada a  distância.   Com relação aos temas sugeridos para o desenvolvimento de Disciplinas  Complementares de Graduação (DCGs), 13 alunos (25%) não fizeram sugestões. As  sugestões apresentadas são similares às disciplinas apontadas para serem agregadas na     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     52  área de Informática. As áreas mais destacadas foram a programação para dispositivos  móveis e voltada para a web. 17 alunos (32,69%) apontaram o tema de programação  para dispositivos móveis, 14 alunos (26,92%) o tema de programação para a web, 6  alunos (11,54%) destacaram a abordagem de jogos e 4 alunos (7,69%) o estudo de um  segundo idioma. As demais sugestões foram apresentadas em menor número.    No final do instrumento havia um espaço para que os alunos pudessem fazer  suas considerações sobre a reforma curricular: Além de responder às perguntas  anteriores, utilize este espaço, se desejar, para sugestões e outras opiniões para a  reforma da matriz curricular. As opiniões, na íntegra, são apresentadas abaixo:   - “Trabalhos mais estruturados com graus de dificuldade elevando aos  poucos, para assim elevar o aprendizado do aluno” (2º semestre);   - “A matriz curricular está boa, porém necessita atualizar para as novas  disciplinas de programação Mobile de Windows Phone e Android, que são a  tendência da atualidade” (2º semestre);   - “Realizar a troca entre matemática e cálculo I, matemática no 1º semestre e  cálculo no 2º semestre” (4º semestre);   - “Oferta de DGCs na modalidade à distância e concomitante com o curso,  com uma variedade maior para possibilitar a escolha pelo estudante” (4º  semestre);   - “Aulas mais práticas e menos teóricas” (4º semestre);  - “Acho interessante a troca dos semestres de matemática e cálculo” (4º   semestre);  - “Disciplina com ênfase em Mobile, como Android ou Windows Phone e   alguma com C#” (4º semestre);  - “Mais prática e menos teorias nas matérias” (4º semestre);  - “Sugiro que as aulas de laboratório sejam um semestre após a de lógica”   (4º semestre);  - “Gostaria que houvesse pelo menos uma matéria voltada pra web” (6º   semestre);  - “Mais disciplinas de programação” (6º semestre);  - “Primeiramente deveríamos definir o rumo do curso de SI, pois a maioria   não sabe se estamos cursando Sistemas de Informação ou ADM” (6º  semestre);   - “Como dito anteriormente vejo a necessidade de aumentar as disciplinas  voltadas à informática” (6º semestre);   - “Como trabalhamos o dia inteiro às vezes fica difícil acompanhar o ritmo  dos professores. Devia se organizar melhor a distribuição das disciplinas  teóricas e das práticas por essa questão” (6º semestre);   - “Voltar a disciplina de matemática para o primeiro semestre e cálculo para  o segundo semestre” (8º semestre);   - “Matérias voltadas para novos sistemas/plataformas. Ex; Mobile” (8º  semestre).    Algumas sugestões se repetem, como a inclusão de disciplinas voltadas para a  programação para dispositivos móveis. As sugestões de troca de semestres entre as     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     53  disciplinas de Matemática e Cálculo, oferta de disciplinas na modalidade a distância e a  divisão das disciplinas de Lógica de Programação e Laboratório de Programação I em  mais de um semestre foram discutidas pelos docentes, durante o workshop realizado.     5 Considerações Finais  Com base nos resultados analisados e na discussão realizada pelos docentes durante o II  Workshop de Qualificação Docente do Curso de Sistemas de Informação, foi possível  chegar a uma proposta de reformulação na matriz curricular. As principais alterações,  com base na matriz curricular existente (UFSM, 2014) são: 1) junção das disciplinas de  Lógica e Algoritmo e Laboratório de Programação I (1º semestre), em uma disciplina de  120h, denominada Programação e Estrutura de Dados I e a junção das disciplinas de  Laboratório de Programação II e Estruturas de Dados em uma disciplina de 120h  (Programação e Estruturas de Dados II). Estas junções visam reduzir a complexidade  dos temas, para que os alunos possam aprender primeiramente a lógica de programação  (pseudocódigo), antes de iniciarem a programação propriamente dita; 2) revisão das  disciplinas da área de Matemática, sendo excluída a disciplina de Cálculo. A disciplina  de Matemática passa a ter o conteúdo mais voltado à Matemática Discreta e foi incluída  a disciplina de Álgebra Linear; 3) inclusão de uma segunda disciplina voltada à  Engenharia de Software (visando o estudo de UML – Unified Modeling Language); 4)  divisão da disciplina de Redes de Computadores em duas disciplinas (Redes de  Computadores I e II).   Além destas alterações, o número de Disciplinas Complementares de Graduação  (DCGs) foi reduzido, passando de 8 para 4 (algumas DCGs ofertadas anteriormente  passaram a ser disciplinas obrigatórias nesta nova proposta, tais como Introdução à  Inteligência Artificial e Linguagem de Programação para a Web). Outra alteração  importante foi a redução do tempo de integralização de 10 para 9 semestres, já que o  Trabalho de Graduação em Sistemas de Informação, que antes era ofertado  isoladamente no 10º semestre, foi dividido em duas partes (TGSI I e II), no oitavo e  nono semestres. A Figura 1 apresenta a matriz curricular proposta.     Figura 1: Proposta de Matriz Curricular     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     54   O corpo docente também irá definir como serão ofertadas atividades na  modalidade semipresencial, com a utilização do Ambiente Virtual de Aprendizagem  Moodle. Atualmente, o corpo docente está revisando as ementas das disciplinas que  foram mantidas na nova matriz curricular e elaborando as ementas das novas  disciplinas. Após estas revisões, o grupo de docentes se reunirá para apresentar os  resultados que serão posteriormente encaminhados para aprovação por parte do NDE e  do Colegiado do Curso, seguindo-se os demais trâmites institucionais. Acredita-se que a  nova matriz curricular possa ser adotada a partir do 2º semestre de 2015.    Referências  CEEInf (Comissão de Especialistas de Ensino de Computação e Informática). “Perfis de   Profissionais e Denominações de Cursos”. Disponível em  <http://www.inf.ufrgs.br/mec/ceeinf.perfis.html>. Consultado em agosto de 2014.   FGCoordI. (2008). “II Fórum Gaúcho de Coordenadores de Cursos de Informática”.  Porto Alegre: UniRitter.   MINISTÉRIO DA EDUCAÇÃO. “Portaria 4059/2004”. Disponível em:  <http://portal.mec.gov.br>.   MINISTÉRIO DA EDUCAÇÃO. “Diretrizes Curriculares Nacionais para Cursos de  Graduação em Computação”. Parecer 136/2012 CNE/CES. Disponível em:  <http://portal.mec.gov.br>.   PRIETCH, S. S.; PAZETO, T. A. “Análise, Sugestões e Perspectivas de um Curso de  Licenciatura em Informática”. Anais do XXIX Congresso da Sociedade Brasileira  de Computação, WEI 2009 – XVII Workshop sobre Educação em Computação.  SBC: Bento Gonçalves.   SILVEIRA, Sidnei Renato; RIBEIRO, Vinicius Gadis. “Uma Reflexão sobre a  Construção de Currículos de Cursos de Sistemas de Informação”. Anais do III  WEITchê – Workshop de Educação em Informática do RS. Torres-RS: ULBRA,  2009.   UFSM, Universidade Federal de Santa Maria. “Projeto Pedagógico do Curso de  Bacharelado em Sistemas de Informação”. Disponível em:  <http://w3.ufsm.br/cesnors/index.php/curso/graduacao/sistemas-de-informacao/2uncategorised/276-ppc-sistemas-de-informacao>. Acesso em agosto de 2014.     Anexo:  Instrumento de Pesquisa     QUESTIONÁRIO DE AVALIAÇÃO CURRICULAR PARA OS ESTUDANTES DO CURSO DE   SISTEMAS DE INFORMAÇÃO      Semestre do curso:__________    1) Você conhece a Matriz Curricular do seu curso?   ( ) Sim      ( ) Não          ( ) Parcialmente    2) Um Curso de Sistemas de Informação envolve as áreas de Administração (especialmente Gestão)  e Informática. Você acredita que o número de disciplinas de cada uma destas áreas está adequado?  (  ) Sim (  ) Não. Justifique sua resposta:      3) Qual(is) disciplina(s) da área de Administração/Gestão poderiam ser eliminadas do currículo do  curso?         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 48 -55  Nov/2014     55  4) Qual(is) disciplina(s) da área de Administração/Gestão poderiam ser agregadas ao currículo do  curso?       5) Qual(is) disciplina(s) da área de Informática poderiam ser eliminadas do currículo do curso?      6) Qual(is) disciplina(s) da área de Informática poderiam ser agregadas ao currículo do curso?      7) Além das disciplinas específicas voltadas às áreas de formação do curso (Administração e  Informática), a formação universitária exige um conjunto de conhecimentos sociais e humanísticos.  Quais disciplinas desta área poderiam ser agregadas ao currículo do curso?    ( ) Sociologia                         ( ) Psicologia Organizacional               ( ) Filosofia  ( ) Meio ambiente e Sustentabilidade        ( ) Acessibilidade    Outra(s):____________________    8) Você acha que há disciplinas com conteúdos repetidos na Matriz Curricular de seu curso?  ( ) Não sei responder   ( ) Não   ( ) Sim. Qual(is)?_____________________________________    9) Você gostaria que fossem incluídas atividades a distância nas disciplinas, permitindo a realização  de até 20% da carga horária de forma semipresencial (utilização do Ambiente Virtual de  Aprendizagem Moodle)?    ( ) Sim        ( ) Não       ( ) Não sei/indiferente      10) O currículo dos cursos de graduação da UFSM prevê a realização de Disciplinas  Complementares de Graduação (DCGs). Quais temas você sugere que sejam abordados nestas  disciplinas?       11) Você já pensou em abandonar ou trancar seu curso?  ( ) Não sei responder   ( ) Não   ( ) Sim     11.1) Em caso afirmativo, quais foram os motivos?   (  ) Dificuldades financeiras   (  )O curso não era o que você esperava/imaginava   (  )O curso não era sua primeira opção (optou por conveniência)   (  )Apresentou dificuldades de adaptação ao ambiente universitário   (  )Apresentou dificuldades de adaptação à cidade   (  )Apresentou dificuldades de se manter longe da família   (  )Apresentou dificuldade em conciliar horários   (  )Apresentou dificuldade no relacionamento interpessoal   (  )Apresentou dificuldade no rendimento acadêmico (dificuldade de aprendizagem, reprovações,  notas baixas, entre outros)    Outros_____________________________________________________________    12) Além de responder às perguntas anteriores, utilize este espaço, se desejar, para sugestões e  outras opiniões para a reforma da matriz curricular:      OBS: Evite deixar questões em branco, quando não souber o que responder ou não quiser responder,  preencha com “NS”          
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     56     Sistema Inteligente para Apoio ao Diagnóstico de Diabetes  Empregando Redes Neurais   Maik Basso, João Paulo Vieira, Fábio José Parreira, Sidnei Renato Silveira,  Adriana Sadowski de Souza     maik@maikbasso.com.br, vieira.jpvieira@gmail.com, fabiojparreira@gmail.com,   sidneirenato.silveira@gmail.com, adrianasadowsi@gmail.com     Universidade Federal de Santa Maria (UFSM) - Centro de Educação Superior Norte  (CESNORS) - Caixa Postal 54 - Frederico Westphalen - RS - Brasil   Departamento de Tecnologia da Informação   Resumo. Este artigo aborda o desenvolvimento de um protótipo de aplicação  que utiliza técnicas de Inteligência Artificial, para apoiar o diagnóstico do  Diabetes. O sistema apoia o diagnóstico, por meio de Redes Neurais Artificiais,  do estado patológico do paciente, cujas informações para treinamento e teste  do sistema foram extraídas da base de dados da comunidade indígena Pima.  Comparando-se os resultados do sistema como as informações da base dados,  foi obtida uma taxa de acerto de 81,31%.   Abstract. This paper presents the development of an application prototype,  using Artificial Intelligence techniques, to support diabetes diagnosis. The  system supports the patient pathological state diagnosis through Artificial  Neural Networks, whose information for training and testing the system were  extracted from the Pina Indian community database. Comparing the results of  the system as the information of the database, an accuracy rate of 81,31% was  obtained.   1. Introdução   Nos últimos anos a incidência do diabetes tem aumentado rapidamente em nível  mundial. Recentemente, a Organização Mundial de Saúde (OMS) reconheceu que a  doença é epidêmica. As estatísticas apontam que o número de casos, em todo o mundo,  atualmente chega a 246 milhões. Até 2025, esse número deve chegar a 350 milhões, de  acordo com a Federação Internacional de Diabetes (IDF). No Brasil, segundo dados do  Ministério da Saúde, estima-se que existam cerca de 11 milhões de portadores de  diabetes, sendo que 7,5 milhões já sabem que tem a doença (Oliveira; Vencio, 2014).   Alguns dos fatores que favorecem esse crescimento alarmante do diabetes são a  obesidade, hereditariedade, hábitos alimentares inadequados e o sedentarismo. Estudos  demonstram que 46,6% dos pacientes diagnosticados desconheciam o fato de serem  portadores da doença, e dos pacientes sabidamente diabéticos, 22,3% não faziam  nenhum tipo de tratamento (Botelho, 2003).   Embora a detecção de diabetes esteja melhorando, o tempo para diagnosticá-lo  pode ser superior a 10 anos, a contar do início da doença, até a concretização do  diagnóstico. Para diagnosticar um paciente com diabetes, o médico tem que analisar  diversos fatores e isto dificulta o seu trabalho. Para auxiliar estes profissionais, da área  de saúde, são utilizados sistemas computacionais com a finalidade de apoiar o  diagnostico. Tais sistemas processam informações, com mais detalhe e em menor  tempo, quando comparados com aos seres humanos, proporcionando uma melhora na     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     57  qualidade dos serviços médicos, além de contribuir para a difusão de conhecimentos  especializados (Kayaer; Yıldırım, 2003).   Neste sentido, o presente trabalho apresenta um protótipo de sistema inteligente,  empregando Redes Neurais multicamadas, para apoiar o diagnóstico de diabetes -  Sistema Neural para Apoio ao Diagnóstico de Diabetes (SND). O artigo apresenta um  breve referencial teórico sobre as áreas envolvidas (diabetes, redes neurais e o banco de  dados para treinar e testar o sistema), situa o estado da arte e apresenta a solução  implementada.    2. Referencial Teórico   2.1. Diabetes  Uma pessoa diagnosticada com diabete sofre de hiperglicemia, que por definição é o  excesso de açúcar no sangue. Este excesso ocorre porque o pâncreas, órgão responsável  pela produção da insulina, não consegue produzir a quantidade necessária deste  hormônio para que a glicose possa entrar na célula, onde seria consumida, o que resulta  no acúmulo desta no sangue. O diabetes não afeta só a capacidade do organismo de  consumir açúcar, mas também a capacidade de utilizar outras fontes de energia como as  proteínas e as gorduras (Baier, Hanson, 2004). Basicamente, existem três tipos  principais de diabetes: o diabetes tipo 1, que afeta principalmente os jovens, o diabetes  tipo 2, que, geralmente, afeta as pessoas adultas e idosas e o diabetes gestacional, que  pode ocorrer durante a gestação (Mazzaferri, 1988).   Para o diabetes tipo 1 existem diversas denominações: diabetes  insulinodependente, diabetes infanto-juvenil ou diabetes imunomediado. A  característica marcante deste tipo de diabetes é a produção insuficiente de insulina, pois  suas células sofrem o que se chama de destruição autoimune. Neste tipo de diabetes a  produção de insulina do pâncreas é insuficiente, pois suas células sofrem o que se  chama de destruição autoimune. Os portadores de diabetes tipo 1 necessitam de   injeções diárias de insulina para manterem a glicose no sangue em valores normais.  Embora este tipo de diabetes ocorra em qualquer idade, é mais comum em crianças,  adolescentes ou adultos jovens (Oliveira; Vencio, 2014).    Já o diabetes tipo 2, denominado também de diabetes não insulinodependente ou  diabetes do adulto, corresponde a 90% dos casos de diabetes e geralmente ele é  detectado em pessoas obesas, com mais de 40 anos de idade. Atualmente este quadro  vem sofrendo mudanças, pois há grande ocorrência em jovens, em virtude de maus  hábitos alimentares, sedentarismo e e e da vida urbana. Neste tipo de diabetes, embora  exista a presença de insulina, a sua ação é dificultada pela obesidade, o que é conhecido  como resistência insulínica. Por ser pouco sintomático, este tipo, na maioria das vezes,  permanece por muitos anos sem diagnóstico e sem tratamento o que favorece a  ocorrência de suas complicações no coração e no cérebro (Botelho, 2003).   Por fim, o diabetes Gestacional, ocorre quando há a presença de glicose elevada  no sangue, durante a gravidez. Ao final da gravidez, após o parto, geralmente a glicose  no sangue, se normaliza. No entanto, as mulheres que apresentam ou apresentaram  diabetes gestacional, possuem maior risco de desenvolverem diabetes tipo 2  tardiamente, o mesmo ocorrendo com os seus filhos.           Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     58  2.2. Redes Neurais Artificiais  As Redes Neurais Artificiais (RNAs) são um paradigma de processamento de  informação inspirado no sistema neural biológico. As RNAs são sistemas massivamente  paralelos e distribuídos, formados por unidades de processamento simples, que  calculam determinadas funções, normalmente não lineares. Essas unidades são  distribuídas em camadas, sendo interligadas por conexões, as quais se associam a pesos.  Estes pesos armazenam o conhecimento representado na rede, servindo para ponderar as  entradas recebidas por unidade constituinte (Haykin, 2001).   Uma das características mais importantes de uma RNA é a capacidade de  aprender através de exemplos, denominados de conjunto de treinamento, sendo estes  apresentados a ela durante a etapa de treinamento. Durante o aprendizado a rede  consegue extrair os padrões existentes neste conjunto de dados e, após finalizar a etapa  de treinamento, ela aprende o suficiente para generalizar o problema. Ao final, na etapa  de teste, a RNA consegue produzir respostas satisfatórias para dados desconhecidos,  que fazem parte do mesmo problema, para o qual ela foi treinada.   Segundo Palma Neto e Nicoletti (2005), os algoritmos de treinamento das RNAs  podem ser agrupados em supervisionados e não supervisionados. Nos supervisionados,  além das informações, cada exemplo de treinamento traz a classe a qual ele pertence.  Nos grupos não supervisionados a RNA é treinada sem considerar as informações da  classe a qual cada exemplo está associado.   Existem várias arquiteturas para a implementação de uma RNA, mas estas  podem ser divididas, basicamente, quanto ao número de camadas, e pelos tipos de  conexões entre os neurônios (Fausett, 1994). De acordo com o número de camadas, a  arquitetura de uma RNA pode ser denominada de camada única ou de múltiplas  camadas. As RNAs com múltiplas camadas distinguem-se de redes com camada única  pela presença de camadas ocultas. Além disso, são utilizadas em problemas mais  complexos, que necessitam analisar várias combinações das entradas da rede, como por  exemplo, o diagnóstico de diabetes.   Quanto aos tipos de conexões, que definem a direção do fluxo de ativações, as  RNAs são definidas como feedforward e  feedback. As RNAs feedforward, também  conhecidas como acíclicas ou não recorrentes, são estruturadas em camadas, e não  possuem realimentação de suas saídas para as entradas. Estas podem ter de uma ou mais  camadas em sua configuração. Dentre os algoritmos para treinamento de redes  feedforward, o back-propagation está entre os que proporcionam uma maior eficiência.  Já as RNAs feedback, também denominadas de cíclicas ou recorrentes, diferenciam-se  das não recorrentes por terem em sua estrutura a realimentação das saídas para as  entradas (Haykin, 2001).   Para que uma rede neural tenha sucesso na resolução de problemas práticos, é  necessário que ela consiga representar funções lineares e não lineares, assim como o  algoritmo de treinamento deve ser suficientemente robusto e genérico, não restringindo  a eficácia na resolução de problemas. As redes neurais de múltiplas camadas, com o  algoritmo para treinamento back-propagation, contemplam essas características  (Massad et. al, 2004).    2.3 Base de dados Pima Indians   Para treinar e testar a aplicação da RNA no protótipo desenvolvido, foi utilizada a base  de dados da Universidade da Califórnia (UCI, 2014), denominada Pima Indians     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     59  Diabetes (PID).  As informações para compor esta base foram coletadas na comunidade  indígena Pima, que vive perto de Phoenix, Arizona, Estados Unidos. Todas as pessoas,  cujos dados foram coletados, são mulheres, com idade igual ou superior a 21 anos.    Diversas pesquisas foram realizadas nesta comunidade, pois ela é conhecida por  apresentar a maior taxa de incidência de diabetes do mundo. Entre os adultos 50% são  diabéticos, além de apresentarem uma alta prevalência de obesidade (Baier e Hanson,  2004). Devido a estas características, os pesquisadores resolveram criar a base de dados  PID, que é composta por 768 pessoas, onde 268 destas foram classificadas como tendo  diabetes, do tipo 2, o que resulta em 34,9% da base. Os outros 65,1% não possuem  diabetes e são classificados como normais.   Para cada pessoa que compõe a base, é informado: o número de vezes que a  paciente ficou grávida, teste oral de tolerância à glicose, pressão arterial diastólica (mm  Hg), espessura da dobra cutânea do tríceps (mm), idade (anos), índice de massa corporal  (IMC) e a classificação (possui ou não diabetes).   3. Estado da Arte  Existem diversos estudos focados no desenvolvimento de mecanismos de diagnóstico  de diabetes. Nas últimas décadas, as abordagens utilizadas extrapolaram o escopo  clássico, voltado para ferramentas matemáticas, adotando técnicas inteligentes, com o  intuito de aprimorar a flexibilidade do mecanismo em relação à dinâmica apresentada  pelo processo de diagnóstico. Dentre as várias abordagens utilizadas, as redes neurais  artificiais vêm sendo largamente utilizadas para auxiliar no diagnóstico de diabetes.   Polat (Polat et. al., 2008) apresenta uma abordagem, para diagnóstico de diabetes  tipo 2, usando análise de componente principal (PCA) com sistema adaptativo neurofuzzy. Inicialmente, o PCA foi utilizado para reduzir as informações da base de dados,  passando de 8 para 4. No segundo estágio, as 4 informações resultantes do PCA são  fornecidas ao sistema classificador adaptativo neuro-fuzzy, que as classificam como  sendo diabéticas ou normais. Este trabalho obteve, como resultado final, uma precisão  de 82,05%, utilizando a base de dados Pima Indian.    Kayaer e Yıldırım (2003) apresentam um sistema para diagnóstico de diabetes  que foi desenvolvido usando a técnica de regressão geral de redes neurais (GRNN).  GRNN aproxima qualquer função arbitrária entre a entrada e a saída, construindo uma  estimativa da função, diretamente, a partir dos dados de treinamento. Logo, neste  sistema, não é requerido um processo de treinamento iterativo. Este sistema obteve uma  precisão de 80,21% na classificação, utilizando a base de dados Pima Indian.    Rajeswari e Vaithiyanathan (2011) apresentam uma abordagem para auxiliar no  diagnóstico de diabetes tipo 2. A abordagem construída combina a modelagem fuzzy  com a arquitetura de RNA. Inicialmente, as informações do banco de dados são  modeladas em uma abordagem fuzzy, sendo que esse resultado é normalizado e na  sequência classificado por uma RNA back-propagation. Ao final o sistema proposto  classifica as informações, referentes a cada pessoa, como sendo diabética ou normal.  Esse sistema obteve uma taxa de eficiência de 83.3% durante a etapa de teste, em um  banco de dados próprio dos pesquisadores, com 600 pessoas.   O sistema proposto, assim como os demais apresentados, utiliza uma Rede  Neural para diagnóstico do diabetes. Entretanto, ao invés de utilizar a lógica fuzzy,  emprega uma RNA feedforward com múltiplas camadas, que será detalhada na próxima  seção, visando aumentar o índice de acertos nos diagnósticos realizados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     60  4. Sistema Neural para Apoio ao Diagnóstico de Diabetes  O Sistema Neural para Apoio ao Diagnóstico de Diabetes (SND) implementado, tem  como pilar computacional a RNA feedforward, com múltiplas camadas, cujo  treinamento é supervisionado, utilizando o algoritmo de treinamento back-propagation.  A escolha deste algoritmo se deve a sua simplicidade computacional para ajuste dos  pesos sinápticos e a capacidade de representar as relações não lineares e lineares. Além  disso o back-propagation decorre da minimização do erro quadrático entre as saídas da  rede e as saídas desejadas, encontrando parâmetros que conduzam o erro quadrático  assintoticamente para zero. Neste artigo será detalhado o SND, conforme apresentado  na Figura 1. Para desenvolver o sistema foi utilizada a linguagem de programação Java,  juntamente com o Sistema Gerenciador de Banco de Dados SQL Server.     Figura 1: SND: Sistema Neural para Auxílio ao Diagnóstico de Diabetes     A base de dados utilizada tanto para treinar quanto para testar o SND foi a Pima    Indians Diabetes(PID) (UCI, 2014), conforme apresenta, graficamente, a tabela 1, e  descrito na seção 2.3.   Tabela 1. Dados de treinamento e teste da RNA     As primeiras 8 colunas (Nb_pregnant a Body_mass) da tabela 1 se referem às   informações utilizadas para classificar cada uma das 768 pacientes. A coluna 9 informa  classe a qual a paciente pertence, 1 para diabética, e 0 normal.   Para possibilitar a utilização das informações (Nb_pregnant a Body_mass) na  RNA elas foram normalizadas. Sendo assim, cada coluna foi normalizada por meio da  função: . Logo  após, foi definido o target bipolar para a RNA, levando em consideração as informações  da coluna 9, de modo que ele tenha valor 1 para diabéticos e valor -1 para não  diabéticos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     61  Também foram criados 2 subconjuntos oriundos de PID. Para isso foram  selecionados 70% (538) dos pacientes, para o subconjunto de treinamento e os outros  30% (230 pacientes) foram utilizados para o subconjunto de teste da RNA.   De posse destas informações, a RNA foi treinada para alcançar um equilíbrio  entre a capacidade de responder corretamente aos padrões de entrada, que são usados  para treinamento (memorização), e a capacidade de fornecer boas respostas a entradas  desconhecidas (conjunto de teste), mas semelhantes aos padrões de treinamento  (generalização).   O treinamento do SND, usando o algoritmo back-propation envolveu três  estágios: a inserção das informações normalizadas e formatadas como entradas  (feedforward, passos de 1 a 3) pertencentes ao conjunto de treinamento da RNA, o  cálculo da retropropagação do erro (back-propagation, passos de 4 a 5) e o ajuste dos  pesos (passo 6). A seguir é detalhado o algoritmo de treinamento em 6 passos (Fausett,  1994), conforme arquitetura apresentada, graficamente, na figura 2. A arquitetura da  RNA utilizada possui 1 camada de entrada, com  8 neurônios (representados de X1 a  Xn), 1 camada oculta, composta por 10 neurônios (representados de Z1 a Zp) e uma de  saída, com 2 neurônios (Y1 e Y2).     Figura 2: Arquitetura da RNA implementada    1)Defina a taxa de aprendizagem α = 0.03.   2)Inicialize os pesos ( ) e bias ( ) com valores randômicos entre 0.5 e -0,5.   3)Inicie a inserção dos padrões de treinamento nas entradas da RNA. Enquanto a  condição de parada for falsa, faça:    3.1)Aplique o padrão de entrada  nas camadas ocultas .  3.2)Para cada unidade oculta ,j=1, ..., p) defina   .  Aplique a função de ativação bipolar em   e calcule  a saída .    3.3) Para cada unidade de saída  defina  .    3.4)Aplique a função de ativação e calcule a saída .   4)Inicie a retropropagação do Erro.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     62  4.1)Calcule a informação do erro ( ), para cada unidade de saída ( )  conforme o target ( ) do padrão de treinamento de entrada, logo   .   4.2) Calcule o termo de correção dos pesos .   4.3)Calcule o termo de correção dos bias .    5) Para cada unidade da camada oculta ,j=1, ..., p) calcule o delta das entradas  .    5.1) Multiplique o  pela derivada da função de ativação e calcule o  termo da informação do erro .    5.2) Calcule os termos de correção de peso .   5.3) Calcule os termos de correção do bias .    6) Inicie a atualização dos pesos e dos bias.   6.1) Para cada unidade na camada de saída (  atualize os   bias e os pesos:  .Onde   6.2) Atualize os bias e os pesos , para cada unidade da   camada oculta: .  7)Teste a condição de parada.   Considere a função de ativação, com intervalo de [-1, 1], bipolar sigmóide como  sendo  e .   O teste do SND envolve somente a etapa de inserção das informações  normalizadas e formatadas como entradas (feedforward, passos de 1 a 3) pertencentes  ao conjunto de teste da RNA.   4.4. Validação  A validação do SND foi realizada com o subconjunto definido para a etapa de teste,  sendo que estas informações, embora pertencentes ao PID, eram até então,  desconhecidas pelo sistema. O total de pacientes usados para compor o teste foram 230,  destes 70% são classificadas como normal e 30% diabéticas. A arquitetura da RNA  utilizada possui 1 camada de entrada, com  8 neurônios e uma de saída, com 2  neurônios. O número de neurônios na camada de entrada é igual à quantidade de  informações utilizadas para classificar cada paciente, ou seja, 8. Os neurônios da  camada oculta foram obtidos de forma empírica. Já os da camada saída foram fixados  de acordo com as possíveis classificações para cada paciente (diabética ou normal), ou  seja, 2. O sistema proposto realizou 2.262 iterações para chegar aos resultados,  conforme apresenta, graficamente, a figura 3.        Figura 3: Gráfico do Erro Quadrático com as iterações.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 56 -63  Nov/2014     63  O sistema proposto obteve uma taxa de acerto de 81.31%, o que resultou em 187  acertos e 43 erros (18,69%). Este resultado torna o sistema muito promissor,  principalmente se comparado aos resultados obtidos pelos trabalhos apresentados em  Polat (Polat et. al., 2008) e Kayaer e Yildirim (2003).   5. Considerações Finais   Este trabalho apresentou a implementação de um protótipo de sistema inteligente para  apoio ao diagnóstico de diabetes, tipo 2, empregando redes neurais artificiais. Ao  realizar um contraponto com trabalhos que utilizaram a mesma base de dados, PID, tais  como os apresentados em Polat (Polat et. al., 2008) que obteve 82,05% de sucesso, e  com Kayaer e Yıldırım (2003) que obteve 80,21% de sucesso, o sistema proposto,  apresenta-se como uma arquitetura promissora no diagnóstico de diabetes, pois foram  alcançados 81.31% de sucesso. Alguns pesquisadores atribuem o sucesso do  aprendizado da RNA (Massad, 2004) (Fausett, 1994) à técnica utilizada durante o  treinamento. Neste trabalho teve-se uma atenção especial para essa etapa, a começar  pela formação dos subconjuntos de treinamento e teste e, depois com a normalização  das informações. Acredita-se que estes dois pontos contribuíram significativamente para  o sucesso dos resultados alcançados pela RNA implementada.   Referências   BAIER, L. J.; HANSON, R. L. Genetic studies of the etiology of type 2 diabetes in   Pima Indians. Diabetes, 53, 1181–1186, 2004.  BOTELHO, J. M. A. Aspectos Clínicos e Epidemiológicos do Diabetes Mellitus:   Coordenadoria de Doenças e Agravos Não Transmissíveis - Superintendência de  Epidemilogia/SES SUS – MG, 2003.   FAUSETT, L. Fundamentals of Neural Networks: architectures, algorithms and  applications, Prentice Hall International, 1994.   HAYKIN, Simon.  Redes Neurais: princípios e prática.  2 ed. Porto Alegre: Bookman,  2001.   KAYAER, K.; YILDIRIM T. Medical diagnosis on Pima Indian diabetes using general  regression neural networks. In: Proceedings of the International Conference on  Artificial Neural Networks and Neural Information Processing  (ICANN/ICONIP) (pp. 181–184), 2003.   MASSAD, E; MENESES, R. X.; SILVEIRA, P. S. S; ORTEGA, N. R. S. Métodos  Quantitativos em Medicina. Barueri, SP: Manole, 2004.   MAZZAFERRI, E. L. Endocrinologia. Columbus, Ohio: Guanabara, 1988.  PALMA NETO, L. G.; NICOLETTI, M. C. Introdução às Redes Neurais   Construtivas. São Carlos, SP: Editora da Universidade Federal de São Carlos, 2005.  OLIVEIRA, J. E. P.; VENCIO, S. Diretrizes da Sociedade Brasileira de Diabetes.   São Paulo: AC Farmacêutica, 2014.  POLAT, K.; GUNES, S.; ASLAN, A. A cascade learning system for classification of   diabetes disease: Generalized discriminant analysis and least square support vector  machine. Expert Systems with Applications, Volume  34, Issue 1, January 2008,  Pages 482-487.   RAJESWARI, K.; VAITHIYANATHAN, V. Fuzzy based modeling for diabetic  diagnostic decision support using Artificial Neural Network. IJCSNS International  Journal of Computer Science and Network Security. v.11, n.4, 2011.   UCI. University of California, Machine Learning and Intelligent System, School of  Information and Computer Science, 2010. Acessado em: 17/08/2014  https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     64  Sistema de Recomendação Fuzzificado de Objetos de  Aprendizagem   Iulisloi Zacarias, Rafael Antônio Vitalli, Naidú Gasparetto de Souza, Fábio José  Parreira, Sidnei Renato Silveira, Adriana Sadowski de Souza   Universidade Federal de Santa Maria (UFSM) - Centro de Educação Superior Norte  (CESNORS) - Caixa Postal 54 - Frederico Westphalen - RS - Brasil   Departamento de Tecnologia da Informação  iuli.zacarias@gmail.com, rafavitalli@gmail.com, naidu.gaspar@hotmail.com,   fabiojparreira.ufsm@gmail.com, sidneirenato.silveira@gmail.com, adrianasadowski@gmail.com   Resumo. Este artigo apresenta um protótipo de sistema de recomendação de  objetos de aprendizagem, desenvolvido por meio da lógica fuzzy. Este sistema  de recomendação será integrado a uma arquitetura que permita a adaptação  de cursos ministrados na modalidade de Educação a Distância (EaD) de  acordo com o estilo cognitivo dos alunos.    Abstract. This paper proposes a learning objects recommender system  prototype developed with fuzzy logic. This recommender system will integrated  with an architecture definition that enables the adaptation of courses offered in  the form of Distance Education (DE) according to the cognitive style of the  students.    1. Introdução  Os conceitos de rede, ciberespaço e hipermídia como linguagem começaram a se  consolidar com a popularização dos computadores pessoais e da internet, que se deu nos  primeiros anos deste século, ocasionando um desenvolvimento notável das formas de  comunicação hipermidiáticas, principalmente na internet, destacando-se a sua utilização  em vários campos, inclusive no educacional. A hipermídia passou a ser a linguagem do  ciberespaço e da cultura em movimento constante e evolutivo, em que seus valores se  reafirmam, pressupondo um mundo de operações, funções e significações diferenciadas,  vividas e experimentadas pelas pessoas. Ela possui como anteparo uma série de mídias  alocadas em um mesmo suporte e apresenta, através dessa união, uma personalidade  diferente, repleta de interatividade, caminhos e opções para os seus adeptos ou usuários.  Dessa forma, compõe-se como um "mix" de linguagens, unindo várias mídias que se  complementam, sustentando-se como linguagem híbrida (Machado, 2001).   É nesse contexto que a UFSM adotou o Moodle como sendo o seu Sistema de  Gerenciamento de Cursos (Course Management System - CMS). Por meio do Moodle é  possível criar e gerenciar as disciplinas ministradas nos cursos presenciais e a distância,  conforme as normatizações da UFSM. Ao iniciar o processo de construção de uma  disciplina no Moodle, o primeiro ponto a ser considerado é quais objetos de  aprendizagem hipermidiáticos poderão ser ofertados com a finalidade de mediar  pedagogicamente o conteúdo a ser ministrado. Além dessa preocupação inicial, é  importante levar em consideração que cada aluno possui diferentes níveis de  conhecimento e formas diferenciadas de entendimento e aprendizagem. Sendo assim, ao  recomendar alguns Objetos de Aprendizagem (OAs) é importante considerar as  incertezas que o aluno traz consigo acerca do conteúdo abordado. Acredita-se que os  conjuntos fuzzy representam perfeitamente estas incertezas. De acordo com Zadeh  (1965) tais conjuntos são baseados na ideia de que existem situações nas quais não está     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     65  claro se um elemento pertence ou não a um determinado conjunto.  Neste sentido, o presente trabalho propõe um sistema de recomendação que   utiliza a lógica fuzzy em seu algoritmo de recomendação de OAs. O artigo apresenta um  breve referencial teórico sobre as áreas envolvidas (objetos de aprendizagem, sistemas  de recomendação e lógica fuzzy), situa o estado da arte e apresenta o andamento da  solução implementada.     2. Referencial Teórico    2.1 Objetos de Aprendizagem  Um objeto de aprendizagem pode ser constituído de uma única atividade ou de um  módulo educacional completo, ou seja, um conjunto de estratégias e atividades, visando  promover a aprendizagem em sala de aula. Segundo Wiley (2000 apud Souza et. al.,  2013): “Objetos de aprendizagem são elementos de um novo tipo de instrução baseada  em computador construído sobre um novo paradigma da Ciência da Computação. Podese usar como recurso didático um só objeto de aprendizagem, como ele pode ser  agregado a outros, ou seja, objetos de aprendizagem relacionados ao mesmo conteúdo  (assunto) formando um novo objeto de aprendizagem”.   Segundo Tarouco (2004 apud Souza et. al., 2013), as seguintes características  são comuns aos objetos de aprendizagem:    - Reusabilidade: essa característica faz com que os objetos de aprendizagem,  como módulos básicos, sejam utilizados de diferentes formas, para abordar  conteúdos diferentes em contextos diferenciados;   - Portabilidade: é a capacidade que um objeto de aprendizagem tem de ser  executado em diferentes plataformas de trabalho (sistemas operacionais);   - Modularidade: refere-se à forma dos objetos de aprendizagem que deve ser em  módulos independentes e não sequenciais, para poderem ser usados em conjunto  com outros recursos e em diferentes contextos;   - Flexibilidade: devem ser construídos em módulos com início, meio e fim, para  serem flexíveis, podendo ser reutilizados sem manutenção. Isso cria mais uma  vantagem que é a interoperabilidade, ou seja, a reutilização dos objetos não  apenas em nível de plataforma de ensino, mas em nível mundial.  A utilização de objetos de aprendizagem vem crescendo significativamente à   medida que melhora o modo como os objetos são armazenados e distribuídos na  Internet.    2.2 Sistemas de Recomendação  A quantidade de informação produzida e disponibilizada na web pode ocasionar uma  sobrecarga cognitiva sobre o usuário final. Devido a este problema várias tecnologias  têm surgido para apoiar a seleção, recuperação e filtragem da informação desejada ou de  interesse do usuário. Esta recuperação na maioria das vezes é realizada por uma  apresentação explícita das necessidades do usuário, ou seja, uso de palavras-chave. Com  o crescimento do comércio eletrônico e, também, da Educação a Distância (EaD) via  internet, houve a necessidade de oferecer serviços personalizados aos usuários. Sistemas  de recomendação (SRs) (Ricci et. al, 2011) surgiram como uma forma eficiente para  solucionar este problema.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     66  Os Sistemas de Recomendação (SRs) são capazes de aprender com as  preferências do usuário e automaticamente sugerir produtos/serviços/itens que atendam  ao seu perfil. Estes sistemas têm sido muito utilizados no comércio eletrônico com o  objetivo de sugerir produtos ou fornecer informações para ajudar o usuário a decidir  sobre uma determinada compra, bem como em sistemas educacionais, sugerindo  materiais didáticos, cursos e objetos de aprendizagem aos alunos (Schafer et al., 2000).    Segundo Herlocker (2000), por muitos anos os cientistas têm direcionado seus  esforços para aliviar o problema ocasionado com a sobrecarga de informações através  de projetos que integram tecnologias que automaticamente reconhecem e categorizam  as informações. Os sistemas baseados nesta técnica têm como objetivo gerar, de forma  automática, descrições dos conteúdos dos itens e comparar a descrição de cada item  com a descrição dos interesses dos usuários ou com o histórico de consumo e/ou  utilização do mesmo, visando verificar se o item é interessante para o usuário em  questão (Herlocker, 2000).   A descrição de interesses do usuário é obtida através de informações fornecidas  pelo próprio usuário, através do perfil do usuário, através de uma consulta, ou  aprendendo com os itens que o usuário consome (aqueles que o usuário gosta e  compra). Esta técnica é chamada de filtragem baseada em conteúdo (FBC) porque o  sistema realiza a filtragem baseada na análise de conteúdo do item e no perfil do usuário  (Herlocker, 2000).    2.3 Lógica Fuzzy  A teoria de conjunto fuzzy (Zadeh, 1965) é considerada o principal pilar da teoria da  lógica fuzzy, ela difere da tradicional, principalmente, ao que se refere a  descontinuidades. Na fuzzy não há uma distinção abrupta entre elementos pertencentes e  não pertencentes a um conjunto, o que leva à admissão da possibilidade de pertinência  parcial, logo um elemento pode pertencer a um dado conjunto, com determinado grau  de pertinência.   Seja um conjunto fuzzy F em um universo de discurso U, a função de pertinência  de F é definida como: µF: U→[0,1]. O valor 0 (zero) indica a não pertinência e o valor  1 (um) a pertinência plena. Este mesmo conjunto é representado por pares ordenados de  µF e u. Sendo u um elemento qualquer e, µF o seu grau de pertinência, neste sentido,  tem-se: F = {µF(u)/u}, u ∈ U.    Entre os conjuntos fuzzy é possível realizar operações. Sendo A e B conjuntos  fuzzy de U, a operação de união, equivalente operador max, é representada por:   . Por sua vez, a operação de interseção,  equivalente ao operador min, é definida por: .   O produto cartesiano é similar à operação de intersecção, tendo-se A1,A2,...,An  como conjuntos fuzzy em U1,U2,...,Un respectivamente. O produto cartesiano, destes,  resulta em um conjunto fuzzy no espaço denotado por U1xU2x,...,xUn, cuja função de  pertinência é:  µA1x µA2x,...,x µAn (u1, u2,..., un,) = min{ µA1( u1), µA2( u2),...,µAn(uAn)} .   Por definição, o produto cartesiano fuzzy é uma relação fuzzy. Uma relação fuzzy  n-ária é definido por: RA1x,RA2x,...,xRAn={µR(a1,a2,...,an)/(a1,a2,..,an)}|(a1,a2..,an)}, ai∈Ai,  i=1,...,n. A composição entre relações, conforme proposta de Zadeh (1965), é a operação  denominada max-min. Logo, a composição entre as relações R e S, em U1xU2 e U2xU3  respectivamente, é denotada por RοS, cuja função de pertinência, é fornecida por:    .     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     67    3. Estado da Arte  Existem diversos sistemas de recomendação de objetos de aprendizagem apresentados  na literatura. Entretanto, não foram encontrados sistemas que apliquem a lógica fuzzy.  Existem sistemas implementados por meio de sistemas multiagentes, tais como os  propostos por Muniz (Muniz et.al., 2012) e Silva (Silva et. al., 2011). Outros sistemas,  tais como os propostos por Cazella (Cazella et. al., 2009) e Zaina (Zaina et. al, 2012)  utilizam algoritmos de recomendação com técnicas de filtragem colaborativa ou de  filtragem baseada em conteúdo.   Muniz (Muniz et. al. 2012) propõe uma abordagem de recomendação baseada  em agentes, recomendando OAs que utilizam o padrão T-SCORM. O padrão TSCORM é uma extensão do padrão SCORM (Shareable Content Object Reference  Model), visando a apresentação de OAs em televisões digitais interativas. O sistema  multiagente (SMA) conta com quatro agentes: estudante, conteúdo, interface e DF. O  agente estudante monitora as atividades dos alunos e envia, para o agente de conteúdo,  informações sobre o perfil do estudante (informadas, explicitamente, pelos alunos) -  estático, além de capturar informações dinâmicas sobre a utilização do sistema. O  agente de conteúdo é o responsável por buscar os OAs no repositório e  selecionar/recomendar os mais indicados para o estudante, utilizando a técnica da  filtragem baseada em conteúdo, considerando os atributos dos OAs e o perfil dos  estudantes. O agente de interface exibe os OAs e o agente DF armazena os serviços que  cada agente oferece na arquitetura. Os agentes foram desenvolvidos utilizando o JADE  (Java Agent Development Framework).   Silva (Silva et. al., 2011) apresenta um ambiente multiagente de aprendizagem, o  MobiLE – ambiente multiagente de aprendizagem móvel para apoiar a recomendação  sensível ao contexto de objetos de aprendizagem. Esta arquitetura também foi  desenvolvida utilizando-se o JADE e o perfil do aluno possui informações estáticas e  dinâmicas, como no trabalho anterior. O diferencial desta arquitetura é que a  recomendação utiliza as técnicas de filtragem baseada em conteúdo (atributos dos OAs  comparados ao perfil do estudante) e de filtragem colaborativa (comparação de  estudantes com preferências semelhantes). A arquitetura conta com três agentes: agente  estudante, agente recomendador e agente de interface. O ambiente móvel foi construído  utilizando-se o framework de desenvolvimento de aplicações MLE (Mobile Learning  Engine).   Uma abordagem de recomendação baseada em filtragem colaborativa e  competências é proposta por Cazella (Cazella et. al., 2009). A recomendação de OAs é  realizada por meio dos gostos dos alunos por determinados objetos de aprendizagem,  bem como pelas competências que devem ser desenvolvidas, estabelecidas pelos  professores. A filtragem colaborativa baseia-se na avaliação que é dada pelos alunos aos  OAs e a similaridade entre os alunos é calculada por meio do coeficiente de Pearson.  Após a definição da predição, o sistema verifica se as competências que devem ser  adquiridas pelo aluno, estabelecidas pelo professor, estão de acordo com os OAs  potencialmente recomendados. A abordagem de recomendação foi validada por meio de  um protótipo desenvolvido em Java.   Zaina (Zaina et. al., 2012) apresenta uma abordagem de recomendação de OAs  denominada e-LORS (e-Learning Object Recommendation System) baseada no  relacionamento entre as dimensões que incorporam as preferências de aprendizagem de  um aluno e os metadados que descrevem os OAs. O sistema de recomendação utiliza a  filtragem baseada em conteúdo, confrontando-se as informações do tema de estudo, o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     68  perfil de aprendizagem do aluno e as possíveis restrições tecnológicas que caracterizam  o ambiente eletrônico em que o aluno interage.    Diferentemente dos sistemas apresentados, este trabalho propõe a recomendação  empregando a lógica fuzzy, tendo-se em vista a possibilidade de considerar as incertezas  que os alunos possuem com relação ao conteúdos (OAs) a serem recomendados.    4. Sistema Fuzzificado Implementado  O Sistema Fuzzificado de Recomendação de Objetos de Aprendizagem (OAs) consiste  em três módulos: o cadastro/alteração de questões, cadastro/alteração de OAs e o  Sistema de Recomendação Fuzzificado de OAs (SRF). Neste artigo será detalhado o  SRF, conforme apresentado na Figura 1.  Para desenvolver o sistema foi utilizada a  linguagem de programação Java, juntamente com o Sistema Gerenciador de Banco de  Dados SQL Server.    Figura 1: SRF: Sistema de Recomendação Fuzzificado de OAs     Inicialmente, é apresentado um questionário ao aluno, contendo dez questões  sorteadas aleatoriamente. Cada questão possui cinco alternativas, que podem ser  marcadas com “V” (verdadeiro) “F” (falso), valendo dois pontos cada.   A equação para calcular os acertos é definida como:  , onde N é o total de alternativas da   questão. Ao final, o questionário produz um conjunto de dados crisp (ou valores  numéricos não fuzzy) da avaliação contendo as notasQuestões(Q1,..,10)=[Q1,...,Q10].    O fuzzificador de dados consiste em converter os dados de entrada em valores  fuzzy, por meio do mapeamento de números reais em conjunto fuzzy. Neste processo a  metodologia de fuzzificação adotada é o conjunto singular. Um fuzzificador singular  mapeia um ponto real u* ∈ U→[0,10] em um conjunto difuso singular F’ em U, que  possui valor de pertinência 1 em u* e 0 em todos os outros pontos em U (Wang, 1997),  conforme segue: . O fuzzificador produz um  conjunto de pares ordenados contendo as notasQuestões(Q1,..,Q10), e seus respectivos  graus de pertinência µQ1,..,µQ10.   A base de conhecimento é composta por uma base de dados e uma base de  regras. A base de dados é formada pelas variáveis de entrada (Conhecimento) e saída  (Recomendação). Graficamente, o Conhecimento e a Recomendação são representados  na figura 2.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     69    Figura 2: Conhecimento do aluno e Recomendação de OAs     Os conjuntos fuzzy da variável de entrada conhecimento são: NS (Não satisfaz)-   conhecimento inferior a 4, indica que o conhecimento do aluno, referente ao conteúdo  previamente estabelecido, está muito abaixo do esperado; SP (Satisfaz parcialmente)  conhecimento em torno de 5 e 7. Neste caso, o aluno está com um pouco de dificuldade  em seu aprendizado; S (Satisfaz) conhecimento superior a 8. O aluno já possui  conhecimentos necessários para conseguir êxito no aprendizado do conteúdo.    Para a variável de saída, Recomendação, os conjuntos fuzzy são: B (Básico) ao  serem recomendados OAs básicos, significa que o aluno está com o conhecimento bem  deficitário, precisando suprir a maioria dos conceitos exigidos na disciplina; I  (Intermediária): para essa recomendação, o aluno está quase conseguindo acompanhar  os conteúdos ministrados em sua integralidade, sendo necessário apenas um pequeno  reforço; A (Avançado): esta recomendação tem a finalidade de manter a aprendizagem  interessante, para aluno que já adquiriu, de alguma forma, os conceitos que serão  ministrados na disciplina, neste caso, são recomendados OAs que representam certo  desafio ao conhecimento do aluno.   A base de regras tem por finalidade associar as variáveis linguísticas de entrada  com as de saída (Campos e Saito, 2004). Sendo assim, ela define as estratégias de  resposta do sistema, por meio de uma coleção de afirmações condicionais, que tem a  forma “Se<antecedente>então<consequente>” (Zadeh, 1988).   Conforme a proposta deste trabalho, o questionário utilizado para quantificar o  conhecimento do aluno possui dez questões, por isso as afirmações condicionais  possuem como antecedentes a variável ConhecimentoQ1,...,Q10, cuja cardinalidade é três  (NS, SP, S). Para a saída, que é o consequente da regra, foi definida a variável  Recomendação, cuja cardinalidade também é três (B, I e A). Sendo assim, as regras  propostas, para recomendar os OAs, são formadas por dez antecedentes e um  consequente, neste contexto, elas podem ser escritas com conjunções (conectivo e) no  antecedente:   R1=SE(Q1 é NS) e (Q2é NS) e (Q3é NS) e (Q4é NS) e (Q5é NS) e (Q6é NS) e (Q7é NS)  e (Q8é NS) e ( Q9 é NS) e (Q10 é NS) ENTÃO Recomendação é B   Rn=Se(Q1 é S e Q2é S e Q3é S e Q4é S e Q5é S e Q6é S e Q7é S e Q8é S e Q9 é S e Q10  é S) então Recomendação é A   Sendo que R1 a Rn são as regras fuzzy inseridas pelos especialistas. O total de  regras a serem inferidas pelo SRF, representado pelo valor de n, é calculado de acordo  com a equação: . Logo o total de  regras é: .   A máquina de inferência, adotada neste trabalho, é baseada na inferência maxmin, proposta por Mamdani (1974).  A seguir é definido um caso especial de inferência,  que é utilizado no SRF, para recomendação de conteúdos. Neste sentido a máquina de  inferência proposta possui duas tarefas bem distintas: agregação e composição. Na  agregação deve-se calcular a importância de cada regra, por meio do coeficiente de  disparo, para selecionar as mais pertinentes à situação corrente. Já na composição  calcula-se a influência de cada regra selecionada, nas variáveis de saída. Neste contexto,  conforme descrito nos passos abaixo, para cada regra, tem-se:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     70   Passo 1: Localiza-se a compatibilidade das entradas (q1, q2...q10), por meio do  grau de pertinência( ,   ou ), conforme apresentado,  graficamente, na figura 2.    Passo 2: Calcula-se a medida do coeficiente de disparo, de cada regra, por meio  da conjunção dos antecedentes:         Passo 3: Ao selecionar todas as regras, cujo , no resultado de cada uma é   aplicado: , onde N é o total de regras selecionadas.   Passo 4: Na agregação dos resultados, , de cada regra, R1, R...Rn, aplica-se:   . Ao final  do passo 4, R é um conjunto fuzzy com seus respectivos elementos e graus de  pertinência, por exemplo: .  A defuzzificação consiste em converter os valores fuzzy de saída em valores   numéricos. Para realizar a conversão, utilizou-se o critério do método do centro de área,  conforme apresentado: , onde  n é o número elementos. Considerando a aplicação desta equação, na saída R, tem-se a  saída defuzzificada como sendo igual a:       A recomendação de OAs é concretizada aplicando-se o  à   variável de saída Recomendação, que três conjuntos fuzzy: B, I e A. De acordo com a  figura 3, tem-se , portanto, este aluno está com grau de pertinência igual a 1,  no conjunto fuzzy intermediário. Logo, os OAs estão em um nível de dificuldade  considerado intermediário. Neste nível, o aluno está quase conseguindo acompanhar os  conteúdos ministrados em sua integralidade, sendo necessário apenas um pequeno  reforço no aprendizado.    5. Considerações Finais  O presente trabalho estabelece um método computacional capaz de interpretar as  competências dos professores, no tangente à recomendação de OAs, em determinado  conteúdo. Este método resultou no Sistema de Recomendação Fuzzificado, que é capaz  de imitar parte do raciocínio humano, e tem como cerne a lógica fuzzy. Ao fazer uso da  lógica fuzzy, que quantifica as incertezas humanas, o sistema demostrou ser uma  importante ferramenta para a recomendação de OAs, pois direciona os alunos em seus  estudos, considerando as incertezas sobre o melhor material a ser estudado, levando em  consideração as dificuldades de cada estudante. Durante a etapa de testes, foram  realizadas pesquisas com 20 alunos, cujas informações foram geradas aleatoriamente.  Destes, somente em 5 casos o sistema não se comportou adequadamente, conforme os  especialistas, foi quando o  é maior que 70 e menor que 75. Para  estes valores o SRF recomenda OAs cujo nível de dificuldade é intermediário. Já os  especialistas concordam que este estudante tem condições de estudar em conteúdos  avançados. Para resolver tal impasse faz-se necessário implementar testes com uma  quantidade maior de conjuntos fuzzy, tanto de entrada quanto de saída, para representar  melhor as incertezas do conhecimento do aluno. O sistema proposto apresenta-se como     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 64 -71  Nov/2014     71  uma arquitetura promissora para a recomendação de OAs, pois foram alcançados 75%  de sucesso. Como trabalhos futuros, pretende-se integrar o SRF à arquitetura de  adaptação apresentada em Souza et. al. (2013). Além disso, pretende-se aplicar  metodologias para pré-selecionar as regras que irão compor a base de regras,  diminuindo assim, a quantidade de regras a serem analisadas.     Referências  Campos, M. M. de; Saito, K (2004). “Sistemas Inteligentes em Controle e Automação de   Processos”. Rio de Janeiro: Ciência Moderna.  Cazella, S. C.; Reategui, E. B.; Machado, M.; Barbosa, J. L. V. (2009). “Recomendação de   Objetos de Aprendizagem empregando Filtragem Colaborativa e Competências”. Anais do  XX Simpósio Brasileiro de Informática na Educação.   Herlocker, J. L. (2000). “Understanding and Improving Automated Collaborative Filtering  Systems”. University of Minnesota, Minnesota.   Machado, A. (2001). “O quarto iconoclasmo (e outros ensaios hereges)”. Rio de Janeiro:  Contracapa.   Mamdani, E. H. (1974). “Application of Fuzzy Algorithms for Control of Simple Dynamic  Plant”. IEEE (Control and Science), v.121(12), p.1585-1588.   Muniz, R. C.; Mendes Neto, F. M.; Burlamaqui, A. M. F.; Souza, R. C. (2012). “Uma  Abordagem Baseada em Agentes para Recomendação de Objetos de Aprendizagem  utilizando o padrão T-SCORM para TVDi”. Revista Novas Tecnologias na Educação. V. 10,  n. 3, dezembro.    Ricci, F.; Rokach, L.; Shapira, B.; Kantor, P. B. (2011). “Recommender Systems Handbook”.  Springer.   Schafer, J. B.; Konstan, J.; Riedl, J. (2000). “Recommender Systems”. In: Conference on  Electronic Commerce, Minneapolis. Proceedings.   Silva, L. C. N.; Mendes Neto, F. M.; Jácome Júnior, L. (2011). “MobiLE: um ambiente  multiagente de aprendizagem móvel para apoiar a recomendação sensível ao contexto de  objetos de aprendizagem”. Anais do XX Simpósio Brasileiro de Informática na Educação.   Souza, N. G.; Silveira, S. R.; Bigolin, N. M.; Parreira, F. J.; Cunha; G. B. (2013). “Arquitetura  para Adaptação de Cursos na Modalidade de Educação a Distância empregando Objetos de  Aprendizagem”. Anais do EATI – Encontro Anual de Tecnologia da Informação.  UFSM/CAFW.   Wang, L. (1997). “A Course in Fuzzy Systems and Control”. New Jersey: Prentice-Hall  International, Inc.   Zadeh, L. A. (1965). “Fuzzy sets”.  Information and Control, v. 8, n. 3, p. 338–353.  Zadeh, L. A. (1988). “Fuzzy logic”. Computer 21(4): 83–93.  Zaina, L. A. M.; Bressan, G.; Cardieri, M. A. C. A.; Rodrigues Júnior, J. F. (2012). “e- LORS:   uma abordagem para recomendação de objetos de aprendizagem”. Revista Brasileira de  Informática na Educação. V. 20, n. 1.          
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     72  Estudo de Frameworks Multiplataforma Para  Desenvolvimento de Aplicações Mobile Híbridas   Ezequiel Douglas Prezotto1,  Bruno Batista Boniati1   1Tecnologia em Sistemas para Internet - Universidade Federal de Santa Maria(UFSM)  Frederico Westphalen – RS – Brasil   prezotto.ezequiel5@gmail.com, bruno@cafw.ufsm.br      Resumo. Com o expressivo crescimento dos dispositivos móveis, suas  variedades de modelos, fabricantes e sistemas operacionais aumentaram  muito. Havendo a necessidade de se disponibilizar um software que atenda  todas (ou mais de uma) plataforma, será necessário desenvolver uma  aplicação especifica para cada uma delas. Tal requisito eleva muito os custos  e o tempo do desenvolvimento. Neste contexto surgem as aplicações híbridas,  que permitem que uma mesma aplicação funcione em diferentes plataformas.  Objetiva-se estudar e analisar os frameworks para desenvolvimento de  aplicações híbridas, bem como características e desempenho.   Abstract. The significant growth of mobile devices, their varieties of models,  manufacturers and operating systems has greatly increased. With the need for  software that attends all platforms available, it will be necessary to develop a  specific application for each of them. This requirement raises a lot the cost  and the time spend on development. In this contest arise hybrid applications,  which allow the same application running on different platforms. Objective is  to study and analyze frameworks for developing hybrid applications as well as  features and performance.     1. Introdução  Com o expressivo crescimento das tecnologias móveis, experimentado ao longo dos  últimos anos, observa-se que a diversidade de tais equipamentos aumentou muito.  Consequentemente o número de plataformas e ambientes/linguagens de programação  para desenvolvimento de aplicações também foi incrementado. Tal situação encarece e  complexifica o desenvolvimento de uma aplicação que venha a atender a todos  dispositivos, pois é necessário conhecimentos específicos de cada plataforma, e também  que seja desenvolvida uma aplicação diferente para cada plataforma.    Neste contexto surgem as aplicações híbridas, em que se desenvolve apenas uma  aplicação, e esta pode ser utilizada em vários dispositivos com diferentes sistemas  operacionais. Isso é possível graças aos frameworks para desenvolvimento de aplicações  híbridas, que são responsáveis por empacotar o código-fonte para as diferentes  plataformas, permitindo que elas sejam instaladas no dispositivo, e possam acessar os  seus recursos, como câmera, GPS e contatos.    Este trabalho visa demonstrar características da programação de aplicações  híbridas os seus pontos fortes e fracos, além de destacar os principais frameworks para  desenvolvimento de aplicações híbridas, que habilitam acesso a recursos nativos, bem   como os frameworks de UI (User Interface - interface do usuário).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     73   Para melhor compreender o funcionamento dos frameworks para  desenvolvimento e das aplicações híbridas, foi desenvolvido um estudo de caso. Neste  estudo, uma aplicação (diário de classe escolar) foi desenvolvida, utilizando-se de  frameworks para aplicações híbridas e disponibilizada em diferentes plataformas.  Entende-se que além de servir como meio de análise do estudo, a aplicação também  resulta em um software útil em meio acadêmico.     2. Dispositivos e Plataformas  Dispositivo móvel é todo aquele equipamento, que pode ser levado a qualquer lugar.  Quanto menos dependente de características físicas, maior será o grau de mobilidade.  Por exemplo, a bateria: quanto maior a duração e menor o tempo de recarga maior a  mobilidade provida pelo dispositivo [MORIMOTO 2009].   São considerados dispositivos móveis os celulares, tablets e outros dispositivos  do gênero que ofereçam mobilidade e autonomia. O presente trabalho não considera  laptops (notebooks ou netbooks) como dispositivos móveis já que ao contrário de  celulares, o usuário não os mantém o tempo todo funcionando e utilizando, apenas o  transporta para o local onde irá utilizá-lo.   Hoje existem muitas plataformas para desenvolvimento móvel, como Android,  iOS, Windows Phone, Firefox OS, BlackBerry, Ubuntu Touch, Fire OS, entre outros.  Cada plataforma possui diferentes formas e linguagens para desenvolvimento, como por  exemplo o Android utiliza Java como linguagem de programação, Firefox OS utiliza  linguagens web (HTML, CSS, JavaScript), iOS utiliza Objetive C.    Cabe ao desenvolvedor ou a equipe de desenvolvimento optar pela plataforma e  pela quantidade de sistemas diferentes que a aplicação deve dar suporte e assim escolher  a forma de desenvolvimento que melhor vai se adequar. Ao fazer esta análise deve-se  levar em conta, os conhecimentos dos desenvolvedores, a quantidade de plataformas  que deverão ser suportadas, o tempo para desenvolvimento, e a quantidade de recursos  que a aplicação vai consumir.     3. Tipos de Aplicações  Além das aplicações híbridas que são o foco do trabalho também serão demonstradas as  aplicações nativas e as Web Apps, para que se possa observar as diferenças entre as  mesmas, e identificar em quais situações determinado tipo de aplicação melhor se  adequa.      3.1 Aplicações Nativas  As aplicações nativas são as que foram desenvolvidas especialmente para aquela  plataforma e somente para ela, utilizando para isso as ferramentas disponibilizadas para  a mesma, como a linguagem de desenvolvimento, ambiente e emulador. A tabela 1  demonstra as principais plataformas existentes bem como suas e características  específicas.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     74  Tabela 1. Listagem de plataformas e suas características  Plataforma IDE Loja de App Linguagem   Android Eclipse Google play Java   IOS XCODE Apple Store Objective-C   Windows Phone Visual Studio WindowsPhone store C#   Firefox OS N/D Mozilla Marketplace Javascript,CSS,HTML   BlackBerry Momentics BlackBerry World C+   Web OS WebOS3.0 SDK WebOS Nation Javascript C/C++   Ubuntu Touch Ubuntu SDK  HTML5, Javascript,CSS   Bada Bada IDE Bada Brasil C++   Symbiam Symbian SDK  C++   Tizen Tizen SDK  C++,HTML5 e Java   Fire os SDK próprio  C, C++, Java    Aplicativos desenvolvidos na linguagem nativa do sistema tem um melhor  desempenho, apesar das outras tecnologias de desenvolvimento terem evoluído bastante  quase que se equiparando. Um ambiente já preparado para o desenvolvimento nativo,  agiliza muito o processo, que é insignificante se for preciso desenvolver para inúmeros  sistemas diferentes, pois a cada sistema é necessário se desenvolver uma aplicação  específica, diferindo assim das outras formas de desenvolvimento mostradas a seguir.   3.2 Web App  Além das aplicações nativas de cada plataforma existe também as Web Apps.  Basicamente são aplicações Web que rodam no browser do dispositivo, dessa forma não  é necessário se preocupar com as diferentes linguagens, pois ela utiliza padrões web  como HTML, CSS e JavaScript para o lado do cliente e PHP, Java ou outras linguagens  para o lado servidor.   Mesmo se utilizando a mesma linguagem para todos os sistemas operacionais,  estas aplicações podem se comportar de maneiras distintas, dependendo se o browser do  dispositivo suporta ou não determinado componente da aplicação, ou mesmo  dependendo da forma como o browser realiza o processamento gráfico da aplicação  [W3C 2014].   Para estas aplicações não é necessário que a mesma seja desenvolvida  especificamente para dispositivos móveis, pois apenas tendo layout responsivo, é  possível fazer com que a mesma aplicação que foi desenvolvida para desktop seja  utilizada em um smartphone. Existem aquelas que foram desenvolvidas pensando  especificamente em dispositivos móveis, que podem ser melhor otimizadas para os  mesmos.     3.3 Híbridas  Estas são aplicações que possuem como finalidade funcionar em qualquer que seja o  dispositivo, sendo que para as diferentes plataformas, será utilizado o mesmo códigofonte. Aplicações híbridas ficam instaladas no dispositivo e podem funcionar  independentemente de se ter ou não conexão com internet. Partindo do princípio de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     75  utilizar uma mesma aplicação para diferentes plataformas, normalmente as aplicações  híbridas são desenvolvidas em linguagens Web que são interpretadas pelo browser  nativo do sistema. Possuem tanto características de aplicações nativas como de web  apps.   Apesar de serem feitas em linguagens web estas aplicações não são Web App,  elas ficam instaladas no dispositivo e quando são acionadas chamam o browser, onde  serão executadas, independente de estarem conectadas à internet. Como são executadas  no browser e este está sujeito à padronização pela W3C, as aplicações que são  desenvolvidas e testadas em uma plataforma devem funcionar da mesma forma nas  outras.    Através do estudo destas diferentes formas de desenvolvimento de aplicações  móveis, foi elaborado um comparativo representado pela figura 1, demonstrando a quais  quesitos cada tipo de aplicação oferece suporte. Aplicações nativas tem acesso a todos  recursos do aparelho como câmera, GPS, contatos, por exemplo. Da mesma forma as  aplicações híbridas que graças ao framework é possível acessar estes recursos, já as web  app tem acesso limitado.      Figura 1. Comparativo dos diferentes tipos de aplicações   Aplicações nativas e hibridas podem ser disponibilizadas através das lojas de  aplicativos, uma vez que elas ficam instaladas no aparelho, ao contrário de uma web app  que nada mais é que um site para dispositivos móveis. Apenas as aplicações nativas é  que são desenvolvidas para plataformas específicas, as web app e aplicações híbridas  em geral independem da plataforma.   4. Frameworks  Os frameworks para desenvolvimento de aplicações híbridas separam-se em dois tipos,  os responsáveis pela interface (UI – User Interface), e aqueles que empacotam a  aplicação para as diferentes plataformas e permitem que ela acesse os recursos do  aparelho.   4.1 Frameworks de UI  Os frameworks de UI, são os responsáveis por definir a aparência que vai ter a  aplicação, sendo ela uma aplicação nativa, Web App ou híbrida, todas tem uma  interface com o usuário. A parte visual da aplicação é aquela que dá a primeira  impressão e que pode causar maior aceitação ou maior rejeição da aplicação. Um  aplicativo com interface amigável e fácil de usar, tem maiores chances de ganhar a  preferência dos usuários se comparado a um que, mesmo tendo a mesma funcionalidade     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     76  ou até outras, apresenta-se com uma interface difícil de usar e pouco intuitiva  [MANZOTTI, 2013].   Segundo Prates e Barbosa (2010), o design de interfaces em sistemas interativos  é uma tarefa tão relevante que se tornou uma das subáreas da interação humanocomputador (IHC) que, por sua vez, visa estudar, planejar e entender como as pessoas e  dispositivos computacionais podem interagir de forma que as necessidades delas sejam  contempladas da forma mais efetiva possível.   Para aplicações nativas existe certa padronização das interfaces, já que elas  obedecem as regras da plataforma, já para as web app e híbridas, podem ser utilizados  os frameworks para desenvolvimento web, como jQuery ou Bootstrap entre outros. Não  é necessário que o framework seja especifico para dispositivos móveis, embora um   específico poderia proporcionar melhor experiência, tanto em e performance quanto em  usabilidade.   4.1 Fameworks  para Acesso a Recursos Nativos  Segundo Ribeiro e Freire (2013), definimos um framework multiplataforma como um  conjunto de arquivos de código-fonte, bibliotecas e ferramentas que oferece suporte a  mais de uma plataforma, pelo menos duas plataformas diferentes. Nesta definição, iOS  e Android são duas plataformas diferentes, iOS 5 e iOS 6 não são, e permite o  desenvolvimento sem ramificações do código-fonte, ou seja o mesmo código para todas  plataformas [RIBEIRO; FREIRE 2013].   Desta forma os frameworks devem possuir uma linguagem unificadora, ou seja,  a mesma para todas as plataformas, APIs que permitam que se possa acessar da mesma  forma um recurso em um Android ou em um Firefox OS, e que possibilite acesso da  aplicação aos recursos nativos do sistema. Durante o estudo foram encontrados vários  frameworks, como  o Titanium [TITANIUM, 2014] , o Trigger.io [TRIGGER, 2014], o  Adobe Phonegap [ADOBE, 2014] e o Apache Cordova [APACHE, 2014].   Após analisar as formas de desenvolvimento de cada plataforma, sua linguagem  e outras características optou-se, para o estudo de caso, o framework do Apache  Cordova. A decisão baseou-se no fato de o mesmo utilizar linguagens web como  HTML, CSS e JavaScript, além disso possuir um maior número de plataformas  suportadas, por possuir maior popularidade (tendo um maior número de  desenvolvedores), além de boa documentação. O Apache Cordova teve origem do  framework Phonegap, que foi adquirido pela Adobe e posteriormente doado à fundação  Apache sendo chamado assim de Cordova, a Adobe deu continuidade ao projeto  Phonegap, adicionando outros produtos como o Phonegap Build.   O framework faz a ponte entre a aplicação e o dispositivo, através de suas APIs,  também com ele é possível empacotar a aplicação, ou gerar o executável para cada  plataforma diferente. Ele é compatível com todos os sistemas operacionais e por não  possuir interface gráfica, todas as operações são feitas por linha de comando:   • Criar projeto: cordova create nomeDaPasta br.com.meu.projeto "nome do  projeto".   • Adicionar plataforma: cordova platform add android(ou iOS, wp7, wp8,  firefoxos).   • Adicionar plugins: cordova plugin add org.apache.cordova.geolocation.  • Compilar:cordova build.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     77  5. Estudo de Caso  De forma a validar as ideias apresentadas por este trabalho, pensou-se em desenvolver  uma aplicação útil, de objetivo prático e funcional, que permite fazer o maior número  possível de testes, para que se possa revelar quais seriam os pontos fortes e fracos das  aplicações híbridas e dos respectivos frameworks utilizados. Considerando tais  requisitos optou-se pelo desenvolvimento de uma aplicação para controle de presenças  na sala de aula.   A aplicação desenvolvida independe de conexão com internet, já que utiliza  banco de dados local e fica instalada no dispositivo, permitindo assim que usuários  possam utilizá-la em locais desprovidos de conexão com a internet. Também se buscou  desenvolver uma aplicação fácil e prática de se utilizar, com bom desempenho e boa  condução ao usuário. Para comprovar o funcionamento das aplicações híbridas, ela  também deve ser testada em mais de uma plataforma, e acessar recursos nativos do  aparelho.   Foram utilizadas para desenvolvimento as linguagens HTML, CSS e JavaScript,  e como editor de código o SublimeText, por se tratarem linguagens web, os testes de  interface puderam ser realizados diretamente no browser. Já testes a outros recursos  como câmera foram feitos diretamente em um dispositivo Android, e os teste  multiplataforma em emuladores como do Firefox OS, Windows Phone e BlackBerry.   Por se tratarem muitas vezes de dispositivos com pouca capacidade de  armazenamento e processamento, foi estruturada uma base de dados simples, que se  encarregue de responder a todas as requisições de forma rápida, para isso foi utilizado o  Web SQL [WEBSQL, 2014], além disso, para armazenamento de informações  adicionais, foi utilizado o LocalStorage [LOCALSTORAGE, 2014], principalmente  para variáveis de controle.   Na aplicação desenvolvida é possível cadastrar alunos e turmas, para em seguida   criar uma aula e marcar os alunos presentes. No cadastro do alunos é possível tirar uma  foto do mesmo para uma melhor identificação durante o processo da chamada. Para  obter acesso às funcionalidades da aplicação o professor deve primeiramente fazer o  login na aplicação, este acesso ficara disponível a ele até que seja feito o logoff.   Os testes da aplicação foram feitos em dispositivos Android e no emulador dessa  plataforma, além disso, também foram feitos testes nos emuladores do Firefox OS e  Windows Phone 7, para assim demonstrar o comportamento da aplicação nestas  diferentes plataformas.   Para admitir um resultado mais preciso, os testes realizados durante o  desenvolvimento da aplicação, foram feitos em plataforma Android, e após concluído o  desenvolvimento, foi então feito o teste nas demais plataformas. Durantes os testes foi  percebido que a interface da aplicação sofre poucas mudanças nas diferentes  plataformas. As mesmas mudanças que sofreriam as aplicações web, por exemplo, em  diferentes browsers.    Foi notado que cada plataforma, interpreta os componentes da aplicação de  formas distintas, como um campo data que no Firefox OS é exibido uma espécie de  calendário para selecioná-la, da mesma forma que o Android , já no Windows Phone 7  este campo é interpretado como uma campo de texto normal obrigando ao usuário a  digitar a data. Pode-se observar na figura 2 um exemplo disso, em uma das telas do  aplicativo desenvolvido, existe um campo de data, que foi interpretado de formas  distintas, nas diferentes plataformas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     78    Figura 2. Comparativo da Aplicação em Diferentes Plataformas       Além da interface, outros componentes da aplicação também se comportaram de  formas distintas nas diferentes plataformas, como por exemplo a base de dados que  utiliza Web SQL, a plataforma Windows Phone 7 não oferece suporte. Nestes casos  deve se pensar em opções alternativas como o IndexedDB [INDEXEDDB, 2014], que  são suportadas por um maior número de plataformas. Por se tratar de uma aplicação de  testes, a utilização do Web SQL dentre outros componentes foi proposital.   6. Conclusões  Ao longo do trabalho buscou-se demonstrar de forma imparcial, dando enfoque nas  aplicações híbridas, os diferentes tipos de desenvolvimento de aplicações para  dispositivos móveis, relatando as características de cada tipo de desenvolvimento.  Destaca-se que não existe uma opção melhor que a outra, mas sim que situações onde  uma opção se adapta melhor do que as outras, cabendo a desenvolvedor decidir qual  melhor se enquadraria em sua necessidade.    Pode-se concluir com base no estudo que comprovadamente as aplicações  híbridas, podem através de um mesmo código fonte originar aplicações para diferentes  plataformas. Também se pode constatar que uma aplicação híbrida possui acesso a  todos recursos do dispositivo, e pode também ser disponibilizadas juntamente com as  aplicações nativas, nas lojas de aplicativos. Porém também pode-se identificar que elas  não se comportam da mesma forma, por isso é muito importante fazer uma análise dos  requisitos, para identificar se a plataforma dará ou não suporte a eles.    Como a aplicação não tem fins lucrativos, todos os códigos-fonte serão  disponibilizados, a partir do Github. Além disso, pretende-se publicar a aplicação nas  lojas oficiais do maior número de plataformas possíveis, para possibilitar o acesso a ela  por todos, além de dar continuidade melhorando-a e adicionando novas funcionalidades.   7. Referências  ADOBE. Disponível em: http://phonegap.com/, Acessado em: Maio/2014.   APACHE. Disponível em: http://cordova.apache.org/, Acessado em: Maio/2014.  INDEXEDDB. Disponível em http://www.w3.org/TR/IndexedDB/, Acessado em:  Agosto /2014.   LOCALSTORAGE. W3C. Web Storage. Disponível em:  http://www.w3.org/TR/webstorage/, Acessado em: Maio/2014.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 72 -79  Nov/2014     79  MANZOTTI, C. S. Design de Interface em Dispositivos Móveis. 2013.   MORIMOTO, C. E. Smartphones Guia Prático. [S.l.]: Sul Editores, 2009.  PRATES, R. O.; BARBOSA, S. D. J. Avaliação de Interfaces de Usuário: conceitos e   métodos. 2010.   RIBEIRO, R.; FREIRE, P. Frameworks de Desenvolvimento Móvel Multiplataforma.  In: CONFERêNCIA DA ASSOCIAçãO PORTUGUESA DE SISTEMAS DE  INFORMAÇÃO, 13., 2013. Anais. . . [S.l.: s.n.], 2013.   TITANIUM. Mobile Development Environment. Disponível em:  http://www.appcelerator.com/titanium/, Acessado em: Maio/2014.   TRIGGER. The Simplest Way to Build Amazing Mobile Apps. Disponível em:  http://trigger.io, Acessado em: Maio/2014.   W3C. W3C Brasil. Disponível em: http://www.w3c.br/, Acessado em: Maio/2014.  WEBSQL. W3C. Web SQL Database. Disponível em:   http://www.w3.org/TR/webdatabase/, Acessado em: Maio/2014.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     80  Comparação de um jogo RPG em ambiente Distribuído com  relação a um ambiente Cliente-Servidor   Leonildo José de Melo de Azevedo1, Evanise Araujo Caldas1, Andres Jessé  Porfirio2, Hermano Pereira2   1Departamento de Ciência da Computação – Universidade Estadual do Centro-Oeste  (UNICENTRO) Caixa Postal 85.040-080 – Guarapuava – PR – Brasil   2Departamento de Tecnologia em Sistemas para Internet – Universidade Tecnológica  Federal do Paraná (UTFPR) Caixa Postal 85.053-510 – Guarapuava – PR – Brasil   {leonildo.azevedo,evanise_caldas}@hotmail.com, andresjesse@yahoo.com.br,  pereira@hermano.com.br    Abstract. Currently the area of digital games has grown massively, using  client-server network environments. However, this environment has a high  cost and limited scalability. This makes the distributed architectures to  become an alternative to the use of multiplayer games. In this study, a clientserver and a distributed environment were implemented and compared in  terms of bandwidth in a RPG (Role Playing Game). In the results, the  distributed environment had a better performance than the client-server for  the amount of connected clients, which were up to five.    Resumo. Atualmente a área de jogos digitais tem crescido massivamente,  utilizando ambientes de rede cliente-servidor. Contudo, esse ambiente tem  custo alto e escalabilidade limitada, e isso faz com que arquiteturas  distribuídas se tornem uma alternativa para o uso de jogos multijogadores.  Neste estudo, um ambiente cliente-servidor e outro distribuído foram  implementados e comparados em relação ao consumo de largura de banda em  um jogo de RPG (Role Playing Games). Nos resultados obtidos, o ambiente  distribuído obteve melhor desempenho que o cliente-servidor para a  quantidade de clientes conectados, que foram até cinco.   1.    Introdução  Diariamente, milhões de pessoas utilizam a Internet para se conectarem a diferentes  gêneros de jogos de computadores, caracterizando uma classe denominada Massively  Multiplayer Online Game (MMOG), que é uma derivação dos jogos multiplayer ou  multijogadores [Novak 2010].    A grande maioria desses jogos utiliza um ambiente de rede cliente-servidor,  contudo, esse ambiente possui certas limitações com relação à escalabilidade e  consistência [Shen 2011]. Escalabilidade corresponde a quantidade de jogadores  possíveis de conectar, e consistência refere-se a perda de acesso às informações [Shen  2011]. Tais limitações fazem com que ambientes distribuídos se tornem uma alternativa  para o campo de jogos eletrônicos.    Os ambientes de rede cliente-servidor, têm preferência na área de jogos  eletrônicos devido a sua simplicidade e organização na implementação [Hallberg 2003].  Outro motivo pelo qual os ambientes de rede cliente-servidor são mais utilizados é  devido ao fato de que os primeiros jogos multiplayer optaram por esse tipo de ambiente  [Novak 2010]. Além disso, o controle é centralizado, ou seja, o controle fica restrito     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     81  somente ao administrador do servidor, facilitando assim a comercialização e obtenção  de lucro com o jogo [Novak 2010; Cecin 2005].    Por outro lado, ambientes de rede distribuídos para jogos eletrônicos são mais  complexos em sua implementação. Por não terem um controle centralizado, necessitam  de um tratamento mais elaborado na distribuição das informações e na forma com que   trafegam na rede [Cecin 2005; Kozovits 2003; Shen 2011].    Para Shen (2011), um motivo que tem influência sobre a quantidade de dados  trafegados pela rede e sua escalabilidade, é modelo de interação do jogo. Tais modelos  se dividem em diversos gêneros, entre eles: RPG (Role Playing Games) jogos de  interpretação de papeis, onde o jogador controla um ou vários personagens virtuais; FPS  (Fisrt Person Shooter) jogos de tiro em primeira pessoa, no qual visualiza apenas do  ponto de vista do protagonista, com o jogador e personagem sendo o mesmo  observador; RTS (Real Time Strategy) jogos de estratégia em tempo real, em geral,  baseiam-se na construção de um “mundo”, com o objetivo destruir ou conquistar o  “mundo” dos outros jogadores. Dentre esses, os jogos de gênero RTS são os que têm  um maior consumo de largura de banda [Cecin 2005].   Neste trabalho os ambientes de rede distribuídos são tratados no contexto peerto-peer, onde cada computador é responsável por fornecer recursos e utilizar os de  outros computadores. Com isso, propõem-se a implementação dos dois conceitos  básicos de cada ambiente de rede para um jogo RPG.    2.    Jogos Multiplayer  Segundo Novak (2010), os jogos multiplayers surgiram décadas antes da  comercialização via Internet. Tudo começou com o PLATO (Programmed Logic for  Automatic Teaching Operations) introduzido em 1961 na Universidade de Illinois, e era  utilizado inicialmente em pesquisas na área de educação em computadores e mais tarde  acabou se tornando uma rede de jogos multiplayer. A partir daí, o crescimento se  expandiu, dando origem aos mais diversos tipos de jogos. O primeiro jogo multiplayer  foi o Space War. Na década de 70, o PLATO ofereceu jogos com Avatar (inspirados em  Dungeons & Dragons), dando início então aos jogos em RPG multiplayers, e junto a  eles a Internet.   2.1.    Dimensão de jogadores em Jogos Multiplayer  Em jogos multiplayers, há duas dimensões de jogadores, divididas em MOGs e  MMOGs [Novak 2010];[Cecin 2005]. MMOGs são classes que derivam dos MOGs,  apresentando duas características particulares. A primeira é que podem envolver uma  quantidade grande de jogadores (chegando a casa dos milhares) interagindo  simultaneamente em tempo real. A segunda é que MMOGs apresentam uma simulação  de estado persistente em permanente mutação, ao contrário dos MOGs que tem  simulações de curta duração e, suportam um número relativamente pequeno de  participantes, que em sua maioria não passam de cem jogadores [Novak 2010; Cecin  2005; Kozovits 2003; Shen 2011; Shen et al. 2012].   2.2.    Modo de Comunicação em Jogos Multiplayer  O tipo de comunicação mais comum é a cliente-servidor, na qual cada host (computador  conectado em rede) conectado ao servidor é um cliente, que troca mensagens apenas  com o servidor, o qual é responsável por armazenar ou distribuir as informações do jogo  para os demais clientes [Hallberg 2003].      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     82  A troca dessas mensagens geralmente é feita utilizando os protocolos TCP  (Transmission Control Protocol) ou UDP (User Datagrama Protocol). O protocolo  TCP é um protocolo com conexão e garantia de entrega de pacotes. Já o protocolo UDP  é um protocolo construído sobre datagramas, que por ser um protocolo sem conexão e  sem garantia de entrega de mensagens, evita sobrecargas de processamento associadas  ao protocolo TCP [Coulouris et al. 2007]. Entretanto, independente da conexão utilizar  UDP ou TCP, a troca de mensagens feita de forma centralizada pode gerar uma  escalabilidade baixa e alta latência na conexão em jogos MMOG [Cecin 2005; Shen  2011; Shen et al. 2012].   Existe também o modo de comunicação distribuído. Segundo Tanenbaum  (2007), “um sistema distribuído é um conjunto de computadores independentes que se  apresenta a seus usuários”. No contexto de jogos, uma comunicação distribuída (com  exceção dos servidores distribuídos) é usualmente entendida como o modelo Peer-toPeer (P2P) [Novak 2010]. Kozovits (2003), em seu trabalho, faz uma análise  considerável em jogos com ambientes distribuídos, concluindo que um mal  gerenciamento da rede pode resultar em um esforço de O(N2) para a distribuição dessas  informações, precipitando um congestionamento na rede, e causando um problema de  escalabilidade. Isso pode ocorrer em sistemas distribuídos unicast, onde todos os  computadores estão conectados entre si e disparam mensagem para todos um a um.    Devido ao problema de escalabilidade dos sistemas unicast houve a necessidade  do uso de broadcast de mensagens. Em vez de ocorrer envio de mensagens para cada  participante, apenas uma única mensagem broadcast será enviada a cada atualização,  diminuindo o esforço para O(N). Outro problema considerável é que não é possível  utilizar broadcast na Internet, para solucionar isso ambientes virtuais são criados,  usando então a comunicação multicast (broadcast na camada de aplicação) [Kozovits  2003; Cecin 2005].   Outras técnicas poder ser aplicadas para contornar esse problema, uma muito  interessante e aplicável é separar o jogo por área de interesse (Area of Interest – AOI),  onde o jogador manda atualizações somente dos objetos alterados em determinada  região e não do cenário inteiro [Shen 2011]. Até o presente momento, não foram  encontrados jogos na literatura que possuíssem comunicação totalmente distribuída. Há  os que tem servidores distribuídos como o EverQuest.   3.    Materiais e Métodos  Para a realização deste trabalho foram utilizadas algumas ferramentas de apoio. As  subseções a seguir descrevem as ferramentas utilizadas, e a metodologia aplicada para a  realização deste trabalho.   3.1.    Ferramentas  Para a implementação de um ambiente de rede cliente-servidor e outro distribuído em  um jogo RPG, foi utilizado o IrrRPG Builder uma ferramenta para criação de jogos  RPG, a ENet uma biblioteca para auxiliar a comunicação em rede e o TCPDump uma  ferramenta para analisar o estado da rede (trafego de pacotes, destino de pacotes, entre  outros).    3.1.1.    IrrRPG Builder  O IrrRPG Builder é uma ferramenta de criação de jogos open source, com manipulação  de objetos em 3D e é compilada em C++. Ela abrange uma grande massa de usuários e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     83  pode ser utilizada para diversos fins  [Porfirio and Hild 2012]. O gerenciamento das  ações de iteração do jogador, com os diversos elementos presentes no cenário do jogo, é  feita por scripts escritos em linguagem LUA, uma linguagem muito utilizada em jogos  eletrônicos. A ferramenta aplesenta uma interface simples, facilitando assim um  desenvolvimento fácil e rápido de jogos RPG.   3.1.2.    Biblioteca ENet  A ENet é uma biblioteca gratuita para C++, com objetivo de dar suporte a jogos. A  biblioteca fornece uma camada de comunicação de redes simples, e trabalha com  protocolo UDP, entretanto, pode funcionar com conexão e garantia de entrega de  pacotes em ordem de envio. Por utilizar UDP a ENet fornece uma flexibilidade maior  no envio dos pacotes, onde o usuário pode definir se o envio será com conexão, garantia  de entrega e controle de fluxo, ou ainda se o envio será sem conexão, sem garantia de  entrega e sem controle de fluxo.   3.1.3.    Análise de tráfego com o TCPDump  TCPDump é uma ferramenta utilizada em linha de comando, contida na maioria dos  sistemas UNIX para gerenciar o estado da rede. Ela monstra uma descrição do conteúdo  dos pacotes trafegados na rede, permitindo-se utilizar de sinalizadores. Tais  sinalizadores podem determinar em qual IP (Internet Protocol) será feita a análise do  tráfego, assim como em qual porta e qual a rede (cabeada ou sem fio).   3.2.    Metodologia  O trabalho procedeu da seguinte maneira: 1. Implementação do ambiente clienteservidor com o uso da biblioteca ENet em modo texto; 2. Criação do protótipo do jogo e  integração do ambiente cliente-servidor; 3. Adaptação da versão cliente-servidor do  protótipo do jogo para comunicação distribuída, e; 4. Elaboração e realização dos testes  com o uso do TCPDump.  3.2.1.    Implementação do ambiente cliente-servidor em modo texto  Primeiramente foi implementada uma comunicação cliente-servidor em modo texto e,  para tal, foi utilizada a biblioteca ENet. A comunicação em modo texto tinha as  funcionalidades de chat (bate papo), onde todos os clientes conectados ao servidor  podem trocar mensagens entre si (com protocolo UDP) por intermédio do servidor.    Nesse ambiente, cada cliente conecta-se ao servidor, havendo troca de  informações apenas entre cada cliente e o servidor, e quando o servidor recebe alguma  mensagem ele distribui essa mensagem por multicast. A Figura 1 apresenta uma  representação gráfica da comunicação cliente-servidor.      Figura 1. Ambiente cliente-servidor típico [Kozovits 2003].     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     84  O envio das informações foram feitos através do protocolo UDP, entretanto, foi  tratada a garantia de entrega, envio com conexão e controle de fluxo. Tais tratamentos  são feitos através de parâmetros da biblioteca Enet, mais especificamente, utilizando o  parâmetro ENET_PACKET_FLAG_RELIABLE que define esses tratamentos. Com  exceção dos pacotes, que foram definidos na criação antes de ser enviado, as conexões  foram realizadas com os parâmetros default da biblioteca ENet.   3.2.2.    Criação do protótipo do jogo e integração do ambiente cliente-servidor  Após feita a comunicação em modo texto, foi criado um protótipo de jogo virtual RPG  com a ferramenta de criação de jogos IrrRPG Builder. O protótipo do jogo apresenta um  cenário simples, resumindo-se a um RPG de caça ao tesouro.    Com o protótipo do jogo criado, foi realizado a integração da comunicação em  rede com o jogo. Na comunicação em rede foi aplicada a técnica de Área de Interesse,  onde o jogador manda atualizações somente da região em que está e não do cenário  inteiro, neste caso a sua posição [Shen 2011]. Para se conectar ao servidor, cada cliente  possui uma lista de possíveis endereços de servidores e, conecta-se primeiro endereço  em que o servidor está disponível. Os pacotes enviados contem a posição do jogador ou  mensagens correspondentes do chat, os pacotes que são trafegados no ambiente clienteservidor têm o mesmo tamanho dos pacotes trafegados no ambiente distribuído.   O servidor continua em modo texto, entretanto, foi modificado para fazer a  verificação de qual jogador encontrou antes o tesouro e se esse jogador requisitou a  missão de caça ao tesouro, ou seja, se o jogador encontrar o tesouro sem ter requisitado  a missão ele não ganha o jogo, contudo, se outro jogador requisitou a missão e  encontrou o tesouro, no momento em que ele requisitar a missão será exibia uma  mensagem “YOU LOST!” notificando-o de que perdeu.   3.2.3.  Adaptação da versão cliente-servidor do protótipo do jogo para  comunicação distribuída  No ambiente distribuído, a parte do servidor migrou para a parte de cliente. Nesse  ambiente os jogadores não se conectavam mais a um único ponto  (servidor), portanto,  foi necessário um tratamento melhor na conexão e na distribuição das informações. Esse  tratamento é descrito pelo Algoritmo 1.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     85  Após todos os jogadores conectados, a estrutura da comunicação entre eles se torna uma  malha em redes de computadores, tendo conexão de todos para todos, como mostra a  Figura 2.     Figura 2. Ambiente peer-to-peer típico [Kozovits 2003].   3.2.4.    Elaboração e realização dos testes com o uso do TCPDump  Na fase de testes, para analisar o estado da rede foi utilizado o comando “tcpdump -ni  <interface> -s <tamanho> udp port <porta> and host <ip>”, os parâmetros do  comando foram retirados da documentação do TCPDump, onde: tcpdump, executa a  ferramenta; -ni, n exibe somente o IP, ou seja, abstrai o nome dos host, e i é utilizado  pra definir onde será analisado o tráfego (rede cabeada ou rede não cabeada), neste  contexto foi a cabeada; -s, utilizada para definir o tamanho da captura dos pacotes, sem  esse parâmetro o TCPDump pode omitir o tamanho de alguns pacotes, para que não  houvesse omissão, o tamanho foi definido como 1500; udp, para analisar apenas pacotes  com protocolo UDP; port, filtra a análise pela porta definida; and, e lógico e host para  filtrar a análise pelo IP definido.   4.    Resultados e Discussões  Para todos os testes foram executadas interações entre os jogadores do protótipo de  RPG de caça ao tesouro, testando a utilização do chat, comunicação com os objetos do  jogo e jogabilidade, aplicando o mesmo cenário para todos os testes.   Foram realizados testes com cinco computadores clientes e um computador para  o servidor, e os mesmos cinco computadores utilizados para os clientes foram utilizados  para os testes do ambiente distribuído. Os computadores apresentavam especificações  semelhantes, com processador equivalente ou superior a um Intel(R) Dual-core,  memória equivalente ou superior a 4 GB e todas com sistema operacional Ubuntu 13.04  (ou superior) rodando nativo nas máquinas. Com estes computadores foram realizados  testes com dois, três, quatro e cinco jogadores. Cada teste foi executado dez vezes e com  duração de dois minutos, sendo obtida a média simples.   O Gráfico 1 exibe o consumo de banda médio total do ambiente cliente-servidor  e do ambiente distribuído, variando o número total de jogadores online. Essa média  total, se dá pela soma da média do consumo de banda de cada computador para cada  teste, somado com a média do consumo de banda por parte do servidor para cada teste  (no ambiente cliente-servidor), de acordo com o número de clientes conectados.  Observa-se também que o crescimento do consumo de banda conforme a quantidade de  jogadores é quase diretamente proporcional. O crescimento não linear se torna mais  notável conforme a quantidade de jogadores, devido ao fato de que, uma quantidade  maior de jogadores tendem a ter um consumo maior de banda.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     86    Gráfico 1. Média total de consumo de banda nos ambientes cliente-servidor e   distribuído, variando a quantidade total de jogadores.   Analisando os resultados obtidos, observa-se que o consumo de largura de banda  pelo ambiente distribuído foi consideravelmente menor que a consumida pelo ambiente  cliente-servidor, que obteve um consumo de banda de 15846 Bytes/s com cinco  jogadores, enquanto que o ambiente distribuído obteve com a mesma quantidade de  jogadores, um consumo de banda de 9585,3 Bytes/s, e tendo um crescimento de até 1,76  vezes menor que o ambiente cliente-servidor.    5.    Conclusão e Trabalhos Futuros   Os jogos com ambiente cliente-servidor podem apresentar problemas de escalabilidade,  devido ao grande tráfego de informações gerado pelo servidor, isso faz com que  ambientes distribuídos se tornem uma alternativa para a comunicação em jogos  multiplayer.     Nesse contexto, a fim de avaliar o quanto essa alternativa é promissora, foi  realizado uma comparação de largura de banda entre os dois ambientes, na qual concluise que com poucos jogadores o ambiente cliente-servidor apresenta um consumo maior  de banda que o distribuído e, que o servidor realmente é o gargalo da comunicação, o  que o determina como fator limitante de escalabilidade. Portanto, a aplicação de  ambientes distribuído em jogos eletrônicos, apresentou-se como uma alternativa  promissora, considerando uma quantidade pequena de jogadores.   Referências  Cecin, F. R.. (2005) “FreeMMG: uma arquitetura cliente-servidor e par-a-par de suporte   a jogos maciçamente distribuídos”. Instituto de Informática, Universidade Federal do  Rio Grande do Sul, Porto Alegre, 101 p..   Coulouris, G., Dollimore, J., Kindberg, T.. (2007) “Sistemas Distribuídos: conceito e  projeto”; tradução João Tortello. 4th ed. Porto Alegre: Bookman. 792 p..   Cormen, T. H., Leiserson, C. E., Rivest, Ronald L., Stein, C.. (2002) “Algoritmos:  Teoria e Prática”. Rio de Janeiro: Elsevier. Tradução da 2th edição americana.   ENet. (2014) “ENet: Reliable UDP networking library”.  Disponível em:  <http://enet.bespin.org/usergroup0.html>. Acessado em: 20 de fevereiro de 2014.   Hallberg, B. A.. (2003) “Networking: Redes de Computadores/Teoria e Prática”. Rio de  Janeiro: Alta Biiks. 292 p.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 80 -87  Nov/2014     87  Kozovits, L. E.. (2003) “Arquiteturas para Jogos Massive Multiplayer”. PUCRioInf.MCC36/03, Rio de Janeiro.   Novak, J.. (2010) “Desenvolvimento de Games”. São Paulo: Cengage Learning,. 443 p..  Porfirio, A. J., Hild, T. A.. (2012) “IrrRPG Builder: uma ferramenta livre para   desenvolvimento de jogos eletrônicos de RPG”. In: X FITEM - Fórum de  informática e tecnologia de Maringá, 2012.   Shen, B., Guo, J., Chen, P.. (2012) “A survey of P2P virtual world infrastructure”.  Ninth IEEE International Conference on e-Business Engineering.   Shen, S.. (2011) “Survey of P2P Game”. Mekelweg 4, Delft, the Netherlands.  Tanenbaum, A. S., Steen M. V.. (2007) “Sistemas Distribuídos: princípios e   paradigmas”. 2th ed. São Paulo: Pearson Prentice Hall.          
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     88   Estudo de Caso Aplicado na Gestão da Cadeia de  Suprimentos de uma Indústria de Cereais Matinais –   Modelagem e Desenvolvimento de um Sistema de Informação  para a Gestão da Cadeia de Suprimentos   João Victor Cunha Oliveira Gomes1, Bruno Souto Borges1   1Universidade Luterana do Brasil (ULBRA)  CEP – 75500-000 – Itumbiara – GO – Brasil   {joaovictor.cogomes, prof.brunosb}@gmail.com   Abstract. Currently, in the enterprise environment, the increase of  competitiveness makes the companies search even more to improve the  processing and availability of their activities’s data, both inside and outside  the company. Thus, the general objective of this paper is to present an  information system for the supply chain management of an industry that  produces breakfast cereal, which was developed to improve the resupply  process of the company, besides improving the relationship between the  industry and their suppliers through the information sharing.   Resumo. Atualmente, no ambiente empresarial, o aumento da competitividade  faz com que as empresas busquem cada vez mais se aprimorarem no  processamento e disponibilização de dados referentes à suas atividades, tanto  dentro como fora da empresa. Assim sendo, o objetivo geral deste artigo é  apresentar um sistema de informação para a gestão da cadeia de suprimentos  de uma indústria de cereais matinais, desenvolvido para melhorar o processo  de reabastecimento da empresa foco, além de aprimorar o relacionamento da  indústria com seus fornecedores através do compartilhamento de informações.   1. Introdução   Atualmente, o conceito de SCM (Supply Chain Management – Gestão da Cadeia de  Suprimentos) vem cada vez mais crescendo, e as grandes empresas buscam implantar  esse conceito em suas práticas e processos. Mas, por envolver uma grande margem de  modificações estruturais e logísticas, como o nível de relacionamento entre os  participantes da cadeia de suprimentos, Pires (2012) lembra que muitas empresas  recuam na ideia de implantar a SCM.   A SCM, segundo Pires (2012, p. 30), pode ser entendida como uma rede de  participantes que são responsáveis pela concepção, produção e liberação de um  determinado produto ou serviço a um determinado cliente final.   Para Chopra e Meindl (2004), a cadeia de suprimentos (SC) “engloba todos os  estágios envolvidos, direta ou indiretamente, no atendimento de um pedido de um  cliente”.   Para tanto, Pires (2012, p. 30-31) argumenta que, basicamente, a estrutura de  uma cadeia de suprimentos é composta por uma empresa foco, fornecedores diretos  (first tier supplier – fornecedores de primeira camada) e indiretos (fornecedores de  fornecedores), além de clientes diretos e indiretos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     89   Um elemento essencial para uma gestão da cadeia de suprimentos bem sucedida,  de acordo com Chopra e Meindl (2004), é a Tecnologia da Informação (TI). A TI  auxilia na gestão da informação e proporciona um melhor desempenho e uma melhor  integração das atividades de uma empresa.   Em vista disso, este artigo tem como objetivo apresentar um sistema de  informação desenvolvido para auxiliar na gestão da cadeia de suprimentos de uma  indústria de cereais matinais. O sistema de informação em questão tem como principais  funcionalidades a melhoria do monitoramento do estoque, redução de custos, melhoria  na previsão de pedidos, auxílio à tomada de decisão, além da melhoria no  relacionamento entre a indústria e seus fornecedores, através do compartilhamento de  informações em tempo real. Para tanto, o funcionamento do sistema se dá em relação ao  monitoramento do estoque e do consumo interno da indústria, para avaliar os dados e  efetuar cálculos para auxiliar na tomada de decisão em relação ao reabastecimento da  indústria. Também foi desenvolvido um módulo web, para os fornecedores consultarem  os pedidos direcionados a eles, para que eles possam analisar os pedidos da indústria e  emitir uma resposta, tornando mais rápida e eficaz a integração entre os participantes da  cadeia de suprimentos.   2. Metodologia   De início, foram estabelecidos os objetivos, requisitos e restrições do software. O  levantamento dos requisitos foi feito através de uma entrevista semiestruturada com um  funcionário do setor de TI e outra entrevista semiestruturada com um funcionário do  setor administrativo, ambos funcionários da indústria de cereais matinais analisada no  estudo de caso. Uma entrevista semiestruturada, de acordo com Manzini (s.d.), tem  como foco um assunto pré-definido com as perguntas principais já elaboradas, porém, a  entrevista é complementada por questões que surgem de forma oportuna, em  determinados momentos da entrevista.   A partir dos requisitos levantados, foram desenvolvidos os diagramas para  auxiliar no entendimento do software. Os diagramas desenvolvidos foram: diagrama de  caso de uso, diagrama de classes e diagrama de entidade e relacionamento (DER), além  de alguns diagramas de atividades para ajudar no entendimento de algumas atividades  realizadas pela empresa.   Em seguida, com todos os diagramas concluídos, foi feita a implementação do  sistema. O sistema foi dividido em duas partes, sendo um sistema desktop (para a  indústria) e um módulo web (para os fornecedores consultarem os pedidos e se  comunicarem com a indústria), utilizando a linguagem Java para ambos, sendo que, no  sistema web também foi utilizado o framework JSF e a biblioteca de interfaces  Primefaces. O desenvolvimento foi feito através do ambiente integrado de  desenvolvimento (IDE - Integrated Development Environment) NetBeans.   A persistência dos dados foi feita com o sistema gerenciador de banco de dados  (SGBD) PostgreSQL. Ambos os sistemas (desktop e web) foram integrados no mesmo  banco de dados.   3. Arquitetura e Funcionalidades do Sistema   Nos tópicos abaixo serão detalhadas as características do sistema, como ele funciona,  além das fórmulas utilizadas para efetuar os cálculos que irão auxiliar na gestão da  cadeia de suprimentos da indústria.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     90   3.1 Composição e Funcionamento do Sistema   Em relação ao sistema desktop (sistema principal para a indústria), seu objetivo é  controlar e monitorar o reabastecimento da empresa foco, além de controlar e monitorar  o estoque e o consumo da indústria, de forma que o processo de produção não fique  prejudicado por falta de matéria-prima. As principais funcionalidades do sistema podem  ser vistas no diagrama de caso de uso, na figura 1, a seguir.     Figura 1. Diagrama de Caso de Uso, com as principais funcionalidades do sistema.   Para tanto, o sistema realiza cálculos estatísticos para disponibilizar informações  para o usuário tomar decisões em relação ao estoque e aos pedidos de compra, sendo  que, o sistema irá calcular os valores de estoque (estoque de segurança, máximo e  mínimo), bem como o ponto de pedido de cada produto em relação a cada fornecedor,  para que o sistema avise o usuário quando for o momento de realizar o pedido de algum  produto. O sistema, então, irá trabalhar da seguinte forma: ele irá analisar o consumo  interno da empresa de um ano atrás, a partir da data da análise. A partir dessa análise,  serão efetuados cálculos estatísticos, como a média de consumo do período, a média  diária de consumo, a variância e o desvio padrão, a duração média de um produto em  estoque, bem como o escore Z, para avaliar o crescimento ou o decrescimento do  consumo em relação à média mensal.   Na figura 2, é ilustrada uma parte do diagrama de classes, com as principais  classes do sistema. A classe “Fornecimento” é responsável por representar os produtos  em relação aos fornecedores, juntamente com os valores de estoque, o ponto de pedido  e o tempo de ressuprimento de um fornecedor para um determinado produto. A classe  “Consumo” representa instâncias relacionadas ao consumo interno da indústria, bem  como os valores estatísticos calculados em relação ao consumo. Assim sendo, o sistema  irá fazer uma análise do consumo anual e verificar os dados relacionados ao  fornecimento de cada produto, para, em função do consumo e do tempo de  ressuprimento, calcular todas as variáveis necessárias para gerar informações de forma  precisa.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     91     Figura 2. Principais classes do sistema.   A partir dos cálculos estatísticos, serão calculados os valores de estoque e o  ponto de pedido. Desta forma, haverá a análise do consumo periodicamente, para  calcular valores médios de consumo, para definir automaticamente o estoque necessário  e o ponto de pedido de um produto, sendo que, o cálculo do ponto de pedido é feito com  base no tempo de ressuprimento de um determinado fornecedor. Além disso, o sistema  realiza um constante monitoramento do estoque, para emitir um aviso para o usuário  quando a quantidade de um ou mais produtos se aproximarem ou atingirem o nível  determinado pelo ponto de pedido. Na figura 3, abaixo, tem-se a representação da tela  de geração do consumo interno da empresa no mês anterior.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     92     Figura 3. Tela de Geração do Consumo Mensal.   A seguir, na figura 4, tem-se a representação da tela de geração do consumo  anual, a qual disponibiliza todas as variáveis para a tomada de decisão em relação ao  consumo/abastecimento, incluindo o consumo durante o ano, as variáveis estatísticas e  os valores de estoque para cada produto em relação a cada fornecedor (os valores de  estoque dependem do tempo de ressuprimento de cada fornecedor).     Figura 4. Tela de consumo anual do sistema principal mostrando, na primeira  tabela, o consumo de cada mês/ano do último ano e as diversas variáveis  calculadas em relação ao consumo de cada produto, e, na segunda tabela, as  previsões de estoque e pontos de pedido calculados para cada fornecedor de  um produto selecionado.   O sistema também disponibiliza a geração de diversos relatórios, que são: o  relatório de registros de compras (movimentações), o relatório de produtos que  atingiram o ponto de pedido, o relatório de fornecimentos (listando os produtos e seus  fornecedores, e vice-versa), e o relatório do consumo anual. Outro recurso que o sistema  disponibiliza é a geração de gráficos de consumo.   Para completar, tem-se também o módulo web, que permite a comunicação dos  fornecedores com a empresa foco (a indústria). Este módulo web disponibiliza os  pedidos direcionados a cada fornecedor, sendo que o fornecedor pode analisar os  pedidos em tempo real e aprovar ou não um pedido, podendo se comunicar com a  indústria através dele. Para tanto, o sistema principal (desktop) e o módulo web estão  integrados. Este módulo web foi desenvolvido justamente para melhorar o  reabastecimento e o relacionamento com seus fornecedores. Portanto, este módulo web  irá aproximar a indústria de seus fornecedores, através da integração em tempo real,  melhorando o processo de reabastecimento na cadeia de suprimentos. A figura 5, a  seguir, ilustra a tela de consulta de pedidos do sistema web.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     93     Figura 5. Sistema web para os fornecedores consultarem os pedidos.   3.2 Fórmulas Utilizadas no Sistema   Para o funcionamento do sistema, foram utilizadas diversas fórmulas, as quais tornam  possível o cálculo de diversas variáveis que auxiliam na tomada de decisão e permitem  o gerenciamento do consumo e do estoque de produtos.   Em relação às variáveis estatísticas, foram calculadas as variáveis vistas a  seguir, juntamente com as definições abordadas por Stevenson (2001):    Média: é a soma dos valores de um conjunto, dividindo esta soma pelo  número n de valores;    Variância: é o somatório do quadrado da diferença entre um valor do  conjunto e a média dos valores do conjunto, dividido pelo número n de  valores do conjunto;    Desvio-Padrão: mostra a dispersão existente em relação à média, ou seja,  indica a variação dos valores do período de consumo. Seu cálculo é feito a  partir da raiz quadrada da variância;    Escore Z: indica a melhora (+), a piora (-), ou nenhuma modificação (0) em  relação a um valor a partir de uma determinada ação. No contexto deste  trabalho, será avaliado o crescimento ou decrescimento do consumo em  relação a um consumo mensal tomado como valor observado e à média  mensal.    Mediana: valor intermediário de um conjunto de valores;  Também foram calculadas a média diária, que é a divisão da média geral pela   quantidade de dias úteis no mês; e a duração média de um produto no estoque, que é  calculada através da divisão da quantidade atual em estoque do produto pela média  diária.   Em relação às variáveis de estoque, o estoque de segurança, como lembram  Corrêa, Gianesi e Caon (2007), é calculado a partir do fator de segurança, do desviopadrão, do tempo de ressuprimento e da periodicidade. A fórmula do estoque de  segurança é representada abaixo:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     94     Onde  é o fator de segurança, que representa o nível de serviço, que no caso   foi utilizado o nível de serviço a 95%, representado pelo fator de serviço equivalente a  1,645. Corrêa, Gianesi e Caon (2007) lembram que, o fator de serviço representa o  número de desvios-padrão que se deve manter no estoque de segurança para garantir o  nível de serviço;  é o desvio-padrão referente ao consumo médio mensal;  é o lead  time (tempo de ressuprimento); e  é a periodicidade à qual se refere o desvio-padrão,  que no caso é representada pela quantidade de dias no mês, no caso, os dias úteis, pois o  desvio-padrão se refere ao consumo médio mensal.   A quantidade mínima, como lembra Ramos (2006), pode ser calculada através  da multiplicação do consumo médio mensal pelo tempo de ressuprimento, dividindo o  resultado desta multiplicação pela quantidade de dias no mês, no caso, os dias úteis. A  seguir, tem-se a representação da fórmula da quantidade mínima:     Já a quantidade máxima, na visão de Ramos (2006), pode ser estabelecida   através da multiplicação da quantidade mínima por dois, ou seja, é o dobro da  quantidade mínima. Sendo assim, leva-se em conta a fórmula abaixo para calcular a  quantidade máxima:     O ponto de pedido, para Corrêa, Gianesi e Caon (2007), pode ser definido   através da multiplicação do consumo médio diário pelo tempo de ressuprimento, sendo  o resultado desta multiplicação somado ao estoque de segurança. O cálculo do ponto de  pedido pode ser feito pela seguinte fórmula:      4. Resultados e Discussão   A partir das carências funcionais encontradas em meio aos processos da indústria de  cereais matinais observada, espera-se que o sistema principal (plataforma desktop)  possa atender às necessidades e aos objetivos da indústria na gestão da cadeia de  suprimentos no sentido montante (fornecedores), trazendo resultados favoráveis através  das funções que ele disponibiliza, como o cálculo de variáveis de estatísticas e de  estoque a partir do consumo realizado em um determinado período, para prever os  pedidos no momento certo, levando em conta o tempo de ressuprimento de cada  fornecedor para cada produto que ele fornece, proporcionando uma redução de estoque  sem deixar produtos em falta, tornando o estoque sempre disponível e com o menor  volume possível. Além disso, espera-se que o sistema possa fornecer um completo  apoio à tomada de decisões através das informações disponibilizadas, advindas da união  de dados, que podem ser de diversos períodos (dados históricos) e de diversas tabelas do  banco de dados, além dos cálculos estatísticos realizados automaticamente pelo sistema,  formando informações importantes, contando com as opções de geração de gráficos e  relatórios.   Outro resultado importante esperado é a melhoria no relacionamento entre a  indústria e seus fornecedores, através da integração propiciada pelo sistema web, que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 88 -95  Nov/2014     95   permite a um determinado fornecedor consultar em tempo real os pedidos direcionados  a ele.   5. Considerações finais   A relevância deste artigo foi mostrar que a utilização da TI para a gestão da cadeia de  suprimentos é essencial, através da apresentação de um sistema para a gestão da cadeia  de suprimentos desenvolvido. Pôde-se observar que a TI permite o rápido  processamento, integração e disponibilização de informações através dos sistemas de  informação, que apoiarão as decisões da empresa no que diz respeito à produção,  reabastecimento e consumo de um determinado período.   Outro benefício importante que a TI pode proporcionar é a melhoria na interação  entre os parceiros da cadeia de suprimentos, através do compartilhamento de  informações proporcionado pelo sistema web, já que, hoje em dia, comunicação  constante e informações em tempo real são essenciais para as empresas atingirem os  objetivos no mercado.   Para trabalhos futuros, tem-se a migração do sistema principal totalmente para a  web, bem como o aprimoramento do sistema para atender o relacionamento da empresa  foco no sentido jusante (downstream), que é o relacionamento direcionado aos clientes  da empresa foco.   Referências   CHOPRA, Sunil; MEINDL, Peter. Gerenciamento da cadeia de suprimentos:  estratégia, planejamento e operação. São Paulo: Pearson Education, 2004.   CORRÊA, Henrique Luiz; GIANESI, Irineu Gustavo N.; CAON, Mauro.  Planejamento, Programação e Controle da Produção. 5 ed. São Paulo: Atlas,  2007.   MANZINI, Eduardo José. Entrevista Semiestruturada: Análise de Objetivos e  Roteiros. Marília, Unesp, s.d. Disponível em:  <http://www.sepq.org.br/IIsipeq/anais/pdf/gt3/04.pdf>.   PIRES, Silvio R. I. Gestão da Cadeia de Suprimentos: conceitos, estratégias, práticas  e casos. 2 ed. São Paulo: Atlas, 2012.   RAMOS, Marcus Vinícius M. Controlando os estoques com inteligência. s.l. 2006.  Disponível em: < http://www.sebrae.com.br/ >.   STEVENSON, William J. Estatística aplicada à Administração. 1. ed. São Paulo:  Harbra, 2001.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     96   Simulador de Robô para Auxílio ao Ensino de Programação     Marco T. Chella, Claudio M. Oliveira, José Caique O. da Silva     Departamento de Computação  Universidade Federal de Sergipe (UFS) – São Cristóvão, SE – Brazil     Chella@ufs.br, cmoliveira1000@hotmail.com, caiqueprog@yahoo.com.br     Abstract. This project's objective is to develop a mobile robot simulator that  applies gamification concepts for improve the programing concepts learning.  The simulator can be used on programing disciplines of computer science and  engineering courses. The robot control is made by an application  programming interface (API) built at this moment for Python  and  Java   programing  languages.  It  is  expected  from  this application to let youth  more interested in technology career.     Resumo. Este projeto tem como objetivo o desenvolvimento de um simulador  de robô móvel aplicando o conceito de gamificação para a aprendizagem de  conceitos de programação.  O simulador pode ser utilizado  em  cursos  de  computação e engenharia nas disciplinas de programação. O simulador é  constituído por um ambiente gráfico 3D contendo o robô móvel com sensores  e atuadores. A interação e controle dos diversos componentes do robô se dão  por meio de uma  int erf ace  de  programação  de  ap l i cações (API)  no momento desenvolvida para as linguagens mais usadas nos cursos de  computação incluindo Java, Python.  É esperado que a utilização do  simulador possa favorecer o desenvolvimento do pensamento computacional  nos alunos e estimular jovens em carreiras tecnológicas.       1.Introdução      É conhecido que no Brasil existe um grande índice de reprovação nas disciplinas de  programação dos cursos de nível superior, a evasão estudantil no ensino superior é um  problema que afeta diretamente o resultado dos sistemas educacionais por não produzir  nenhum retorno.      As perdas de estudantes que iniciam e não terminam seus cursos são desperdícios  sociais, acadêmicos e econômicos. No setor público, são recursos públicos investidos  sem o devido retorno.  Já no setor privado, é uma  importante  perda  de receitas. Em  ambos os casos, a evasão pode ser tomada como fonte de ociosidade de professores,  funcionários, equipamentos e espaço físico [Giraffa e Mora 2014].      Pesquisas feitas mostram que a evasão dos estudantes dos cursos de tecnologia  não é algo novo [Pazeto e Prietch 2010]. Um dos motivos para esta desistência está  relacionado com as dificuldades encontradas nas disciplinas de programação que  possuem como objetivo o desenvolvimento do raciocínio lógico voltado para a  resolução de problemas em áreas diversas.      Estes índices de evasão são preocupantes, pois a busca pelos cursos na área das  ciências exatas é pequena, o que resulta em muitas vagas em aberto no mercado de  trabalho que terminam não sendo preenchidas.      Segundo [Giraffa e Mora 2014] esses índices de desistência estão associados às  deficiências relacionadas à expressão em língua materna (escrita), hábitos de estudo e  pesquisa, interpretação de texto e devido a uma formação básica deficitária no que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     97   tange a conteúdos de matemática. Outro motivo que pode levar a reprovação nas  disciplinas de programação é a falta de motivação e associação da teoria com a prática.  Segundo [Neto e Schuvartz 2007] o uso de ferramentas computacionais para o ensino  aumenta a produtividade e assimilação do conteúdo estudado.     2.   Trabalhos Relacionados      Os softwares simuladores, que buscam reproduzir o mundo real, têm sido amplamente  utilizados no desenvolvimento e aperfeiçoamento de produtos e estudo de fenômenos  físicos. Na área educacional os simuladores podem oferecer uma forma segura e de  baixo custo para exploração de conteúdos de estudo.      O SARGE [Craighead et al. 2008] é um simulador de drones de resgate  desenvolvido por alunos da University of South Florida que pode ser utilizado para a  preparação de profissionais que realizam pesquisas com esses equipamentos, fazendo  com que o custo para a preparação dos mesmos seja diminuído significativamente.      O Gazebo, Gazebosim [2014], é um simulador de robôs desenvolvido pela Open  Source Robotics Foundation que é usado pela DARPA Robotics Challenge para  programação e teste de uma versão virtual de robôs humanóides das forças armadas,  com o intuito de desenvolver uma API robusta para o mesmo e diminuir custos.      ProGame, [Dantas e Sales 2010], é um jogo para o ensino de algoritmos e  programação com o propósito de aumentar o estímulo no aprendizado de algoritmos por  meio da gamificação do estudo de programação.     3.   Motivação      Segundo o Sebrae [2014] o mercado de jogos digitais no Brasil em 2012 cresceu 32%  em  relação  a  2011  possuindo  um  total  de  35  milhões  de  usuários.  Com  essa  porcentagem de crescimento considerável em apenas um ano é notório que o público  brasileiro possui um interesse crescente por jogos eletrônicos. Dessa forma o uso do  simulador que constitui num ambiente gráfico onde existe a interação direta com o  usuário, onde são apresentados alguns desafios, pode despertar o interesse pelo estudo  de programação.      A inserção de desafios, objetivos e recompensas é conhecida como gamificação  [Fardo 2013], que consiste em transformar atividades monótonas em aventuras  prazerosas com maior produtividade e aprendizado. Este projeto tem por objetivo unir o  ensino utilizando um simulador que aplica o conceito de gamificação, onde o desafio é  desenvolver algoritmos para resolução de labirintos e a recompensa seria o aprendizado  no adquirido no processo.      Esta abordagem permite ao usuário uma forma livre para testar seus algoritmos  interagindo e visualizando de maneira simples e didática como as modificações nos seus  próprios algoritmos influenciam no desempenho de determinado agente no decorrer da  simulação. Dessa forma, o programador que antes vivia preso a atividades insípidas e a  uma tela preta, é  i n s e r i d o  em um ambiente onde o mesmo decide o que fazer  e como fazer, obtendo resultados mais significativos.     4.   Ambiente de aplicação      O projeto consiste em um simulador, que assim como O SARGE [Craighead et al.  2008], foi desenvolvido por meio do motor de jogos Unity3D, este foi escolhido por  possuir ferramentas que diminuem a complexidade de desenvolvimento (interface  gráfica e física), e por possuir uma documentação bastante completa e acessível. O  simulador implementa um robô móvel e seu conjunto de sensores e atuadores para  interação com o ambiente ao redor do mesmo.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     98      A arquitetura do projeto funciona com a idéia de cliente-servidor, a qual pelo  menos dois aplicativos se comunicam via sockets que utilizam o protocolo de controle  de transmissão (TCP), de maneira a possibilitar a simulação. O aplicativo servidor é o  simulador em si o qual mostra ao usuário, por meio da interface gráfica, o  comportamento do(s) robô(s) no ambiente proposto. Já os aplicativos clientes são  escritos e compilados pelo próprio usuário, o qual escreverá algoritmos para o(s)  robô(s) em uma linguagem de programação de sua escolha no ambiente de  desenvolvimento que mais se sentir confortável, fazendo a comunicação com o servidor  controlando determinado(s) robô(s), utilizando uma API que é disponibilizada para cada  linguagem de programação (atualmente Java e Python). A Figura 2 ilustra o  funcionamento do sistema.           Figura 2: Diagrama de blocos      A API possui uma documentação que especifica as funções que mapeiam os sensores e  atuadores do robô mostrados na Figura 4, dessa forma as principais funções para  interação do robô com o ambiente são as leituras dos sensores (sonar, infravermelho,  etc) e movimentação (frente, ré, direita, esquerda, direcionar sensores). A Figura 3  demonstra um código simples em Java o qual quando em execução faz o robô andar  para frente, até detectar um obstáculo, e então para.                            Figura 3: Uso de funções do simulador no ambiente Java.    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     99          Figura 4: O robô e seus sensores/atuadores.        O simulador possibilita a escolha do ambiente no qual o robô será inserido, podendo  variar desde um cenário de sumô de robôs até um labirinto modificável pelo usuário,  como mostra a Figura 5. O objetivo da flexibilização do cenário é que assim o usuário  poderá fazer um ambiente particular e desenvolver um algoritmo para a resolução do  mesmo testando via simulação. Para os problemas que envolvem a resolução de  labirintos, o usuário poderá implementar soluções a partir de algoritmos já existentes  ou variações deles, como Trémaux’s [Nien-Zheng et al. 2011] e o algoritmo de  inundação [Willardson 2001] , Figura 6 ilustra esse tipo de cenário. A outra forma de  simulação que pode ser explorada está relacionada às competições de sumô de robô  [Chew 2009], ilustrado na Figura 7.      Essas competições apesar de serem muito importantes por difundirem o uso de  robôs [Passold 2006], e possibilitarem o aprendizado em eletrônica, mecânica e  programação dos envolvidos nas mesmas, possuem o limitante que é a construção do  robô que nem sempre é algo simples e barato, o que se torna uma barreira para o  crescimento da área, além de exigir um espaço para a realização de testes. O uso de  simuladores é uma boa opção para contornar esse problema, já que o competidor pode  desenvolver os algoritmos e testá-los obtendo um resultado realista dispensando a  utilização de um robô real.      O simulador possibilita a atuação de mais de um robô no mesmo ambiente,  como o sistema é baseado na comunicação em rede o usuário poderá formar equipes  em rede local (LAN) para a resolução de problemas, possibilitando o trabalho em  equipe, ou poderá fazer competições, ou ainda utilizar mais que uma aplicação no  mesmo computador cada uma delas executado um algoritmo diferente para verificar  qual seria mais eficiente no ambiente proposto.      Pode acontecer que os problemas a princípio não sejam resolvidos, mas deve  ser considerado que com o estudo, e pela visualização do funcionamento de seus  algoritmos, o usuário terá um aprendizado significativo, e dessa forma melhorará seu  raciocínio para a resolução de problemas computacionais.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     100     Figura 5: Tela de entrada     Figura 6: Cenário   labirinto          Figura 7: Cenário sumô de  robô                       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     101   5.Considerações Finais     Os simuladores apresentam uma dinâmica interessante por toda sua praticidade e  experiência que pode ser adquirida durante o seu uso, essa afirmação pode ser feita  dado os exemplos apresentados neste artigo onde grandes instituições como a DARPA  fazem uso destes.   Aplicar os simuladores para que estes possam auxiliar no aprendizado é uma  alternativa interessante podendo trazer uma melhoria do ensino no ambiente de  computação. Outro ponto positivo sobre o uso de simuladores é o seu baixo custo que  o torna mais acessível que os modelos reais (se tratando de robôs), além de evitar  riscos e prejuízos quando está sendo utilizado.   Diante do trabalho feito os próximos passos serão a aplicação do projeto em  turmas do departamento de computação da Universidade Federal de Sergipe e a  disponibilização dos resultados obtidos.       Referências    Chew, M.T. et. al (2009). “Robotics competitions in engineering education”.   http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=4804032&url=http%3A%2 F%2Fieeexplore.ieee.org%2Fxpls%2Fabs_all.jsp%3Farnumber%3D4804032  [acesso em 12 de julho de 2014].     Dantas, V. e Sales, C. (2010). "ProGame: um jogo para o ensino de algoritmos e   programação". http://www.br-ie.org/pub/index.php/sbie/article/viewFile/1558/1323   [acesso em 29 de maio de 2014].     Fardo, M. (2013). "A gamificação aplicada em ambientes de aprendizgem".   http://seer.ufrgs.br/renote/article/viewFile/41629/26409 [acesso em 03 de julho de  2014].     GazeboSim. http://gazebosim.org/wiki/Overview/  [acesso em 12 de junho de 2014].    Giraffa, L. e Mora, M. (2014) "Evasão na Disciplina de Algoritmo e Programação:   Um Estudo a partir dos Fatores Intervenientes na Perspectiva do Aluno".  http://www.alfaguia.org/wwwalfa/images/ponencias/clabesIII/LT_1/ponencia_completa_136.pdf [acesso em 03  demaio de 2014].     Neto, W. e Schuvartz, A. (2007). "Ferramenta Computacional de Apoio ao Processo   de EnsinoAprendizagem dos Fundamentos de Programação de Computadores".  http://www.lbd.dcc.ufmg.br/colecoes/sbie/2007/0022.pdf [acesso em 30 de  junho2014].     Nien-Zheng, Y. et. al (2011). "Recursive Path-finding in a Dynamic Maze with   Modified Tremaux’s Algorithm". http://waset.org/publications/11300/recursivepath-finding-in-a-dynamicmaze-with-modified-tremaux-s-algorithm [acesso em 14  de julho de 2014].     Passold, F. (2006). “Despertando para a importância das competições de robô”.   http://usuarios.upf.br/~fpassold/sumo_cobenge_2006.pdf [acesso em 12 de julho  de2014].        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 96-102  Nov/2014     102   Pazeto, T. e Prietch, S. (2010). "Estudo sobre a Evasão em um Curso de Licenciatura  em Informática e Considerações para Melhorias".    https://www.cesmac.com.br/erbase2010/papers/weibase/65258.pdf. [acesso em  27de maio de 2014].     Sebrae. Brasil tem o maior mercado de games do mundo em 2012.    http://www.sebrae2014.com.br/Sebrae2014/Alertas/Brasil-tem-o-maior-mercadode-games-no-mundo-em-2012#.VEP1cVXF8y4 [acesso em 17 de junho de 2014].     Willardson, D. (2001). "Analysis of Micromouse Maze Solving Algorithms".   http://web.cecs.pdx.edu/~edam/Reports/2001/DWillardson.pdf [acesso em 14  dejulho de 2014].           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     103   Estruturação do Plano de Continuidade de Negócio: um  estudo de caso   Clédson de Souza Magalhães1, Letícia Ribeiro P. de Oliveira1, Ivo Sócrates M. de  Oliveira2   1Curso de Gestão de TI – Instituto Federal do Tocantins (IFTO)  Caixa Postal 151 – 77.600-000 – Paraíso do Tocantins – TO – Brasil   2Eixo de Informação e Comunicação – Instituto Federal do Tocantins (IFTO) e Instituto  de Ciências Matemáticas e de Computação – Universidade de São Paulo (USP)   Caixa Postal 151 – 77.600-000 – Paraíso do Tocantins – TO – Brasil.  {cledsomagalhaes, lete1002}@gmail.com, ivosocrates@usp.br   Abstract. Attacks on information systems (IS) have increased, coinciding with  the emergence of new digital pests. So it's a challenge keep the information  available uninterruptedly. With the purpose of prepare the organization for a  possible attack of success is that it should be adopted a Business Continuity  Planning (BCP). Therefore, this paper presents an analysis of a hospital  public institution, in order to diagnose the threats that surround the institution  and prepares it to recover quickly in the event of materialization of risks. This  research allowed the formalization of a BCP, which enables improvements  relevant to the organization. Beyond the comprehension of the values  attributed to the institutional business.   Resumo. Os ataques aos sistemas de informação (SI) têm aumentado,  coincidindo com o surgimento de novas pragas digitais. Portanto, é um  desafio manter as informações disponíveis initerruptamente. Com o intuito de  preparar a organização para um possível ataque de sucesso é que deve ser  adotado um Plano de Continuidade de Negócio (PCN). Logo, o presente  trabalho apresenta uma análise de uma instituição pública hospitalar, visando  diagnosticar as ameaças que cercam a instituição e prepara-la para se  recuperar rapidamente em caso de ocorrência de riscos. Tal pesquisa  permitiu a formalização de um PCN, que viabiliza melhorias relevantes para  a organização. Além da compreensão dos valores dos negócios institucionais.    1. Introdução   Os diversos incidentes relacionados à segurança da informação têm despertado os  interesses das organizações na preparação para situações adversas. A principal ação que  é gerada no campo de segurança da informação é a prevenção da ocorrência dos riscos,  tal prevenção pode ser acompanhada através de um lúcido relatório de gestão de riscos.    Porém, muitos riscos, mesmo que monitorados, podem se concretizar, caso se  concretize o que fazer? O Plano de Continuidade de Negócios (Business Continuity  Planning) possui o objetivo de responder tal questionamento e representa um  diagnóstico contendo um conjunto de planos alternativos de ação para eventuais  incidentes previamente identificados.     Um Plano de Continuidade de Negócio (PCN) tem como finalidade garantir que  os serviços, bem como as informações essenciais à sobrevivência da organização sejam  devidamente reestabelecidos sem que haja o comprometimento das atividades     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     104   eliminando ou minimizando os impactos destes sobre os negócios organizacionais  (SILVA, 2011, p. 23).     Segundo a ABNT ISO/IEC 27002 (2005, p. 103), o PCN deve ser implementado  objetivando a minimização dos impactos a um nível aceitável sobre a organização  através da combinação de ações preventivas e de recuperação de perdas de ativos da  informação, caso ocorram, independentemente do motivo pelo qual estes possam ser  resultantes, como por exemplo: desastres naturais, acidentes, falhas de equipamentos ou  até mesmo de ações intencionais.     Fontes (2008 apud JUNIOR, 2008, p. 27) apresenta que muitas organizações só  compreenderam a importância da continuidade de negócio após os ataques terroristas ao  World Trade Center, em 11 de setembro de 2001 em Nova Iorque, pelo fato de algumas  organizações simplesmente deixarem de existir por não terem um PCN. A partir de  então, a pergunta deixou de ser, “Qual a probabilidade disso acontecer?” e passou a ser,  “E se isso acontecer?”.     Uma dúvida que permeia entre alguns gestores é a diferenciação entre  Gerenciamento de Riscos e Plano de Continuidade de Negócio. No primeiro, os  esforços são específicos no sentido de se minimizar o risco da ocorrência de um  incidente de segurança da informação. No segundo, o incidente já aconteceu.     O plano de contingência de um PCN pode ser composto pelos seguintes planos:  Plano de Administração de Crises (PAC) – define passo a passo os procedimentos a  serem executados pelos diretores da organização antes, durante e depois da ocorrência  do incidente, permitindo que os executivos tenham maior controle sobre a organização  durante a crise (MAGALHÃES e PINHEIRO, 2007, p. 437); Plano de Recuperação de  Desastres (PRD) – Segundo Junior (2008, p. 31), trata-se de diretrizes que definam  como deverão ser restauradas as funcionalidades dos ativos humanos, operacionais e  tecnológicos voltados para o suporte dos negócios, tendo como objetivo o  reestabelecimento do ambiente e suas condições operacionais originais no menor espaço  de tempo possível prevendo os impactos possíveis de ser causado pelo incidente; Plano  de Continuidade Operacional (PCO) – Junior (2008, p. 30), define PCO quais os  procedimentos a serem tomados a fim de reestabelecer os ativos que suportam cada  atividade, reduzindo o tempo de indisponibilidade bem como os impactos aos negócios  da organização como um todo.     Um PCN bem elaborado garante de forma precisa a identificação de riscos e  seus prováveis impactos possibilitando a elaboração de estratégias e planos de ação que  possibilitem reduzir danos ao patrimônio, ao meio-ambiente e as pessoas envolvidas.  Desta forma, ele poderá contribuir para a proteção da imagem da organização uma vez  que favorece a minimização de ações judiciais e ainda coordena a comunicação com os  vários públicos que fazem parte dos negócios organizacionais.     Existem diversos documentos, livros e estudos voltados para o assunto, porém o  que melhor dispõe de informações precisas, claras e objetivas são as normas técnicas  ABNT NBR 15999-1 (2007) (código de práticas) e ABNT NBR 25999-2 (2008)  (requisitos), as quais foram elaboradas como um guia para a preparação de um PCN.    É comum encontrar organizações que insistam em afirmar ser totalmente segura.  Porém, “afirmar que uma organização está 100% segura é um grande erro”. Segundo  Nakamura e Geus (2007, p. 63), isto ocorre principalmente quando o assunto é  segurança da informação, tendo em vista a complexidade envolvida por meio dos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     105   aspectos humanos, tecnológicos e tantos outros, o que faz com que não possa existir um  modelo de segurança que possa assegurar cobertura total à organização.     Nesse aspecto, é indispensável que o PCN aborde pelo menos três características  essenciais à continuidade de negócio, que são: disponibilidade, confiabilidade e  recuperação. E segundo Alves (2007, p. 35-36) ele deve conter, pelo menos, os  seguintes tópicos: sumário executivo, gerenciamento dos elementos de emergência,  procedimentos de resposta à emergência, documentos de suporte, identificação de  desafios e priorização de atividades.     O hospital público alvo da pesquisa não possui nenhum documento formalizado  para regulamentar, direcionar ou até mesmo tornar obrigatória as práticas citadas  anteriormente. Tal hospital foi implantado na década de 90 em uma das cidades do  estado do Tocantins, sendo um dos 17 hospitais públicos da rede SESAU (Secretaria  Estadual de Saúde), tendo como objetivo o atendimento de urgência e emergência à  pacientes do sistema SUS (Sistema Único de Saúde) desta localidade, bem como de  várias cidades circunvizinhas, possuindo para tal cerca de 450 colaboradores e  disponibilizando 90 leitos para observação e internação.     Ainda está em fase de implantação um sistema ERP (Enterprise Resource  Planning) no local. E a infraestrutura de hardware conta com uma pequena sala, onde  funciona a Central de Processamento de Dados (CPD), de onde todos os ativos de  informática são monitorados e controlados e, ainda, sendo utilizada para a manutenção  de equipamentos em caso de danos aos mesmos.     A infraestrutura conta com uma rede interna baseada em Switches 10/100/1000,  que interliga cerca de 5 servidores, sendo utilizados para o sistema ERP implantado  (banco de dados e aplicativos), para o controle de domínio, firewall/proxy e backups de  arquivos dos mais de 50 microcomputadores espalhados nos diversos setores que  compõem toda a estrutura hospitalar.    O objetivo da pesquisa é o de realizar uma análise da segurança da informação  em uma instituição pública hospitalar, visando diagnosticar as ameaças que cercam a  instituição, para que ao final seja apresentado um Plano de Continuidade de Negócio,  alinhado as necessidades da instituição.    O presente trabalho está organizado como se segue. Na seção 2, são  apresentados os materiais e métodos da pesquisa. Na seção 3, são apresentados os  resultados e discussões. Finalmente, na seção 4, são apresentadas as conclusões.    2. Materiais e Métodos   A abordagem metodológica foi qualitativa, por se tratar de um estudo de caso centrado  em um único caso, através do contato direto com a realidade da instituição pesquisada.  E quantitativa, por selecionar um grupo específico de funcionários para auxiliar no  diagnóstico do caso. A pesquisa foi realizada em 1 dos 17 hospitais públicos do estado  do Tocantins da rede SESAU, entre fevereiro a julho de 2013. A estrutura de coleta de  dados foi com base na análise dos documentos, processos observados, questionários,  entrevistas, além de sua complementação através da realização de pesquisas  bibliográficas, ou seja, por meio de um estudo sistematizado com base em materiais  publicados em livros, artigos, teses, dissertações, normas técnicas e a Internet. O  questionário foi aplicado aos funcionários da organização pesquisada buscando  identificar as opiniões dos funcionários quanto à percepção da segurança da informação.  O questionário foi aplicado a todos os funcionários da organização pesquisada, que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     106   possuíam contato direto com a Tecnologia da Informação (TI), buscando identificar as  opiniões dos funcionários. Após responder os questionários, foram realizadas  entrevistas presenciais com cerca de 15% dos funcionários, ou seja, 36 funcionários,  que lidam com os processos com rotinas que possuem contato direto com os recursos de  TI.     3. Resultados e Discussões   Os resultados da pesquisa foram obtidos através do confronto das técnicas utilizadas na  organização, para a obtenção de um lúcido diagnóstico da organização, com as práticas,  normas e conhecimentos teóricos obtidos através de uma extensa revisão de literatura,  que permitiu propor um PCN ajustado para a organização.     No PCN proposto para a organização foram definidas estratégias e ações a  serem adotadas com o objetivo de possibilitar a redução de danos às informações, e,  portanto, ao patrimônio e as pessoas envolvidas, contribuindo para a proteção da  imagem organizacional.  Para tanto, tomou-se como base o diagnóstico feito através  do Relatório de Gestão de Riscos, que forneceu insumos relevantes para elaboração do  PCN, visto haver em seu contexto a identificação das principais vulnerabilidades e  ameaças que expõem aos riscos as informações manuseadas e armazenadas pelos  usuários da organização.     Somente a partir da identificação dos pontos críticos, os quais são apresentados a  seguir, é que se fez possível a realização de um mapeamento que permitisse a  identificação dos processos, atividades e informações afetadas por estes, caso viesse a  ocorrer algum incidente.  A partir de levantamentos, as ameaças que potencializam  riscos na instituição pesquisada, bem como o levantamento do quantitativo de  ocorrência destas são apresentadas no gráfico da Figura 1.    Foram identificados cerca de 75 riscos, pelos quais estão expostos os sistemas de  informação da organização pesquisada, ocorrendo com menor frequência a destruição  de recursos de hardwares e com a maior frequência a interrupção de serviços, que gerou  27% das ameaças, conforme apresentado na Figura 1.    Na fase de análise e avaliação dos riscos foram avaliados os fatores: aspecto,  classificação, origem, razões de ocorrência e as prováveis consequências sofridas a  partir de cada ameaça identificada, considerando a possibilidade de ocorrência. Um  destes fatores que se destaca é o aspecto dos riscos detectados.     Figura 1. Gráfico das ameaças e suas respectivas ocorrências    Os aspectos dos riscos foram identificados como físicos, humanos, processuais e  tecnológicos e ainda mensurados de acordo com suas ocorrências em todo o ambiente,  sendo os resultados obtidos apresentados no gráfico da Figura 2.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     107     Figura 2. Gráfico dos aspectos e suas respectivas ocorrências    Para os aspectos dos riscos identificados, o processual foi o que menos se  destacou obtendo uma pontuação de apenas 9% de ocorrências, porém, o risco humano  obteve uma pontuação superior a 50% de ocorrências, conforme resultados apresentados  na Figura 2.     No processo de elaboração da proposta levou-se em conta, desde o  primeiro momento, a possibilidade de adoção e aplicação do mesmo não apenas naquela  instituição, mas visando ainda que esta se estenda a qualquer outro hospital da rede  SESAU do Estado do Tocantins, uma vez que todos possuem limitações e fatores  idênticos ao da instituição pesquisada.     O ponto chave do processo de elaboração do PCN foi o de não subestimar  quaisquer ameaças identificadas no Relatório de Gestão de Riscos. Por fim, o PCN foi  construído, basicamente, através da sequência de passos apresentados a seguir:  Identificação dos processos e ativos que necessitavam de proteção; Identificação dos  potenciais desastres; Identificação do grau de exposição dos ativos ao desastre;  Estimativa do impacto de cada desastre; Análise das medidas de proteção; e Estratégias  para manter a produção perante um desastre, estratégias envolvendo comunicação,  responsabilidades e papéis de controle, priorização de atividades, base de dados e base  de conhecimento para suporte.    Assim sendo, foi elaborado e proposto um modelo de PCN para o hospital  estudado, sendo sugerida à equipe de TI bem como à direção do mesmo a adoção de tal.  Podendo o documento resultante de tal estudo, ou seja, o PCN proposto propriamente  dito, ser visto na integra através da observação do Apêndice A, que se encontra na parte  final deste artigo.     4. Conclusões   Um Plano de Continuidade de Negócios (PCN) não é um documento muito comum na  maioria das organizações brasileiras, portanto após ocorrência de qualquer ataque é  comum que os sistemas de informação fiquem dias sem operação para seus clientes,  demonstrando o total despreparo da organização perante ação das ameaças.    A organização pesquisada não possuía um PCN, durante a fase de diagnóstico  foi possível identificar as ameaças e, também, como a instituição estava despreparada  para os mais diversos tipos de desastres, desde pequenos incidentes até os acidentes de  maiores proporções.     A criação da proposta do PCN não apresentou grandes dificuldades, devido à  colaboração dos funcionários e a presença de um Relatório de Gestão de Risco bem  estruturado obtido na fase de diagnóstico.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     108    Ao final da pesquisa os funcionários puderam identificar o valor que o PCN  agregava. Conscientizaram também da necessidade de manter o mesmo atualizado,  resguardando não só a imagem da organização, mas também, à própria imagem  profissional. Possuindo rápida aderência pelos funcionários e gestores locais.     Espera-se que as propostas apresentadas continuem sendo utilizadas pela  organização pesquisada para o fortalecimento institucional e que os resultados desta  pesquisa possam servir de alerta para outras organizações.      Como trabalhos futuros espera-se elaboração de sistema de monitoramento para  revisão do documento, reanálise perante grandes modificações no ambiente e  monitoramento de melhorias e manutenção destas através da utilização de ferramentas e  bibliotecas, tais como: ITIL, COBIT e outras que possam surgir.    Referências  Alves, R. M. e Zambalde, A. L. Segurança da Informação. 1ª ed. Lavras, MG:   UFLA/FAEPE, 2007, 151 p.  ISO 15999-1. ABNT NBR ISO/IEC 15999-1:2007 – Gestão de continuidade de   negócios – Parte 1: Código de prática. Associação Brasileira de Normas Técnicas –  Rio de Janeiro: ABNT, 2007.   ISO 25999-2. ABNT NBR ISO/IEC 25999-2:2008 – Tecnologia da Informação –  Técnicas de segurança – Código de prática para a gestão da segurança da  informação. Associação Brasileira de Normas Técnicas – Rio de Janeiro: ABNT,  2008.   ISO 27002. ABNT NBR ISO/IEC 27002:2005 – Tecnologia da Informação – Técnicas  de segurança – Código de prática para a gestão da segurança da informação.  Associação Brasileira de Normas Técnicas – Rio de Janeiro: ABNT, 2005.   Junior, J. H. P. de P. Plano de Continuidade de negócios aplicado à segurança da  informação. Porto Alegre, 2008. 60p. Monografia (Especialização em Tecnologias,  Gerência e Segurança de Redes de Computadores) – Universidade Federal do Rio  Grande do Sul, 2008.   Magalhães, I. L. e Pinheiro, W. B. Gerenciamento de serviços de TI na prática: uma  abordagem com base na ITIL. 1ª edição. Porto Alegre: Novatec, 2007. 672 p.   Nakamura, E. T. e Geus, P. L. Segurança de redes em ambientes cooperativos. São  Paulo, SP: Novatec, 2007.  482 p.   Silva, E. Políticas de segurança e Planos de Continuidade de Negócios. Brasília, 2011.  45 p. (Pós-Graduação Latu Sensu em Segurança da Informação) – Faculdade de  Tecnologia SENAC DF, Brasília, DF, 2011.   Apêndice   Apêndice A: Plano de Continuidade de Negócio Sugerido   Neste Apêndice é apresentado o PCN, propriamente dito, através da Tabela 1.     Tabela 1. Plano de Continuidade de Negócio Proposto para a Instituição  Pública Hospitalar   Plano de Continuidade de Negócios - PCN  Identificação de Incidentes Tratamento do Incidente  Incidente Causas Plano de Continuidade  (PCO) Plano de Recuperação  (PRD)   Falta de energia  elétrica   Externa   Acionamento imediato do gerador  estacionário e rede elétrica alimentada  por este até que seja reestabelecida a   normalidade   Acionamento junto á prestadora de  energia elétrica          Solicitação do   reestabelecimento dos serviços  elétricos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     109   Interna   Uso de nobreaks nas principais  máquinas, tais como switches,   servidores e microcomputadores  responsáveis pelos serviços crítico   Acionar o setor de manutenção elétrica  do hospital para que seja feito reparos  à rede elétrica do hospital, verificando  o cabeamento, disjuntores, fusíveis e   tomadas.   Danos ao nobreak  Substituição do nobreak danificado por   um reserva até que seja reparado o  danificado   Levá-lo à manutenção para que seja  feito reparos tais como:  limpeza,  trocas de baterias, ou conserto de   placa.   Indisponibilidade dos  serviços de redes   Danos a Switch  Substituição da switch danificada por   um reserva até que seja realizados  reparos   Levá-la à manutenção para que seja  feito reparos tais como: limpeza e   conserto.  Danos ao   cabeamento  Substituição do cabo danificado por   outro já previamente preparado  Substituir ou reparar o cabo danificado   Danos ao servidor  de arquivos   Substituição do servidor ou dispositivo  danificado e restauração do sistema e   dos dados do mesmo através do último  backup realizado   Encaminhar o servidor danificado para  manutenção junto ao departamento   específico da SESAU   Danos ao servidor  de domínio   Encaminhar o servidor danificado para  manutenção junto ao departamento   específico da SESAU  Danos à placa de   redes do  computador   Substituição da placa danificada por  uma reserva   Identificação das causas que  ocasionaram o dano e correção para   que não se repita  Moderação acidental   de dados   Reparo dos dados através da restauração  de backup realizado anteriormente   Identificar meios pelos quais foram  possíveis se fazer a moderação e tratálos em conformidade com a Política de   Segurança da Informação adotada  Moderação   proposital de dados   Remoção proposital  de dados   Identificar meios pelos quais foram  possíveis se fazer a remoção e tratá-los   em conformidade com a Política de  Segurança da Informação adotada      Indisponibilidade dos  serviços de Internet   Danos à linha  telefônica   Acionamento de um link extra diferente  da tecnologia utilizada que permita a   liberação de serviços nos pontos críticos  que necessitam exclusivamente da   Internet para realização de suas  atividades até que os serviços normais   sejam reestabelecidos   Acionar representante/consultor da  prestadora de serviços de   telecomunicação, o qual realizará o  devido reparo ou troca do  equipamento danificado   Danos a algum  ponto da fibra óptica   Danos ao Modem   Vírus  Contaminação por   vírus  Isolamento da máquina para evitar a   proliferação às demais   Fazer atualização e varredura de  antivírus e identificar os meios que   possibilitaram a contaminação  tratando-os segundo a Política de   Segurança da Informação adotada.  Indisponibilidade de   restauração de  backups   Danos às mídias de  armazenamento de   backup   Dar continuidade aos serviços que não  dependam das informações do backup   até que estas sejam recuperadas   Fazer recuperação através de  softwares e equipamentos específicos   Falha de Hardwares   Danos à impressora   Substituição da impressora danificada  por uma reserva ou a configuração para  impressão em uma outra impressora até   que o reparo seja concluido   Acionar assistência técnica, que  realizará o reparo ou troca do   equipamento   Danos ao  microcomputador   Substituição da máquina danificada por  uma reserva até que a danificada seja   reparada   Caso não seja possível o conserto  localmente, encaminhar a máquina   danificada para manutenção junto ao  departamento específico da SESAU   Falha de Softwares   Danos ao Sistema  Operacional   Substituição da máquina danificada por  uma reserva até que a danificada seja   reparada   Identificar a causa do dano e fazer  reparo e/ou reinstalação do Sistema   Operacional danificado  Danos Causados por   atualização de  softwares próprios   Reestabelecer os serviços através da  restauração de backups   Identificar as causas do problema e  saná-la   Danos Causados por  atualização de  softwares de   terceiros   Fazer isolamento do módulo danificado  Solicitar a imediata manutenção ao  proprietário do software danificado   Danos à Software  utilitário   Nos casos dos departamentos que  necessitem do sistema de atendimento,   devem fazê-los manualmente para  garantir o andamento de suas atividades   até o reestabelecimento do aplicativo   Reparo através da restauração do  sistema por meio de backup realizado  anteriormente ou ainda a reinstalação e   atualização do Software  Casos como do eletrocardiograma e  ultrassonografia que possuem seus   aplicativos em máquinas específicas  sem possibilidade de redundância,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 103-110  Nov/2014     110   devem ser avaliados e, se possível,  encaminhados para outro hospital que   realiza tais exames  Demais casos fazer uso de uma outra   máquina ou aguardar seja feito o devido  reparo   Falta de refrigeração  Danos aos aparelhos  de ar condicionado   Substituição do aparelho danificado por  um reserva até que o danificado seja   reparado   Acionar o setor de manutenção para  que seja feito consertos ao mesmo   Danos causados às  mídias de backups   Armazenamento  inadequado   Fazer uso da penúltima cópia  Fazer cópias extras em mídias   diferentes e armazená-las em um cofre  de propriedade do hospital   Incêndio Desconhecida   Nos casos dos departamentos que  necessitem do sistema de atendimento,   devem fazê-los manualmente para  garantir o andamento de suas atividades   até o reestabelecimento do aplicativo Montagem de recursos de hardwares e  softwares que permitam o   reestabelecimento imediato dos  serviços críticos da instituição   Casos como do eletrocardiograma e  ultrassonografia que possuem seus   aplicativos em máquinas específicas,  estas devem ser reconfiguradas para   trabalho autônomo e liberado uso  Demais casos aguardar seja feito o   devido reparo           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     111   Aprendizagem dos Números para Crianças com o Uso do  Kinect   Kleber M. Mesquita1, Robson S. Siqueira1   1Instituto Federal de Educação, Ciência e Tecnologia do Ceará  (IFCE) – Maracanaú,  CE – Brasil   {kleber099,siqueira.robson.dasilva}@gmail.com   Abstract. Development of new technologies to human-computer interaction has  receive the most interest of researchers in developing new techniques and  applications that facilitate and qualify people's lives. The popularization of  depth sensors such as Microsoft Kinect has enabled progress in techniques that  had many restrictions on the use of RGB images, minimizing occlusion  problems like skin recognition. This paper presents a technique to identify  numbers with hand gestures applied to interactive teaching children. The  presented method aims to assist professionals in early childhood education to  design programs that can get information about the learning progress.   Resumo. Com o rápido surgimento de novas tecnologias, a interação homemmáquina tem renovado o interesse de pesquisadores no desenvolvimento de  novas técnicas e aplicações que facilitem e qualifiquem a vida das pessoas. A  popularização de sensores de profundidade como o Microsoft Kinect, tem  permitido evoluir em técnicas que possuíam muitas restrições com o uso de  imagens RGB, minimizando problemas como oclusão e reconhecimento de  padrões de pele. Este artigo apresenta uma técnica para identificar números  com os gestos das mãos, aplicado ao ensino interativo de crianças. O método  apresentado tem por objetivo auxiliar os profissionais em educação infantil a  projetar programas que possam obter informações sobre o andamento do  aprendizado.    1. Introdução   Reconhecimento de gestos das mãos é de grande importância para a interação homemmáquina (HCI), por causa de suas inúmeras aplicações na realidade virtual,  reconhecimento de linguagem de sinais e jogos de computador [2]. Apesar de muitos  trabalhos anteriores, métodos de reconhecimento de gestos de mão tradicionais, com  base na visão [7, 8] ainda estão longe de ser satisfatórios para aplicações na vida real.  Devido às limitações dos sensores ópticos, a qualidade das imagens capturadas é  sensível às condições de iluminação e de fundo ofuscado, assim não é capaz de detectar  e identificar as mãos de forma robusta, o que afeta em grande medida o desempenho do  reconhecimento de gestos [1].     Graças ao recente desenvolvimento de câmeras de profundidade de baixo custo,  por exemplo, o Kinect, novas oportunidades para o reconhecimento de gesto surgem,  esse trabalho propõe reconhecer gestos das mãos utilizando o Kinect, verificando  quantos dedos estão sendo mostrados nas cenas capturadas, possibilitando realizar a  quantificação, identificação de formas e atribuir posteriormente a execução de ações ao  reconhecer cada padrão estabelecido. Tornando possível gerar indicadores, por  exemplo, sobre o processo de aprendizagem de números para crianças que estão no  nível adequado esse tipo de conhecimento, bem como para crianças ou adultos que     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     112   estejam reaprendendo, após processos traumáticos de perda total ou parcial de memória  ou de outras faculdades cognitivas.    A geração desses indicadores, sob a coordenação de um profissional da área,  pode ser obtida com testes não supervisionados aos usuários finais, de maneira a  auxiliá-los na avaliação do nível de cognição visual, auditiva, motora ou tempo de  reação, dentre outras informações que possam ser disponibilizadas e sejam importantes  para os especialistas.      Todo esse trabalho será realizado com processamento e análise das imagens de  profundidade do Kinect com o intuito de identificar a quantidade de dedos dos gestos  das mãos e apresentar um modelo para aplicações no aprendizado infantil.   2. O Kinect e sua utilização na Educação Infantil   O processo de aprendizagem vai além do ambiente da sala de aula e está presente em  todos os momentos em que uma troca de experiência, não necessariamente entre  professor e aluno, possa vir a acrescentar conhecimento ao indivíduo [3]. Devem-se  criar diferentes formas de organização da classe, dos tempos e espaços didáticos, dos  objetos, recursos e estratégias pedagógicas [5]. Diferenciar é organizar as interações e as  atividades, de modo que cada aluno seja constantemente confrontado com as situações  mais fecundas para ele, que sejam do seu interesse ou que seja um obstáculo à  construção do conhecimento. Assim, o ensino diferenciado implica a utilização de  diversas estratégias didáticas [4].     Através da NUI (Natural User Interface) pode se criar um ambiente de forma  mais natural, por que se baseia em um ambiente feito por interações. Muitas dessas  interações são rotineiras e conhecidas por usuários, no caso crianças. A interface que  proporciona a NUI é um design de aplicação que permite explorar do usuário a melhor  forma de interagir com o objeto em questão, fazendo com que a experiência de uso do  produto se aproxime do mais confortável, intuitivo e simples possível, para o usuário  que está utilizando a aplicação [6].    Em pouco tempo Kinect pouco a ser utilizado como objeto de estudo e  desenvolvimento de aplicações em Realidade Aumentada (RA) devido a sua capacidade  de reconhecimento de movimento, comando de voz, sem a necessidade de algum outro  dispositivo adicional. Dessa forma, permite pessoas interagirem com os jogos, sistemas  e dispositivos, utilizando se do movimento do próprio corpo [3]. Além disso, é capaz de  perceber a terceira dimensão (profundidade).    Uma das grandes vantagens de utilizar imagens de profundidade no lugar de  imagens RGB são as restrições ligadas, principalmente, à iluminação do ambiente. A  detecção de pele, utilizada para detectar as mãos, é muito dependente da iluminação que  pode alterar os parâmetros de reconhecimento pré-definidos pelo sistema [9]. O sensor  de profundidade não precisa de luz para funcionar e por isso não sofre com problemas  de sombreamento se houver uma fonte luminosa predominante, de forma similar à  imagem em tons de cinza, tem um canal que possui uma janela com largura e altura  características. A diferença está no significado do valor do pixel, no caso da imagem em  tons de cinza, ela equivale ao tom da cor cinza; já no caso da imagem de profundidade,  diz respeito à distância entre o sensor e a superfície do objeto detectado. Outra diferença  importante é que a imagem em tons de cinza possui 8 bits, correspondendo à 256 tons;  no caso da imagem de profundidade são 11 bits, dos quais 10 correspondem à distância     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     113   da superfície do objeto ao sensor e o outro indica se o ponto é válido ou não. No caso, a  distância pode variar de 0 a 1023, caso contrário, o pixel é desconsiderado.   3. Reconhecimento de Gestos da Mão   3.1. Ambiente de Pesquisas e Testes   O ambiente de desenvolvimento e testes desse trabalho foi realizado em sistema  operacional Linux, distribuição Debian Wheezy. Os algoritmos na pesquisa foram  inscritos nas linguagens C/C++, utilizando a biblioteca OpenCv, afim de manipular,  tratar e processar as imagens. Diversos usuários realizaram gestos com as mãos na  frente do Kinect e as imagens geradas foram utilizadas pelos algoritmos desta pesquisa  a fim de reconhecer e obter informações importantes a cerca das mãos. (O uso da  aplicação deverá ser utilizado em computadores conectados com o Kinect.)   3.2. Método de Reconhecimento da Mão     A Fig. 3.1 mostra o fluxograma das etapas que foram necessárias no processo de  reconhecimento da mão, que foi composto da aquisição da imagem pelo o kinect até a  delimitação das regiões que são dedos e extração das informações importantes a cerca  da mão.     Figura 3.1. Fluxograma de reconhecimento da mão    Como foi mencionado na seção 2, o sensor de profundidade do Kinect atribui  valores conforme a distância dos objetos na cena. Para capturar somente as mãos, foi  utilizada uma janela com intervalo entre 300 e 500 na coordenada de profundidade, isto  equivale à uma distância entre 100 e 150 cm do sensor, que pode ser modificada de  acordo com o ambiente onde será realizado o teste. Foi construído um algoritmo que  atribui para atribuir cores aos objetos identificados de acordo com a distância que e  encontra os objetos estão do sensor    A próxima etapa constitui em binarizar a imagem capturada do Kinect, para que  somente dois níveis de cores fossem utilizados. Caso o objeto estivesse no intervalo de  janela estabelecido, seria atribuída à cor branca (valor 255), se não estivesse seria  atribuída à cor preta (valor 0). Com isso, foi possível separar as mãos do restante dos  outros objetos que estavam presentes na cena. A Fig. 3.2 apresenta a imagem após o  processo de binarização.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     114   Figura 3.2. Imagem após a aplicação do algoritmo de divisão por janelas e  binarização da imagem    Em seguida foi aplicado o filtro da média na imagem utilizando o tamanho 5x5.  Com isso foi possível suavizar as imagens adquiridas e retirar os diversos ruídos que o  sensor do Kinect detectou. A imagem tratada com o filtro da média pode ser visualizada  na Fig. 3.3.a.       (a) (b) (c)   Figura 3.3. (a): Comparação entre a imagem binarizada e aplicação do filtro da  média. (b): Identificação do contorno da mão. (c): Centro geométrico do  contorno    Após o tratamento com o filtro da média, foi possível identificar o contorno das  mãos, necessário para obter informações que ajudarão a demarcar a região onde se  encontram os dedos na imagem e a quantidade destes  que está sendo mostrada em  cada mão. O contorno de uma mão pode ser visualizado na Fig. 3.3.b.    Com o contorno de cada mão encontrado, a próxima etapa foi encontrar a  centroide (ou centro geométrico) de cada um. Centroide é o ponto central de uma forma  geométrica qualquer, caso a forma geométrica seja homogênea, então o centroide  coincide com o centro de massa. Nos casos em que essa forma não é homogéneo, então  esse ponto coincide com o centro gravitacional. O Centro geométrico do contorno da  mão pode ser visualizado na Fig. 3.3.c.    Foi utilizado o ponto central da mão para encontrar a distância entre cada ponto  do contorno em relação ao seu centro geométrico. Para calcular essa distância, foi usado  distância Euclidiana entre dois pontos, dada por:        O ponto  representa cada ponto que faz parte do contorno e   é o ponto central que está dentro do contorno. A  partir desses dois   pontos, é possível calcular a distância  .    Em seguida foram construídos gráficos para representar as formas adquiridas  pelo Kinect. A Fig. 3.4.a apresenta o gráfico de uma mão, onde é representada a  distância entre o centro geométrico em relação a cada ponto do contorno. Os pontos do  contorno mais distantes do centro geométrico estão concentrados nos picos do gráfico, e  os pontos com menor distância em relação ao centro estão nas regiões mais inferiores  no gráfico. Os picos são as pontas de cada dedo. A imagem 3.4.a contém cinco picos  referentes aos cinco dedos da mão esquerda, caso seja detectado menos dedos, menos  picos serão apresentados, conforme Fig. 3.4.b.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     115      (a) (b)   Figura 3.4. (a): Gráfico da distância entre cada ponto do contorno e o centro da mão. (b):  Gráfico da mão com três dedos    Para identificar a quantidade de dedos, definiu-se um limiar  que identifique a  presença de dedos nas imagens adquiridas. Limiar é um valor limite que divide duas ou  mais classes. Para esse trabalho, objetivou-se encontrar um  que dividisse as regiões  que contivesse dedos daquelas que não contivesse. Um aspecto importante de definição  deste limiar é que ele deve servir para tamanhos de mãos diferentes, pois o algoritmo  pode ser aplicado a crianças, jovens ou adultos. Isso somente é possível se for utilizado  um valor adimensional, com base em alguma característica da mão. Neste caso, foi  utilizado como parâmetro o raio inscrito na mão, como sugerido por Zou-Zang[1].    Para encontrar o círculo inscrito dentro do contorno, foi calculada a menor  distância entre o centroide e o contorno de cada mão. Essa distância calculada é o raio   do círculo inscrito de cada contorno, o qual pode ser visualizado na  Fig. 3.5.a.  Com o raio do círculo inscrito ao contorno, utilizou-se o valor de , a fim de estabelecer  um  que vai identificar a presença de dedos nos contornos obtidos. Ao utilizar uma  constante  qualquer, estabeleceu-se uma fórmula para encontrar um valor para , dada  por . Dentro do universo de 1000 imagens adquiridas para teste de 10  usuários diferentes, o valor de  para  mostrou se o mais adequado. Pela Fig. 3.5.b,  percebe-se que ao utilizar esse limiar, o círculo da figura intercepta todos os dedos do  contorno, então, as distâncias  representam as regiões que são dedos no contorno  encontrado.   Em seguida foi delimitada a sequência de pontos de cada dedo, detectando o  limite inicial e o final de cada um deles, assim foram obtidas informações importantes  como, por exemplo, a área, quantidade de pontos em cada dedo e estabelecidos critérios  para classificar se as regiões encontradas eram realmente dedos. A Fig. 3.5.c apresenta  os pontos que fazem intercessão entre o contorno e o círculo de raio , os quais  delimitam o início e fim de cada dedo.   Ao obter os limites de cada dedo e juntos com seus pontos de contorno,  calculou-se a área pelo número de pixels existentes dentro do contorno. Na Fig. 3.5.d  pode-se visualizar as regiões da imagem que foram detectadas como dedos denotados  pelas áreas pintadas pela cor branca. São justamente os pontos cujo , caso ,  tais pontos não pertencem a dedos e suas regiões não serão identificados como tal.        (a) (b) (c) (d)   Figura 3.5. (a): Circulo inscrito no contorno de raio . (b): Circulo com    (c): Pontos que delimitam cada dedo. (d): Detecção de dedos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     116   4. Testes   Como visto na seção 3.2, é possível obter informações importantes a cerca da mão. Para  os testes, foi utilizado a área da mão , as áreas de cada dedo: polegar , indicador ,  médio , anelar  e mindinho ;  a quantidade de pontos de cada dedo: polegar   , indicador , médio , anelar  e mindinho ; a distância da ponta de cada  dedo em relação ao centro: polegar , indicador , médio , anelar  e mindinho    e a excentricidade de cada dedo: polegar , indicador , médio , anelar  e  mindinho .     Foram utilizados os valores acima para calcular dados estatísticos das  características das mãos, à média  e o desvio padrão , para estabelecer um intervalo  de confiança.  A média das áreas de cada dedo em relação à área da mão: correspondeu   à , , ,  e ; a média da quantidade de pontos de  cada mão: , , ,  e ;  a média da distância da ponta de cada dedo ao centro:   , , ,  e  e a média da excentricidade de cada dedo: , , ,  e .     Sejam  todos os valores obtidos das formas ou regiões capturadas, se  ,  é uma característica de uma mão, então, a forma ou região é de   uma mão. Caso os valores não estejam no intervalo de confiança, as formas ou regiões  não podem ser consideradas como mão.   5. Resultados   A Tabela 5.1 mostra os valores calculados das estatísticas das imagens adquiridas de  uma base de dados, com amostras de 1000 imagens que tenha somente mãos.   Tabela 5.1 Valores estatísticos das características da mão   Polegar             0.041149 0.012238 29.619835 6.187760 71.475207 3.160326 0.239564 0.101158     Indicador              0.061531 0.006850 43.057851 6.456814 83.739669 5.246976 0.227218 0.060416   Médio             0.071748 0.009371 37.060606 6.830291 88.703857 5.918449 0.233051 0.061386   Anelar             0.051712 0.009089 29.049587 6.690004 80.106061 6.221302 0.279684 0.080880   Mindinho             0.028489 0.009147 24.588154 6.079458 70.998623 5.891783 0.276541 0.113298     Nos diversos testes realizados em 95% dos casos os valores estavam  dentro do intervalo de confiança, os demais casos não foram classificados como mãos,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     117   pois eles estavam fora do intervalo de confiança. A Tabela 5.2 mostra alguns valores  obtidos nos testes realizados.   Tabela 5.2 Valores das características da mão    Observa-se pela tabela que cada dedo tem características próprias e esse valores  estatísticos pode ser utilizados para identificar um dedos particular, pois a faixa de  valores de cada característica está em intervalo diferente de valores para cada dedo.   6. Aplicação de Aprendizagem de Números   Conforme o usuário vai realizando gestos em frente do sensor do Kinect o aparelho vai  capturando seus movimentos. É importante que a mão do usuário esteja em destaque na  frente do sensor. À medida que o usuário vai realizando gestos a aplicação vai  reconhecendo os dedos apresentados. Ao reconhecer certa quantidade de dedos é  mostrado o número correspondente, como mostra a Fig. 6.1.     Figura 6.1. Contagem dos dedos     A aplicação reconhece no máximo cinco dedos em cada mão. A taxa de acerto  chega a 95%, sendo a maioria dos erros devido a fusão de dois dedos adjacentes.   7. Conclusão e Trabalhos Futuros   Embora o algoritmo funcione realizando a contagem dos dedos apresentados, a  aplicação pode funcionar de outras formas, como a apresentação aleatória de números  na tela, aguardando que o usuário reproduza o mesmo com os dedos das mãos. O  mesmo pode ser feito com o uso de voz, apresentando um comando com o som do  número, ou mesmo realizando uma operação de soma simples. O uso contínuo do  algoritmo pelo usuário faz com que ele naturalmente, observe os casos em que há erro  de detecção e realiza o correto posicionamento e abertura entre os dedos das mãos,  diminuindo a oclusão. O erro na detecção pode ser reduzido com o tratamento de vários   Polegar Indicador Médio                 0.03065 25 69 0.161692 0.059473 49 88 0.249996 0.062905 34 91 0.213605   0.030820 24 72 0.324245 0.058002 44 87 0.235579 0.064864 41 92 0.220216   0.044286 29 72 0.174301 0.060145 46 84 0.183015 0.064169 33 91 0.254420   Anelar Mindinho                       0.044303 30 75 0.216659 0.030071 30 65 0.286135   0.042916 29 86 0.261702 0.022781 27 66 0.262790   0.046045 28 83 0.230703 0.030644 19 71 0.279992     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 111-118  Nov/2014     118   frames seguidos com uma máquina de estado que consiga assegurar o estado estável  mais provável.    Trabalhos futuros devem realizar a identificação da posição das mãos na cena,  tirando a restrição de o usuário estar em determinada distância do sensor. Sem essa  restrição, pode-se identificar mais de um usuário no cenário o que possibilitaria o uso  interativo para aplicação em torneios cooperativos.   8. Referências   R, Zhang and Y, Junsong. (2011) Robust Hand Gesture Recognition Based on Finger-  Earth Mover’s Distance with a Commodity Depth Camera. In: Proceedings of the  19th ACM international conference on Multimedia, pages 1093-1096.   J. P. Wachs, M. Kölsch, H. Stern, and Y. Edan. (2011) Vision-based hand-gesture  applications. In Communications of the ACM, v.54:60–71.   A. Rodrigo,  A. Jefferson & M. Francisco. (2012) AlfabetoKinect: Um aplicativo para  auxiliar na alfabetização de crianças com o uso do Kinect. In SBIE, Anais.   Perrenoud, P. (2011) A pedagogia na escola das diferenças: fragmentos de uma  sociologia do fracasso. In Porto Alegre: Artmed.   Amaro, D. G. and Macedo, L. (2011) Da lógica da exclusão à lógica da inclusão:  reflexão sobre uma estratégia. In Seminário Internacional Sociedade Inclusiva,  Anais. Belo Horizonte.   Jensen, M. B. (2011) Natural user interfaces from all angles: An investigation of   interaction methods using depth sensing cameras. Aalborg University.   C. Chua, H. Guan, and Y. Ho. (2002) Model-based 3d hand posture estimation from a  single 2d image. Image and Vision Computing, 20:191 – 202.   B. Stenger, A. Thayananthan, P. Torr, and R. Cipolla. (2003) Filtering using a treebased estimator. In Proc. of IEEE ICCV.   S. Jaiswal, S. Bhadauria, R. S. Jadon, and T. Divakar. (2011) Brief description of image  based 3d face recognition methods. 3D Research , 1(4):1-14.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     119   Uma Metodologia para Estimativa de Esforço em Projetos  de Softwares Desenvolvidos com ICONIX Empregando Use   Case Points   Fabrício S. Melo1   1Universidade Estácio de Sergipe (FASE)  Rua Teixeira de Freitas, 10, Salgado Filho – Aracaju, SE - Brasil   fs-melo@bol.com.br   Abstract. This paper presents a methodology for estimating the development  effort of object-oriented software, still in the phase of requirements analysis,  using Use Case Points (UCP) applied to projects executed with the ICONIX  process. A procedure as an alternative to arbitrary estimates typically found  in agile software development was presented. Although the technique of UCP  is not as widespread as the function point analysis, this study showed that it is  still quite useful to be easily achievable in the first phase of the process under  study, ensuring thereby a systematic estimation, adaptive to changes  requirements and extremely rapid, contributing to software quality without  neglecting the agile philosophy.   Resumo. Este artigo apresenta uma metodologia para estimar o esforço no  desenvolvimento de software orientado a objetos, ainda na fase de análise de  requisitos, utilizando Use Case Points (UCP) aplicada a projetos executados  com o processo ICONIX. Foi apresentado um procedimento em alternativa às  estimativas arbitrárias normalmente encontradas em desenvolvimento ágil de  software. Apesar da técnica de UCP não ser tão difundida quanto à análise de  pontos de função, esse estudo mostrou que ela ainda é bastante útil por ser  facilmente realizável na primeira fase do processo em estudo, garantindo,  com isso, uma estimativa sistematizada, adaptável às mudanças de requisitos  e extremamente rápida, contribuindo para qualidade do software sem deixar  de lado a filosofia ágil.   Introdução   Nos últimos anos o desenvolvimento ágil de software foi proposto como solução para  muitos dos problemas enfrentados no trabalho em projetos de software. Essa filosofia  preconiza o desenvolvimento iterativo e incremental de softwares que evoluem através  da colaboração de equipes multifuncionais motivadas e auto-organizadas que têm como  missão promover um planejamento adaptativo e respostas rápidas e flexíveis às  mudanças, principalmente de requisitos, ao longo do ciclo de vida do software. Sob essa  ótica o ICONIX define-se como um processo de desenvolvimento de software ágil  situado entre a alta complexidade, formalismo e abrangência do RUP (Rational Unified  Process) e a simplicidade do XP (Extreme programing) [Rosenberg & Stephens 2007;  Rosenberg, Stephens & Collins-Cope 2005].    Assim como o RUP, o ICONIX é um processo dirigido por casos de uso UML  (Unified Modeling Language) que guiam o esforço de desenvolvimento com alta  rastreabilidade de requisitos, no entanto mais leve que este. É tão leve e simples quanto  o XP, mas não dispensa as tarefas de análise e projeto. Utiliza apenas quatro diagramas     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     120   UML. Por essa razão, o processo ICONIX é bem adequado para projetos ágeis, onde o  feedback rápido é necessário, tais como atividades de requisitos, projeto, e estimativas.    Segundo Pressman (2006) ao início de um projeto de software são necessárias  elaborações de um plano organizado e de estimativas quantitativas, mas nesse momento  geralmente não há informação sólida disponível. Para o autor uma análise detalhada dos  requisitos de software pode fornecer a informação necessária para as estimativas, mas a  análise frequentemente prolonga-se por longos períodos na execução do projeto. Quanto  ao plano de desenvolvimento, esse pode ser elaborado examinando o produto e o  problema que ele pretende resolver no início do projeto para então proceder a  elaboração de seu escopo. A qual é a primeira atividade de gestão de um projeto de  software.    Em resposta ao problema da elaboração do escopo no início do desenvolvimento  e do elevado tempo para tanto, alguns processos ágeis, como ICONIX, podem remediar  o embate. No entanto, para além da determinação de um escopo, o bom e eficiente  planejamento deverá apresentar estimativas fidedignas no início da execução de um  projeto para que as atividades de monitoramento e controle possam prosseguir de forma  a garantir um produto final que atende os prazos e custos acordados. Nesse sentido o  presente trabalho objetiva estabelecer uma metodologia para estimar o esforço no  desenvolvimento de software orientado a objetos, ainda na fase de análise de requisitos,  utilizando Use Case Points (UCP).   Visão Geral do Processo ICONIX   Segundo Rosenberg e Stephens (2007), mentores do processo, seu principal objetivo é  estabelecer uma sequência de passos para transformar casos de uso em código fonte  limpo de forma ágil. Para tanto os fluxos de trabalhos são divididos em dinâmicos e  estáticos, e podem passar de uma iteração de todo o processo para um pequeno grupo de  casos de uso. Do ponto de vista temporal, os autores dividem o ciclo de  desenvolvimento em quatro fases e apontam para as atividades que devem executadas  em cada uma. São elas:   Requisitos   Nessa fase são identificados os casos de uso envolvidos, criada uma lista de requisitos  funcionais e elaborado o modelo de domínio composto por um diagrama de classes de  alto nível que em seguida são associadas aos requisitos funcionais e aos casos de uso.   Análise e projeto preliminar    Aqui é desenhado um diagrama de robustez, reescrito cada caso de uso, e atualizado o  modelo de domínio com atributos das classes e novos objetos encontrados.   Projeto detalhado   Agora são desenhados diagramas de sequência (um por caso de uso) para mostrar em  detalhes o que vai ser implementado, atualizado o modelo de domínio e adicionadas  operações para os objetos de domínio.   Implementação   Por fim é escrito o código e os testes de unidade, ou, a critério, escreve-se os testes de  unidade e, em seguida, o código; seguindo com os testes de integração e uma revisão de  código e modelo de atualização para se preparar para a próxima iteração de  desenvolvimento.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     121    Contudo, conforme inclusive sintetiza Silva e Videira (2001), o ICONIX  consiste na produção de artefatos que retratam as visões dinâmicas e estáticas de um  sistema e que esses modelos são desenvolvidos em paralelo durante todo ciclo de vida  do processo, de acordo com a Figura 1.        Figura 4 - Visão geral do ICONIX [Rosenberg e Stephens 2007]      Determinação do Escopo   Modelos de casos de uso são usados em análise orientada a objetos para capturar e  descrever os requisitos funcionais de um sistema. Considerados artefatos distintos, mas  intimamente ligados, um requisito funcional e um caso de uso podem associar-se em  uma relação de muitos para muitos (n:n). Essa colocação é muito importante na  determinação do escopo do sistema que será projetado, pois ao final da fase de  requisitos uma lista que os associa à(s) classe(s) de domínio servirá para orientar o  processo de desenvolvimento demonstrando o que deve ser produzido e, de forma  bastante dispersa, alguma informação sobre o esforço a ser despendido na execução do  projeto, já que cada caso de uso estará associado à produção ou até mesmo a  reutilização, de um número de classes, conforme exemplo na Tabela 1.      Tabela 1 - Lista de associação entre requisitos, casos de uso e classes   Requisitos Casos de Uso Classes a Produzir Classes Reutilizadas   R1, R2, R3 CU-01 CL-01, CL-02    R2, R4, R5 CU-02 CL-03 CL-01   R1, R2, R6, R7 CU-03 CL-04, CL-05 CL-01        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     122    No entanto, apesar de demonstrar um escopo candidato ao projeto, a lista acima  ainda não apresenta uma forma sistemática para inferir estimativas iniciais que seriam  usadas para planejar prazos e custos. O que pode ser solucionado com utilização da  contagem de Use Case Points (UCP). Um método de estimativa de esforço proposto por  Karner (1993), o qual se inspirou no modelo de Pontos de Função proposto por Albrech  (1979) e posteriormente melhorado por Symons (1988).   Estimativa de Esforço em Projetos de Softwares com Use Case Points   O modelo de contagem por casos de uso proposto por Karner, o UCP, traz o benefício  de poder ser executado ainda na fase de requisitos, mas foi criado para aplicação no  processo Objectory. Ele começa com a medição da funcionalidade do sistema baseado  no modelo de casos de uso em uma contagem não ajustada chamada Unadjusted Use  Case Point (UUCP). Nesse momento são avaliados fatores de complexidade técnica  (TCF) envolvidos no desenvolvimento desta funcionalidade. O último passo na  estimativa é avaliar o fator ambiental (EF) proposto pelo autor. O número de UCP é  dado então pela Equação 1 e deverá ser multiplicado pela taxa média de esforço para  encontrar a estimativa de esforço total do projeto.                                                 (Equação 1)    Em seu estudo Karner (1993) analisou três projetos estimados com UCP, os  quais apresentaram uma taxa média de esforço entre 20,0 e 28,7 homem-hora/UCP.  Apesar de muito pequena a mostra, notou-se a simplicidade, versatilidade e capacidade  de adaptabilidade dessa técnica. Mais tarde as experiências de Schneider e Winters  (2001) corroboraram com isso encontrando uma taxa de 20 ou 28 homem-hora/UCP  segundo a simplicidade ou complexidade do sistema, respectivamente.    Segundo Kress et al (2014) o fato do método de Pontos de Caso de Uso nunca  ter sido completamente calibrado usando análise de regressão, devido à falta de um  número estatisticamente suficiente de projetos, torna-o passível de uma grande  fraqueza. No entanto, o dimensionamento de fácil aplicação e regras de contagem  proporciona muitos benefícios para estimativas em fases iniciais e, assim, permite medir  rapidamente o tamanho funcional de uma aplicação.    Contagem de Unadjusted Use Case Points (UUCP)   O UUCP é calculado para aferir a cada ator e cada caso de uso um grau de  complexidade, simples, médio ou complexo, através da aplicação das regras da Tabela 2  e da Tabela 3, respectivamente.      Tabela 2 - Ponderação dos atores, adaptada de Karner, 1993   Complexidade Definição Peso(Wi)   SIMPLES  Um ator é simples, se ele representa outro sistema com uma  interface de programação de aplicativo definido.   1   MÉDIO  Um ator é médio se:    1. Uma interação com outro sistema através de um protocolo.      2. Uma interação humana com um terminal de linha.   2   COMPLEXO  Um ator é complexo se ele interage através de uma interface  gráfica do usuário.   3     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     123   (Equação 2)   (Equação 3)   Tabela 3 - Ponderação dos casos de uso, adaptada de Karner, 1993   Complexidade Definição Peso(Wi)   SIMPLES Um caso de uso é simples, se tiver 3 ou menos transações,  incluindo cursos alternativos. Você deve ser capaz de perceber  o caso de uso com menos de 5 objetos de análise.   5   MÉDIO Um caso de uso é médio se tem de 3 a 7 transações, incluindo  cursos alternativos. Você deve ser capaz de perceber o  caso de uso com 5 a 10 objetos de análise.   10   COMPLEXO Um caso de uso é complexo se ele tem mais de 7 transações,  incluindo cursos alternativos. O caso de uso deve, no mínimo,  possuir 10 objetos de análise a serem realizados.   15    Agora se devem somar os pesos dos atores e dos casos de uso em conjunto para  obter o UUCP, conforme Equação 2.                Onde ni é o número de itens de variedade i.   Contagem do Fator de Complexidade Técnica (TCF)   O fator de complexidade técnica (TCF) varia de acordo com a dificuldade de construção  do sistema e é calculado pela Equação 3.       Onde C1 = 0,6 , C2 = 0,01 e Fi é um fator que é classificado numa escala de 0, 1, 2, 3, 4  e 5, conforme Tabela 4. O peso 0 significa que o fator não é relevante e 5 significa que é  essencial.   Tabela 4 - Fatores de Complexidade Técnica, adaptada de Karner, 1993   Fi Fatores de Contribuição na Complexidade Peso(Wi)   F1 Sistemas distribuídos. 2   F2 Objetivos de desempenho do aplicativo, em qualquer resposta ou transferência. 1   F3 Eficiência do usuário final (on-line). 1   F4 Complexidade de processamento interno. 1   F5 Reutilização, o código deve ser capaz de reutilizar em outras aplicações. 1   F6 Facilidade de instalação. 0.5   F7 Facilidade operacional, facilidade de utilização. 0.5   F8 Portabilidade. 2   F9 Mutabilidade. 1   F10 Concorrência 1   F11 Recursos de segurança especiais. 1   F12 Proporcionar o acesso direto para terceiros. 1   F13 Facilidades de treinamento do usuário especial 1     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     124   (Equação 4)   Contagem do Fator ambiental (EF)   O fator ambiental (EF) nos ajuda a estimar o quão eficiente é o nosso projeto. E é  calculado pela Equação 4.                Onde C1 = 1.4, C 2 = -0.03 e Fi , assim como no TCF, é um fator que é classificado  numa escala de 0, 1, 2, 3, 4 e 5, conforme Tabela 5. O peso 0 significa que o fator não é  relevante e 5 significa que é essencial.     Tabela 5 - Fatores ambientais, adaptada de Karner, 1993   Fi Fatores Contribuição na Eficiência Peso(Wi)   F1 Familiarizado com o processo 1.5   F2 Trabalhadores a tempo parcial -1   F3 Capacidade do Analista 0.5   F4 Experiência de aplicação 0.5   F5 Experiência em orientação a objetos 1   F6 Motivação 1   F7 Dificuldade na linguagem de programação -1   F8 Requisitos estáveis 2   Resultados e Discussão   A metodologia proposta para estimativa de projetos desenvolvidos com ICONIX  através da contagem de UCP é apresentada pelo procedimento abaixo:  1. Produzir uma tabela listando as associações entre requisitos funcionais, casos de   uso e classes de domínio, conforme modelo da Tabela 1;   2. Calcular os pontos de pontos de casos de uso não ajustados (UUCP),   ponderando a Tabela 3 com base no número de classes de domínio detectado na  Tabela 1, excluindo-se aquelas reutilizadas, já implementadas anteriormente;    3. Calcular o fator de complexidade técnica (TCF);   4. Calcular o fator ambiental (EF);   5. Calcular os pontos de casos de uso (UCP);   6. Calcular o esforço médio (EM) multiplicando os UCPs calculados pela taxa   média de esforço (homen-hora/UCP) (TME) observada nas estatísticas de projetos  anteriores para encontrar a quantidade de recursos necessários (em homem-hora)  conforme Equação 5.                                                          (Equação 5)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     125    Para ilustrar o procedimento de cálculo da UCP, um sistema de pedidos on-line  será utilizado. A Figura 2 mostra o diagrama de caso de uso para o sistema em  desenvolvimento, esse deverá interagir através de uma interface gráfica com três atores,  os quais são classificados como complexos.     Figura 5 - Sistema de Pedidos on-line    Na construção da tabela de associações, seguindo a Tabela 1 de exemplo, notouse que em todos os casos de uso panejados não se observa mais de dois ou três objetos  de domínio. Sendo assim os nove casos de uso apresentados são classificados como  simples. Dessa forma os pontos de pontos de casos de uso não ajustados foram  calculados pela Equação 2 da seguinte forma .    Calculando o fator de complexidade técnica através da Equação 3 temos       Calculando o fator ambiental através da Equação 4 temos   .    Utilizando a Equação 1, fazendo , temos  .       Como pode ser visto abaixo foi encontrado o esforço médio (EM) pela aplicação  da Equação 5 usando uma taxa média de esforço de 24 homen-hora/UCP, conforme  encontrado na literatura [Schneider e Winters 2001].    homen-hora    Por fim, o processo de estimativas em discussão deverá ser melhorado a cada  final de iteração do processo ICONIX adaptando a taxa média de esforço ao histórico de  projetos da equipe de desenvolvimento, no entanto, de início poderão ser usadas taxas  como descritas na literatura citada anteriormente, entre 20 e 28 homem-hora/UCP.    Conclusão   A metodologia apresentada trouxe uma alternativa às estimativas arbitrárias  normalmente encontradas em desenvolvimento ágil de software. Apesar da técnica de  UCP não ser tão difundida quanto à análise de pontos de função, esse estudo mostrou  que ela ainda é bastante útil por ser facilmente realizável ainda na primeira fase do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 119-126  Nov/2014     126   processo em estudo, garantindo, com isso, uma estimativa sistematizada, adaptável às  mudanças de requisitos e extremamente rápida, contribuindo para qualidade do software  sem deixar de lado a filosofia “ágil”.    Nota-se, então que a aplicação da técnica em questão (UCP) satisfaz os objetivos  iniciais desse trabalho, e que novas pesquisas deverão explorar testes em maiores  espaços amostrais, inclusive com o uso de práticas de inteligência artificial, primando  pela contagem e ajuste dos pontos de casos de uso e pela validação estatística do  modelo.   Referências   ALBRECHT, A. J (1979). Measuring application development productivity. Proc. of  IBM Applic. Dev. Joint SHARE/GUIDE Symposium, Monterey, CA, pp. 83-92.   KARNER, G. (1993), Resource Estimation for Objectory Projects – Objective Systems.   KRESS, C.F.; HUMMEL, O.; HUQ, M. (2014), A Practical Approach for Reliable PreProject Effort Estimation. In: CEUR Workshop Proceedings, Vol. 1138, p. 23.   PRESSMAN , R.S. (2011), Engenharia de Software, Rio de Janeiro: McGraw Hill, 6 ed.   ROSENBERG, D. & STEPHENS, M. (2007), Use Case Driven Object Modeling with  UML: Theory and Practice. Apress.   ROSENBERG, D., STEPHENS, M. & COLLINS-COPE, M. (2005), Agile  Development with ICONIX Process. Apress.   SCHNEIDER, G.,WINTERS, J.P. (2001), Applied Use Cases, A Practical Guide,  Addison-Wesley, Reading, MA.   SYMONS, C. R. (1988), Function Point Analysis : Difficulties and improvements.  IEEE Transactions on Software Engineering, Vol. SE-14, No. 1. Jan.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     127   GPRS network used to monitor the generation and use of  solar energy in residences     Robson da Cunha Santos(a,b), Gerson Gomes da Cunha(c), Marcos Antônio Cruz  Moreira(a), Mônica Castelo Branco(b), David Douglas Nunes Oliveira(a), Matheus   Muzitano Reis(a)     (a)Fluminense Federal Institute, Campus Macaé, Automation and Control Engineering  164 km Amaral Peixoto Road, Brazil   (b)Estácio de Sá University, General Alfredo Bruno Gomes MartinsHighway, s/n -Braga  - Cabo Frio / RJ, Brazil   (c)Federal University of Rio de Janeiro, Alberto Luiz Coimbra Institute Graduate  Engineering and Research, Civil Engineering Program/COPPE/UFRJ     (a)profrobsons@yahoo.com.br, (b)gerson@lamce.ufrj.br mail,(c) macruz@iff.edu.br,   (d)xxmoninfante@yahoo.com.br  (e)daviddouglas@gmail.com,(f) fenmattcf@hotmail.com        ABSTRACT  The article describes a system for solar power  generation, integrated into a "grid-tie" inverter,  converting Direct Current "DC", generated by the plates  in Alternating Current "AC" on the standards of  electrical distribution network. The energy generated is  quantified by smart metering module that transmits the  information in specified periods of time to a  microcontroller via GSM modem. The modem provides  the measured data on the internet, using networks and  cellular antennas. The monitoring, fault detection and  maintenance are performed by a supervisory station.  Employed board types, best inverter selection and  studies about control equipment and devices have been  described. The article covers and explores the global  trend of implementing smart distribution electrical  energy networks and the incentive to use solar  renewable energy. There is the possibility of the excess  energy produced by the system be purchased by the  local power utility.     Keywords: Smart Grid, Microcontroller, Supervisory,  Solar Energy, GSM.     1. INTRODUCTION  The concessionaires of electricity distribution provide  their customers a fully manual system that does not  offer the customer control of its consumption, nor is  there an opportunity of interacting with the current  system. Cited by many researchers and checked in  CRESESB (Reference Center for Solar Energy and  Wind Sérgio Salvo de Brito) site, one observes that  solar power has not yet reached a level of economic  competitiveness with conventional energy sources, due  to a number of factors, including lack of incentives (tax  reduction) and low efficiency of solar panels marketed  today (Pinho, 2014).  Despite these factors, one cannot   consider using these panels merely as an alternative  energy source, but also as a technically feasible option.  For it is possible to have a return on investment in the  long term by reducing pollution through the steep fall in  emissions carbon and eliminating the need of flooding  deforestation of large areas such as the hydro entails.   The research is justified for developing an  automated system, which enables the consumer no  longer being just a passive agent of the generation and  transmission of electric power business, bringing the  possibility of him/her being in charge of its central  micro generator installed at his residence.   Installing a variable frequency drive connected to  the power grid causes the consumer to make available  all mains power generated during the day. This energy  is born by the concessionaire for distribution to other  consumers and overnight the consumer - that generated  energy during the day - shall take back the energy he  generated during the day.  The energy meters installed  in rural homes works amounting consumption or  regressing consumption if the unit is power generating.     At the end of the month the negative (energy  generated greater than consumed) or positive (energy  consumed greater than that generated) balance occurs.  To current Brazilian legislation, in case of negative  balance, nothing will be paid by the consumer, but it is  now under study for some years adjusting the law so  that the consumer can receive for its energy generated  more than consumed.   The installation of the new Grid Tie inverter  technology eliminates the need for installing batteries,  which have a high cost and a low life (about five years).  In older versions of solar panels installing the battery  bank accounted for nearly fifty percent of the total  investment. Regarding modern data acquisition systems,  portability and mobility are essential for most  applications. In this sense, it has become essential to     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     128   add internet connection to the new and modern data  acquisition systems. In view of this new perspective,  this paper proposes an acquisition data system based on  cutting-edge and innovative technology inside current  marketplace. This includes data capture using  microcontroller and data transmission via cellular,  specifically using the GPRS / Internet technology.   These data are checked from a supervisory system and  this enables making decisions for the case of low  efficiency of the system and to check for fraud or  intervention required for maintenance.     2. DESIGN PARTS  Power generation through solar panels is somewhat  already well consolidated around the world. However,  there is still much room for modernization of systems,  as more modern ones are created, and use becomes  increasingly common due to the continuous increase in  system efficiency.     2.1 Solar panels  The solar panel can be defined as a device designed to  convert solar radiation into energy. For relying solely  on the sun, the most abundant energy source on the  planet, it is the cleanest method known of power  generation (Sukhatme, 2008). The Photovoltaic Solar  Panels are associations of photovoltaic cells that convert  sunlight into electricity. Most of these solar cells are  made of silicon or gallium arsenide, and present dark  color, for greater capture of light energy. The silicon  solar cells produce less energy compared to gallium, but  their cost is proportionately lower.             Figure 1: Solar Panels (Pinho,2004)     In the previous figure are shown two examples of  solar panels, the difference between them is visible once  the left figure, it is polycrystalline panel and the right  figure is in a monocrystalline panel, the difference is in  the manufacturing process (Pinho, 2014).     2.2 Inversor Grid Tie  Before the development of Grid Tie Inverters (grid  connected) there were only standalone inverters (OffGrid Inverter) that are not connected to the power grid  and were designed to create an AC voltage from DC  power stored in batteries.  The later ones are used in  autonomous systems such as detached houses, boats,  and UPS systems (emergency power supply). These  devices are not simultaneously connected to the mains  power supply grid.  As seen in the following figure, one   notices that the load has no connection to the power  network; its energy demand is supplied exclusively by  the battery.     Figure 2: Stand-alone photovoltaic system (the author)      The grid-injection inverters (Grid Tie Inverter)   create an AC voltage directly from the Photovoltaic  panels; without using batteries. They inject energy into  the grid, thus allowing trading of electricity. The main  difference between a conventional inverter (Off-Grid  inverter) and Grid-Tie inverter is that the latter is able to  interconnect with the network utility, due to its ability  to synchronize its frequency and its output voltage to  the network in which to connect. They are also able to  break away from the utility grid when it does not supply  power. The panels can be connected directly to the  inverter. There is no spending on batteries and charge  controllers.        Figure 3: Grid Tie Inverter Connection (the author)      2.3 Smart Meter  The meter from manufacturer Elster A102C model  displayed in the following figure provides an  economical solution for domestic applications. The  meter provides a communication port IRDA (Infra Red  Data Aquision), optical output for reading different  information on the meter operation.  In the liquid crystal  display one may view the total energy measured in  kWh.   This can be configured for single-phase  measurement of direct or direct/reverse energy both for  residential and small commercial / industrial users.  Furthermore, it provides the measure of active and  reactive power. The meter has an output that can  provide signals for power controllers, demand  controllers or remote reading systems.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     129    The meter from manufacturer Elster A102C model  displayed in the following figure provides an  economical solution for domestic applications.         Figure 4: Elster A102C meter (Elster,2012)      2.4 Plataforma Arduino  The Arduino project was created in Italy in 2005 with  the goal of providing a low cost, easy using platform for  electronics prototyping, to be used by anyone interested  in creating interactive desings with objects and their  environment. (Banzi,2011).   The Arduino electronics board contains multiple  inputs and outputs, analog and digital, and serial  interface via USB connection to communicate with the  computer. The smart card is an element of the AVR  microcontroller family that allows thousands recordings  and rewrites in its program memory.   In order to increase the functionality of the Arduino  board, several companies have developed hardware for  connecting additional electronic boards on the Arduino  terminal. These additional electronic boards are called  "Shields" and add various functions specific to the  Arduino. In this article will be described the GSM  Shield.   The Arduino Mega 2560, displayed in the  following figure, is a microcontroller board based on  the ATmega2560 microcontroller. It has 54 pins for  digital inputs / outputs, 16 analog inputs, 4 UARTs  (hardware serial ports), a crystal oscillator of 16 MHz ,  a USB connection, an input power, an ICSP connection  and a reset button.        Figure 5: Arduino Mega2560 (Banzi,2012)      2.5 GSM Shield  The card with GSM module SIM900 displayed in figure  6 is a board that can be easily attached on the   Mega2560 Arduino board, extending the functionality  of the GSM module to the resulting assembly. This  board is stacked on the Arduino board, through all its  pins. The GSM module SIM900 board uses this  structure to its power feeding and functioning. (Banzi,  2012).   The SIM900 GSM module, produced by SIM Com,  is responsible for communication with the GSM  network making possible the effecting and receiving  phone calls and text messages.   The modem is a device for wireless  communication. This equipment enters a new trend of  technology known as M2M (Machine to Machine) in  which this project is based.   GSM modems can operate even in voice mode, but  their greatest uses are for data transmission that occurs  through three types of technology: CSD Connection  (Circuit Switch Data); GPRS Connection (General  Packet Radio System) and SMS (Short Message  Service).        Figure 6: SIM900 GSM/GPRS (IteadStudio, 2012)      2.6 Supervisory and Data Acquisition System   The supervisory and data acquisition systems (SCADA)  were created due to the need for an interface that was  operator friendly to plant control. Are also known as  Human Machine Interface (HMI) or 'Supervisory' only.   The main objective of the Supervisory system is to  provide a simple way to monitor, control and manage  multiple points of an automated plant. The data that will  be processed by the SCADA can be obtained through a  connection with a controlling element, equipped with  sensors or even the data is entered directly by the  operator.     3. ASPECTS OF INTERNET-INTEGRATED   WIRELESS COMMUNICATION   Since the creation of the telegraph, through the creation  of radio communication, reaching the creation of the  phone until the creation of the cell phone, much has  evolved in terms of point to point communication.  However, the major event of the last century was the  development of wireless and mobile communication,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     130   like the cell phone.  From this, it comes the need and  wish to improve the cell phone. The GSM network  which was created and later enhanced to data  communication, as previously it was possible only  voice communication.     3.1 Historical of GSM Technology  The data transmission via mobile phone has become an  innovative solution for the incorporation of new values  in technology, which allows to add a quality hitherto  existing services in fixed-line telephony service with the  mobility factor, the main distinguishing point in cellular  telephony. Added to this, there is now a full integration  between the mobile phone and the Web network, which  forms a vast technological potential application  (Wirelessbrasil, 2012).     3.2 GSM Network Operation  According to the schematic of Figure 7, the mobile  stations (MS), that may be mobile (and portable) phones  or mobile units installed in cars, talk with the Base  Station System (BSS) through the air interface of Radio  Frequency (RF). The Base Station System (BSS)  consists of a Base Transceiver Station (BTS) and Base  Station Controller (BSC). It is common for several BTS  be located in one same location, creating two to four  sectored cells surrounding a common antenna tower.   The BSC are often linked to the BTS by microwave  links. The link to the BTS BSC is called the Abis  interface. Typically, 20 to 30 BTS are controlled by a  BSC. In turn, several BSS are subject to a Central  Switch and Control (MSC), which controls the traffic  between several different cells.  Each Central Switching  and Control (MSC) will have a Visitor Location  Register (VLR) in which the mobile units that are out of  the cells of their local area will be listed, so that the  network knows where to find them. The MSC is also  connected to the Location Register of Local Mobile  Unit (HLR), the Authentication Center (AUC) and the  Equipment Identity Register (EIR), so that the system  can verify that users are subscribers and equipment  legal situation. This helps preventing the use of  fraudulent or stolen mobile units. There are also  facilities within the system to the Operations and  Maintenance Organizations and Network Management  (NMC).        Figure 7: GSM Network Frame (Wirelessbrasil, 2012)     4. SOLAR ENERGY AS A SOURCE OF   ELECTRICITY   Solar energy as an energy source will not have the  ability to substitute other energy sources used today  because its generation is seasonal not allowing a  continuous feed of large systems. However, its  popularity, with the implementation of new systems  around the world, will make it complement other  sources of generation, thus reducing the environmental  impact generated by other energy sources     4.1 Historical of Photovoltaic Solar Energy  As a definition, solar photovoltaic energy is the energy  coming from the direct conversion of light into  electrical energy. In 1839, this phenomenon was first  described by French physicist Edmond Becquerel, when  reporting the properties of selenium, which produced an  electrical current directly proportional to the incident  radiation.   The subject began to receive a great attention from  the '60s, during the Cold War, as, despite its high cost,  this technology proved suitable to meet the energy  demands in aerospace missions as well as for supplying  satellites. Government programs in countries like  Germany, Spain and Japan stimulated domestic  application of this technology, which allowed for a  production scale, further reducing costs.   Nowadays photovoltaic cells are quite popular,  produced with thin films. They use even less material  and energy in their manufacturing process than the  polycrystalline silicon, which justifies its price more  affordable (Serrão, 2010).    4.2 Environmental Impacts  It can be said that the environmental impact is one of  the most relevant points as it comes to solar energy. The  most significant environmental impacts occur at the  production, construction and decommissioning of  photovoltaic cells.   In constructing these plates, various types of  environmental and health hazardous materials are used,  besides being consumed a large amount of energy,  which is related to the emission of air pollutants such as  greenhouse gases. Compared with a conventional  thermal power plant, solar power generation emits 20%  less CO2 for the same amount of energy produced  (Naturlink, 2012).    4.3 Current Feasability in Brazil   According to a study conducted by the Energy Research  Company (EPE), residential solar power production is  now economically viable for 15% of Brazilian  households.   Under the new resolutions of the National Electric  Energy Agency (ANEEL), published in 2012,  customers who possess solar panels in their homes can  not only reduce the consumption of electricity  purchased from concessionaire but also generate credits  for use in other months.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     131   Under this system, the generating unit installed in a  residence, for example, will produce power and what is  not consumed will be injected into the distribution  system, which uses the credit to subdue the  consumption of subsequent months. The credits can be  used for a period of 36 months and information will be  provided for the consumer, so that one knows the  balance of power and have control over his invoice.   In 2012 there were only eight projects of this type  and some residences distributed, generating  approximately 15MW of a total of 430,000 MW  consumed by Brazil (BRAZIL, 2012).   The country has the option of waiting for the cost  of solar power to decline to put it on auctions or to  create a specific auction so there is no dispute with  other cheaper sources such as wind. But that would be  sold a small amount of energy not to burden the  consumer (Tolmasquim, 2012)     5. SISTEM DESIGN  System integration was the most laborious part of the  project, due to the high level of detail required for its  integration. It required a high volume of surveys of sites  of companies and components manufacturers.    5.1 Motivation  Initially, the goal was to create a monitoring system for  some kind of alternative energy, to be deployed by a  company that would provide installation and  maintenance of equipment used in the generation of a  residential customer.   The methods to achieve these results were studied  and analyzed to choose the technologies which fitted  best the goal. The decisions were taken at the beginning  involved the following circumstances:     • Renewable Energy Generation Method: Solar  or Wind Power.   • Harnessing System: Battery bank, Direct Grid  Injection or Hybrid System.   • Measurement of Power Generated:  Conventional Electronic Meter or Analog  Voltage and Current Readers.   • Process Controller: PIC, PLC or Arduino.  • Monitoring System Communication Interface:   Wi-fi, GPRS or SMS.  • Monitoring System: Webserver, Elipse ou   Intouch.       5.2 Research and Choices   The initial stages of project development involved long  research time and studies for decision making. The  primary research methodology was accessing several  sites on the subject, in addition to performing some  technical visits, which had great influence in the paths  to be followed in the project.      5.2.1 Renewable Energy Generation Option   To decide which method of power generation would be  used, several studies were conducted to understand the  advantages and disadvantages of each alternative energy  source.   The price for wind power generation is  significantly cheaper than the solar power generation  although the techniques for wind energy are well  developed and should not evolve much in the short  term.   Solar power is still quite expensive to be produced,  but the growing trend in production technologies is that  due to government incentives these energy prices will  fall enough and should equal the wind energy prices  shortly. This point has greatly influenced the choice as  one of the goals was to have a vision of the future solar  power market and proved to be the wisest choice.   Another point that influenced the choice of solar  energy was that the blades of the wind turbine have an  impact on the local birds, especially due to the shock of  these birds in blades and unknown effects on modifying  their usual migration behaviors. Furthermore the noise  impact caused by wind power generators that may reach  a constant noise up to 43 dB, which can disturb the  inhabitants of the residence up to 300m distances.    Then photovoltaic panels were chosen to generate  alternative energy, harnessing solar energy. Two  modules KD54 plates of 50Watts each were acquired  from Kyocera, the most trusted brand and market leader  in Brazil.     5.2.2 Harnessing System  At first the idea was to mount a hybrid system to  harness the energy generated. Throughout the research  it was noticed that there was no a need to use a battery  bank, except in cases where there is no electricity grid  next the residence. In the Lakes Region, location of the  tests, almost all residences have access to the electricity  grid, confirming the dispensability of a system with  battery bank. Thus, all the energy generated by the  system will be injected directly into the grid of the  power supply company (concessionaire) and  slaughtered the amount that has consumed the  dealership.   The equipment was chosen for this Inverter Grid  Tie400W of GreenEnergyStart, which is a company  focusing on alternative energy and use of current  technologies.     5.2.3 Measurement of Energy Generated  At the beginning it was thought to use voltage and  current readers in order to reach the energy generated  because knowing the voltage and current power which  is the product of these two quantities could be  calculated.   The main methods found to construct a current  player were the utilization of high power resistor and  precision and very low resistance, which are known as  shunt resistors and the utilization of Hall effect sensors,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     132   which  are analog signal proportional to the magnetic  field created by a current that flows close to the sensor.   The solution was to acquire a meter certified by  INMETRO, a trust company in the Brazilian market.  Through contact with the supplier decided to buy an  Electronic meter company Elster (A102C).    5.2.4 Process Controller  In any automated system, and monitoring, there is a  necessity of a device that scan the sensors and treat the  data according to the need.   One of the options for this type of process is the  Programmable Logic Controller (PLC), but the factors  that have eliminated the PLC project were its high cost  and its high power consumption when in operation.   It was then decided by the use of a microcontroller,  by owning a low cost and power consumption is  extremely low.   The plate was chosen for the Arduino MEGA2560,  which has more than 60 I / O and communication is  based on an Atmel 2560 processor.     5.2.5 Means of Communication with the Monitoring   System  Currently, there is a tendency in industries increasingly  frequent use of wireless technologies for  communication. Taking advantage of the growth of  wireless networks, it was decided to this method to  make communication between field elements and the  monitoring system.   GSM networks are present in almost all places in  Brazil, thanks to the "boom" of the cell and increased  technical capacity of operators. In the Lakes Region  almost everywhere already have access to this  technology. So GSM networks has become a great  option for use in this project, as it currently has lower  costs for sending packets through GPRS connection and  sending short messages (SMS).   For these purposes, was chosen GSM Shield V1.1  Icomsat company because its integration with Arduino  is fast and easy, besides it be based on SIM900D which  is a Quad Band GSM SIMCOM chip company.     5.2.6 Monitoring System  For the choice of supervisory system, two softwares, the  Intouch and the Ellipse were considered and soon  consolidated in the market to attend the need of the  project.   The option was for the supervisory of the Ellipse,  for being a Brazilian software and with an excellent  technical support by phone, which could be useful, not  to mention its lower price.   A Webserver is a complement to supervisory,  because it can be accessed by mobile phones, tablets  and other portable devices currently used.   The next step was the choice of communication  protocol. Researching quite found out that the best  solution was the Modbus TCP protocol, which is free  from any type of recovery and is not complicated to use.      5.3 The Project Design  The project design was divided into parts, each part  consisting of a different system design.      5.3.1 Mounting the System Generator  The project was started with the mounting of the solar  power generation system. The first step was the  determination of the best place for installation of solar  panels. For added security, The location must be high,  to prevent theft and animal access and should not be  obstructions from sun rays (shade).    Then there was the determination of a position and  an inclination to the plate, so that better take advantage  of solar cycles. As the location of this project is the  Southern Hemisphere, it is necessary to position the  plate towards the north. To determine the ideal  inclination, it is necessary to verify the latitude of the  installation location and the approximate formula for  calculating the inclination is that this should be 130% of  latitude. In Rio de Janeiro, the approximate latitude of  23° is in this way allows an inclination of 30 ° on each  plate.    The binding plates were performed in parallel,  which gives a sum of currents of each plate, and  maintains a voltage equal to a single plate. The  following figure shows the installation and positioning  of the plates.        Figure 8: Panels in parallel (Mpptsolar 2012)     After the connection of the plates, the connection   of the Grid-tie was made. The positive output terminal  of the plates was connected at the positive input of the  CC inverter and also the negative output terminal was  connected to the negative CC input inverter. Soon after,  was connected to the AC output of the inverter in the  network, by transforming all input power direct current  into alternating current.     5.3.2 Installation of the Measuring System  With the generation system installed and working,  the  meter Elster A102C was installed between the inverter  and the electric grid. The meter is installed in series  with the inverter and the grid. The determined meter has  3 methods to inform the measured data. The output in  standard IRDA, which works through infrared, pulse     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     133   output, is available through the auxiliary outputs, and an  LCD display on the meter itself.       Figure 9:Padrão da Mensagem IRDA(Meterspec)     As the meter uses the LED emitting red light to   send serial devices to reading information then was  acquired a phototransistor infrared to decode the  information in the standard meter IRDA. Each bit of  zero value the meter wants to send, it sends a pulse of  infrared LED emitter in Figure 9.     5.3.3 Controller  The monitoring system starts with the treatment of  information measure and this function is realized by  Arduino MEGA 2560.   The IRDA output was initially used to receive the  data, but it was noticed that to be a serial message, the  difficulty to decode the data would be much greater and  more imprecise, since any loss of pulse would cause an  incorrect reading. The pulse output of the meter was  then used to obtain the required data.   Using a programming library that transforms the  Arduino in a Modbus device. The pulse output is  connected on the Arduino interrupt pin and when it  detects a pulse signal, the Arduino registers and saves  this information. Powering the Arduino is done by an  external source or then connected directly at the output  of the plate solar.     5.3.4 GSM communication  The Shield GSM has been connected in the Arduino  board, as shown in Figure 10 and inserted a SIM card  from a wireless carrier.       Figure 10: Mounting the GSM Shield with the Arduino   (the author)  In programming, GSM is functioning as a   transparent device, ie, it transmits any message that   arrives at your receptor. Programming the GSM plate is  made by Arduino.   The function of GSM Shield is connect to the  internet through GPRS and connect to a server through  port 502, which is the default port for Modbus.   Then, when the Arduino sends a message to the  GSM, it transmits directly to the IP defined through the  door 502. This server is the supervisory station.     5.3.5 Supervisory station  In this step, the process of creating screens for user  interface was started. There are two options for  monitoring, one for the company that provides the  system and one for the user who purchases the system.   Both are password protected and the user is only  able to access the monitoring of your own residence.  The company operator can access the monitoring of all  installed points.   The first screen, known as the Home screen,  displays the logo of the company supplying of the  system described in this project, the version of  supervisory and rights to creators, plus a welcome  message and option to start the program. Clicking the  named "About" button several information about the  program, such as licenses and rights, information about  the current version and contact is displayed, as shown in  Figure 11.     Figure 11: Home screen the supervisory    (the author)  In the version of the user, after the program is    started, a screen is displayed for this user in case there is  more than one installation point for him, so that he can  select the point that he wants to see, that is to say, the  information of the installed system.   In the version of the operator , a screen is  displayed where you can choose, with one click, the city   to be monitored. After it is performed by the operator  ,he selects the point at that he wants to view the data  received by the generation system of the selected  location. If any the system is producing below the  normal standard, the place is displayed with a yellow  circle. If the system is not producing,  a red circle is  displayed, as shown in Figure 12.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     134        Figure 12: Map of the city of Macae in the highlighted  points (the author)     In Figure 13, it  may be perceived a common   screen to the user and the operator. It shows the data  processed by the Arduino, as the quantity of energy  generated at the moment and in the last 12 hours.         Figure 13: Screen Supervisory Control (the author)     The communication driver that was used in the   supervisory is Modbus and was configured with  parameters of identification of Arduino. A tag  communication was created to store the information  obtained by Arduino through register read function. The  Ellipse performs in the range of 1 minute, reading the  register that stores the information from the meter and  displays on screens previously determined. The history  is done by storing in a internal database values and the  tag after displaying the chart.   A low alarm value has been placed in this tag  communication and time associated with a solar shift,  ie, in a time of solar generation a certain house is not  generating a signal is displayed on the selection screen  of points to be monitored and because there is a  problem with the system and if the alarm persists a  technical should go to the local to do the verification.     6. RESULTS OBTAINED   After adjustment of the positioning experiments the  plates were made for sampling results on the relevance  of the project. Sampling and analyzing the total energy  generated per day in the second fortnight of November  2012, there was obtained an average of 240Wh per day  for each plate of 50W of power, as shown in Table 1.   Each plate 50W Kyocera, used in the project,  costing on average R$500.00 and each inverter 400W   R$600.00 costs on average and supports up to 8 plates  50W.     Table 1: Total generation Nov./2012 second fortnight        The tariff of local dealership in the region is 0.66  R$ / kWh. If the average is maintained throughout the  month will be achieved approximately 7.2 kWh per  month for each plate installed 50W. Considering the  maximum charging of the inverter, which are eight  plates is 57.6 kWh per month.   This value generated by eight plates 50W, means  an economy in R$ 38.02 per month for the consumer.   Therefore, each system with eight plates Kyocera  50W and 400W inverter GreenEnergy costs an average  of R$4,600.00. Following this reasoning, in 132 months  or 11 years, the savings would pay the amount  originally spent. Considering that the life of the plates is  30 years, the results are acceptable.     7. CONCLUSION   Based on this project remote monitoring it is possible to  glimpse many other alternatives for use of the system  by modifying and adapting specific points to the desired  need.   In this way, it was possible to view part of a  worldwide trend that is M2M (Machine to Machine), ie  establish communication Machine to machine without  human interference, and the solution that makes it  possible multiple mobile machines and equipment be  monitored remotely.   By means of M2M, it is possible that all the  information collected by the monitoring modules are  transmitted through a data network, be it wi-fi, ethernet,  RF, Zigbee, GPRS, 3G, LTE, PLC and etc..   Analyzing the possibilities of using of using M2M  opens up an enormous range. M2M applications involve  different fields, such as fleet management (public  safety, public transportation, taxis, delivery vehicles);  utilities (SmartMeters - electricity meters, gas, water,  and Telemetry - telemetry sensors and controllers,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 127-135  Nov/2014     135   navigation systems, vehicle maintenance, passenger  safety and anti-theft systems), electronics (cameras and  cameras, video games, ebook readers ) and others such  as monitoring patients requiring constant monitoring,  ATMs and self-service machines (credit card).   Thus, developing a project using newly discovered  resources and on the rise causes the project to be very  gratifying. It is estimated that the M2M market in Brazil  should have a rate higher than the rest of the  telecommunications market growth, averaging  approximately 3.7% of the subscription market in 2016.   The possibility of developing new grouped the  generation of clean energy technologies and add  generation connected directly to the electrical grid,  something that is also innovative because until a few  years ago there was not the technology viable Grid Tie  Inverter for minigeneration and microgeneration.   Therefore it is very satisfying to develop a project  that contributes to sustainability, something the modern  world will need to enhance with intense speed so that  future generations can live in a nice planet as we live  today.   There is a need of  investment in rural residences  which are not completely isolated and without  opportunities for growth so that people could  know a  new world and approach the ones  who live in large  urban centers.    REFERENCES    ANEEL (National Electric Energy Agency). Resolution   482. Available in  <www.aneel.gov.br/cedoc/ren2012482.pdf>  accessed 01.nov.2012.    Arduino. Available in <http://www.arduino.cc/>  accessed 07.set.2012    Banzi, M., "Getting Started with Arduino" book, Vol,  No 1., December/2011, NovaTec.    BRAZIL. Government Information. available in  <http://http://www.brasil.gov.br/noticias/arquivos/ 2012/07/03/energia-solar-ja-e-economicamenteviavel-para-15-dos-lares-brasileiros-diz-epe>  Accessed 22.out.2012    BRAZIL, Solar - Photovoltaic Energy. Available in  <http://solarbrasil.com.br> accessed 02.nov.2012.    CRESESB (Reference Centre for Solar Energy and  Wind Sérgio de Brito Saved). Studies of Solar  Energy. Available in  <http://www.cresesb.cepel.br> accessed  01.nov.2012    Elster. Measurement systems. Available in  <http://http://energia.elster.com.br/pt/eletronicos_ monofasicos.html> accessed 01.nov.2012.    Energy, Solar - Photovoltaic Energy. Available in  <http://www.solarenergy.com.br> accessed  02.nov.2012.    FirstSolar. Solar Panels. available in  <http://www.firstsolar.com/Projects/Projects/Proje cts-Under-Development/Agua-Caliente-SolarProject/Overview> Accessed 22.nov.2012    Iteadstudio. GSM Shield. Available in  <http://blog.iteadstudio.com/tag/shield/> accessed  09.set.2012    FSI. TCP / IP Architecture. Available in <http://fsiufam.blogspot.com.br/2009/11/modelo-osi.html/>  accessed 21.nov.2012    InfoWester. GSM network. Available in  <http://www.infowester.com/2g.php> accessed  02.nov.2012    Junior, Pedro Adolfo de Souza. Managed Access  Control System Via GPRS. 2011. 65f. Completion  of course work (undergraduate) - Department of  Electrical Engineering, Federal University of  Paraná. Available in  <http://www.eletrica.ufpr.br/ufpr2/tccs/176.pdf>  accessed 02.out.2012.    Leitão, José Miguel, "Solar Energy: Bet or Necessity,"  E-topia: Electronic Journal of Utopian Studies, 11  (2010)..    Meterspec. Elster A102C manual. Available at  <http://www.meterspec.com/143.pdf> Accessed  20.nov.2012    Mpptsolar. Solar Energy. Available in  <http://www.mpptsolar.com/pt/paineis-solaresem-serie.html> accessed 02.nov.2012    Oliveira, Victor Hugo Freitas. Development of a  Remote Telemetry System. 2009. 58f. Completion  of course work (undergraduate) - Department of  Computer Engineering and Automation, Federal  University of Rio Grande do Norte. Available in  <http://www.engcomp.ufrn.br/publicacoes/TCC2009-1-1.pdf> accessed 05.out.2012.    Painelsolares. Solar Panels. Available in  <http://painelsolares.com/o-que-e-um-painelsolar/> accessed 01.nov.2012    Serrão, Marcons Antônio dos Santos. Sizing a  Photovoltaic System For A summer house in  Paraty Pouso da-Cajaíba. 2010. 89F. Project  Completion of course (Undergraduate) -  Department of Electrical Engineering, Polytechnic  University of Rio de Janeiro. Available in  <http://monografias.poli.ufrj.br/monografias/mono poli10000620.pdf> accessed 02.nov.2012.    Sukhatme, SP, Nayak, JK 2008 Solar Energy - Solar  Energy:. Principles of Thermal Collection and  Storage.3rd Ed - Tata McGraw-Hill, 125-142.       
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     136   Explorando o cenário das Metodologias de Engenharia de  Software Orientado a Agentes    Eduardo Augusto Ferreira da Silva1, Heder Dorneles Soares1, Rafael Sampaio Rocha  Machado1   1Instituto de Computação – Universidade Federal Fluminense (UFF)  Niterói – RJ – Brasil    {eferreira, hdorneles, rmachado}@ic.uff.br   Abstract. The scenario methodologies of traditional software engineering is  agreed and widespread. However, in the context of multiagent systems, yet to  explore the field of agent-oriented methodologies because of the  particularities. The objectives of this work are: (i) present and discuss the  definition of what is and what is a methodology for software engineeringoriented agents, (ii) discuss the standards adopted by the methodologies  ADELFE, Gaia, Message and MaSE; (iii) to compare these methods with the  criteria of the life cycle, iterative, traceability and focus.   Resumo. O cenário de metodologias de engenharia de software tradicionais é  convencionado e difundido. Entretanto, no contexto de Sistemas Multiagentes,  ainda há de se explorar no campo das metodologias orientadas a agente  devido as suas particularidades. Os objetivos deste trabalho são: (i)  apresentar e discutir a definição do que é e no que consiste uma metodologia  de engenharia de software orientado a agentes, (ii) discorrer sobre os padrões  adotados pelas metodologias ADELFE, Gaia, Message e MaSE e (iii)  comparar estas metodologias com os critérios de ciclo de vida, iteratividade,  rastreabilidade e foco.   1. Introdução   Independente da aplicação de metodologias, tanto para sistemas orientado a objetos  quanto para sistemas orientados a agentes, é de suma importância utilizar a abordagem  adequada para direcionar o desenvolvimento de softwares. Gerentes de projetos,  desenvolvedores, arquitetos de software, engenheiros de software, analistas de testes e  todos os demais profissionais envolvidos em projetos de software podem ter seus papéis  e responsabilidades melhores definidos sobre as atividades exigidas para realização do  desenvolvimento e entrega do sistema. Além do que, o uso de metodologia apoiando no  desenvolvimento de software, através do uso de boas práticas, técnicas e ferramentas,  tem o objetivo de proporcionar ao produto de software final uma gestão de escopo,  tempo, custo, qualidade e recurso. Metodologias são os resultados de transferência de  conhecimento da engenharia de software. No cenário de sistemas multiagentes [Iglesias  et. al. 1999], as metodologias de desenvolvimento de software orientado a agentes não  possuem a mesma maturidade como a abordagem orientada ao objeto.    O escopo deste artigo é: (i) apresentar e discutir a definição do que é e no que  consiste uma metodologia de engenharia de software orientado a agentes, (ii) discorrer  sobre os padrões adotados pelas metodologias ADELFE, Gaia, Message e MaSE e (iii)  comparar estas metodologias com os critérios de ciclo de vida, iteratividade,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     137   rastreabilidade e foco.  Sendo assim, será apresentada uma perspectiva sobre o rumo das  metodologias orientadas a agente.   2. Conceituando Metodologias de Software   Por definição, a aplicação de uma engenharia de software compreende em utilização de  sistemática e disciplina em uma abordagem quantificável para operação e manutenção  de software. Portanto, engenharia de software e metodologias consiste no estudo de  como são aplicadas estas abordagens.     O termo Software engineering (do português engenharia de software) surgiu  inicialmente em 1968 no nome de uma conferência patrocinada por North Atlantic  Treaty Organization (NATO). O foco desta conferência foi dado pelos diversos  problemas que afetam a indústria de software: atraso das entregas, complexidade do  produto final, custo de projeto. [Jorge J. Gomez-Sanz et. al. 2011]    A utilização de engenharia de software e metodologias engloba questões  essenciais, em especial: competências técnicas e humanísticas. As competências  técnicas são requisitos fundamentais para os analistas, como por exemplo,  conhecimento da linguagem de programação mais adequada para a complexidade da  aplicação a ser desenvolvidas ou então o próprio conhecimento de boas práticas,  ferramentas e técnicas a serem adotas nas atividades de desenvolvimento do sistema  [Jorge J. Gomez-Sanz et. al. 2011].    2.1. SWEBOK   O conhecimento de engenharia de software é definido e especificado no Software  Engineering Book of Knowledge (SWEBOK). O foco é no conhecimento essencial que  suporte a seleção da tecnologia apropriada, no tempo e na circunstância apropriados.     No SWEBOK são descritas onze áreas de conhecimento. Porém, a área que deve  ser levada em conta pela relevância no contexto de sistemas multiagentes é a área de  “Ferramentas e Métodos de Engenharia de Software”. Segue abaixo as citações sobre os  conceito de ferramentas, métodos e suas relações:   “Ferramentas são frequentemente projetadas para suportar métodos de  engenharia de software particulares, reduzindo qualquer carga administrativa  associada com aplicação dos métodos manuais. Como métodos de engenharia  de software, ferramentas pretendem fazer a engenharia de software mais  sistemática e variam no escopo de suporte individual de tarefas para abranger  o ciclo de vida completo.” [IEEE, SWEBOK 2004]     “Métodos de engenharia de software impõem estrutura na atividade de  engenharia de software com o objetivo de fazer a atividade sistemática e  ultimamente mais sucedida. Métodos usualmente provem uma notação e  vocabulário, procedimentos para desempenharem tarefas identificáveis e  princípios básicos para checarem tanto processo quanto produto. Métodos  variam amplamente no escopo, de uma única fase de ciclo de vida para  completar o ciclo de vida. A ênfase nesta área de conhecimento é métodos de  engenharia de software abrangendo múltiplas fases de ciclo de vida, desde  métodos de fases específicas abordadas por outras áreas do conhecimento.”  [IEEE, SWEBOK 2004]        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     138    Considerando as definições expostas, é intrínseca e tênue a relação de métodos e  ferramentas. Processos, notações, técnicas e linguagens a serem utilizadas são desafios e  objetos de estudo para a modelagem de métodos e ferramentas.    3. A abordagem da orientação a agentes    No contexto da Engenharia de Software Orientada a Agentes pode-se categorizar o  método heurístico cujo sistema é interpretado como uma coleção de agentes. O método  deve ser entendido como bem sucedido ao torná-lo sistemático e cíclico.      O método também é possível fornecer notação, vocabulário, procedimentos para  desempenharem tarefas identificáveis e princípios básicos para checagem tanto de  processos quanto de produtos [Jorge J. Gomez-Sanz et. al. 2011]. Ou seja, os conceitos  básicos e o que se esperar de metodologias e ferramentas pelo SWEBOK também pode  ser utilizado no universo de Engenharia de Software Orientada a Agentes.        Há dois grandes grupos de propostas de metodologias. Uma metodologia que  primeiro tenta construir uma notação e vocabulário para direcionar algumas fases de  desenvolvimento específicas. Na outra, notação e vocabulário são contempladas a  ferramentas que permitem andar com a análise e design para implementação.  [Jorge J.  Gomez-Sanz et. al. 2011].    Apesar da distinção, esses dois grupos estão se convergindo. O que se espera de  metodologias candidatas são que tenham ferramentas de suporte (similar a existente na  metodologia ZEUS) e se atentem mais ao ciclo de vida do software. Metodologias como  INGeniAS, PASSI, ADELFE ou Prometheus crescem pois são caracterizadas por obter  maior padronização, definição de fases de desenvolvimento, coleta de requisitos,  implementação e testes.    4.  Metodologias orientadas a agentes   As metodologias precisam ser usadas continuamente para evoluírem de maneira  progressiva. Sendo assim, a evolução poderá direcionar novas atividades de  desenvolvimento e incrementar o escopo da metodologia. Há estudos anteriores [Dam  2004] que já realizaram comparações sobre as metodologias.    As particularidades de sistema multiagentes se diferem das outras devido às  características específicas de definição de agente: comunicação entre agentes, normas,  recompensa, proibição e raciocínio. Nos próximos tópicos, serão brevemente abordadas  algumas das metodologias orientadas a agentes.   4.1. ADELFE    ADELFE é comparado ao Processo Unificado da Rational (RUP), porém dedicada a  engenharia de software para sistemas multiagente adaptativos. É comparado ao RUP  por definir primeiro três núcleos de workflows. Durante a fase de requisitos, o ambiente  do sistema estudado deve ser definido e caracterizado. Então, na fase de análise, o  engenheiro é guiado para decidir o uso de tecnologia de multiagente adaptativa e a  identificação de agentes junto ao sistema e aos modelos de ambiente. Finalmente, o  workflow de projeto do ADELFE deve fornecer o modelo de agente cooperadora e  ajudar a desenvolver a definição de comportamento de agentes.    ADELFE é baseado em metodologias orientada a objeto seguindo o Processo  Unificado da Rational (RUP) e usa notações UML e AUML. Alguns passos foram     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     139   adicionados nos workflows clássicos para serem específicos para adaptação de sistemas  multiagentes. Isto não é uma metodologia geral como a GAIA ou TROPOS, mas tem  um nicho de aplicações interesses que requerem design de sistemas multiagentes  adaptativos usando a teoria AMAS. ADELFE segue o processo inteiro de engenharia de  software como  MESSAGE, PASSI e TROPOS. [Carole Bernon et. al. 2002]. Veja  abaixo a ilustração contendo as atividades de cada workflow e seu caráter cíclico:     Figura 6 Workflows ADELFE [Adaptado de Bernon et. al. 2002]    A metodologia ADELFE é direcionada para sistemas multiagentes com  ambientes e características de sistemas adaptativos, com comportamentos dinâmicos. O  que caracteriza esta metodologia de maneira interessante é a similaridade com o RUP e  uso dos três workflows no seu ciclo de vida: requisito, análise e projeto (design). Em  cada workflow, similar ao RUP, é possível revisitar cada etapa e atividade, sempre  priorizando a atualização e definição mais completa do sistema.    4.2. Gaia   A metodologia GAIA é basicamente dividida em duas definições: Análise e Design. Na  etapa de análise é feito: a decomposição de organização em sub organizações, modelo  de ambiente, modelo de papéis preliminares, modelo de interação preliminar e regras da  organização. A seguir a ilustração contendo o escopo da GAIA:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     140     Figura 7 Modelo de Gaia e suas Relações [Zambonelli et al., 2003]     Na etapa de design as definições previamente concebidas na análise são  consolidadas no que se prevê em: topologia e controle da estrutura na estrutura  organizacional, modelo final de papéis, modelo final de interação, modelo de agente e  modelo de serviço.     A metodologia Gaia é uma das mais utilizadas devido a sua simplicidade e  especificação razoavelmente definida. Além da versão inicial, também houve evolução,  sendo nomeada para a versão 2: Em particular, em Gaia v.2, em adição às funções e  protocolos, o ambiente no qual um sistema de multi  agente está imerso é escolhido para  uma análise primária e abstração de design. [Cernuzzi et al., 2004]     Diferente de outras metodologias como a ADELFE e TROPOS, a metodologia  GAIA não aborda é a fase de requisito. A GAIA não apresenta técnicas de modelagem  particulares ou sistemas de notações específicos. Outra fase importante não  contemplada no escopo desta metodologia é a implementação, não caracterizando uma  metodologia completa em percorrer todo o ciclo de vida de desenvolvimento de um  sistema multiagente.   4.3. Message   MESSAGE baseia-se na definição da metodologia no uso de meta modelos como  formalismo na especificação. Linguagens de meta modelagens fazem possível a  extensão do núcleo de especificação pelo uso de mecanismo de geração de construção.  Também, instâncias dos meta modelos (ex: os modelos que descrevem MAS), se opõem  para maioria dos formalismos, podendo ser detalhado parcialmente e refinado junto de  etapas sucessivas (similarmente para UML, onde diagramas de classes não precisam ser  completos na iniciação, mas podem crescer em detalhes durante o desenvolvimento.  [Jorge et. al. 2001]     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     141    Uma característica relevante da metodologia MESSAGE é a adoção da base do  RUP, como adotado na ADELFE.  A evolução e maturidade da metodologia   MESSAGE podem ser comprovadas pelo manual técnico [Caire et. al. 2002] de  especificação da metodologia.  Muitas atividades podem ser um argumento para  desacreditar a metodologia, mas em fato nós devemos considerar que atividades são  definidas para cada visão do sistema (há cinco em MESSAGE: organização, agente,  tarefas/objetivos, interações e domínios) e essas visões são normalmente desenvolvidas  em paralelo (devido a suas relações). Também, engenheiros de softwares rodeiam a  aplicação de algumas atividades quando deparam com domínios de aplicação simples.  [Jorge et. al. 2001]   4.4. MaSE   A Engenharia de Sistema Multi Agente - MaSE metodologia pega uma especificação  inicial e produz um conjunto de documentos de design formais em um estilo baseado  graficamente.     O foco primário da MaSE é guiar o designer junto ao ciclo de vida de software  por uma prosa de especificação para uma implementação de sistema de agente. MaSE é  independente de uma arquitetura de sistema multiagente particular, arquitetura de  agente, linguagem de programação ou sistema de troca de mensagem. Um sistema  projetado em MaSE pode ser implementado em diversas maneiras diferentes de um  mesmo design. MaSE também oferece e habilita o acompanhamento de mudanças  através de processo. Todo objeto de design pode ser traçado posteriormente ou  anteriormente por diferentes fases da metodologia junto dos seus correspondentes de  construção [M. Wood e S. DeLoach 2001].      A metodologia MaSE pode ser considerada uma metodologia tradicional pelas  definições de modelos e fases.   A seguir está a visão geral da metodologia MaSE e  seus modelos:     Figura 8 A Metodologia MaSE [Adaptado de M. Wood e S. DeLoach 2001]     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     142   6. Resultado da comparação das metodologias   Baseado no estudo apresentado, segue abaixo (quadro 1)  a comparação das  metodologia orientada a agentes  pelos seguintes critérios: (a) Ciclo de vida, (b)  iteratividade, (c) rastreabilidade e (d) foco.   Quadro 3 Comparação de Metodologia por Critérios   Metodologia   Critério ADELFE Gaia Message MaSE   Ciclo de vida  (refere-se ao ciclo de vida em  fases da metodologia)   Requisito,  Análise, Design,  Implementação e  Teste.   Análise,  Design    Coleta de  Requisito,  Análise,  Design   Análise e  Design   Iteratividade  (indica se há ciclos de  iteratividade na metodologia)   Sim. Baseada no  RUP.   Não  especifica do.   Sim. Baseada  no RUP.   Sim.  Baseada no  RUP.   Rastreabilidade  (refere-se a relação de  comunicação entre os  artefatos)   Sim. Há evolução  dos artefatos por  iteração.   Sim.   Interelaçõ es entre  modelos.   Sim. Há  evolução dos  artefatos por  iteração.   Sim.   Interelações  entre  modelos.   Foco  (refere-se ao conjunto de  modelagem contemplados e  priorizados pela metodologia)   Requisito,  Análise, Design,   Análise e  Design   Análise,  Design   Análise e  Design      7. Conclusão   Com base no estudo e nas comparações das metodologias orientadas a agentes  abordados neste trabalho, espera-se fomentar discussão na comunidade de Engenharia  de Software Orientada a Agentes. Apesar da heterogeneidade presente nestas  metodologias comparadas, há similaridade nos resultados dos critérios avaliados.    Há muito a se explorar na área de engenharia de software orientada a  multiagentes, inclusive o aperfeiçoamento das metodologias existentes na definição e  melhoramento contínuo de processos, técnicas, métodos e ferramentas.  Para  progressão da área de metodologias de engenharia de software orientada a agentes, há  uma forte demanda de melhoria geral em ferramentas de suporte e aumento do número  de desenvolvedores para avaliar as possibilidades de cada metodologia.    Referências   Caire, G., Leal, F., Chainho, P., Evans, R., Garijo, F., Gomez-Sanz, J. J., Pavon, J.,  Kerney, P., Stark, J.,and Massonet, P. Eurescom P907: MESSAGE - Methodology  for Engineering Systems of Software Agents.  http://www.eurescom.de/public/projects/P900-series/p907/default.asp . 2002.   Carole Bernon , Marie-Pierre Gleizes , Sylvain Peyruqueou , Gauthier Picard,  ADELFE: a methodology for adaptive multi-agent systems engineering, Proceedings  of the 3rd international conference on Engineering societies in the agents world III,  September 16-17, 2002, Madrid, Spain     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 136 - 143 Nov/2014     143   Cernuzzi, L., Juanand, T., Sterling, L., Zambonelli, F.: The Gaia Methodology: Basic  Concepts and Extensions. In: Methodologies and Software Engineering for Agent  Systems. Kluwer, Dordrecht (2004)   Dam, Khanh Hoa, and Michael Winikoff. "Comparing agent-oriented methodologies."  Agent-Oriented Information Systems. Springer Berlin Heidelberg, 2004.   IEEE. Guide to the Software Engineering Body of Knowledge (SWEBOK). 2004  Version.   Iglesias, Carlos A., Mercedes Garijo, and José C. González. "A survey of agent-oriented  methodologies." Intelligent Agents V: Agents Theories, Architectures, and  Languages. Springer Berlin Heidelberg, 1999. 317-330.   Jorge J. Gomez-Sanz, Ruben Fuentes-Fernández, Juan Pavon (2011), Understanding  Agent Oriented Software Engineering Methodologies. AOSE 2011.   Jorge J. Gómez-Sanz, Juan Pavón. Agent Oriented Software Engineering with  MESSAGE. 2001.   M. Wood, S. DeLoach. An Overview of the Multiagent Systems Engineering  Methodology, In P. Ciancarini and M. Wooldridge, editors, Agent-Oriented Software  Engineering - First International Workshop (AOSE), Limerick, Ireland, June 10,  2000. Lecture Notes in Computer Science. Vol. 1957, Springer Verlag, Berlin, 2001.   Zambonelli, F., Jennings, N. R., and Wooldridge, M.J. (2003). Developing multiagent  systems: The Gaia methodology. ACM Transactions on Software Engineering and  Methodology, 12(3):417-470.              
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     144   Avaliação do Modelo Elétrico Battery considerando  Baterias de Lítio Íon e Lítio Íon Polímero   Marcia de F. Brondani1, Airam Sausen1, Paulo S. Sausen1   1Universidade Regional do Noroeste do Estado do Rio Grande do Sul, Programa de  Pós-Graduação Stricto Sensu em Modelagem Matemática, Departamento de Ciências  Exatas e Engenharia, Rua Lulu Ilgenfritz, 480, Bairro São Geraldo, 98700-000 – Ijuí,   RS, Brasil.  marciabrondani@yahoo.com.br,{airam,sausen}@unijui.edu.br   Abstract. This work presents the application of the Battery electrical model in  the prediction of the life time of Lithium Ion and Lithium Ion Polymer  batteries. The study used energy discharge simulations, adopting a vast array  of discharge currents. The model validation was carried comparing the results  obtained from the simulations to the data acquired from the experiments in the  test bed. For the Lithium Ion batteries the model presented an average error  of 2.54%, while for the Lithium Ion Polymer batteries the average error was  3.42%. The results have shown that the Battery model has an average error  rate, for the studied cases, inferior to the expected value for electrical models,  i.e., 5%.   Resumo. Este artigo apresenta uma aplicação do modelo elétrico Battery na  predição do tempo de vida de baterias de Lítio Íon e Lítio Íon Polímero, a  partir de simulações de descargas de energia, adotando um amplo conjunto  de descargas. A avaliação do modelo consiste na comparação entre os  resultados das simulações computacionais e os resultados dos ensaios obtidos  de forma experimental. Assim, para as baterias de Lítio Íon o modelo  apresenta um erro médio de 2,54%, enquanto que para as baterias de Lítio  Íon Polímero obteve um erro médio de 3,42%. Os resultados mostram que o  referido modelo possui uma taxa de erro médio, para os casos estudados,  inferior ao erro esperado para modelos elétricos, isto é, 5%.    1. Introdução  Nos últimos anos, a busca por computação ubíqua tem crescido, e uma grande gama de  dispositivos móveis tem ganhado espaço nos sistemas de informação. Para que estes  dispositivos possam proporcionar uma experiência satisfatória para o usuário, é  essencial que possam trabalhar desconectados da rede elétrica pelo maior tempo  possível, através do uso de baterias. A bateria é considerada o principal elemento dos  dispositivos móveis, os quais estão vinculados operacionalmente à vida útil da mesma.  O tempo de vida de uma bateria é definido como o tempo que ela demora para atingir o  nível de estado mínimo de carga (i.e., nível de cutoff), no qual a bateria fica incapaz de  fornecer energia elétrica para o sistema (Porciuncula et.al., 2012).    Ao considerar a evolução dos sistemas alimentados por baterias, é essencial que  as baterias sejam capazes de atender às especificações dos aparelhos portáteis,  possuindo maior desempenho e durabilidade. Neste sentido, destaca-se que é possível  predizer o tempo de vida de baterias através de modelos matemáticos que descrevem o  comportamento das mesmas em condições de cargas/descargas estáticas ou dinâmicas,  em diversas aplicações. Existem diferentes modelos matemáticos com características  distintas que modelam as diferentes propriedades relacionadas a cada tipo de bateria,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     145   tais como os analíticos (Rakhmatov e Vrudhula, 2001), os modelos elétricos (Chen e  Rincón-Mora, 2006), os modelos estocásticos (Chiasserini e Rao, 1999), os modelos  eletroquímicos (Fuller e Newman, 1994), os modelos via teoria de Identificação de  Sistemas (Ljung, 1999) e os modelos híbridos (Kim, 2012). Neste estudo é dada ênfase  ao modelo elétrico Battery, disponibilizado pelo programa Matlab/Simulink,  desenvolvido pela companhia The Mathworks.  O modelo elétrico Battery é escolhido  por ser prático no que se refere à extração de seus parâmetros empíricos e considerar um  efeito não linear importante que ocorre em um processo real de descarga, i.e., o efeito  de recuperação (Jongerden e Haverkort, 2008), que influencia diretamente no tempo de  vida da bateria.    Desta forma, neste artigo é apresentada a aplicação do modelo elétrico Battery a  partir de simulações de descargas de energia, considerando baterias de Lítio Íon e Lítio  Íon Polímero.  Para a realização das simulações admite-se um amplo conjunto de  descargas, composto de correntes baixas, médias e altas, obtido de uma plataforma de  testes. Destaca-se que os resultados das simulações computacionais do modelo são  comparados com os resultados dos ensaios obtidos de forma experimental. Ainda, é  apresentada a análise comparativa dos resultados das simulações com as baterias de  Lítio Íon e Lítio Íon Polímero. Assim, o artigo está organizado da seguinte forma. Na  Seção 2 tem-se o estudo teórico sobre o modelo elétrico Battery, descrevendo as  hipóteses de modelagem e a extração de parâmetros do modelo. Na Seção 3 encontramse os dados obtidos experimentalmente e as simulações realizadas. Na Seção 4, a  conclusão.          2. O Modelo Elétrico Battery  O modelo elétrico Battery, semelhante ao modelo proposto por Tremblay e Dessaint  (2009), possibilita simular os seguintes tipos de baterias: Chumbo-Ácido, Níquel  Cádmio, Níquel Metal Hidreto e Lítio Íon. Assim, o cálculo da tensão difere,  dependendo do tipo de bateria a ser simulada. Neste sentido, no site da MathWorks  encontra-se a equação matemática (1) que descreve o decaimento da tensão para as  baterias de Lítio Íon e Lítio Íon Polímero utilizadas neste estudo,     1)   onde:  é a tensão constante,  é a constante de polarização ou resistência de  polarização,  é a corrente dinâmica em baixa freqüência,  é a capacidade extraída,   é a capacidade máxima da bateria,  é a tensão exponencial e  é a capacidade  exponencial.    Para modelar o processo de descarga de energia nas referidas baterias é essencial  considerar as hipóteses de modelagem do modelo Battery, as quais estão baseadas nos  seguintes pressupostos, conforme Tremblay e Dessaint (2009): a resistência interna é  considerada constante durante a carga e descarga da bateria, não variando com a  amplitude da corrente; a capacidade efetiva da bateria não se altera com as variações de  amplitude da corrente (efeito PEUKERT); a temperatura é negligenciada, não afetando  o comportamento do modelo; a auto-descarga da bateria não está representada; o  modelo não tem efeito memória.            Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     146   2.1 Extração de Parâmetros do Modelo  Os parâmetros do modelo elétrico Battery são informados para representar um tipo  específico de bateria, Porciuncula et. al. (2012). Destaca-se que, na sua maioria, estes  parâmetros são obtidos diretamente dos dados presentes nos datasheets das baterias,  sendo somente três parâmetros extraídos por meio de curvas características de  descargas, são eles: capacidade na tensão nominal, tensão exponencial e capacidade  exponencial. Como as baterias simuladas neste trabalho não possuem em seus  datasheets curvas típicas de descarga, é preciso gerá-las de maneira experimental  utilizando dados obtidos a partir de uma plataforma de testes (Figura 1) desenvolvida  pelo Grupo de Automação Industrial e Controle (GAIC), localizada no Laboratório de  Sensores Inteligentes, na Unijuí.     Figura 1. Foto da plataforma de teste.   Uma curva característica de descarga é composta por três seções: a primeira  representa a queda de tensão exponencial quando a bateria está totalmente carregada; a  segunda representa a carga que pode ser extraída da bateria até a tensão decair abaixo da  tensão de cutoff; e a terceira representa a descarga total da bateria, quando a tensão  diminui rapidamente, conforme mostrado na Figura 2.      Figura 2. Curva característica de descarga (Tremblay e Dessaint, 2007).   No site da MathWorks encontram-se os valores do parâmetro de resistência  interna, correspondente a 1% do produto entre a tensão nominal (cutoff) e a capacidade  típica da bateria; do parâmetro capacidade máxima, considerado 105% da capacidade  típica da bateria; e, o tempo de resposta, definido como 30 s, representando de maneira  satisfatória a dinâmica da tensão da bateria. Após a obtenção dos parâmetros é     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     147   necessário realizar a calibração do modelo, a qual consiste em informar todos os  parâmetros em uma interface gráfica presente no modelo elétrico Battery. Em seguida,  para realizar as simulações, basta submeter o modelo já calibrado a diferentes tipos de  perfis de descarga.    3. Validação do Modelo Elétrico Battery  O modelo elétrico Battery é avaliado a partir de uma análise comparativa entre os  resultados simulados e os resultados experimentais obtidos através da plataforma de  testes, considerando dois tipos de baterias: Lítio Íon e Lítio Íon Polímero. A seguir são  apresentados os resultados das simulações do tempo de vida para tais baterias.   3.1 Baterias de Lítio Íon  Para a realização das simulações do tempo de vida das baterias de Lítio Íon são  adotados diferentes perfis de descargas contínuas, com correntes baixas, médias e altas.  O modelo é calibrado considerando as seguintes correntes nominais de descarga: 0,1 A,  0,4 A e 0,8 A. Na Tabela 1 são apresentados os tempos de vida experimentais médios  (Tve), os tempos de vida simulados (Tvs) obtidos a partir das simulações com o modelo  elétrico Battery e o erro encontrado, dado pela diferença entre o tempo de vida médio  experimental e o tempo de vida simulado pelo modelo. Ainda, observa-se que a corrente  constante utilizada para calibrar o modelo Battery não é utilizada na comparação dos  resultados com as simulações computacionais.   Tabela 1. Tempos de vida experimentais médios (Tve) e tempos de vida  simulados (Tvs) com o modelo elétrico Battery com descargas contínuas,  considerando as baterias de Lítio Íon.   Cal.  (A)   Perfis  (A) 0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8   Erro  Médio   Tve (s) 35722 17858 11629 8743 7115 5717 4740 4122   0,1 Tvs (s) - 17020 11292 8428 6709 5563 4744 4130   Erro (%) - 4,92 2,98 3,74 6,05 2,77 0,08 0,19 2,98%   0,4 Tvs (s) 34596 17235 11448 - 6818 5660 4832 4212   Erro (%) 3,25 3,61 1,58 - 4,36 1,01 1,90 2,14 2,14%   0,8 Tvs (s) 34970 17440 11596 8673 6920 5751 4915 -   Erro (%) 2,15 2,40 0,28 0,81 2,82 0,59 3,56 - 2,15%   Apresenta-se na Figura 3, o gráfico que mostra o decaimento da tensão da  bateria até atingir o nível de Cutoff, para uma taxa de descarga constante de 0,5 A, com  calibração do modelo para 0,3 A. O tempo de vida simulado pelo modelo Battery é de  7121 segundos e o tempo experimental é de 7115 segundos, obtendo-se um erro entre os  tempos de vida igual a 0,08%.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     148   0 1000 2000 3000 4000 5000 6000 7000 8000  3.2  3.4  3.6  3.8  4  4.2  4.4  Tempo (s)  T en  sã o   el ét  ric a   (V )        Experimento Simulação    Figura 3. Comparação entre dados experimentais e resultados simulados para  a descarga contínua de 0,5 A, considerando a corrente nominal de 0,3 A.   Além dos resultados apresentados acima, são realizadas simulações para oito  calibrações diferentes no modelo, referentes às curvas de descargas contínuas de 0,1 A,  0,2 A, 0,3 A, 0,4 A, 0,5 A, 0,6 A, 0,7 A e 0,8 A. Cada calibração é submetida aos  seguintes perfis de descargas 0,1 A, 0,2 A, 0,3 A, 0,4 A, 0,5 A, 0,6 A, 0,7 A e 0,8 A. Na  Figura 4 é apresentado o erro médio (%) obtido pela diferença entre os tempos de vida  simulados em cada calibração do modelo considerando os nove perfis de descargas  contínuas e os tempos de vida experimentais.      Figura 4. Erro médio (%) em cada calibração do modelo.   3.2 Baterias de Lítio Íon Polímero  Para a realização das simulações do tempo de vida das baterias de Lítio Íon Polímero  são adotadas as seguintes correntes nominais de descargas para calibrar o modelo: 0,1  A, 0,4 e 0,8 A. Na Tabela 2 são apresentados os tempos de vida experimentais médios  (Tve), os tempos de vida simulados (Tvs) obtidos a partir das simulações com o modelo  elétrico Battery e o erro encontrado, dado pela diferença entre o tempo de vida médio  experimental e o tempo de vida simulado pelo modelo.                        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     149   Tabela 2. Tempos de vida experimentais médios (Tve) e tempos de vida  simulados (Tvs) com o modelo elétrico Battery com descargas contínuas,  considerando as baterias de Lítio Íon Polímero.   Cal.   (A)   Perfis   (A)  0,1 0,2 0,3 0,4 0,5 0,6 0,7 0,8 Erro Médio   Tve (s) 24355 11757 7681 5573 4411 3340 2993 2483   0,1 Tvs (s) - 12194 7937 5808 4531 3678 3069 2612   Erro (%) - 3,58 3,22 4,03 2,63 9,18 2,46 4,91 4,29%   0,4 Tvs (s) 24836 12121 7881 - 4487 3638 3030 2574   Erro (%) 1,94 3,00 2,53 - 1,67 8,18 1,20 3,51 3,15%   0,8 Tvs (s) 24029 11674 7554 5493 4256 3430 2839 -   Erro (%) 1,36 0,71 1,68 1,47 3,66 2,62 5,45 - 2,42%   Apresenta-se na Figura 5, o gráfico que mostra o decaimento da tensão da  bateria até atingir o nível de Cutoff, possibilitando a comparação entre os dados  experimentais e os resultados simulados para um perfil de descarga constante de 0,55 A,  com calibração do modelo para 0,675 A. Neste caso, o tempo de vida simulado pelo  modelo Battery é de 4039 segundos e o tempo de vida experimental é de 4038  segundos, obtendo-se 0,01% de erro.    0 500 1000 1500 2000 2500 3000 3500 4000 4500  3.2  3.4  3.6  3.8  4  4.2  Tempo (s)  T en  sã o   el ét  ric a   (V )       Experimento Simulação    Figura 5. Comparação entre dados experimentais e resultados simulados para  a descarga contínua de 0,55 A, considerando a corrente nominal de 0,675 A.   Na Figura 6 é apresentando o erro médio (%) obtido pela diferença entre os  tempos de vida simulados e os tempos de vida experimentais, considerando as  calibrações do modelo referentes às seguintes correntes nominais: 0,1 A, 0,2 A, 0,3 A,  0,4 A, 0,5 A, 0,6 A, 0,7 A e 0,8 A; e os seguintes perfis de descargas 0,1 A, 0,2 A, 0,3 A,  0,4 A, 0,5 A, 0,6 A, 0,7 A, 0,8 A.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     150     Figura 6. Erro médio (%) em cada calibração do modelo.    3.3 Comparação entre os resultados das simulações dos tempos de vidas das  baterias de Lítio Íon e Lítio Íon Polímero  Ao analisar os resultados das simulações realizadas com as baterias, observa-se que com  as baterias Lítio Íon o modelo elétrico Battery apresenta um erro médio de 2,54% em  relação aos dados experimentais, e com os resultados simulados com as baterias de Lítio  Íon Polímero obteve um erro médio de 3,42% em relação aos dados experimentais. Na  Figura 7 são apresentados os erros médios de cada calibração do modelo Battery, para  as baterias simuladas.     0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0  1  2  3  4  5  6  Calibração (A)  E rr  o  m  éd io   ( %  )       Lítio Íon Polímero Lítio Íon    Figura 7. Erro médio (%) de cada calibração do modelo elétrico Battery.   4. Conclusão  Neste trabalho foi estudado e aplicado o modelo elétrico Battery por meio de  simulações de descargas de energia utilizando baterias de Lítio Íon e Lítio Íon Polímero.  O modelo foi validado a partir da comparação entre os tempos de vida simulados e os  tempos de vida experimentais obtidos pela plataforma de testes, para ambas as baterias.  Destaca-se que a precisão do modelo para os casos simulados é melhor em baterias de  Lítio Íon, com erro de 2,54%. Logo, conclui-se que o modelo Battery obteve resultados  satisfatórios para predição do tempo de vida de baterias, considerando que o erro médio  encontrado nas simulações é inferior a 5%, limite de erro esperado em simulações  computacionais com modelos elétricos.   Assim, importantes características do modelo Battery, como o processo  relativamente mais simples de extração de parâmetros quando comparado a outros  modelos que predizem o tempo de vida de baterias, assim como a boa precisão  demonstrada neste trabalho, fazem desse modelo uma excelente ferramenta a ser     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 144 - 151  Nov/2014     151   aplicada para os diversos dispositivos móveis, melhorando o desempenho para o  usuário.   Referências  Chen, M.; Rincón-Mora, G.  “Accurate electrical battery model capable of predicting   runtime and i-v performance,” IEEE Transactions on Energy Conversion, vol. 21,  no. 2, june 2006.   Chiasserini, C.; Rao, R. “Pulsed battery discharge in communication devices,”  Proceedings of the 5th International Conference on Mobile Computing and  Networking, pp. 88–95, 1999.   Fuller, M. D. T. F.; Newman, J. “Simulation and optimization of the dual lithium ion  insertion cell,” Journal of the Electrochemical Society, vol. 141, no. 1, pp. 1–10,  1994.   Jongerden, M.; Haverkort, B. “Battery modeling,” Thecnical Report in Faculty  Electrical Engineering, Mathematics and Computer Science, 2008.   Kim, T. “A hybrid battery model capable of capturing dynamic circuit characteristics an  nonlinear capacity effects”. Muly 2012.   Ljung, L. System Identication: Theory for the User, 2nd ed. New Jersey: Prentice Hall  PTR, 1999.   MathWorks, "Implement generic battery model", Disponível em:  <http://www.mathworks.nl/access/helpdesk/help/toolbox/physmod/powersys/ref/batt ery.html>. Acesso em: 18 jun. 2014.     Porciuncula, C. M. D. et. al. Avaliação comparativa entre o modelo elétrico Battery e  os modelos analíticos Linear e Lei de Peukert Revista Brasileira de Computação  Aplicada (ISSN 2176-6649), Passo Fundo, v. 4, n. 1, p. 71-80, mar. 2012.   Rakhmatov, D.; Vrudhula, S. “An analytical high-level battery model for use in energy  management of portable electronic systems,” National Science  Foundation’sState/Industry/University Cooperative Research Centers’  (NSFS/IUCRC) Center for Low Power Electronics (CLPE), pp. 1 – 6, 2001.   Tremblay, O.; Dessaint, L.-A.; Dekkiche, A.-I., A Generic Battery Model for the  Dynamic Simulation of Hybrid Electric Vehicles, Vehicle Power and Propulsion  Conference, 2007. VPPC 2007. IEEE , pp. 284-289, 9-12 Sept. 2007.   Tremblay, O., Dessaint, L.-A. "Experimental Validation of a Battery Dynamic Model  for EV Applications." World Electric Vehicle Journal. Vol. 3 - ISSN 2032-6653 - ©  2009 AVERE, EVS24 Stavanger, Norway, May 13 - 16, 2009.           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     152   Avaliação de Técnicas para Redução de Base de Dados de  Produção   Edward Alves R. Neto¹, André Assis Lôbo de Oliveira¹, Plínio de Sá L. Junior¹,  Celso G. Camilo Junior¹, Cassio Leonardo Rodrigues¹, Auri Marcelo R. Vincenzi¹   ¹Instituto de Informática – Universidade Federal de Goiás (UFG)  Caixa Postal 131 – 74.001-970 – Goiânia – GO – Brasil.   {edward_neto,andreoliveira,plinio,celso,cassio,auri}@inf.ufg.br   Abstract. This paper focuses on the evaluation of techniques for reducing  Database Production using SQL queries to software testing. In the context was  selected two approaches, the first uses reduction for queries coverage and the  second uses Genetic Algorithms. Was used a Benchmark as common database  and SQL Mutation to evaluate the test data generated by the techniques. The  experiments compares results in terms of efficiency (runtime) and effectiveness  (quality of data). The results show that data quality is maintained  proportionally by the size of the base test.  Resumo. Este artigo centra-se na avaliação de técnicas para redução de  Bancos de Dados de Produção, utilizando instruções SQL para o teste de  software. No contexto foram utilizadas duas abordagens, a primeira utiliza  redução por cobertura de instrução e a segunda faz o uso de Algoritmos  Genéticos. Utilizou-se um Benchmark como base de dados comum e a Análise  de Mutantes SQL para avaliar os dados de testes gerados pelas técnicas. A  experimentação compara os resultados em termos de eficiência (tempo de  execução) e eficácia (qualidade dos dados). Os resultados revelam que a  qualidade dos dados é mantida proporcionalmente pelo tamanho da Base de  Dados de Teste.   1. Introdução  A obtenção da qualidade de software tem sido o alvo de muitas empresas e pesquisas do  segmento de desenvolvimento de software. Por isso, atividades de Validação,  Verificação e Teste (VV&T) devem ser executadas durante todo processo de construção  de um software [Delamaro, Jino e Maldonado, 2007]. Dentre as atividades de VV&T, o  Teste de Software tem grande importância por fazer uso de técnicas e critérios de teste  para avaliação da adequabilidade de um conjunto de teste. Dentre os diferentes critérios  existentes destaca-se o Teste de Mutação (TM, ou Análise de Mutantes), por ser  reconhecidamente eficaz na revelação de defeitos.   Assim como qualquer código, instruções de consulta SQL (Structured Query  Language) precisam ser testadas para garantir a qualidade do produto a ser entregue. A  Análise de Mutantes SQL (AMS) é uma abordagem do TM para testar as instruções  SQL que serão utilizadas na base de dados.   Todavia, o alto custo computacional advindo da execução dos mutantes é um  dos grandes problemas de aplicabilidade do TM devido a grande cardinalidade do  conjunto de teste. Por isso, manter um banco de dados de testes (BDT) tão pequeno  quanto possível tem grande importância [Tuya, 2009], uma vez que um conjunto de  teste reduzido diminui o custo da aplicabilidade do critério. Por outro lado, espera-se  também que um BDT de tamanho reduzido tenha um conteúdo adequado [Queiroz,  2013] para não perder a qualidade dos testes.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     153   Neste contexto, pesquisas vêm sendo realizadas para propor técnicas que  obtenham eficácia e eficiência. O objetivo desta pesquisa consiste em avaliar diferentes  técnicas de redução de Banco de Dados em termos de eficácia (qualidade) e eficiência  (tempo gasto para redução).   Na avaliação foram consideradas duas abordagens de redução: i) Algoritmos  Genéticos (AG) [Monção, 2013] e; ii) a redução por Consulta Consciente (QueryAware) [Tuya, 2009]. Além disso, para avaliar a qualidade das reduções, foi utilizado  um Benchmark desenvolvido especificamente para avaliação de técnicas de redução de  Banco de Dados.    Este artigo está estruturado da seguinte forma: a Seção 2 apresenta uma revisão  teórica da Análise de Mutantes e expõe as vantagens da redução de bancos de dados  para fins de testes; a Seção 3 apresenta as abordagens que serão utilizadas, bem como o  motivo de seleção das mesmas; a Seção 4 apresenta os resultados obtidos; a Seção 5  realiza as conclusões e apresenta os trabalhos futuros.   2. Revisão  2.1 Análise de Mutantes  A Análise de Mutantes ou Teste de Mutação é um critério de teste da técnica baseado  em defeitos. Surgiu em 1978 na Universidade de Yale com o artigo “Hints on test data  selection. Help for the practicing programmer” que apresentaram duas principais  ideias: a hipótese do programador competente e o efeito de acoplamento. A hipótese do  programador competente adota que bons programadores escrevem códigos muito  próximos de estarem corretos. Acerca da afirmação, então, assume-se que os erros  acontecem por pequenos desvios sintáticos que alteram a semântica do programa. E o  efeito de acoplamento diz que defeitos complexos são causados por pequenos erros.   No Teste de Mutação, dado um programa P, são gerados n programas P’  (mutantes) que foram modificados sintaticamente utilizando operadores de mutação. O  caso de teste é executado no programa original e no mutante visando o resultados  gerados. Se a saída do mutante for diferente do programa original, diz-se então que o  mutante foi morto. Há casos em que são gerados mutantes equivalentes que, embora  sintaticamente sejam diferentes, são semanticamente equivalentes ao programa original.    Após a execução dos casos de testes em todos os mutantes, realiza-se o cálculo  do escore de mutação (EM). O valor do escore varia de 0 a 1 e é calculado através de  uma relação entre os mutantes gerados e os mutantes mortos. Ele fornece uma medida  objetiva de quanto o conjunto de casos de teste analisado aproxima-se da adequação  [Delamaro, Jino e Maldonado, 2007], representado pela equação:      Onde:  ms(P, T): escore de mutação do conjunto de testes T;  DM(P,T) : número de mutantes mortos pelo conjunto de casos de teste T;  M(P): número total de mutantes gerados a partir do programa P; e  EM(P) número de mutantes equivalentes a P;   O principal problema no TM consiste na possibilidade de geração de um grande  número de mutantes, o que irá demandar de um alto esforço e custo computacional para  que os mutantes sejam executados contra todos os casos de teste.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     154   A Análise de Mutantes SQL é uma técnica que utiliza o TM como abordagem,  sendo análoga ao Teste de Mutação tradicional, os programas nesse caso são as  instruções SQL e o conjunto de casos de teste T pode ser considerada como todo o  Banco de Dados de Produção (BDP). O objetivo também é análogo ao TM, consistindo  em formar uma BDT reduzida com alto escore de mutação.    2.2 Redução de Banco de Dados (BD)  No contexto de testes de instruções SQL, o domínio de entrada para a execução dos  testes pode possuir mais de um banco de dados e o uso do BDP para testes pode ter um  alto custo computacional considerando o tamanho do BDP e complexidade das  instruções SQL [Monção, 2013]. A redução de uma base de dados baseia-se na seleção  de um número menor de tuplas que possa representar o BDP de forma mais adequada  possível.   Diversas técnicas vêm sendo aplicadas no problema de redução de Banco de  Dados para o teste de instruções SQL. Manilla e Raiha (2006) propõem a geração  automática de um BDT de determinada instrução SQL. Gupta et al (2010) trabalham  com a geração de BDT para matar mutantes SQL considerando as mutações nas  cláusulas JOIN e nos operadores relacionais. Monção (2013) propôs a geração de BDTs  utilizando computação evolucionária com o uso de AG, evoluindo os dados de testes até  serem os mais adequados possíveis. Tuya et al. (2009) desenvolveram uma ferramenta  para redução de banco de dados através da cobertura de instruções SQL.   Tuya et al. propuseram uma técnica que mantém o foco na extração de uma  quantidade mínima de tuplas, preservando a cobertura das instruções SQL, baseada nos  critérios de cobertura MC/DC [Tuya, 2010]. Foi desenvolvida uma ferramenta para  automatizar o processo denominada QAShrink (Query-Aware Shrinking, do inglês  Redução por Consulta Consciente).   Um estudo de caso foi apresentado e obteve como resultado, a redução de um  BDP com 137.490 tuplas em 31 tabelas para apenas 223 linhas, uma redução de  99,84%. O resultado também mostrou que o escore de mutação do BDT foi de apenas  0,5% menor em relação ao original e sendo executado no tempo total de 125,2  segundos. Percebe-se que a relação eficiência/eficácia do método é bastante promissora.    Monção (2006) trabalhou com Algoritmos Genéticos, uma meta-heurística a fim  de explorar a busca selecionando melhores indivíduos candidatos para compor o BDT.  Para a avaliação dos dados selecionados utilizou-se da Análise de Mutantes para SQL.  Foram desenvolvidos os AG Canônico (AGCA), AG com Grupo de Eleitos (AGGE) e o  InVitro (AG InVitro). A estrutura do AG pode ser representada pela figura 1:   Figura 1. Estrutura de execução do AG.                     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     155   3. Abordagem Proposta  A presente pesquisa tem por objetivo avaliar diferentes técnicas de redução de Banco de  Dados. Todavia, para alcança-la, existe a necessidade de um Benchmark que permita a  avaliação das técnicas selecionadas.    Queiroz (2013) propôs um Benchmark¹ para o auxílio na avaliação de diferentes  técnicas de redução de BDP. O Benchmark possui dois cenários, o primeiro utiliza um  BD (Banco de Dados) hipotético e o segundo utiliza a aplicação de um BD real, além  disso possui um BDE (Banco de Dados de Experimentos) que contém as informações  obtidas a partir da redução pelo método aleatório de busca. A escolha de um Benchmark  auxilia na avaliação por comparação de diferentes métodos, uma vez que, dispõe de um  ambiente comum para o uso das técnicas. Os experimentos deste artigo utilizam o  cenário 2 (tabela 1) como base comum para os experimentos de testes das ferramentas.   Tabela 1. Informações do cenário 2 do Benchmark  BDP UFG  Tabela Tuplas  histórico 232485  disciplinas 23106   Foram selecionadas 4 consultas (instruções 1, 4, 8 e 15) baseadas no espaço de  melhoria médio, que é a diferença entre o escore de mutação dos BDTs do Método  Aleatório e o escore de mutação do BDP do Benchmark, e instruções que utilizassem  somente uma tabela na consulta, pois o AG selecionado não oferece suporte para  instruções com mais de duas tabelas na consulta. As instruções são:  1) select codTurma, nomecampus from histórico where nomeCurso like 'Mestrado em  Química%';   4) select chave from historico where professor = 1597;   8) select * from historico where professor = 5962 and nomeCurso = 'Zootecnia' and  situacao = 'aprovado'; e   15) select discente, situacao from historico where disciplina = 22 and nomeCampus <>  'Campus de Catalão' and situacao = 'Aprovado' and discente not in (78661, 80836,  79782, 86615, 85339).   A pesquisa utiliza as técnicas de redução por Consulta-Consciente (QAShrink)  [Tuya, 2009] e redução por Algoritmos Genéticos [Monção, 2013], para serem  avaliadas em termos de escore de mutação (eficácia) e tempo de execução (eficiência).    Na primeira abordagem, somente são necessários como parâmetros de entrada as  instruções SQL e o Banco de Dados de Produção que deseja ser reduzido, além disso foi  necessária a criação de um BDT somente com a estrutura do BDP, para que pudessem  ser armazenados os dados após a redução. As instruções selecionadas utilizam somente  a tabela “histórico” do cenário 2 e foram executadas isoladamente umas das outras.    A execução da primeira abordagem gerou BDTs de tamanhos diferentes para  cada instrução selecionada. Para a instrução 1 e 4, o método reduziu o BDP para apenas  2 tuplas, já com a instrução 8 a redução foi para 4 tuplas e a instrução 15 com 5 tuplas.  Em média as reduções foram de cerca de 99% para todos os casos.  ¹ Considera-se um Benchmark como sendo a composição de uma estrutura (cenário) juntamente com um  conjunto de instâncias de problemas [Queiroz, 2013].    A partir da execução da primeira técnica, proveu-se dos dados de entrada para a  realização dos testes com o AG. Para que os métodos pudessem ser comparados, o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     156   tamanho do BDT gerado pelo QAShrink foi o parâmetro de entrada para a realização  dos testes com o AG. Nesse contexto o tamanho do cromossomo (que é o tamanho do  BDT que se deseja) foi ajustado para que recebesse o valor do tamanho do BDT gerado  pela primeira abordagem. A tabela 2 apresenta os valores utilizados:   Tabela 2. Parâmetros para execução do AG  Execução do AGCA  Parâmetros Fixos Parâmetros Variáveis  Tx. de cruzamento (%) 80 Instrução 1, 4, 8, 15  Tam. população 45  Qtde. gerações 50 Tam. do cromossomo   (tamanho do BDT)  2 (instrução 1 e 4)   Op. cruzamento 1 4 (instrução 8)  Elitismo 2 5 (instrução 15)  Escore do BDP 1 Tx. de Mutação (%) 5, 10, 20, 30 e 40  Qtde. experimentos 10     A função objetivo do AG para cálculo do fitness (ou escore de mutação) foi  adaptada para realizar a avaliação dos BDTs provenientes do QAShrink.   4. Resultados  Os resultados das execuções com o QAShrink e do AGCA utilizando o cenário 2 do  benchmark estão expressos nos gráficos, 1, 2, 3 e 4. Todos os resultados consistem na  média de 10 execuções dos métodos. A primeira fase dos resultados consiste na análise  dos escores de mutação (eficácia) de cada técnica em cada problema.    Gráfico 1. Resultados da instrução 1        Gráfico 2. Resultados da instrução 4     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     157       Gráfico 3. Resultados da instrução 8                    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     158   Gráfico 4. Resultados da instrução 15      Em geral, os dados de teste gerados pelo AG obtiveram um melhor escore de   mutação na maioria dos casos. A instrução 15 foi a que obteve maior diferença de  escores entre as duas técnicas. Nesses casos percebe-se que a taxa de mutação é o  parâmetro que causa essa diferença, quanto maior a taxa maior a diferença entre os  escores.   Bons escores de mutação são aqueles que têm o valor elevado, mais próximo do  BDP possível. Considerando as instruções utilizadas nota-se que o valor dos EM são  bastante baixos. Uma possível explicação para isso consiste no fato de que foi realizada  no primeiro método uma redução de mais de 99% em todos os casos, o que interferiu na  qualidade dos escores obtidos, assim as instâncias alcançadas não podem ser  consideradas representativas em relação ao BDP original.     A tabela 3 apresenta o tempo médio gasto na execução de cada experimento.   Tabela 3. Tempos de execução das ferramentas (em segundos)   Instrução QAShrink AG (variação da tx. de mutação)  5% 10% 20% 30% 40%   1 3,33 1510,04 1045,11 1000,67 1194,21 1065,15  4 2,22 1156,21 1639,83 1347,02 1438,49 1564,11  8 2,69 1536,83 1683,93 1679,61 1953,03 1953,06  15 2,18 2340,20 4260,47 3252,35 3677,34 3347,82     Analisando a tabela 3 obtemos que, em termos de tempo de execução a técnica  QAShrink realizou a busca por BDTs em um tempo bastante inferior que o AG.  Todavia, percebe-se que o AG na maioria dos casos obteve maiores escores de mutação,  ou seja, a primeira abordagem obteve uma eficiência (tempo para execução) melhor  enquanto a segunda foi melhor em termos de eficácia (qualidade dos dados de teste).     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 152-159  Nov/2014     159   5. Conclusões e Trabalhos Futuros  Neste artigo foram avaliadas duas técnicas de redução de Banco de Dados de Produção:  redução por Consulta-Consciente [Tuya, 2009] e redução por Algoritmos Genéticos  [Monção, 2009]. Para avaliação dos dados de teste gerados foi realizada a Análise de  Mutantes SQL em um Benchmark específico para a avaliação de técnicas de redução de  Banco de Dados [Queiroz, 2013].    As técnicas foram avaliadas sob a perspectiva de Escore de Mutação (Análise de  Mutantes SQL) para avaliar a qualidade das reduções (eficácia), bem como sobre o  tempo gasto para obter a redução (eficiência). Na primeira técnica, obteve-se um tempo  de execução bastante inferior em relação a segunda, já o AG obteve uma melhor  qualidade dos dados obtidos. Com base nos resultados, podemos concluir que uma  grande redução no BDP pode prejudicar a qualidade dos dados de teste.    Como trabalhos futuros pretende-se propor uma abordagem que seja capaz de  identificar o tamanho ideal para um banco de dados de testes (BDT), a fim de que tal  redução não comprometa a sua qualidade para revelação de defeitos.   Referências  Delamaro, M. E.; Jino, M.; Maldonado, J. C. Introdução ao Teste de Software. Campus,  2007.   DeMillo, R. J Lipton, and F. G. Sayward. “Hints on test data Selection: help for the  practicing programmer”. In IEEE Computer Society Press Los Alamitos, p. 34-41,  1978.  Gupta, B. P.; Vira, D; Sudarshan, S. X-data: Generating test data for killing sql mutants.  In: Li, F. et al. (Ed.). Proceedings of the 26th International Conference on Data  Engineering, ICDE 2010.   Manilla, H; Raiha, K. J. Test Data for Relational Queries. In: Proceedings of the fifth  ACM SIGACT-SIGMOD Symposium on Principles of Database Systems, 1986.   Monção, A. C. B. L.; Camilo Junior, C. G.; Queiroz, L. T.; Rodrigues, C. L.; LeitaoJunior, P. S.; Vincenzi, A. M. R. “Shrinking a Database to Perform SQL Mutation Tests  Using na Evolutionary Algorithm”. In IEEE Congresso n Evolutionary Computation,  2013.   Monção, A. C. B. L. “Uma Abordagem Evolucionária para o Teste de Instruções  SELECT SQL com o uso da Análise de Mutantes”, 2013.   Queiroz, L. T. “Um Benchmark para Avaliação de Técnicas de Busca no Contexto de  Análise de Mutantes SQL” 2013.   Tuya, Javier; Suárez-Cabal, José M.; Riva, Claudio de la. “Query-Aware Shrinking  Databases”. In: 2nd International Workshop on Testing Databases Systems, 2009.   Tuya, Javier; Suárez-Cabal, José M.; Riva, Claudio de la. “Full predicate coverage for  testing SQL database queries”. In: Software Testing, Verification and Reliability, 2010.               
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     160   Um Operador de Mutação para Algoritmos Evolucionários  na Seleção de Casos de Teste da Análise de Mutantes   Beatriz Proto Martins1, André Assis Lôbo de Oliveira1, Plínio de Sá Leitão Júnior1,  Celso Gonçalves Camilo-Junior1, Auri Marcello Rizzo Vincenzi1   1Instituto de Informática – Universidade Federal de Goiás (UFG)   Caixa Postal 131 – 74.001-970 – Goiânia – GO – Brasil  {beatrizmartins,andreoliveira,plinio,celso,auri}@inf.ufg.br   Abstract. This paper is situated in the field of Evolutionary Algorithms for Test  Cases Selection on Mutation Analysis. It is proposed a hybrid mutation  operator, aiming to achieve variability as well as effectiveness on the selected  test cases subsets, by using both random and classificatory mechanisms.  Experiments were performed in five algorithms, applied to real benchmarks,  totaling 11520 executions. Althought there is a high computational cost in  verifying each test case contribution on the selected subsets, the operator was  sucessful when applied to most benchmarks, reducing costs up to 62%.   Resumo. Este artigo situa-se no campo dos Algoritmos Evolucionários para  Seleção de Casos de Teste através da Análise de Mutantes. É proposto um  operador de mutação híbrido, com o intuito de propiciar variabilidade e  eficácia dos subconjuntos de casos de teste selecionados, ao utilizar tanto  mecanismos aleatórios quanto mecanismos classificatórios. Foram realizados  experimentos sobre cinco algoritmos, aplicados a benchmarks reais,  totalizando 11520 execuções. Apesar do custo computacional de verificar a  contribuição de cada caso de teste nos subconjuntos selecionados, o operador  obteve êxito na maioria dos experimentos, ocasionando uma redução de  custos de até 62%.   1. Introdução   Durante a etapa de teste de um software, pode ser necessário um grande conjunto de  casos de teste. O desafio consiste em encontrar um subconjunto capaz de representar os  demais, sendo este um dos problemas mais complexos da área de Teste de Software. De  acordo com Pezzè e Young (2008), provar que um subconjunto de casos de teste garante  a corretude do programa é tão difícil quanto provar que o programa está correto e, para  tanto, deveria ser possível provar a corretude sem teste algum.    Um bom caso de teste é aquele com grande possibilidade de revelar um defeito  no software [Delamaro, Maldonado e Jino 2007], assim, informações a respeito da  qualidade dos casos de teste podem ser obtidas analisando falhas anteriores do software.  Essas especificações delineiam a técnica baseada em defeitos, na qual se destaca a  Análise de Mutantes.     Apesar de não haver a garantia de se encontrar um subconjunto ótimo de casos  de teste, é possível achar uma solução que melhor se aproxime da esperada. Tal artifício  é utilizado pela Search-Based Software Testing (SBST), uma abordagem genérica que  soluciona problemas de Teste de Software através de técnicas de busca e otimização  meta-heurísticas [McMinn 2011].     A presente pesquisa propõe o Operador de Mutação Aleatório e Classificatório     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     161   (OMAC), um operador híbrido para Algoritmos Evolucionários (AEs) utilizados pela  SBST na Seleção de Casos de Teste da Análise de Mutantes. Os AEs são então  comparados com e sem o uso do operador, juntamente com o algoritmo aleatório, a fim  de encontrar as melhores configurações possíveis. Entre os resultados, foi obtido uma  redução de tempo de até 62% sobre um benchmark de grande porte utilizando o  Algoritmo Genético canônico.   2. Revisão   2.1. Análise de Mutantes   A Análise de Mutantes ou Teste de Mutação foi primeiramente apresentada no artigo de  DeMillo, Lipton, e Sayward (1978). A técnica baseia-se na “hipótese do programador  competente”, partindo do princípio de que programadores experientes escrevem  programas corretos ou bem próximos do correto, e no “efeito de acoplamento” em que  defeitos complexos são causados por defeitos simples.    Nessa técnica são aplicadas variações sintaticamente corretas no programa em  teste para simular possíveis falhas, cada variação resulta em um programa chamado  mutante. Um caso de teste deve provocar uma saída diferente em relação ao programa  original, caso contrário o mutante é equivalente ou devem ser aplicados novos casos de  testes, pois a falha pode estar no programa original. Quando as saídas são diferentes, o  mutante é morto, caso contrário permanece vivo [DeMillo, Lipton, e Sayward, 1978].    Na Análise de Mutantes é possível avaliar um conjunto de casos de teste através  do escore de mutação, calculado na Equação 1. O escore varia de 0 a 1 e quanto maior  ele for, maior é capacidade do conjunto de casos de teste de matar mutantes [Delamaro,  Maldonado e Jino, 2007].         (1)   Onde:  - ms(P, T): escore de mutação do conjunto de testes T em relação ao programa P;  - DM(P, T): total de mutantes mortos pelo conjunto de casos de teste T;  - M(P): total de mutantes gerados a partir do programa P;  - EM(P): total de mutantes equivalentes a P.   2.2. Trabalhos Correlatos   Os AEs formam uma subárea da Computação Evolucionária que, por ter sido criada  recentemente nos anos 60, tem sido destaque em trabalhos acadêmicos. Os algoritmos  genéticos são os mais estudados, suas várias vertentes e aplicações, como em  aprendizagem e redes neurais, são apresentadas por Tanomaru (1995).    McMinn (2011) destaca as soluções oferecidas pela SBST na geração e seleção  de casos de teste. Em seu trabalho, é possível notar que, ao contrário dos algoritmos  aleatórios, os AEs oferecem uma solução razoável para o Teste de Software,  especificamente para a Seleção de Casos de Teste, uma vez que as soluções para esse  problema normalmente ocupam uma pequena fração de um grande espaço de busca.    Em seu trabalho, Oliveira (2013) expõe uma visão abrangente da aplicação de  AEs na Análise de Mutantes e contribui para esse critério de teste com o conceito de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     162   Efetividade Genética, ao propor um Algoritmo Genético Coevolucionário (AGC).   3. Abordagem Proposta   Dado um conjunto de casos de teste, surge a necessidade de reduzi-lo a um subconjunto  capaz de representar os demais. A SBST resolve esse problema razoavelmente através  de AEs em suas configurações convencionais. Entretanto, quando aplicados na Seleção  de Casos de Teste, é possível guiar ainda mais a busca por meio da classificação dos  casos de teste em termos de suas contribuições na matança de mutantes. Um caso de  teste contribui para o conjunto quando é o único a matar pelo menos um mutante  [Oliveira, Camilo-Júnior e Vincenzi 2013a].    Um subconjunto de casos de teste pode ser visto como um indivíduo nos AEs,  enquanto que um caso de teste é representado por um cromossomo. Normalmente,  durante a operação de mutação do AE, é alterado um cromossomo aleatoriamente.  Nesse trabalho foi desenvolvido o OMAC que funciona da seguinte forma, dado um  indivíduo a ser mutado: 1) sorteia-se um número; 2) se o número estiver acima da  porcentagem de classificação escolhida, um caso de teste é mutado aleatoriamente; 3)  senão, é feita a mutação dos casos de testes que não contribuem para o subconjunto.    O método classificatório do operador funciona do seguinte modo: 1) recupera-se  os mutantes mortos por cada caso de teste do subconjunto; 2) realiza-se a ordenação  decrescente do subconjunto  de acordo com os casos de teste que matam mais mutantes;  3) armazena-se os números dos mutantes mortos pelo caso de teste que mata mais; 4)  para cada caso de teste ordenado restante é feito o que segue; 4.1) analisa-se se o caso  de teste mata algum mutante além dos que já foram mortos; 4.2) se sim, os números dos  novos mutantes mortos são guardados; 4.3) senão, o caso de teste é mutado.   4. Metodologia   4.1. Algoritmos e Benchmarks   Eiben e Smith (2003) explicam o funcionamento dos AEs que, aplicados no Teste de  Mutação, podem ser descritos da seguinte forma: 1) gera-se uma população composta  por subconjuntos de casos de teste (indivíduos) aleatórios; 2) cada candidato é avaliado  de acordo com a Equação 1 (função de aptidão); 3) enquanto o tempo ou escore de  mutação máximos não são atingidos (condição de parada); 3.1) são selecionados  subconjuntos (pais); 3.2) os subconjuntos são recombinados e/ou; 3.3) mutados e; 3.4)  passados para a próxima geração (filhos).    Nos experimentos foram comparados cinco algoritmos, sendo quatro  evolucionários e um aleatório a fim de verificar a eficácia do OMAC. São eles:    AG: algoritmo genético canônico que utiliza os 3 operadores (seleção,  recombinação e mutação) e na qual a seleção é aleatória [Tanomaru 1995];    EE: estratégia evolutiva com seleções determinísticas (µ,λ)-EE e (µ+λ)-EE onde  µ pais geram λ filhos, sendo que no primeiro caso os filhos substituem os pais e,  no segundo caso, pais e filhos competem entre si [Eiben e Smith 2003].    EST: algoritmo genético com reprodução de estado estável em que,  normalmente, somente um indivíduo é trocado por geração [Tanomaru 1995].    MI: algoritmo genético no modelo de ilhas em que subpopulações (ilhas) são  evoluídas paralelamente e indivíduos migram entre elas, através de uma     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     163   topologia de comunicação, após cada época, isto é, após um certo número de  gerações [Tanomaru 1995].    AL: consiste no algoritmo de abordagem aleatória utilizando alguns conceitos  dos AEs. O algoritmo pode ser descrito em 3 passos: 1) gera-se uma população  aleatória; 2) calcula-se a aptidão dos indivíduos conforme a Equação 1; 3)  escolhe-se o melhor indivíduo entre todos os avaliados; 4) se a condição de  parada não for satisfeita, retorna-se ao passo 1.    Todos os experimentos foram executados em sistema desktop modelo Dell  Precision T7500 de 64 bits com as configurações padrões de fábrica. Os AEs foram  executados através do Watchmaker Framework1, um Software Livre na linguagem Java  desenvolvido por Daniel Dyer e disponibilizado sob a licença Apache 2.0.    Nos experimentos foram utilizados oito programas, dos quais quatro são  utilitários UNIX escritos em linguagem C, são eles: a) cal; b) comm; c) look e; d) uniq.  Para geração dos mutantes foi utilizada a ferramenta Proteum [Oliveira 2013 apud  Delamaro 1996]. Os demais programas são escritos em linguagem Java e seus mutantes  foram gerados pela ferramenta MuJava [Oliveira, Camilo-Júnior e Vincenzi 2013b apud  Ma 1997], são eles: a) bubcorrecto; b) fourballs; c) mid e; d) trityp. Os benchmarks  resultantes contêm os status dos mutantes quando executados com cada caso de teste, os  detalhes se encontram na Tabela 1, onde o subconjunto mínimo corresponde ao  subconjunto mínimo de casos de teste capaz de matar todos os mutantes.   Tabela 1. Informações sobre os benchmarks usados nos experimentos        4.2. Parâmetros dos algoritmos   Em cada experimento foram realizadas 30 execuções com, no máximo, 180 segundos  cada uma (em alguns casos esse limite pode ser ultrapassado porque a verificação é feita  após o final de uma geração que pode ser longa). No algoritmo AL foram aplicados os  mesmos parâmetros dos AEs para tamanho da população, tamanho do indivíduo e  condição de parada.     Os experimentos foram realizados com e sem o uso do OMAC. Dado um  indivíduo a ser mutado com o operador, são aplicadas as seguintes porcentagens de uso  dos mecanismos classificatórios: 10, 40 ou 70%. Nota-se que utilizar 0% de  classificação seria equivalente a usar um operador de mutação tradicional.    Foram estabelecidos os seguintes parâmetros para os AEs: a) operador de  seleção: torneio com 2 competidores; b) taxa de cruzamento: 95%; c) taxa de mutação:  5% e; d) tamanho do indivíduo: de acordo com o subconjunto mínimo da Tabela 1,  porém respeitando o tamanho mínimo 2 para possibilitar a recombinação.     O tamanho da população está de acordo com a Equação 2 em que a quantidade                                                   1 Disponível em: <http://watchmaker.uncommons.org/>.   cal comm look uniq bubcorrecto fourballs mid trityp Nº de mutantes 4622 1869 1980 1618 80 212 181 309 Nº de equivalentes 344 222 233 224 12 44 43 70 Nº de casos de teste 2000 801 255 490 255 96 125 216 Escore máximo 0,99742 1,0 1,0 1,0 1,0 1,0 1,0 1,0 Suconjunto mínimo 20 22 22 4 1 5 5 17    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     164   total de casos de teste em uma população, isto é, o tamanho da população multiplicado  pelo tamanho do indivíduo, corresponde a uma porcentagem do total de casos de testes  do benchmark em questão. Tais variações foram realizadas para dificultar ou facilitar as  disputas de forma a ocupar o intervalo de tempo disponível por execução. Nesse sentido  k foi fixado em 0.05 quando T < 300; 0.3 quando 300 <= T < 1000 e; 0.5 quando T >=  1000). Assim, o tamanho da população para cada benchmark é o seguinte: a) cal: 51; b)  comm: 12; c) look: 5; d) uniq: 39; e) bubcorrecto: 8; f) fourballs: 2; g) mid: 3 e; h)  trityp: 2.     1+min÷Tk=Bpop   (2)   Onde:   - pop(B): população do algoritmo utilizando o benchmark B;   - k: porcentual de casos de teste para disputas;   - T: quantidade total de casos de teste;   - min: subconjunto mínimo de acordo com a Tabela 1;      Para o algoritmo MI foram estabelecidas 2 ilhas com estratégia de migração em  anel. Além disso, alguns parâmetros específicos por algoritmo foram variados:    EE1: a) estratégia: (1, 7)-EE (valor recomendado por Eiben e Smith  (2003));     EE2: a) estratégia: (1+7)-EE;    EE3: a) estratégia: (1+1)-EE;    EST1: a) pais selecionados: 2 e; b) filhos gerados: 2;    EST2: a) pais selecionados: 2 e; b) filhos gerados: 1;    MI1: a) épocas: 25 e; b) migração: 5;    MI2: a) épocas: 50 e; b) migração: 5;    MI3: a) épocas: 50 e; b) migração: 1.   5. Resultados   O algoritmo AL se mostrou mais eficiente nos benchmarks da ferramenta MuJava com  exceção do Trityp, quando comparado aos AEs (mostrados adiante), os resultados  podem ser vistos na Tabela 2. Entretanto, todos os benchmarks serão ainda abordados  neste artigo para fins de comparação.   A Tabela 3 apresenta as comparações do algoritmo EE2 para cada benchmark,  em que a esquerda de cada coluna estão os resultados sem o uso do OMAC e a direita  com 40% de uso da classificação. O operador obteve resultados melhores.   Tabela 2. Escore máximo alcançado (MAX), escore médio (MED), desvio padrão  (DESVP) e tempo médio (TEMPO) em segundos de cada benchmark                   MAX MED DESVP TEMPO bubcorrecto 1 1 0 0,0056 fourballs 1 1 0 0,0283 mid 1 1 0 4,1999 trityp 0,9665272 0,9566248 0,0008222 180,0073 cal 0,973352 0,9664251 0,0004485 180,2266 uniq 1 0,9997848 0,0000032 104,3589 look 0,9828277 0,9615531 0,0010145 180,0127    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     165   Tabela 3. Comparação entre o uso e não uso do OMAC com o algoritmo EE2.      Dentre os parâmetros apresentados na Seção 4.2, as menores médias de tempo  em cada benchmark foram as dos seguintes algoritmos: a) EE2; b) EST1 e; c) MI1.    A Tabela 4 apresenta para cada benchmark a porcentagem de experimentos, na  coluna SUCESSO, em que o uso do OMAC, independentemente da taxa de  classificação, possui um tempo médio menor (ou escore de mutação médio maior, para  os casos em que o tempo máximo é atingido) do que com o uso do operador tradicional.  Também é mostrada a razão entre o tamanho do indivíduo e quantidade total de casos  de teste (TAM_IND / QTD_CT), além da quantidade total de mutantes em relação ao  tamanho do indivíduo (QTD_MUT / TAM_IND).    Observando-se a Tabela 4, nota-se uma forte influência do tamanho do  indivíduo em relação a porcentagem de sucesso, principalmente para os benchmarks cal  e uniq em que o indivíduo abrange menos de 1% do total de casos de teste e cada caso  de teste deve matar, em média, uma grande quantidade de mutantes. Além disso, o custo  computacional para se classificar muitos indivíduos é maior do que o custo para se  classificar um indivíduo grande e, nesses experimentos, o tamanho da população é  inversamente proporcional ao tamanho do indivíduo.      Tabela 4. Possíveis influências no sucesso obtido pelo OMAC.     O benchmark cal é o mais complexo para seleção de casos de teste dentre os  benchmarks utilizados. Por isso, ele foi utilizado para realização de novas  experimentações com os melhores parâmetros encontrados anteriormente. Os  experimentos foram configurados aumentando o tamanho do indivíduo para 34 e  diminuindo o tamanho da população para 31 visando manter, aproximadamente, a  mesma quantidade de casos de teste em uma população. Obteve-se um resultado  positivo, pois além de diminuir o tempo médio, tal configuração permitiu a visualização  do aumento no escore de mutação médio provocada pelo OMAC (Gráficos 1 e 2).  Observando-se a convergência da curva, nota-se que uma taxa de cerca de 70% na  aplicação da classificação pode representar uma relação custo-benefício razoável, uma  vez que aumentar a taxa de classificação, aumenta a quantidade de cálculos.         cal comm look uniq bubcorrecto fourballs mid trityp SUCESSO 20% 90% 90% 0% 80% 80% 40% 40% TAM_IND / QTD_CT 0,01 0,027 0,086 0,008 0,0078 0,052 0,04 0,078 QTD_MUT / TAM_IND 231,1 84,9 90 404,5 40 42,4 36,2 18,2  MAX MED DESVP TEMPO bubcorrecto 1 1 1 1 0 0 18,0996 17,3545 fourballs 1 1 0 0 0 0 14,9078 12,564 mid 1 1 0 0 0 0 7,4448 10,6777 trityp 1 1 1 1 0 0 18,5671 18,9456 cal 0,9974287 0,997429 0,995286 0,9940704 0,0001663 0,00037 176,2194 168,4677 uniq 1 1 0 0 0 0 19,362 20,4549 look 1 1 0,9999809 1 0,0000003 0 43,2228 37,2112 comm 1 1 0,999616 0,999717 0,0000107 0,0000094 139,6696 120,3308    Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     166   Gráfico 1. Tempo médio do benchmark cal com indivíduos maiores        Gráfico 2. Escore de mutação médio do benchmark cal com indivíduos maiores      6. Conclusões e Trabalhos Futuros   Com a aplicação do OMAC, foi proporcionada uma alta variabilidade, isto é, foram  evitadas estagnações em máximos locais, uma vez que são mutados aleatoriamente  tanto casos de testes bons, quanto ruins, mas mutando principalmente os ruins através  da classificação. Na maioria dos experimentos isso ocasionou tempos de execuções  menores sem piorar o escore de mutação.     Frente a isso, acredita-se que seja vantajoso utilizar o OMAC, principalmente  em benchmarks de grande porte, desde que sejam devidamente parametrizados, isto é,  com o tamanho do indivíduo maior do que o tamanho da população em cada geração, os  quais representam 50% dos casos de teste do benchmark, e aplicando a classificação  pelo OMAC em 70% dos casos em que é requisitada a mutação. Observou-se também o  bom desempenho dos algoritmos genéticos canônico e em ilhas, além das estratégias  evolucionárias com os parâmetros previamente recomendados.     Como trabalhos futuros, pretende-se investigar quais fatores influenciam na  escolha da taxa de classificação e comparar com diferentes taxas de mutação. Pretendese, ainda, desenvolver um operador de seleção híbrido, análogo ao OMAC.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 160-167  Nov/2014     167   Referências   M. Pezzè, M. Young (2008) “Teste e análise de software: processo, princípios e  técnicas”. Ed. Bookman, Porto Alegre, RS.   M. Delamaro, J. Maldonado, M. Jino (2007) “Introdução ao teste de software”. Rio de  Janeiro: Elsevier Campus, 2007. 394p.   P. McMinn (2011) “Search-Based Software Testing: past, present and future. In:  International Conference on Software Testing, Verication and Validation Workshops  (ICSTW) p. 153-163.   R. A. DeMillo, R. J. Lipton, F. G. Sayward (1978) “Hints on test data selection: help for  the practicing programmer”. In: IEEE Computer Society Press Los Alamitos, p. 3441.   J. Tanomaru (1995) “Motivação, Fundamentos e Aplicações de Algoritmos Genéticos”  II Congresso Brasileiro de Redes Neurais.   A. Oliveira (2013) “Uma Abordagem Coevolucionária para seleção de Casos de Teste e  Mutantes no Contexto do Teste de Mutação”. Dissertação, 155 f. - Goiânia,  Universidade Federal de Goiás, Instituto de Informática.   A. Oliveira, C. Camilo-Junior e A. Vincenzi (2013a) “Um Algoritmo Genético  Coevolucionário com Classificação Genética Controlada aplicado ao Teste de  Mutação”. Congresso Brasileiro de Software: Teoria e Prática (CBSoft).   A. Oliveira, C. Camilo-Junior and Vincenzi (2013b) “A Coevolutionary Algorithm to  Automatic Test Case Selection and Mutant in Mutation Testing”. In: IEEE Congress  on Evolutionary Computation (CEC).    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     168   Análise de Acessibilidade Aplicada ao Website da  Universidade Federal de Santa Maria   Janaína Gomes1, Paulo Henrique Vianna1, Diego Carvalho1, Sara Spolti Pazuch1,  Aline Lorini1, Diego Carvalho1, Rubia Steffens1    1Centro de Educação Superior Norte - RS – Universidade Federal do Santa Maria  (UFSM)   Frederico Westphalen – RS – Brazil  jgomes.fw@gmail.com, {paulo.vianna, dcardiego, sara.pazuch}@ufsm.br, alilorini@yahoo.com.br, bia steffens@hotmail.com   Abstract. This paper presents an evaluation of accessibility for persons with  visual disabilities on the main page from the website of the Federal University  of Santa Maria (UFSM). This is an exploratory study that uses accessibility  protocols from the Federal Government to compare the old and the new  versions of that website. Advances were observed, but programming of the  new UFSM website is not planned and executed so that a blind person can  use. Programmers still use inaccessible resources to a person with visual  disabilities without presenting solutions capable of promoting autonomy and  consequently empowering users.   Resumo: Este artigo apresenta uma avaliação de acessibilidade para pessoas  com deficiência visual presente na página principal do portal da Universidade  Federal de Santa Maria (UFSM). Trata-se de estudo exploratório que utiliza  os protocolos de acessibilidade do Governo Federal para comparar a versão  antiga e a nova do referido portal. Foram contatados avanços, mas a  programação do website novo da UFSM ainda não é planejada e executada  para que uma pessoa cega possa utilizar. Programadores ainda utilizam  recursos inacessíveis para uma pessoa com deficiência visual sem apresentar  as soluções disponíveis capazes de promover autonomia e consequentemente  empoderamento dos usuários.    1. Introdução  A abordagem referente ao conceito de deficiência evoluiu nas últimas décadas. Segundo  a Classificação Internacional de Funcionalidade, Incapacidade e Saúde (CIF, 2004),  divulgada pela Organização Mundial da Saúde - OMS (World Health Organization -  WHO), entende a incapacidade como um resultado tanto da limitação das funções e  estruturas do corpo quanto da influência de fatores pessoais e ambientais sobre essa  limitação. O presente trabalho considera essa abordagem quando define como públicoalvo do mesmo são alunos com deficiência visual da Universidade Federal de Santa  Maria que utilizam o website para sua interação com a instituição.    De acordo com o Censo – 2010, 35.744.392 milhões de pessoas no país se  declaram deficientes visuais, sendo em torno de 18% da população total brasileira  (IBGE, 2010). Esses dados do Censo referem-se a todas as pessoas que possuem algum  tipo de dificuldade de visão, independente do seu grau. Nesse contexto, estudos sobre  acessibilidade em mídias digitais tornam-se fundamentais, tendo em vista o desafio que  programadores, comunicadores e webdesigners têm para atender esse público.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     169   2. Referencial Teórico  Conforme a Lei Federal da Acessibilidade n° 10.098/2000 Capítulo VII art. 17 é  responsabilidade do Poder Público promover a eliminação de barreiras na comunicação,  além de criar alternativas para que os sistemas de comunicação e sinalização sejam  acessíveis às pessoas com algum tipo de dificuldade, garantindo-lhes o direito ao acesso  à informação, educação, transporte, trabalho, comunicação, cultura, esporte e lazer  (BRASIL, 2000). Além da Lei Federal há a Portaria nº 3/2007 que institucionaliza o  Modelo de Acessibilidade em Governo Eletrônico – e-MAG, este consiste em um  conjunto de recomendações para tornar os portais governamentais acessíveis a todos os  cidadãos (BRASIL, 2007).     No que tange ao objeto de estudo deste artigo, é necessário considerar os  preceitos indicativos das práticas em comunicação pública para promover a cidadania e  a cidadania digital, pois permeiam a comunicação que ocorre entre a universidade e  seus públicos, no nosso caso específico, os alunos da Universidade Federal de Santa  Maria, com deficiência visual. A comunicação pública só ocorre quando há um discurso  que facilite o entendimento frente ao assunto em questão. Matos (2012, p. 45), afirma  que “a comunicação pública deve ser pensada como um processo político de interação  no qual prevalecem a expressão, a interpretação e o diálogo”, tornando-se instrumento  fundamental na construção da cidadania. O indivíduo só se torna cidadão no momento  que passa a participar ativamente da sociedade em que vive, construindo e fazendo parte  da história em busca de um interesse em comum com todos. Segundo Scheer (1997,  apud BRITO, 2006, p. 118 e 119) “o cidadão só é reconhecido na sociedade à medida  que participa da sua história, que possua interesse e relação com a política e com os dela  falam, com orientação para um destino comum”.    Assim, é importante que o cidadão tenha a oportunidade de debater sobre seu  futuro na sociedade, criando espaços de comunicação que construam o conhecimento e  a interação com o Estado. Covre (1993, p. 66), traduz de forma clara o objetivo dessa  relação: “é preciso criar espaços para reivindicar os direitos, mas é preciso também  estender o conhecimento a todos, para que saibam da possibilidade de reivindicar”.   Dessa forma, observou-se a necessidade de criar um grupo de pesquisa dedicado  a monitorar a comunicação pública veiculada pela Universidade de Santa Maria nas  mídias digitais. O grupo “Acessibilidade e usabilidade em mídias digitais: um estudo  sobre o relacionamento entre a UFSM e os acadêmicos com deficiência visual”, vem,  desde 2013 aplicando os parâmetros de acessibilidade e usabilidade das páginas da  UFSM indispensáveis para a permanência dos alunos com deficiência visual.   A avaliação da acessibilidade em websites para garantir o acesso e a participação  das pessoas com deficiência visual pautam as pesquisas interessadas no avanço do  design e da programação na web na perspectiva da inclusão (CUSIN, VIDOTTI, 2009;  BACH, FERREIRA, SILVEIRA, 2009; TANGARIFE, MONT'ALVÃO, 2005; MELO,  2007; MELO, BARANAUSKAS, BONILHA, 2004). Além de seguir os preceitos  legais, tais estudos apontam para um ambiente informacional “capaz de expandir as  questões técnicas e realçar a necessidade de considerar a acessibilidade do ponto de  vista do desenvolvedor web e do usuário” (CUSIN, VIDOTTI, 2009, p. 233).       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     170   3. Metodologia   O presente trabalho é um estudo exploratório, de natureza qualitativa, que pretende  fornecer uma análise de acessibilidade da página principal do Website UFSM, e realizar  uma comparação entre esta seção do antigo site e do novo, veiculado até 2014/1, para  monitorar as modificações que foram feitas na nova versão, para compreender como  funciona esse modelo e se possui acessibilidade em sua execução. Para isso, o estudo  contou com a consultoria da aluna com deficiência visual do Curso de Jornalismo da  UFSM – Campus Frederico Westphalen, Rubia Steffens, que auxiliou na avaliação,  efetuando a navegação com o Leitor de Tela Non Visual Desktop Access (NVDA), o  qual tem domínio e experiência de uso.    Para a avaliação das duas versões do Website da UFSM utilizamos o Modelo de  Acessibilidade em Governo Eletrônico - e-MAG (BRASIL, 2013) e o Checklist de  Acessibilidade Manual para Deficientes Visuais (BRASIL, 2010). O checklist é uma  lista de perguntas que são formuladas considerando o formato que links, atalhos de  teclado e outros recursos de programação estão dispostos em um site. Para responder às  perguntas é necessário analisar cada parte de uma página. É um protocolo fácil de ser  utilizado, apesar de conter alguns termos técnicos de programação que podem ser  esclarecidos com pesquisa e auxílio de um profissional. No caso deste trabalho, a equipe  conta com a consultoria de um Analista de Sistemas que colabora para o  desenvolvimento do trabalho e a aplicação do questionário na página, possibilitando a  compreensão total dos itens listados no checklist.    4. Resultados  Com a realização dos procedimentos metodológicos descritos anteriormente obteve-se  dados comparativos ligados a acessibilidade aplicada no portal da Universidade Federal  de Santa Maria. Estes dados demonstram os níveis de acessibilidade apresentados pelo  website antigo, e seu sucessor.   Para uma melhor visualização destes dados resultantes das análises,  desenvolvemos uma tabela (Tabela 1), que deve considerar os indicadores apresentados  abaixo:  ● 0: Não apresenta Acessibilidade;  ● 1: Apresenta Acessibilidade parcial;  ● 2: Apresenta Acessibilidade.          Tabela 1. Resultados Análise Acessibilidade Website UFSM    Site Antigo Site Novo   Links para outras páginas 0 1   Navegação com o Teclado 0 1   Localização em um Conjunto de Páginas 0 0   Imagens/Gráficos 0 0   Verborragia (Informação sem Importância) 0 2     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     171   Textos Gerais 1 2   Conteúdo em Flash 0 0   Arquivos para Leitura ou Download 1 1   Tabelas (Apresentação de Dados) 2 2   Formulários (Inserção e Pesquisa de Dados) 2 2   Padronização da Estrutura 0 0   Menus de Navegação 0 0   Mapa do Site (Auxilio a Localização) 0 0   Tabulação e Organização de Dados 0 1   Recursos para Baixa Visão 2 2   Disposição do Conteúdo 1 2      Analisando a tabela 1, podemos observar que mesmo com o desenvolvimento de  uma nova página principal da instituição, não foram solucionados todos os problemas  relacionados com a acessibilidade. Mesmo apresentando uma melhora em alguns  pontos, a página principal do website da UFSM não oferece uma boa experiência para o  usuário com deficiência.    Nesse contexto, foram realizados estudos no sentido de apresentar quais ações  poderiam ser realizadas durante o desenvolvimento da página principal do website da  UFSM para torná-lo mais acessível. Com a utilização do checklist de acessibilidade  (BRASIL, 2010) para desenvolvedores do e-MAG (BRASIL, 2013) para a orientação,  foi possível encontrar soluções técnicas para os problemas encontrados. Todas as  soluções se utilizam somente de tecnologias de desenvolvimento web abertas, tais  como:  ● HTML (MACEDO, 2004): É uma linguagem de marcação que descreve a   estrutura, o conteúdo e a apresentação de um documento e sua relação com outros  documentos.    ● CSS (MACEDO, 2004): É um padrão de formatação para documentos HTML,  basicamente o CSS permite ao designer um controle maior sobre os atributos  tipográficos de um site, como tamanho e cor das fontes, espaçamento entre linhas  e caracteres, margem do texto, entre outros. Introduziu também a utilização de  layers (camadas).   ● Javascript (MACEDO, 2004): É uma linguagem de script  para o HTML. A sua  arquitetura baseada em objetos permite realizar uma ampla variedade de funções,  como validar dados de entradas de usuários, acrescentar elementos interativos e  efetuar cálculos matemáticos. A vantagem de usar javascript reside no fato de ele  ser executado no lado do cliente, ou seja, pelo navegador do usuário.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     172    Abaixo apresentamos a tabela 2, com a descrição de problemas encontrados no  site antigo e que seguem existindo no novo site da instituição, apresentando também a  possível solução do problema.   Tabela 2. Possíveis soluções para os problemas com acessibilidade encontrados  Problema Solução   Os submenus do menu principal não pode  ser acessado via teclado.   Esta incompatibilidade está sendo gerada  devido a função em Javascript que é  chamada para abrir o submenu. Isto pode  ser resolvido com a utilização de sublistas  para mapear os submenus, utilizando CSS e  refatorando o código Javascript para  compatibilizá-lo com as chamadas do  teclado.   Descrição de imagens e links nem sempre  são apresentadas, quando presentes são  muito pobres.   Inserção da propriedade 'alt' e descrição do  destino do link, na tag <img> da respectiva  imagem.   As páginas não possuem atalhos para o  teclado   Disponibilizar no topo das páginas, atalhos  para determinados locais do site via teclas  chave do teclado, Esta ligação entre teclado  e conteúdo específico pode ser realizada  com a utilização da propriedade 'accesskey',  nativa do HTML, combinadas com funções  Javascript que capturam eventos do teclado.   O Slide principal que possui imagens das  ultimas notícias do site é ignorado pelo  leitor de telas.   Alterar os códigos na linguagem Javascript  para que os mesmos não ocultem a  descrição das imagens após a realização dos  efeitos de transição dos slides.   Ao acessar as notícias da página principal,  na leitura de textos pelo leitor de tela, são  lidos dados que não fazem parte da notícia  como elementos contidos nas barras do topo  do site.   Isolar os textos a serem lidos através de tags  html como: <p> e <span>.   Arquivos são disponibilizados para  download apenas no formato PDF.   Os documentos devem ser disponibilizados  preferencialmente em HTML. Também  podem ser utilizados arquivos para  download no formato ODF, tomando-se os  cuidados para que sejam acessíveis. Se um  arquivo for disponibilizado em PDF, deverá  ser fornecida uma alternativa em HTML ou  ODF. É necessário, também, informar a  extensão e o tamanho do arquivo no próprio  texto do link.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     173   O portal não possui um 'Mapa do Site'. Deverá ser fornecido um mapa do sítio para  sítios que contenham páginas internas que  não estão presentes no menu. O mapa do  sítio deve ser disponibilizado em forma de  lista, podendo conter quantos níveis forem  necessários.     5. Conclusão    Ao final deste processo de pesquisa pode-se enxergar com clareza a importância da  acessibilidade na web. A mesma se trata de uma plataforma aberta e livre, em que  qualquer cidadão tem o direito de utilização, isso incorre diretamente na importância da  apresentação de um conteúdo que possa ser acessado e utilizado por pessoas com  necessidades especiais.    Juntamente com a evolução da internet são apresentadas novas soluções e  ferramentas para propiciar uma maior acessibilidade ao conteúdo disponível, porém, é  necessário que os desenvolvedores fiquem atentos a elas, tornando o desenvolvimento  de elementos acessíveis uma etapa corriqueira no desenvolvimento para web. Este  conceito deve ser absorvido e incorporado tanto pelas empresas de desenvolvimento  quanto pelas instituições públicas, que ainda estão longe de um padrão ideal, como  demonstrado no presente trabalho.    Soluções simples quando incorporadas da maneira correta em páginas web,  podem fazer toda a diferença no que diz respeito a inclusão digital, fortalecendo a  internet e propiciando um ambiente digital com mais igualdade.   7. Referências Bibliográficas     CUSIN, C. A.; VIDOTTI, S. A. B. G. Acessibilidade em ambientes informacionais  digitais. Revista de Sistemas de Información y Documentación, Vol. 3, 2009.  Disponível em: http://www.ibersid.eu/ojs/index.php/ibersid/article/viewArticle/3744 .  Acesso em: out., 2014.   BACH, C. F. Avaliação de acessibilidade na web: estudo comparativo entre  métodos de avaliação com a participação de deficientes visuais. Dissertação  (Mestrado) Universidade Federal do Rio de Janeiro, Programa de Pós-graduação em  Informática, 2009. Disponível em: http://livros01.livrosgratis.com.br/cp132146.pdf.  Acesso em: out., 2014.   BRASIL, Presidência da República. (2007) Lei no 10.098. Disponível em:  http://www.planalto.gov.br/ccivil_03/leis/l10098.htm. Acesso em: set., 2014.   BRASIL, Ministério do Planejamento, Orçamento e Gestão. (2007) Portaria no 3 de 07  de maio de 2007: Modelo de Acessibilidade em Governo Eletrônico (e-MAG).  Disponível em: http://www.governoeletronico.gov.br/o-gov.br/legislacao/portaria-no03-de-07-de-maio-de-2007. Acesso em: set., 2014.    BRASIL Ministério do Planejamento, Orçamento e Gestão. Secretaria de Logística e  Tecnologia da Informação. (2010) Checklist de Acessibilidade Manual para Deficientes     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 168-174  Nov/2014     174   Visuais. Disponível em:  http://www.governoeletronico.gov.br/biblioteca/arquivos/checklist-manual-deacessibilidade-deficientes-visuais. Acesso em: set., 2014.   BRASIL, Ministério do Planejamento, Orçamento e Gestão. Secretaria de Logística e  Tecnologia da Informação. (2013) eMAG Modelo de Acessibilidade em Governo  Eletrônico. Brasília : MP, SLTI, 2014. 92 p.: color.  BRITO, J. A. P. (2006) Cibercidadania: a virtualização na Comunicação Pública  Contemporânea. Disponível em:  http://revistaorganicom.org.br/sistema/index.php/organicom/issue/view/4. Acesso em:  ago.  de 2014.  CIF (2004) - Disponível em http://www.inr.pt/uploads/docs/cif/CIF_port_%202004.pdf  -Acesso em: set., 2014.  COVRE, M. de L. M. (1993). O que é cidadania. 2. ed. São Paulo: Brasiliense.   IBGE – Instituto Brasileiro de Geografia e Estatística. (2010) Censo Demográfico.   Disponível em:   ftp://ftp.ibge.gov.br/Censos/Censo_Demografico_2010/Caracteristicas_Gerais_Religiao _Deficiencia/tab1_3.pdf . Acesso em: set., 2014.   MACEDO, M. S. (2004). Construindo Sites Adotando Padrões Web. Rio de Janeiro:  Ciência Moderna.   MATOS, H. (2012) Comunicação Pública: interlocuções, interlocutores e  perspectivas. São Paulo: ECA/USP.   MELO, A.  M. Design inclusivo de sistemas de informação na Web. Tese (doutorado)  Universidade Estadual de Campinas, Instituto de Computação, 2007.    MELO, A. M.; BARANAUSKAS, M. C. C.; BONILHA, F. F. G. Avaliação de  acessibilidade na Web com a participação do usuário: um estudo de caso. Anais do VI  Simpósio sobre Fatores Humanos em Sistema Computacionais, Curitiba, p. 17-20,  2004.   TANGARIFE, T; MO.T'ALVÃO, C. Estudo comparativo utilizando uma ferramenta de  avaliação de acessibilidade para web. In: Proceedings of the 2005 Latin American  conference on Human-computer interaction. ACM, 2005. p. 313-318.            
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     175   Criação de material educativo no formato ePub utilizando um  processo adaptado de Engenharia de Software   Kássia L. Souza1, Deivid S. Silva1, Vanessa O. Silva1, Ane Priscila Santos1, Marla T.  B. Geller2   1 Bolsistas PROICT Curso de Sistemas de Informação – Centro Universitário Luterano de  Santarém (CEULS/ULBRA) Santarém – PA – Brasil    2 Curso de Sistemas de Informação – Centro Universitário Luterano de Santarém  (CEULS/ULBRA) Santarém – PA – Brasil – Orientadora do projeto.   kassiia.souza@gmail.com, deivid.eive@gmail.com,  vanessaperola19@gmail.com, anepriscilasantos@gmail.com   Abstract. This paper proposes the development of e-book using the Software  Engineering principles. The educational software development is a process  that requires attention to mechanisms teaching and learning that form the  basis of any instrument of teaching and learning. For development of software  of this nature, it is necessary to use a suitable procedure development. So, the  P@PSEduc - Agile Process for Software Development, is used to guide the  educational digital material development in ePub format titled "A culpa é da  mãe d’água". The theme of the work is the study of "tidal bore" phenomenon to  be presented in a playful and interactive resources for users. The research also  explores some points as the process's adaptation of software development,  digital materials and implementation resources, and presents the planning and  modeling e-book stages.   Resumo. Este trabalho propõe o desenvolvimento de e-book utilizando os  princípios da Engenharia de Software. O desenvolvimento de software  educativo é um processo que exige atenção aos mecanismos pedagógicos e  didáticos que constituem a base de todo o instrumento de ensinoaprendizagem. Para a elaboração de um software dessa natureza, é  necessário o uso de um processo de desenvolvimento adequado. Portanto, o  P@PSEduc – Processo Agil para Software Educativo, é utilizado para  orientar o desenvolvimento de um material educativo digital no formato ePub  intitulado “A culpa é da mãe d’água”. O tema do trabalho é o estudo do  fenômeno da “pororoca” que deve ser apresentado de forma lúdica e com  recursos de interatividade para os usuários. A pesquisa explora ainda alguns  pontos como a adaptação dos processos de desenvolvimento de software,  material digital e recursos para implementação, além de apresentar as fases  de planejamento e modelagem do e-book.   1.Introdução  Diversos modelos de processos orientam o desenvolvimento de software e já estão  definidos na literatura, como exemplo, o Modelo Cascata e o Processo Unificado.  Pressman (1995) classificou os processos de desenvolvimento de software em Modelos  Prescritivos e Metodologias Ágeis, onde os primeiros são os processos que definem um  arcabouço, com atividades, ações da engenharia de software, artefatos a serem  produzidos, estes são mais burocráticos e detalhados. E os classificados como Modelos  Ágeis que tem como principal característica o desenvolvimento iterativo e incremental,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     176   para atender as mudanças contínuas dos sistemas atuais. O que acontece, porém, no  mundo do desenvolvimento de sistemas, é o aumento da demanda por projetos com  características específicas como o desenvolvimento de software para pequenas  empresas, de software educativo, de jogos eletrônicos, entre outros. As especificidades  de cada um impõem uma busca por processos customizados que atendam ao contexto.    O desenvolvimento de software educativo, por sua vez exige cuidados adicionais  aqueles de um sistema comercial ou de um site web. É necessária atenção aos  mecanismos pedagógicos e didáticos, que constituem a base de todo o instrumento de  ensino e de aprendizagem. É preciso o envolvimento interdisciplinar de profissionais  como: psicólogos, professores, especialistas na área do conhecimento, técnicos da área  computacional, entre outros. As teorias de aprendizagem discutidas no meio  educacional devem repensar a forma de como estabelecer o elo entre o meio  (tecnologia) e o fim (aprendizado), para que o aluno não seja apenas um receptor de  informações, mas interaja de forma a construir seu conhecimento utilizando os recursos  tecnológicos. O livro digital ou e-book se apresenta como uma forma de dinamizar a  leitura facilitando a disseminação de conhecimento.  Segundo Silva (2014) “Uma  pessoa pode ler um livro em formato impresso; pode ler a versão digital do mesmo livro  em um e-reader, tablet, smartphone ou computador; pode ainda ouvir a mesma obra em  formato de áudio. O conteúdo será o mesmo, ainda que um ou outro detalhe escape em  cada uma das leituras”.    Desta forma, cresce a demanda por material educativo que possua estes  requisitos e, em consequência, a necessidade de metodologias e ferramentas que  possibilitem a construção deste tipo de material com qualidade. Os princípios da  engenharia de software disponibilizam um arcabouço de processo para organizar as  atividades de desenvolvimento de software de qualquer natureza. Com o objetivo de  atender estas exigências, optou-se por utilizar o Processo Ágil para Desenvolvimento de  Software Educativo – P@PSEduc, que foi adaptado para o contexto educacional e teve  origem em processos já consolidados como o Scrum, a Programação Extrema e o  Processo Unificado. O P@PSEduc será detalhado na seção II.    A proposta deste trabalho é apresentar um material educativo – e-book,  intitulado “A culpa é da mãe d’água”, que explica o fenômeno da pororoca de forma  lúdica e atraente. A produção do livro digital é guiada pelas fases do P@PSEduc, que  orienta uma equipe de desenvolvimento interdisciplinar necessária para o contexto deste  trabalho.    Este artigo está organizado em seções, onde após esta introdução encontra-se a  segunda seção que apresenta adaptação do processo de desenvolvimento para softwares  educativos. Na seção três são apresentados os materiais digitais e recursos para  implementação do e-book. A penúltima seção trata do desenvolvimento do produto, e  finaliza com a conclusão e trabalhos futuros.   2. Adaptação do Processo de Desenvolvimento  Há uma grande diversidade de processos de desenvolvimento de software existentes que  são definidos e detalhados na literatura. Porém, o que se pode constatar é que a partir de  um arcabouço de processo, há sempre necessidade de adaptações para adequação ao  contexto e às características das equipes de desenvolvimento, pois quando o processo é  muito definido e específico torna-se engessado para as subjetividades inerentes ao  próprio sistema, ao desenvolvedor e as características da organização. Com o objetivo  de adequar um processo que auxilie equipes pequenas, com pouca experiência e para o     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     177   desenvolvimento direcionado para produção de material educativo foi criado o  P@PSEduc – Processo Ágil para Software Educativo que mesclou as características das  metodologias ágeis com um processo prescritivo como descrito em 2.1. Este é o  processo utilizado para orientar o desenvolvimento do produto deste trabalho.    2.1 P@PSEduc   O processo de desenvolvimento de software utilizado para o sistema proposto é o  resultado da customização de processos existentes e teve como origem os processos  SCRUM, XP (Programação Extrema) e o Processo Unificado, resultando no P@PSEduc  – Processo Ágil para Software Educativo.    A metodologia Scrum compartilha com XP a adoção das práticas de  desenvolvimento ágil de software. O foco do método Scrum é a flexibilidade,  adaptabilidade e a produtividade. A característica forte deste modelo é a visibilidade da  gestão do projeto, o que possibilita à equipe melhor controle de prazos. A metodologia  XP, por sua vez, é um meio ágil para equipes menores de desenvolvedores (pequenas e  médias empresas) que projetam software com requisitos vagos ou que estão em  constantes mudanças. A XP possui práticas que são aplicadas a qualquer outro processo  e que agregam valor à equipe de desenvolvimento. Entre estas práticas estão:  programação em pares, cliente presente, reuniões breves, testes frequentes, refatoração  do código, integração contínua, semanas de 40 horas [Beck 2004]. Portanto, esses  modelos de processos ao invés de preverem o que pode acontecer no futuro, adaptam-se  às mudanças, baseando-se em situações concretas, que realmente acontecem com os  sistemas, [Geller 2007].   Para organizar melhor a combinação das metodologias ágeis citadas,  considerou-se importante adicionar características do Processo Unificado que trouxe ao  P@PSEduc a segurança da prescrição, mostrando à equipe o que fazer (definindo  artefatos) e quando fazer (definindo uma sequência de passos).    Para desenvolver softwares educativos existe a necessidade de entender o  público, a fim de que se possa fazer uma aplicação que auxilie no seu ensino e  aprendizado, sendo então, útil e benéfica ao aluno. Deste modo, o P@PSEduc torna-se  um modelo colaborativo entre a área tecnológica e a psicopedagógica, constituída de  quatro etapas: planejamento, modelagem, desenvolvimento e encerramento (Figura 1).     O início do processo passa pela Fase de Planejamento, onde é preciso uma  contribuição eficiente do professor, do pedagogo, do orientador educacional, ou  qualquer profissional ligado à área da educação. É preciso definir o tema, considerar as  aplicações existentes e os recursos disponíveis. Se houver muitos requisitos a serem  atendidos, deve-se dividí-los em módulos, ou seja, priorizar os requisitos mais  importantes, e desenvolvê-los de uma forma incremental.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     178     Figura 1. Diagrama de Atividades do P@PSEduc    O Produto Total é o principal artefato desta fase e representa a especificação de  todo o produto a ser desenvolvido. Ao priorizar um requisito ou módulo do software a  ser desenvolvido, passa-se para a Fase de Modelagem que tem o objetivo de facilitar a  compreensão, discussão e aprovação do sistema antes de começar a construí-lo. Uma  aplicação hipermídia, como no caso da maioria dos softwares educativos, inclui a  criação de três modelos: Modelo conceitual, que apresenta o conteúdo da aplicação;  modelo navegacional, que define quais os caminhos permitidos entre todos os nós, para  que o conteúdo seja apresentado de forma correta; e modelo de interface, que deve estar  de acordo com o conteúdo, devendo seguir, portanto, o modelo conceitual e o modelo  navegacional. A próxima fase é a Fase de Desenvolvimento, onde serão criadas,  organizadas, integradas e avaliadas as mídias, códigos e os demais recursos disponíveis  para a criação do e-book. Finaliza-se com a Fase de Encerramento, que objetiva a  conclusão do módulo para que o próximo se inicie. Quando todos os módulos ou  requisitos estiverem concluídos e o produto apresentar todas as funcionalidades  necessárias para atender ao seu objetivo, faz-se a entrega e distribuição do produto.   3. Material digital e recursos para implementação  Com a disseminação dos aparelhos eletrônicos como tablets, smartphones,  computadores, além dos chamados eReaders, crescem as possibilidades de uso da  tecnologia como auxiliar no processo de ensino e aprendizagem. A tecnologia permite  criar material digital como os e-books (livros eletrônicos), que representam a evolução  do livro impresso, pois oferecem peculiaridades como: facilidade de interação entre  usuários, mobilidade, capacidade de armazenamento, leitura facilitada, entre outras  vantagens. Conforme Itzkovitch (2013) os e-books desenvolvidos com a tecnologia  ePUB3 podem integrar facilmente áudio, vídeo e interatividade, oferecendo ao leitor  uma difusão de conteúdos em um novo paradigma de leitura.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     179   3.1 Epub 3  O ePUB, abreviação de Electronic Publication ou Publicação Eletrônica, é um padrão  aberto gratuito usado pelo Fórum Internacional de Publicação Digital. Seu conteúdo é  adaptável e flexível podendo ser aberto em vários aplicativos e dispositivos de leitura,  sendo esta sua principal característica, além de vantagens como acessibilidade e  recursos de interatividade. A proposta deste formato é ser utilizado em qualquer tipo de  publicação digital, não somente em e-books, [Garrish 2011].    O ePUB3 é a nova versão do formato adotado como padrão, que traz  potencialidades interativas à publicação digital e está disponível no mercado desde  outubro de 2011, tendo como base as linguagens web CSS3 e (X)HTML5,  possibilitando assim o uso de recursos midiáticos sem os problemas decorrentes de sua  versão anterior.  O formato é um dos frutos da Open Web Plataform, formada por  tecnologias, serviços e formatos que orbitam ao redor do HTML5, permitindo soluções  que dão uma nova vida ao conteúdo: plasticidade, organicidade, modularidade,  interatividade e ubiquidade, [Flatschart 2013].    A grande vantagem nesta versão é o suporte a áudio e vídeo, algo possível  também no ePUB2, entretanto, com constantes travamentos e problemas de exibição.  Além disso, possui um mediaquery, que ajusta o conteúdo para designs opostos quando  visualizado em diferentes leitores.   4. Desenvolvimento do produto   Como já descrito anteriormente, o P@PSEduc é o processo que orienta a criação do ebook “A culpa é da mãe d’água”, produto deste trabalho. A seguir são apresentadas as  fases do processo com os artefatos criados.   4.1. Planejamento  Nesta fase é preciso considerar o produto a ser desenvolvido, definir os objetivos da  aprendizagem e requisitos do software, além de definir o escopo e o público alvo,  [Benitti 2005].    4.1.1 Tema, objetivo e público alvo  O primeiro passo foi definir o tema do produto – Fenômeno da Pororoca - realizado  com a contribuição de uma pedagoga, proporcionando assim uma visão mais  característica do usuário na área da educação. Em seguida, definiu-se que o objetivo é o  ensino deste fenômeno, sobre o que é e onde ocorre, a explicação geográfica e cultural e  os efeitos socioambientais do mesmo, de modo que os discentes do ensino médio  tenham à disposição um material lúdico que sirva de apoio no processo de ensino e  aprendizagem.    4.1.2. Recursos  Para tornar esse produto real foram identificados alguns recursos, dentre os quais, a  ferramenta livre Sigil 0.7.4 destacou-se por ser um software capaz de produzir e-books  no formato ePub, que suporta recursos midiáticos tornando o produto mais interativo. O  Sigil foi desenvolvido com o propósito de ser simples e de fácil uso, e está em constante  atualização aprimorando seus recursos. Como todo software ele também tem suas  limitações e problemas, porém, por ser aceito nos principais sistemas operacionais do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     180   mercado ele torna-se uma boa alternativa para desenvolvimento de livros digitais  simples e de qualidade, [Buse 2013].   4.1.3 Produto total  O produto idealizado é um e-book com o título “A culpa é da mãe d’água”, que trata de  forma didática sobre a temática ambiental do Fenômeno da Pororoca. O material será  produzido em formato ePUB possibilitando a disponibilidade em diferentes dispositivos  como celulares, tablets, e-readers e computadores, para que os alunos, independente de  sua plataforma, possam ter acesso ao e-book.    4.1.4 Requisitos do produto total  O processo P@PSEduc possibilita o desenvolvimento do produto de forma iterativa, ou  seja, pode-se priorizar requisitos, de forma a desenvolvê-los conforme um cronograma  pré-definido. A cada iteração do processo, novos requisitos vão sendo desenvolvidos e  integrados no Produto Total. Desta forma, foi definida uma sequência de requisitos: 1º  requisito: Capa; 2º requisito: Meta-dados; 3º requisito: Sumário; 4º requisito:  Introdução; 5º requisito: Capítulos com recursos midiáticos (áudio, imagem e vídeo), 6º  requisito: Referências.   4.2. Modelagem  Modelar um sistema é apresentá-lo de forma a facilitar a compreensão, discussão e  aprovação do sistema antes de começar a construí-lo.   4.2.1 Modelo conceitual  O e-book abordará o tema escolhido “Fenômeno da Pororoca” distribuindo-a em  capítulos que incluem: Sumário, Introdução, Meta-dados, A lenda, A Pororoca: como e  onde ocorre, Efeitos socioambientais e Referências. Cada capítulo será dividido em  tópicos, para facilitar o entendimento e a navegação pelo e-book, além de contar com  recursos de áudio, vídeo e imagem de modo a tornar a leitura agradável e interativa. Os  conteúdos abordados foram selecionados com o auxílio de uma pedagoga a fim de  contemplar os assuntos necessários para o entendimento de todos os tópicos.   4.2.2 Modelo navegacional   O modelo navegacional define quais caminhos podem ser acessados no e-book, qual a  ordem mais apropriada para que o conteúdo seja apresentado de forma correta,  organizando a informação para o usuário.    Em virtude do público alvo ser jovem, com maior poder de escolha sobre o que  precisam conhecer do fenômeno, a navegação pelo e-book permite que os tópicos sejam  acessados pelo sumário, possibilitando ao leitor uma leitura de livre escolha.    4.2.3 Modelo de interface   Esta fase deve estar de acordo com o conteúdo a ser abordado no e-book, seguindo os  passos definidos anteriormente pelos modelos: conceitual e navegacional, criando a  identidade visual do produto.     As interfaces, que darão vida ao e-book, abordarão de maneira didática sobre o  fenômeno da pororoca. A capa é a primeira interface a ser produzida e deve ser atrativa  aos olhos do leitor a fim de desencadear a leitura, seguida da interface dos meta-dados,  onde são inseridas informações sobre os autores do e-book, ano de publicação e editor.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     181   O sumário reproduzirá a estrutura e organização do conteúdo ao longo do livro. A  introdução fará uma abordagem global sobre a temática, facilitando o entendimento  para entrada nos capítulos, que serão otimizados pela utilização de recursos midiáticos  como áudio, imagem e vídeos. Por fim a interface das referências, construída para  disponibilizar as fontes de embasamento bibliográfico do conteúdo.     A capa do livro “A culpa é da mãe d’água” foi desenvolvida de forma que a  imagem possa ilustrar o fenômeno da pororoca, e em conjunto com o título despertem o  interesse e curiosidade do leitor em descobrir o que o livro reserva. O título faz  referência à lenda da pororoca, que segundo o folclore da região explica o surgimento  deste fenômeno amazônico (Figura 2).       Figura 2. Modelo de interface da capa do livro   5. Conclusão e trabalhos futuros  O desenvolvimento do produto com fins educacionais tornou-se simples e eficaz,  seguindo as fases do P@PSEduc para a sua elaboração. Vale lembrar que, para a  construção de um material desta natureza, é primordial a participação de profissionais  da educação em parceria com a área de TI (tecnologia da informação) de modo que o  produto seja desenvolvido com características que permitam a interação aluno -  software educativo - professor.       O P@PSEduc, nesse contexto,  foi escolhido para orientar o projeto de  construção do livro digital sobre o fenômeno natural da pororoca, denominado “A culpa  é da mãe d’água”. O processo inicialmente criado para desenvolvimento de software  educativo atendeu de forma eficiente o desenvolvimento do e-book. A importância de se  ter produtos educacionais digitais de qualidade exige a presença de princípios da  engenharia de software de forma a garantir bons resultados. Desenvolver através de um  processo adequado faz esta tarefa mais simples.   O produto está em fase de planejamento e modelagem e pretende-se dar  continuidade ao projeto finalizando o e-book para que possa ser divulgado e  disponibilizado. O feedback dos usuários será uma contribuição para que novos e-books  interessantes possam ser criados com qualidade, abordando outros conteúdos  relacionados à fenômenos e características naturais da Região Norte do Brasil, como  Encontro das Águas, Fenômeno das Cheias, características dos diferentes rios da Bacia  Amazônica, dentre outros.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 175-182  Nov/2014     182   6. Referências  Beck, K. Programação Extrema Explicada – XP Bookman Companhia, 2004.   Benitti, F. B. V. Processo de Desenvolvimento de Software Educacional: proposta e  experimentação. Novas Tecnologias na Educação V. 3 Nº 1, Maio, 2005.   Flatschart, Paulo.  ePUB3: publicações multimídia interativas. Disponível em:  <http://imasters.com.br/frontend/web-standards/epub3 publicacoes-multimidiainterativa>. Acesso em: 17 dez. 2013.   Garrish, Matt.What is EPUB 3?.Sebastopol: O’Reilly, 2011.   Geller, M. et al. “GTA - Grupo de Trabalho Ágil – Desenvolvimento Ágil de Software  Através da Customização de Processos”. In Anais do SIGE 2007, pág. 64 a 72, 2007.   Itzkovitch, Avi. How Interactive Ebooks Engage Readers And Enhance Learning. UX  Magazine, Nova York, abr. 2012. <http://mashable.com/2012/04/13/interactiveebook-apps/>. Acesso em: 17 out. 2013.   Pressman, Roger S. Engenharia de Software. 3ª. Ed.São Paulo:MacGraw Hill, 1995.   Silva, Ronaldo Alves da. E-books em bibliotecas: novos desafios para os bibliotecários.  Anais do CBBD: Florianópolis – SC. v.25(2013). Disponível em:  <http://portal.febab.org.br/anais/article/view/1398>. Acesso em: 21 Mai. 2014.   BUSE, Jarret W. Epub from the Ground Up: A Hands-on Guide to EPUB 2. New York:  McGraw-Hill, 2013.           
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     183   Um Modelo de Sistema de Detecção de Anomalias em  Redes de Computadores Baseado na Extração de   Características Dinâmicas   Marcelo Antonio Righi¹, Raul Ceretta Nunes¹   ¹Programa de Pós-Graduação em Informática – CT – UFSM   Av. Roraima, 1000, B. Camobi – Santa Maria (RS) – Brasil   marcelo.righi@bol.com.br, ceretta@inf.ufsm.br   Resumo. A detecção de anomalias baseada em redes vem sendo muito  explorada atualmente devido aos inúmeros e persistentes ataques de negação  de serviço. Um ponto chave nesta exploração é a técnica para extração de  características utilizada para melhorar a eficiência da detecção de ataques.  Esse artigo propõe um novo modelo de detecção de anomalia baseado numa  técnica de extração de características dinâmicas que utiliza quatro algoritmos  em conjunto: a Transformada Wavelet, a Recorrência, o K-Means e o J48. O  novo modelo delimita uma Zona Crítica com base num limiar (threshold)  derivado do algoritmo K-Means, permitindo uma melhor condição de  detecção de anomalias.   Palavras-Chave: Detecção de anomalias. Recorrência. K-Means. Árvore de  decisão.  Abstract.  Due to the increasing number of denial of service attacks, the  network anomaly detection has been current widely explored. A key point in  this exploration is the technique for traffic feature extraction that could to  improve the efficiency of detecting attacks. This paper proposes a new model  of anomaly detection based on a dynamic feature extraction technique that  uses a combination of four algorithms: Wavelet Transform, Recurrence, KMeans and J48. The new model defines a Critical Zone based on a threshold  from K-Means algorithm, allowing a better quality on detecting anomalies.  Keywords: Intrusion Anomaly detection. Recurrence. K-Means. Decision Tree.   1.  Introdução   Tradicionalmente, detectores de intrusão procuram por comportamentos maliciosos  utilizando técnicas baseadas em assinaturas ou anomalias [Mirkovic 2004]. A detecção  por assinatura compara o tráfego com uma base de dados de ataques previamente  conhecidos (assinaturas), enquanto a detecção por anomalias compara os dados  coletados com registros de atividades consideradas normais no sistema.       Em detectores baseados em anomalias, foco deste artigo, as características de rede  extraídas do tráfego podem ser estacionárias ou não, ou seja, não variam  expressivamente em um determinado período de tempo ou podem oscilar bastante em  outro. As características não estacionárias indicam que a observação de tráfego mostra  características dinâmicas não lineares, se consideradas a frequência e a recorrência  [Grossglauser 1999].   A Construção de novos modelos de extração e alerta, com  precisão de detecção e  baixa taxa de falsos alarmes,  necessita de um sistema de defesa em profundidade,  considerando várias camadas de segurança [Northcutt 2003].   Este artigo propõe um novo modelo chamado de Wavelet-Recorrência-ClusterÁrvore da Decisão (WRCA), para extração de características dinâmicas e detecção de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     184   anomalias de rede. As principais contribuições deste trabalho são: (1) um novo modelo  para calcular as características dinâmicas multi-escalares do tráfego da rede, utilizando a  transformada wavelet e análise de recorrência; (2) um modelo de pré-detecção de  anomalias (seleção de tráfego suspeito), com base nessas características dinâmicas e  utilizando a clusterização; e (3) um modelo de confirmação de anomalias, com base na  árvore da decisão (algoritmo J48).    O restante deste artigo está organizado da seguinte forma. Seção 2 apresenta  conceitos fundamentais para o entendimento do artigo. A Seção 3 apresenta a  abordagem proposta em detalhes para a implementação do modelo de WRCA. A Seção  4  apresenta detalhes de implementação para o sistema proposto. Na Seção 5 os  trabalhos relacionados e na Seção 6 apresenta-se a conclusão do artigo.   2. Conceitos fundamentais  2.1. Detecção de Intrusões de Rede Baseada em Anomalias  Detectores de intrusão baseados em anomalias procuram identificar comportamentos  anômalos no tráfego de rede, comparando-o com características de tráfego considerado  normal (sem ataque). A principal limitação é a ocorrência de alarmes falsos, dado que  nem toda atividade “não usual” (anormal) representa um ataque [Northcutt 2003].   2.2 Algumas Técnicas Utilizadas na Detecção de Anomalias de Rede   A. Transformada Wavelet Discreta  A Transformada Wavelet Discreta (TWD) é um método matemático de análise multiescalar  usada para verificar um sinal em diferentes níveis de resolução. A TWD pode  ser implementada através do algoritmo de Mallat [Burrus 1997], que utiliza um banco  de filtros digitais com blocos dizimadores acoplados em suas saídas filtradas para  decompor o sinal original. São utilizados dois tipos de filtros: um passa-baixa (L) e um  passa - alta (H). Os sinais provenientes da filtragem passa-baixa recebem o nome de  coeficientes de aproximação (cA), enquanto os sinais provenientes da filtragem passa -  alta recebem o nome de coeficientes de detalhes (cD).  B. Clusterização (K-Means)  O algoritmo K-Means [MacQueen 1967], também chamado de K-Médias, realiza o  agrupamento (clusterização) de informações de acordo com os próprios dados para  gerar as classes (Clusters) e classificar as ocorrências com base nos valores comparados  com seus limiares (threshold) e no cálculo da distância euclidiana. O algoritmo  identifica um centróide para cada classe.    C. Recorrência   A análise de recorrência [Graham 1995] é uma técnica matemática usada para definir  sequências, conjuntos, operações ou algoritmos, que generalizam situações a partir de  situações particulares (anteriores). A Recorrência [Eckmann 1987] tem surgido como  uma técnica de análise não-linear de sistemas dinâmicos. A análise de quantificação de  recorrência surgiu como forma de potencializar as avaliações, a partir do  desenvolvimento das medidas de quantificação de recorrência [Webber 1994].   D. Árvore de Decisão   Uma árvore de decisão é um instrumento de apoio à tomada de decisão que consiste  numa representação gráfica das alternativas disponíveis geradas a partir de uma decisão  inicial. Uma das grandes vantagens de uma árvore de decisão é a possibilidade de  transformação/decomposição de um problema complexo em diversos subproblemas  mais simples [Breiman 1984].     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     185   E. Threshold (limiar)  A técnica de limiarização (threshold) define os valores de limiares que permitem rotular  o tráfego de rede como padrão (normal) ou anômalo, sendo definidos valores de  threshold, que podem ser fixos [Gao 2006] ou dinâmicos [Kim 2008].   3.  Modelo Wavelet-Recorrência-Cluster-Árvore da Decisão (WRCA)  Nesta seção é apresentado o modelo de detecção de anomalias baseado na extração de  características dinâmicas denominado Wavelet-Recorrência-Cluster-Árvore da  Decisão (WRCA). A Figura 1 apresenta a arquitetura do modelo e as seções 3.1, 3.2 e  3.3 detalham seus módulos internos.   Figura 1. Arquitetura do Modelo WRCA   3.1. Módulo de Extração de Características Dinâmicas  O módulo de extração de características dinâmicas do WRCA é subdividido em três  fases. A primeira extrai as características pré-selecionadas: (i) Taxa de SYN, Taxa de  FIN/RST, Fluxo por minuto (S1), Média de Pacotes por minuto (S2), Média de Bytes  por fluxo (S3), Média de Bytes por pacote (S4) e a Média S1/S4 (S5), que serão usadas  no Módulo de identificação preliminar de anomalias; (ii) nove atributos para o  algoritmo J48 (psizeCL, psizeSV, pnumCL, pnumSV, smallpkt, dataDIR,  brecvCL, brecvSV, Duration), que só serão utilizadas no módulo de confirmação  de anomalias, caso necessário. A segunda fase aplica a transformada wavelet discreta  para selecionar o tráfego em diferentes frequências (L e H) (vide seção 4 Passo 1 e 2). A  terceira fase computa o cálculo da recorrência e executa a extração das características  dinâmicas (vide seção 3.1.1), tanto para o período de treinamento, com tráfego normal,  como para o período de análise (detecção).      3.1.1. Cálculo da Equação da Recorrência e das Características Dinâmicas  A.  Equação  da Recorrência (ER)   Segundo [Yuan 2014] e [Maia 2011], com base em uma série de tráfego x = {xi}, i = 1,  2, ..., n,  o estado do tráfego é expresso conforme Equação (1), sendo m a dimensão de  imersão, t o tempo de atraso e N = n - (m-1) τ.     NjmxjxjxjXj ,...,2,1],)1(,,[                                                  (1)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     186       Depois de calcular os estados de tráfego, utiliza-se a Equação (2) da Recorrência   para analisar os fenômenos de recorrência de cada um deles.    NjXjXiRij ...,2,1||),||(                                                     (2)  Na Equação (2), Rij é um elemento da matriz de recorrência, ε é o limiar, Xi é um   estado do sistema no espaço de fase m-dimensional, ∥ · ∥  norma, N é o número de  estados e Θ(·) é a função definida pela Equação (3).    0001)(    y yy                                                                              (3)   Se a distância entre os estados Xi e Xj é menor do que o limiar (ε), então o valor de  Rij é 1 e existe um ponto preto em (i, j) na equação de recorrência ER; caso contrário, o  valor de Rij é 0 e existe um ponto branco em (i, j).     B. Cálculo da Razão da Recorrência, Determinismo e Entropia  Para poder avaliar qualquer série de tráfego após a fase de treinamento as texturas da  estrutura ER são quantificadas através do cálculo da Razão de Recorrência (RR),  Determinismo (DET) e Entropia (ENT), como segue.   1) Razão de Recorrência (RR) - mede a densidade dos pontos de recorrência em ER.           RR=  R ji  N  jiN ,1,2 1        2) Determinismo (DET) – mede a relação entre os pontos de recorrência que formam as  estruturas de linhas diagonais em ER e todos os pontos de recorrência.         DET=       N  ji ji  N  ll  R llP  1, ,  min )(     3) Entropia de Shannon (ENT) - mede a distribuição de frequência dos comprimentos  das linhas diagonais.    ENT= )()( min  2 log lplp  N  ll                       p(l)=   N  ll lP  lP  min )(  )(    3.2. Módulo de Identificação Preliminar de Anomalias   O módulo de identificação preliminar de anomalias procura identificar anormalidades  no tráfego e indicar tráfegos suspeitos. Para tal, aplica-se o algoritmo K-Means [Yuan  2014] para realizar uma classificação e avalia-se se a maioria dos valores de K-Means  estão dentro do intervalo considerado como Zona Crítica (threshold = ( ) +/- 10% ).  Em paralelo, verifica-se as taxas de SYN/FIN.      O uso de uma margem de segurança (threshold (  ) +/- 10% ) delimita a Zona  Crítica e permite obter melhor eficiência na detecção, através de uma avaliação mais  acurada do tráfego limítrofe ao ( ). Em resumo, este módulo executa três atividades:   1) Classificação do tráfego pelo Algoritmo K-Means (suspeito ou não suspeito);  2) Verificação da Taxa SYN/FIN;  3) Verificação se os valores de K-Means ficam no intervalo:        %10)(%10  MeansKaloresMaioriadeV       Após análise e classificação do tráfego pelo algoritmo K-Means, é verificado o  comportamento da Taxa SYN/FIN e dos valores da classificação K-Means frente a  Zona Crítica delimitada. Havendo suspeitas, o tráfego será dirigido ao Módulo de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     187   Confirmação de Anomalias para avaliação pelo algoritmo J48 (confirmação ou não de  suspeito ou não suspeito) no Módulo de Confirmação de Anomalias. Caso contrário, se  não ocorrerem suspeitas nas atividades 2 ou 3 o tráfego classificado suspeito é  denominado ANÔMALO e o tráfego classificado não suspeito é denominado  NORMAL.        3.3.  Módulo de Confirmação de Anomalias  Esse módulo faz a verificação do tráfego que apresentou características de suspeito ou  não suspeito no Módulo de Identificação Preliminar de Anomalias (vide seção 3.2). Ele  tem a finalidade de gerar uma árvore de decisão baseada em um conjunto de dados de  treinamento, sendo usado para classificar as instâncias no conjunto de teste.    O Módulo adota o algoritmo J48, uma implementação em java do algoritmo C 4.5  [Quinlan 1993], que, segundo [Librelotto 2013], se mostra adequado para os  procedimentos envolvendo as variáveis (dados) qualitativas contínuas e discretas  presentes nas bases de dados e é é considerado o que apresenta o melhor resultado na  montagem de árvores de decisão a partir de um conjunto de dados de treinamento. Para  a montagem da árvore, o algoritmo J48 utiliza a abordagem de dividir-para-conquistar,  onde um problema  complexo  é  decomposto  em  subproblemas  mais  simples.   A aplicação do algoritmo J48 foi realizada considerando o banco de dados de  atributos construído por [Dos Santos 2011] (vide Tabela 1), sendo os atributos extraídos  no Módulo de Extração de Características Dinâmicas. Esta etapa do modelo WRCA só  é aplicada para confirmação, ou não, da suspeita no tráfego sob análise.   4. Implementação do Modelo de Detecção WRCA  A implementação do modelo ainda está em curso e utilizará dados de bases de tráfego,  tal como a da base DARPA 1999, bem como dados de coleta realizada na rede da  instituição.       Considerando os dados disponíveis, os experimentos estão planejados para comparar,  no Módulo de Identificação Preliminar de Anomalias, cinco estatísticas: Fluxo por  minuto (S1), Média de Pacotes por minuto (S2), Média de Bytes por fluxo (S3), Média  de Bytes por pacote (S4) e a Média S1/S4 (S5). Os dados de treinamento serão  confrontados com o fluxo corrente de tráfego.    Tabela 1. Atributos utilizados pelo classificador J48. Adaptado de [Dos Santos 2011]   Atributo Descrição  psizeCL (bytes) Tamanho médio dos pacotes recebidos pelo cliente.  psizeSV (bytes) Tamanho médio dos pacotes recebidos pelo servidor  pnumCL Número de pacotes recebidos pelo cliente  pnumSV Número de pacotes recebidos pelo servidor  Smallpkt Porcentagem de pacotes pequenos  dataDIR Direção do tráfego  brecvCL (bytes) Total de dados recebidos pelo cliente  brecvSV (bytes) Total de dados recebidos pelo servidor  Duration Diferença em segundos - último pacote e o primeiro         Caso o tráfego seja processado pelo Módulo de Confirmação de Anomalias, os  atributos indicados na Tabela 1 serão comparados pelo algoritmo J48, que deverá emitir  o resultado final de confirmação ou não do que foi pré-determinado pelo Algoritmo KMeans.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     188    A seguir o detalhamento dos passos do algoritmo resultante:   Entrada: séries  temporais  de  tráfego (cinco estatísticas)   nixix ,...,2,1},{  ,   Taxa  SYN/FIN e  Atributos segundo Tabela 1.                       Saída: tráfego normal ou anômalo   Passo 1: para uma série de tempo de tráfego x, empregar a transformada wavelet para  reconstruir a baixa freqüência L e a alta frequência H;   Passo 2: com base na janela deslizante, utilizar o método da Recorrência para calcular  as características de recorrência de diferentes séries de tráfego L e H, respectivamente;    wENTrDETrRRr NrfffFLrL ,...,2,1]},,,{[}{ ;;;    wENTrDETrRRr NrfffFHrH ,...,2,1]},,,{[}{ ;;;     onde r  é a r-enésima subsérie, wN  é o número de subsérie,  1     s w W  Wn N  .  Onde:  ]},{[}{ FHrFLrFx r     Passo 3: para cada série de tráfego (cinco estatísticas), repetir as etapas 1 e 2 e, em  seguida, combinar as características dinâmicas da série de cinco tráfegos juntos para  descrever os padrões de comportamento do tráfego, de acordo com a seguinte  expressão:                                              ]},,,,{[}{ 54321  rrrrr FFFFFXrX    Passo 4: usar o algoritmo K-Means para classificar cada rX  em diferentes grupos e  identificar o tráfego em suspeito ou não suspeito com base na regra de Limite  (Threshold).  Passo 5: verificar se a Taxa de SYN/FIN está alterada e se o tráfego está compreendido  na Zona Crítica.  Passo 6: Caso ocorra uma e outra condição do Passo 5, o tráfego é analisado pelo  algoritmo J48, no Módulo de Confirmação de Anomalias, com base nos nove atributos  (Tab. 1), extraídos no Módulo de extração de características dinâmicas e comparados  com [Dos Santos 2011].  Passo 7: Caso confirme tráfego suspeito, a saída será ANÔMALO, do contrário a saída  será NORMAL; caso confirme tráfego não suspeito, a saída será NORMAL, do  contrário a saída será ANÔMALO. Se não ocorrer ao menos uma condição do Passo 5,  o Módulo de Confirmação de Anomalias não será utilizado, os nove atributos serão  descartados e a saída será a mesma determinada pelo algoritmo K-Means (suspeitoANOMALO, Não suspeito-NORMAL).   5.  Trabalhos Relacionados  Em [Wang 2002] é proposta uma detecção usando a razão entre o número de pacotes  TCP SYN e o número de pacotes TCP FIN e RST, mostrando que o normal seria uma  relação perto de 1 em um período suficientemente longo, uma vez que a maioria das  sessões TCP começa com um SYN e termina com um  FIN.   Em [Grossglauser 1999] é sugerido que o tráfego de rede se expõe a  propriedades onipresentes de auto-similaridade e dependência de longa duração, ou  seja, de correlações em uma ampla gama de escalas de tempo, demonstrando a  Recorrência como técnica para detecção de anomalias.   A extração de características dinâmicas é primeiramente descrita em [Yuan  2014], que contribuiu de maneira fundamental para a detecção de anomalias, pois pode     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     189   ser utilizada independentemente do fluxo de rede estar elevado ou não no momento do  ataque.     A literatura sugere que a combinação de múltiplos classificadores pode melhorar a  acurácia da detecção, como demonstra [Chou 2009].   Uma contribuição importante deste trabalho é a delimitação de uma Zona Crítica  do threshold, que após a fase de testes pode produzir uma confiabilidade maior dos  limiares, construindo uma pré-identificação de anomalias e uma análise mais “refinada”  caso necessário, sem sobrecarregar o sistema e diminuindo os falsos alarmes. E,  também, a combinação de quatro algoritmos, de características dinâmicas e  estacionárias em diferentes profundidades ou níveis, melhorando a eficácia do sistema.   6.  Considerações finais  Este artigo relata uma abordagem nova na busca da redução do número de falsos  alarmes na detecção de intrusão em redes baseadas em anomalias, utilizando diversas  técnicas existentes de maneira híbrida, com a extração de características dinâmicas  combinadas de forma efetiva e qualitativa durante o tráfego em um determinado espaço  de tempo.   O Modelo WRCA mostra-se promissor na detecção de anomalias, pois se  caracteriza pela análise do tráfego em níveis de profundidade, que combinados podem  melhorar o desempenho dos sistemas atuais, fazendo uma verificação “grosseira” e  outra mais “refinada” sem sobrecarregar a memória, pois só utiliza a árvore da decisão  (J48) em caso de necessidade. Isto faz com que a maioria das requisições seja  determinada pelo algoritmo K-Means (verificação grosseira), sem a necessidade de uma  verificação mais profunda (árvore de decisão), só realizada se a combinação de fatores a  exigirem.   Referências  Breiman, L., Friedman, J. H., Osshen, R. A. (1984). Classification and regression   tress. Belmont: Cahpman&Hall.  Burrus, S.C.; Gopinath, R.A. and Guo (1997). H..Introduction to Wavelets and   Wavelet Transforms: A Primer. PrenticeHall.  Chou, T., Fan, J., Fan, S. and Makki, K. (2009). Ensemble of machine learning   algorithms for intrusion detection. In Systems, Man and Cybernetic, pages 3976-3980.  Dos Santos, Adriana (2011). Uma Metodologia para Caracterização do Tráfego de   Redes de Computadores: Uma Aplicação em Detecção de Anomalias. Disponível em:  sid.inpe.br/mtc-m19/2011/02.15.17.55-TDI.       Eckmann, J. P.; Kamphorst S. O.; Ruelle, D.(1987). Recurrence plots of dynamical  systems.Europhys. Lett., 56(5):973–977.   Gao, J.(2006) et al. Anomaly Detection of Network Traffic Based on Wavelet  Packet. In: Asia-pacific Conference on Communications. Proceedings.   Graham, Ronald J., Knuth, Donald E., Patashnik, Oren (1995). Matemática Concreta:  Funda-mentos para a Ciência da Computação. Rio de Janeiro. Livros Técnicos e  Científicos Editora.   Grossglauser, M.; Bolot, J. C. (1999). On the relevance of long-range dependence in  network traffic, IEEE/ACM Transactions on Networking, 7(5):629-640.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 183-190  Nov/2014     190   Kim, S. S.; Reddy, A. L. N.(2008). Statistical techniques for detecting traffic  anomalies through packet header data. IEEE/ACM Transaction on Networking,  Piscataway, NJ, USA: IEEE Press, v. 16, n. 3, p. 562-575.   Librelotto, S. R.; Mozzaquatro, P. M. (2013). Análise dos Algoritmos de Mineração  J48 e Apriori Aplicados na Detecção de Indicadores da Qualidade de Vida e Saúde.  Revista Interdisciplinar de Ensino, Pesquisa e Extensão (RevInt), v.1, n.1, pp.26-37.   MacQueen, J. B. (1967). “Some Methods for Classification and Analysis of  Multivariate Observations”, Em Proceedings of the Fifth Symposium on Math,  Statistics, and Probability, pp. 281–297.   Maia, Leonardo P.; Souza, Iberê O. K.(2011). Gráficos de Recorrência de Sistemas  Dinâmicos.  Disponível em: https://uspdigital.usp.br/siicusp/cdOnlineTrabalho  VisualizarResumo?numeroInscricaoTrabalho=60&numeroEdicao=19.   Mirkovic J., P. Reiher (2004). A taxonomy of DDoS attack and DDoS defense  mechan-    isms, ACM SIGCOMM Computer Communications Review 34 (2) 39.   Northcutt, S. (2003). Novak, J. Network Intrusion Detection – Ed. New Riders  Publishing.   Quinlan, J. R. (1993). C4.5: Programs for machine learning. Morgan Kaufmann  PublishersInc., San Francisco, CA, USA.   Wang H., D. Zhang, K.G. Shin (2002) Detecting SYN flooding attacks, in:  Proceedings of IEEE INFOCOM’2002, New York City, NY, pp. 1530–1539.   Webber, C. L.Recurrence Quantification Analysis, v. 13.1. June 2009. Software  Package disponível em: < http://homepages.luc.edu/~cwebber/> Acesso em 29 ago  2011.       Yuan J., R. Yuan, X. Chen. (2014). Network Anomaly Detection based on Multiscale Dynamic Characteristics of Traffic. INT J COMPUT COMMUN, ISSN 18419836, 9(1):101-112, February.          
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     191   Proposta Metodológica de um Ambiente de Ensino Ubíquo  Leo Natan Paschoal1, Patricia Mariotto Mozzaquatro1, Michele Ferraz Figueiró1   1 Universidade de Cruz Alta (UNICRUZ)  Campus Universitário Dr. Ulysses Guimarães - Rodovia Municipal Jacob Della Méa,   Km 5.6 - Parada Benito - CEP 98.020-290 - Cruz Alta – RS – Brazil  leonpaschoal@hotmail.com,{patriciamozzaquatro,mferrazfigueiro@}@gmail.  com   Abstract. The present article aims at doing a study about methods used for  construction of a new module to virtual environment of Moodle learning. This  module is going to implement an adaptation in which a mobile environment  will become ubiquitous. In it will be considered a use of computational  techniques for adaptation, based on scientific research of relevance in the  area. Modeling System was developed in order to verify the possibilities and  scope of this proposal.   Resumo. O presente artigo tem como objetivo realizar um estudo sobre  métodos utilizados para construção de um módulo ao ambiente virtual de  aprendizagem Moodle. Este módulo realizará uma adaptação, no qual um  ambiente móvel tornar-se-á ubíquo. Nele será considerada a utilização de três  técnicas computacionais para adaptação, baseando-se em pesquisa científicas  de relevância na área.  Foi desenvolvida a modelagem do Sistema a fim de  verificar as possibilidades e abrangência desta proposta.   1. Introdução   Atualmente os campos de pesquisa em computação ubíqua estão se tornando cada vez  mais relevantes. Esta área da ciência da computação é responsável por abordar as  maneiras de como tornar a computação onipresente. Mark Weiser (1991) é considerado  o primeiro pesquisador a abordar este tipo de assunto, o autor considerou que a  computação seria divida em três eras. A primeira é a dos mainframes, a segunda a dos  computadores pessoais, e a terceira a computação onipresente, na qual os computadores  estarão em todos os lugares e os usuários não perceberão sua presença. Autores como  Augustin (2004), Barbosa (2007), Gomes (2007), e Piovesan (2011) consideram em  suas pesquisas que a interação do usuário com o computador possui como objetivo a  realização de determinada tarefa, e não o dispositivo utilizado para a realização.  Baseando-se no contexto educacional estas considerações podem ser relevantes.    Os Ambientes Virtuais de Aprendizagem (AVAs) estão tornando-se cada vez  mais interativos. Os usuários possuem a disposição, no momento, à tecnologia mobile  learning, onde os materiais e atividades de uma disciplina a distância podem ser  acessados por meio de um dispositivo móvel (MOZZAQUATRO, 2010). No entanto,  existem muitos formatos de arquivos que não são suportados por alguns dispositivos  (FRANSCISCATO, 2010), o que faz com que o usuário acabe não utilizando este  recurso. Outro fator, é que muitos objetos digitais de aprendizagem exigem velocidade  alta de conectividade com a internet, para abrir ou fazer o download. Estes fatores  acabam muitas vezes afastando o usuário desta tecnologia.     Segundo a escrita de Barbosa (2007), deve haver em um ambiente virtual de  aprendizagem diversos formatos de arquivos, pois existem dispositivos móveis  heterogêneos. Neste raciocínio pode-se pensar nos estilos de aprendizagem, no quais,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     192   cada usuário do ensino eletrônico possui um estilo de aprendizagem. Mozzaquatro  (2010) propôs, em sua dissertação, a detecção do estilo de aprendizagem por meio de  diferentes dispositivos móveis. A pesquisadora enfatizou que o professor da disciplina  deve ofertar os materiais didáticos em diferentes formatos, pelo fato de que cada aluno  possui uma maneira de aprender e quando relacionado a ensino eletrônico, para alguns  alunos determinados formatos de arquivos de conteúdo, são melhores de se aprender do  que outros. Analisando estes dois contextos é possível enfatizar que o professor deve  ofertar diferentes formatos de conteúdos nos ambientes virtuais de aprendizagem.    Ainda existem nos ambientes virtuais problemas de distração ao usuário. Isto  ocorre às vezes por problemas ao redor do utilizador, objetos de aprendizagem que não  são executáveis no dispositivo de acesso do usuário, falhas na conectividade da internet,  entre outros fatores que atrapalham o usuário no estudo. Estes problemas de distrações  poderão ser finalizados com a utilização da computação ubíqua, segundo as pesquisas  de Barbosa (2007) e Piovesan (2011).    A autora Barbosa (2007), desenvolveu o modelo de educação ubíqua em sua tese  denominado GlobalEdu, que é uma infraestrutura de suporte a educação ubíqua,  utilizando agentes inteligentes e recursos de ontologia. Piovesan (2011) se deteve na  utilização da computação em nuvens para a adequação do ambiente a velocidade de  conexão do usuário. Observando estes cenários é possível perceber que a projeção,  adaptação e construção de ambientes ubíquos estão em constantes processos de  desenvolvimento.    Baseando-se nas palavras acima grifadas, o objetivo deste artigo é realizar uma  proposta metodológica para o desenvolvimento de um módulo ao AVA Moodle, a fim  de torná-lo ubíquo. O ambiente deverá oferecer os seguintes suportes: detectar o estilo  de aprendizagem dos alunos, por meio do uso do ambiente pelos mesmos  (MOZZAQUATRO, 2010), detectar o dispositivo móvel que o usuário estiver  utilizando e verificar se existem softwares específicos para a execução de determinados  formatos de objetos de aprendizagem ou arquivo (FRANCISCATO, 2010). Com esta  adaptação, o AVA também detectará a conexão com a internet do usuário (BEZERRA,  2009), e com isto caso o usuário tente fazer o download ou a visualização de um objeto  que exige determinada conexão que o dispositivo móvel não possua no momento, uma  mensagem será carregada ao usuário informando o problema. Esta proposta de  adaptação ocorrerá no AVA Moodle, pois o mesmo é open source.    O artigo está estruturado da seguinte forma: na seção 2 são apresentados os  elementos característicos da ubiquitous learning e algumas considerações; na seção 3 é  apresentada a análise das técnicas propostas para a adaptação do ambiente.  Na seção 4  é apresentado um teste de uso, utilizando conceitos de engenharia do software com  diagrama de sequência e construção de caso de uso. Por fim, são apresentadas as  considerações finais.   2. Elementos característicos da U-learning   A autora Barbosa (2007) em sua tese defende que para ocorrer educação ubíqua são  relevantes as características do aprendiz e do ambiente computacional. Estas  considerações foram realizadas por meio de análise das pesquisas propostas por Ogata  (2004), Thomas (2005) e Yang (2006). As características do ambiente computacional  são também apontadas por Augustin (2004) em suas pesquisas sobre computação  pervasiva e móvel, as quais se referem à computação consciente ao contexto. A  computação consciência ao contexto é, segundo Maran e Bernardi (2014), um item     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     193   chave em ambientes ubíquos, os autores baseiam-se na pesquisa de Parise et al (2014),  onde os mesmo realizam uma comparação entre oito arquiteturas ubíquas encontradas  na literatura e verificam que em todas existe a detecção do contexto .     Uma definição clara de sensibilidade ao contexto é realizada na escrita de  Fleischmann (2012):   “a sensibilidade ao contexto busca analisar e descrever o comportamento de  um sistema de acordo com as mudanças que ocorrem em seu interior.  Sistemas sensíveis ao contexto se dispõem a apresentar caráter proativo às  modificações ocorridas, adaptando-se a elas.” (FLEISCHMANN, 2012).    A escrita de Dey (1999), também deixa clara a definição de computação  consciente ao contexto:   "contexto é qualquer informação que pode ser usada para caracterizar a  situação de uma entidade. Uma entidade é uma pessoa, um lugar ou um  objeto que é considerado relevante para a interação entre o usuário e uma  aplicação, incluindo o próprio usuário e a própria aplicação." (DEY, 1999).    Maran e Bernardi (2014) afirmam que   é necessário que os sistemas  ubíquos sejam capazes de se adaptar, esta adaptação, de acordo com Barbosa (2007) e  Piovesan (2011), deve ser de acordo com o contexto do usuário.     A detecção de contexto no ensino eletrônico deve abranger tanto o contexto do  ambiente (espaço físico e virtual) quanto contexto do aprendiz (características de  aprendizagem do usuário). Para realizar estas detecções, este trabalho irá propor a  utilização de técnicas ainda não exploradas para serem utilizadas na construção de um  módulo ao AVA Moodle, o qual fará com que ele permita a aprendizagem ubíqua.    3. Análise das Técnicas    Para que o ambiente seja considerado ubíquo, é necessário que o mesmo se adapte a  qualquer dispositivo móvel, para isto será utilizado à técnica de adaptação Bootstrap.  Será utilizada esta técnica, pois o Moodle possui um plugin desta técnica e o mesmo é  open source. Ainda destaca-se o uso dela, pois, ela pode ser integrada “ao Moodle sem a  necessidade de alteração do endereço de acesso para os usuários como se faz necessário  no MLE-Moodle” (Voss et al, 2013). A adaptação automática é outro fator relevante  quando se trabalha com ubiquidade, e a escolha da técnica é importante, pois ela adapta  a interface de acordo com o dispositivo utilizado, por meio de design responsivo (VOSS  et al, 2013).     Ainda existem outras maneiras de adaptação ao ambiente Moodle como a  utilização do Mle-Moodle ou Moodle Mobile, mas as mesmas foram descartadas pelo  fato de não possuírem layout responsivo. O design responsivo, de acordo com Rosa e  Silva (2013) permite a melhor visualização de uma aplicação em qualquer dispositivo  de acesso.    As características de aprendizagem do usuário serão um fator essencial deste  ambiente, onde haverá a detecção do estilo de aprendizagem do usuário. A detecção do  estilo de aprendizagem é utilizada por Piovesan (2011), para verificar as características  de aprendizagem de um usuário. No caso, a detecção do estilo de aprendizagem faz  parte do contexto de aprendizagem, que é descrito por Barbosa (2007), como fato  importante em educação ubíqua.     A detecção do contexto do aprendiz ocorrerá pela técnica de clusterização, na  qual permitirá que o estilo de aprendizagem seja detectado de acordo com o perfil e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     194   preferências do usuário, no que se refere a opções distintas de objetos de aprendizagem.  Está técnica será considerada pelo fato de que o próprio ambiente deve se adaptar e o  usuário não deve intervir no sistema para qualquer alteração, está detecção será  onipresente e permite uma fuga dos questionários que geralmente são utilizados para  detecção de estilos de aprendizagem como o SEDECA proposto por Mozzaquatro  (2010). A técnica de hipermídia adaptativa foi estudada para ser utilizada no trabalho,  no entanto a mesma foi descartada, pelo fato de uma contribuição científica já existente  proposta por Piovesan (2011) a educação ubíqua, e está técnica acaba deixando o  usuário a mercê dos questionários para então realizar as adaptações.    A detecção do contexto do ambiente ocorrerá de duas formas, uma para o  ambiente físico e outra para o ambiente computacional. No ambiente computacional,  será dada relevância aos aplicativos do dispositivo móvel que acessa o ambiente já  adaptado. O sistema detectará se o dispositivo que o usuário esta acessado pode suportar  determinado tamanho e formato do objeto de aprendizagem oferecido pelo professor  (FRANCISCATO, 2010). Caso o dispositivo não suporte, o objeto de aprendizagem não  será ofertado ao usuário como opção de estudo, o ambiente então deverá mostrar ao  usuário outro tipo de objeto que o dispositivo do usuário suporte, dando preferência a  formatos de arquivos que foram detectados no estilo de aprendizagem do aluno.     Na detecção do contexto do ambiente acessado por dispositivos móveis, será  utilizado a técnica TERA-WURFL - Mobile Device Identification (TERA, 2006). Está  técnica de acordo com a dissertação de Franciscato (2010) é uma API para a linguagem  de programação PHP, a qual será utilizada para implementação do módulo ao Moodle.  Está técnica “identifica o dispositivo móvel de acesso e permite pesquisa pelas diversas  características do mesmo” (FRANCISCATO, 2010). O autor ainda afirma que essas  características “são definidas no arquivo Wireless Universal Resource File – WURFL,  que é um arquivo XML que contém informações sobre as características de diversos  dispositivos móveis” (FRANCISCATO, 2010).     Para realizar esta detecção por meio da TERA-WURFL, será criada um instância  da classe ‘TeraWurfl ()’, como foi feita por Franciscato (2010). Esta instância permite o  acesso a função ‘getDeviceCapabilityFromAgent’ “que recebe como parâmetro o  ‘HTTP_USER_AGENT’ do browser, o qual define, de forma única, o dispositivo móvel  de acesso” (FRANCISCATO, 2010) (Quadro 1).    $wurflObj = new TeraWurfl();  $matched = $wurflObj->getDeviceCapabilitiesFromAgent ($_SERVER['HTTP_USER_AGENT']);  $width = $wurflObj->getDeviceCabability("resolution_width");   $height= $wurflObj->getDeviceCabability("resolution_height");   Quadro 1. Código utilizado por Franciscato (2010)    No Quadro 1, é apresentado o código desenvolvido pelo autor Franciscato  (2010), este pequeno trecho de código permite realizar uma consulta sobre a resolução  da tela do dispositivo de acesso. Estas características são relevantes para os ambientes  ubíquos, pois é importante verificar se o dispositivo móvel irá suportar o tamanho de  uma imagem, por exemplo. Vale ressaltar que formatos que o dispositivo não suportar,  serão verificados antes de serem mostrados ao usuário, no momento da adaptação do  ambiente ubíquo.    Ainda será realizada a detecção do contexto do ambiente físico. Este tipo de  detecção é normalmente utilizado por meio de sensores, no entanto com o ambiente  ubíquo é virtual, será utilizado uma técnica de computação que detecte o contexto     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     195   físico. Quando o assunto é ambiente virtual o contexto físico de usuário a ser trabalhado  é por meio da conectividade a internet. Então, para tornar um ambiente onipresente, no  qual o usuário não tenha distrações é necessário dar fim aos problemas de conexão com  internet, este contexto refere-se ao ambiente físico que o usuário se encontre, pois em  diferentes locais e momentos existe variação no tráfego de dados o que remete a  velocidade da internet (BEZERRA, 2009). Assim, o ambiente detectará a velocidade de  conexão do usuário, se a velocidade de conexão com a internet for baixa, o ambiente  não apresentará ao usuário objetos de aprendizagem como vídeos, pois estes demoram  muito para serem carregados (PIOVESAN, 2011).   A técnica que será utilizada para verificar a conectividade é a métrica de grafos  não direcionados. Conforme o Bezerra (2009) um grafo é um conjunto de pontos,  chamados vértices (ou nós), conectados por linhas, chamadas de arestas (ou arcos).  Dependendo da aplicação, arestas podem ou não ter direção. Quando as mesmas  possuem direcionamento de ida e vinda, chama-se de grafos não direcionados.  Para a  definição formal dessa métrica, a topologia da rede no instante t será representada pelo  grafo não direcionado “G(t) ={V,E(t)}”, onde os nós móveis correspondem ao conjunto  de vértices “V = {vi}”, e enlaces de comunicação ao conjunto de arestas representado  por “E(t) = {ei,j(t)}”. Os grafos serão implementados por meio de matrizes de  adjacência, ou seja, associa-se vértices às linhas e colunas da matriz e os elementos da  matriz v indica se há aresta entre os dois vértices (BEZERRA, 2009).   4. Teste de Uso   Com a proposta metodológica definida, desenvolveu-se um diagrama de sequência para  visualizar por meio de uma projeção como funcionará o sistema. O diagrama foi  desenvolvido como a ferramenta StarUML1, para realizar um melhor entendimento de  como o sistema funcionará. Primeiramente é possível perceber que nesta proposta e por  meio do diagrama não foi considerado aspecto de como funcionará o ambiente ubíquo  ao professor, apenas foi considerado que o professor deverá postar materiais didáticos  variados, com diferentes formatos. Por este motivo o diagrama de sequência dá ênfase  no acesso do aluno.     No momento em que o usuário (aluno) acessar o sistema, o mesmo  automaticamente se adaptará ao dispositivo móvel do usuário, por meio da técnica  Bootstrap. Após o aluno acessar seu login, será realizada a verificação do estilo de  aprendizagem por meio da técnica de clusterização, para ocorrer a adaptação de  conteúdos de acordo com o perfil do usuário. Ainda será realizada a verificação de  conectividade do dispositivo por meio da técnica de grafos não direcionados. Após será  ainda realizada a técnica de adaptação ao modelo do dispositivo TERA-WURFL. Por  fim, será então mostrado ao aluno o perfil dele (estilo de aprendizagem) e as disciplinas.    Foi desenvolvido também para melhor entendimento um caso de uso (Figura  02).                                                   1 Software Open Source link: http://staruml.io/     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     196     Figura  1. Diagrama de Sequência       Figura  2. Caso de Uso     O caso de uso representado na Figura 02 demonstra que o aluno ao acessar o  ambiente móvel, o  ambiente realiza uma validação no login e após esta, é inicializado o  processo de adaptação de materiais, por meio das técnicas: clusterização, métrica de  grafos não direcionados e adaptação TERA-WURFL. Após a adaptação o aluno acessa     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     197   os materiais e tarefas disponibilizados de acordo com o perfil do usuário, dispositivo de  acesso e conectividade.    Foram desenvolvidos estes diagramas a fim de verificar a efetividade desta  proposta.   5. Considerações Finais   Aos devidos fins desta pesquisa foi possível verificar algumas técnicas pouco  exploradas pela computação ubíqua, as mesmas serão empregadas para construção de  um módulo ao AVA Moodle. Este módulo será capaz de incorporar a educação ubíqua  no AVA.     Como o foco da educação a distância é a autoaprendizagem, é importante  ressaltar que a computação ubíqua gera novas oportunidades de se aprender. Pois o  objetivo dela é acabar com as distrações que rodeiam o usuário nos momentos de  estudo. Problemas com conexão com a internet serão despercebidos pelo usuário, o  mesmo para problemas de arquivos que não são suportados pelo dispositivo do usuário.  Outro fato importante é que o usuário irá aprender de acordo com seu perfil de  aprendizagem, ou seja, não irá precisar outro tipo de material didático para estudar, o  que o professor postar será suficiente.     O usuário professor não foi o foco deste trabalho, e por isto, as próximas  pesquisas a serem realizadas antes da implementação destas técnicas serão focada no  comportamento do usuário professor no ambiente ubíquo. Ressalta-se que existe pouca  referencia na literatura sobre o comportamento do professor em um ambiente ubíquo.    Referencias   AUGUSTIN, I. (2004). “Abstrações para linguagem de programação visando aplicações  móveis em um ambiente de pervasive computing”. Tese (Doutorado em Ciência da  Computação)- Instituto de Informática, Universidade Federal do Rio Grande do Sul,  Porto Alegre.   BARBOSA, D. N. F. (2007). “Um modelo de educação ubíqua orientado à consciência  do contexto do aprendiz”. Tese (Doutorado em Ciência da Computação)- Instituto de  Informática, Universidade Federal do Rio Grande do Sul. Porto Alegre.   BEZERRA, R.L. (2009). “Análise da conectividade em redes móveis utilizando dados  obtidos na mobilidade humana”. Dissertação (Mestrado em Engenharia de Sistemas e  Computação), Universidade Federal do Rio de Janeiro.   DEY, A. K.; ABOWD, G. D. (1999). “Towards a better understanding of context and  context-awareness”. Georgia Institute of Technology, College of Computing  (Technical Report GIT-GVU-99-22).   FLEISCHMANN, A. M. P. (2012). “Sensibilidade à Situação em Sistemas  Educacionais na Web”. Tese (Doutorado em Ciência da Computação)- Instituto de  Informática, Universidade Federal do Rio Grande do Sul. Porto Alegre.   FRANCISCATO, F. T. (2010). “ROAD: Repositório semântico de Objetos de  Aprendizagem para Dispositivos móveis”. Dissertação de Mestrado do Programa de  Pós-Graduação em Informática. Universidade Federal de Santa Maria, Santa Maria.   GOMES, A. R. (2007).  “UbiquitOS  –  Uma  proposta  de  arquitetura  de middleware  para a adaptabilidade de serviços em sistemas de computação ubíqua”.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 191-198  Nov/2014     198   MARAN, V.; BERNARDI, G. (2014). “Uma Ontologia de Representação de Materiais  de Apoio e Adaptações Baseadas em Informações de Contexto”. Revista ArgentinaBrasil de Tecnologias da Informação e Comunicação, v.1, n.1.   MOZZAQUATRO, P. M. (2010). “Adaptação do Mobile Learning EngineMoodle  (MLE Moodle) aos Diferentes Estilos Cognitivos Utilizando Hipermídia  Adaptativa”. Dissertação de Mestrado do Programa de Pós-Graduação em  Informática. Universidade Federal de Santa Maria, Santa Maria.   OGATA, H.; YANO, Y. (2004). Knowledge awareness for a computer-assisted  language learning using handhelds. International Journal of Continuous Engineering  Education and Lifelong Learning, v.14, p.435-449.   PARISE, D.; PARISE, M.; MARAN, V.; BATTISTI, G. (2014). “U-Learning- O futuro  do EAD?”. Anais do 3º Seminário Nacional de Inclusão Digital. Passo Fundo.   PIOVESAN, S.D. (2011). “U-SEA: Um Ambiente de Aprendizagem Ubíquo utilizado  cloud computing”. Dissertação de Mestrado do Programa de Pós-Graduação em  Informática. Universidade Federal de Santa Maria, Santa Maria.   ROSA, D.; SILVA, T.L. (2013). “Adaptação de interfaces para dispositivos móveis com  HTML5”. Anais do EATI - Encontro Anual de Tecnologia da Informação e Semana  Acadêmica de Tecnologia da Informação.   TERA (2006). Mobile Device Identification- Tera WURFL.   THOMAS, S. (2005). “Pervasive, persuasive eLearning: modeling the pervasive  learning space”. In: IEEE INTERNATIONAL CONFERENCE ON PERVASIVE  COMPUTING AND COMMUNICATIONS WORKSHOPS, PERCOMW, 2005.  Proceedings... Los Alamitos, CA: IEEE Computer Society.   VOSS, G.B.; NUNES, F.B.; HERPICH, F.; MEDINA, R.D. (2013). Ambientes Virtuais  de Aprendizagem e Ambientes Imersivos: um estudo de caso utilizando tecnologias  de computação móvel. Anais do Simpósio Brasileiro de Informática na Educação.   WEISER, M. The Computer for the 21st Century. Scientific American, 1991, p.94-104.   YANG, S. J. H (2006). Context Aware Ubiquitous Learning Environments for Peer-toPeer Collaborative Learning. Educational Technology & Society. v.9 p. 188-201.       
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     199   Análise da página ‘Freis Franciscanos’ com os dados  divulgados do Facebook no Brasil   Lucas Carvalho da Silva¹, Moysés-Halley D’gilfa O. Maciel2, Rômulo F. Pereira3   1 Acadêmico de Tecnologia em Análise e Desenvolvimento de Sistemas,  Instituto Federal de Roraima (IFRR) – Boa Vista – RR – Brasil.   2  Acadêmico de Bacharelado de Ciências da Computação, Universidade Federal  de Roraima (UFRR). Especialista em Engenharia de Software. Tecnólogo em Análise e   Desenvolvimento de Sistemas – IFRR.   3 Especialista em Governança de Tecnologia da Informação. Tecnólogo em  Análise e Desenvolvimento de Sistemas – IFRR.   lucascarvalho_silva@hotmail.com, tzhalley@gmail.com,  romulo.ferreirap@hotmail.com   Abstract. Appeared in 2004 the Facebook, considered the biggest social  network in the world, not being different in Brazil. The Catholic Church has  acted as evangelizing, encouraging young people in the way of virtual  evangelization. The Province of St. Francis of Assisi in Brazil, belonging to  the Order of Friars Minor, acts in the state of Rio Grande do Sul, and has up a  Facebook page ‘Franciscan Friars’. that way, This research aims to examine  the accompanying public page ‘Franciscan Friars’. For so, was used for  qualitative and quantitative research. The research revealed what data should  be converted to the ways of followers.    Resumo. Surgiu em 2004 o Facebook, considerada a maior rede social do  mundo, não sendo diferente no Brasil. A Igreja Católica vem atuando como  evangelizadora, incentivando os jovens no caminho da evangelização virtual.  A Província São Francisco de Assis, pertencente à Ordem dos Frades  Menores, atua no estado do Rio Grande do Sul, e conta com uma página no  Facebook ‘Freis Franciscanos’. Desse modo, esta pesquisa tem como objetivo  examinar o público que acompanha a página ‘Freis Franciscanos’. Para  tanto, utilizou-se de pesquisa qualitativa e quantitativa. A pesquisa revelou  quais dados devem ser convertido aos modos dos seguidores.   INTRODUÇÃO  Com o avanço da informática, percebemos que a informação ocupa muito a vida das  pessoas (NEGROPONTE, 1995). A grande rede, denominada internet, está cada dia  mais acessível a novos dispositivos e a novos usuários. Desse modo, a internet socializa  atualmente inúmeras relações, sejam de trabalho, acadêmicas e pessoais entre os  dispositivos ou quaisquer indivíduos.   Desse percurso informacional, surgiram as redes sociais: uma “rede de  relacionamento que permite que os usuários criem perfis e os utilizem para se conectar a  outros usuários, compartilhar informações e se agrupar de acordo com interesses em  comum” (INTERNET, 2012). Atualmente existem diversas opções com o intuito de  criar e compartilhar conteúdo, podendo ser realizado através de blogs, sites, sites para  associação e aplicativos dedicados a imagens e textos.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     200   A popularidade das redes sociais, assim como qualquer atividade midiática que  chega a tornar-se predominante no dia a dia e que, em si, possui inúmeras utilidades,  desde lembrar do aniversário até a realização de uma reunião de negócio, tem se tornado  cada vez mais transparente no cotidiano do brasileiro. Tal fator é compreendido ampla e  facilmente quando percebemos a popularidade do Facebook, maior rede social do  mundo (MARQUEZI, 2013).    Neste sentido foi criado em novembro de 2012 a página ‘Freis Franciscanos’ no  Facebook, com o intuito de aproximar-se do público católico, devotos de São Francisco  de Assis e ser instrumento de contato entre vocacionados e frades menores, além de ser  uma forte ferramenta de divulgação para o anuncio do Evangelho, devido a facilidade  de acesso à rede.   Dessa forma, o objetivo de realizar um estudo comparativo da página ‘Freis  Franciscanos’ com os percentuais nacionais e mundiais, tendo como variáveis os  horários de acesso, faixa etária do público e a participação do mesmo na página, fez-se   necessário sendo sua importância social, religiosa, vocacional, congregacional e  midiática.    Como resultado, o relacionamento do público que curte a página, revelou os  horários de pico, que correspondem às 11h, 15h e 21h. Já no modo de acesso o uso de  smartphone predomina, o que exige certa limitação nas publicações. O estudo revelou  também que a maior parte do público possui idade entre 18 e 34 anos.    Desse modo, tornou-se benéfico para a instituição que administra e utiliza a  página como meio de divulgação, conscientização, oração e partilha, que conforme os  dados revelados pode planejar as postagens de acordo com o resultado obtido, e assim  os seguidores que usufruem da página encontram estímulos para envolverem-se nas  atividades que a página oferece.   FACEBOOK, A MAIOR REDE SOCIAL DO MUNDO  Criado em 2004, o Facebook não era um site de relacionamentos muito diferente dos  outros, reunia amigos que trocavam mensagens, compartilhavam fotos e informações.  Mas desde o primeiro dia a rede social de Mark Zuckerberg já causou impacto, devido à  compulsão das pessoas pelo serviço, tornando-o em dez anos, a maior rede social do  mundo, com 1,19 bilhão de usuários (POLINI, 2014).    No Brasil, um dado que corrobora essa afirmativa, a rede social mais acessada  do país, é o fato de que a cada 10 brasileiros, 8,4 estão no Facebook, segundo pesquisa  da agência Hello Reserarch com usuários de oito redes sociais, assim, as demais redes  têm ocupado 16% dos internautas e, de acordo com o Ibope, 94, 2 milhões de brasileiros  conectam-se à internet, e 58% desses frequentam o Facebook (MARQUEZI, 2013).    A referida rede social, revela ser um excelente ambiente de fonte de observação  quanto ao comportamento, revelações, pontos positivos e críticas do ambiente e dos  seguidores, assim como despertar reflexões para posteriores iniciativas tendo em vista  os dados divulgados a respeito da rede.   A PRESENÇA DA IGREJA NA ERA CONECTADA   A Igreja como instituição vem aderindo a um novo modelo de evangelização, tornandose acessível por diversos dispositivos, meios e redes sociais fazendo-se objeto de  informação aos fiéis de todo o mundo.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     201   No acesso às redes sociais e até mesmo aos sites e jornais de circulação nacional  é possível, sem muito esforço, ter acesso, até mesmo indireto, à informações da Igreja  Católica. De acordo com Rothman (2013) os seguidores de crença religiosa cresceram  60% nos últimos dez anos.    Segundo a autora Paula Rothman, a página ‘Jovens Católicos’ no Facebook  possuía 14.000 seguidores em dezembro de 2013, já no mês de abril de 2014 a página  contava com mais de 147.000 seguidores (CONECTADOS, 2014), um avanço  estrondoso em apenas quatro meses.   A Pastoral Juvenil Nacional, segundo sua coordenação, informa que tem o  objetivo de “integrar as diferentes expressões que trabalham com a evangelização dos  jovens, sejam elas as pastorais, movimentos, congregações ou novas comunidades, para  que cada vez mais a Igreja conte com o protagonismo juvenil”2 afirmam os responsáveis  pelo site ‘JovensConectados.org.br’ e concluem relatando que a evangelização como  trabalho representa um importante espaço de unidade (Conectados, 2014).   Mendonça (2013, p. 83) pesquisador do Programa de Religiosidade e  Espiritualidade no Consumo e nas Empresas (Prece) afirma que “No universo católico,  a figura mais importante é a do papa”, visto que o Pontífice tem conquistado multidões  de fiéis com sua humildade e simplicidade no modo de agir e falar, além de sua  passagem pelo Brasil durante a Jornada Mundial da Juventude 2013.   O bispo de Roma, Papa Francisco, em sua Mensagem para o 48º Dia Mundial  das Comunicações Sociais, anunciou:    Não tenhais medo de vos fazerdes cidadãos do ambiente digital. É importante  a atenção e a presença da Igreja no mundo da comunicação, para dialogar  com o homem de hoje e levá-lo ao encontro com Cristo: uma Igreja  companheira de estrada sabe pôr-se a caminho com todos. Neste contexto, a  revolução nos meios de comunicação e de informação são um grande e  apaixonante desafio que requer energias frescas e uma imaginação nova para  transmitir aos outros a beleza de Deus (FRANCISCO, 2014)3.    Portanto, é altamente recomendável a presença da Igreja em diversos ambientes,  sobressaindo os virtuais, onde encontram-se milhares de jovens a todo o momento,  realizando a partilha, o testemunho e a vivência da Palavra de Deus.   A PROVÍNCIA SÃO FRANCISCO DE ASSIS COMO PÁGINA DE  EVANGELIZAÇÃO NO FACEBOOK  A Província São Francisco de Assis, atuante no estado do Rio Grande do Sul, tem  intensificado a sua forma de estar presente nos meios de comunicação em massa para  chegar de forma clara e precisa às pessoas do mundo (PROVÍNCIA SÃO FRANCISCO  DE ASSIS, 2014).   Instituída em 04 de outubro de 1976 como “Província São Francisco de Assis do  Brasil”, a instituição está ligada à Ordem dos Frades Menores (OFM), onde possui  atualmente 99 frades atuantes entre serviços missionários e em etapas de formação, à  frente de 21 paróquias do estado do Rio Grande do Sul e com freis em missão em Boa                                                   2 Disponível em: < http://www.jovensconectados.org.br/coordenacao-nacional-de-pastoral-juve nildiversidade-na-unidade>.  3 Disponível em: <http://papa.cancaonova.com/mensagem-do-papa-para-48o-dia-mundial-das-co  municacoes/>.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     202   Vista – RR, Petrópolis – RJ, Roma – Itália, e em Jerusalém – Israel (PROVÍNCIA SÃO  FRANCISCO DE ASSIS, 2014).   Com isso buscou-se acompanhar o progresso da página ‘Freis Franciscanos’ no  Facebook, desde sua criação em 08 de novembro de 2012 até o início de maio de 2014,  tendo como prioridade o ano de 2014.   METODOLOGIA  A abordagem empregada neste estudo trata-se da quanti-qualitativa, onde Richardson  (2010, p. 80) relata que “os estudos que empregam uma metodologia qualitativa podem  descrever a complexidade de determinado problema, analisar a interação de certas  variáveis, compreender e classificar processos dinâmicos vividos por grupos sociais”.   Com isso, destaca-se também que através do método quantitativo é possível  contribuir satisfatoriamente para o processo de mudança de determinado grupo e  possibilitar, em um amplo nível de profundidade, a compreensão das particularidades do  comportamento dos indivíduos, já que este método é próprio para técnicas estatísticas  (GIL, 2010).   A pesquisa bibliográfica foi realizada com base em publicações como livros e  revistas, além de toda gama de informação virtual disponibilizada na rede mundial de  computadores. Para Gil (2010), a principal vantagem da pesquisa bibliográfica reside no  fato de permitir ao pesquisador uma ampla cobertura de fenômenos do qual se pode  pesquisar diretamente.    Dessa forma, os instrumentos de coleta de dados quanto ao Facebook foram  revistas de circulação nacional oriundas de empresas especializadas, onde apresentaram  os percentuais e suas interpretações, além de depoimentos de colaboradores e  especialistas da área. Já quanto à análise dos dados, utilizou-se do acesso aos  administradores da página ‘Freis Franciscanos’ para a coleta de dados, como: horário,  faixa etária e formas de acesso.   Assim, nas interpretações foram obtidas descrições tanto quantitativas: dados  estatísticos levantados através das referências bibliográficas e da página; quanto  qualitativas: informações coletadas através de entrevista com o mentor da página ‘Freis  Franciscanos’, realizada através de e-mail.    RESULTADO DA PESQUISA  Em entrevista via e-mail com o responsável pelas redes sociais da instituição, Frei  Malone Rodrigues da Silva, com questionamentos voltados para a adesão às redes  sociais, o entrevistado informou que:    na verdade não foi uma decisão da província, partiu mais de mim, de  compreender que este ‘espaço’ se faz necessário evangelizar, ainda mais na  província, não só pela resistência de freis idosos, mas por alguns jovens,  nossa presença no Facebook não é bem vista – incoerente, pois estes mesmos  jovens que não curtem, possuem perfil pessoal na rede. Mas é uma  caminhada feita, que ganhou apoio devido às vocações (SILVA, 2014).    Já em relação às análises do mesmo quanto a este novo caminho de  evangelização o frade mencionou que:   a instituição reagiu com bons olhos quando a página Freis Franciscanos  apresentou retorno de vocacionados tanto para a si quanto para o país. O  cunho das postagens sempre foi de divulgar o carisma com um foco     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     203   vocacional, com o passar do tempo maximizamos o foco, tendo em vista que  a rede principalmente as sociais, são dinâmicas e se reformulam rapidamente  (SILVA, 2014).   Percebe-se juntamente ao progresso de adesão a aceitação da instituição como  instrumento além das vocações religiosas, despertando um relacionamento mais  franciscano, modo de vida dos frades da instituição, como a obediência, castidade e  pobreza, além de toda espiritualidade idealizada por São Francisco de Assis no cuidado  com o próximo, aos animais e com a natureza.   Em um ramo em expansão na comunicação, o das redes sociais, as empresas e  instituições em geral, tem buscado tornar cotidianamente maior o acesso dos usuários a  seus serviços, dado esse totalmente claro, onde o usuário brasileiro tem mudado seus  hábitos no acesso à web, como mostra a pesquisa da Mobile Marketing Association  (INFO, 2013) nas tabelas 1 e 2 a seguir:   Observa-se que 25% dos brasileiros usam aparelho celular como principal meio  de acesso à internet e quando a categoria por idade é filtrada, os dados são conforme a  tabela 1 (INFO, 2013).                    Já quanto ao momento de utilização dos celulares pelos usuários, a mesma  pesquisa revelou, conforme tabelas 2, que:    Tabela 2. Momento em que os usuários utilizam os celulares para acessar a internet.                           Quanto aos dados revelados sobre o Facebook no Brasil, Pedro Ivo, da agência  digital Riot afirma que “o Facebook se tornou uma identidade social na internet.” (IVO,  2014, p. 66), e o diretor do Facebook no Brasil, Tristão (2014, p. 66) revela que: “Hoje  o desafio recai sobre a necessidade de oferecer a melhor experiência possível em uma  infinidade de aparelhos que se proliferam tão rapidamente que é difícil até quantificar.   De 10 a 17 anos 17%   De 18 a 24 anos 27%   De 25 a 34 anos 28%   De 35 a 49 anos 17%   Mais de 50 anos 11%   Logo após acordar 36%   Vendo TV 24%   No banheiro 21%   Durante as refeições 16%   Antes de dormir 47%   Tabela 9. Percentual do uso de celulares por faixa etária no Brasil.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     204   A próxima grande onda de usuários da internet virá de plataformas móveis, e no  Facebook não será diferente.” afirma o diretor.   Após a criação da página Freis Franciscanos (www.facebook.com/freisrs), em  novembro de 2012 até o início de maio do ano corrente, a página contou com mais de  9.000 seguidores, conquistados com publicações diárias, momentos de interação entre  público e carisma franciscano. Concentrando a análise no gênero predominante de  seguidores, apresenta-se a figura 1:   Percebe-se que há inversão quanto ao percentual de gêneros predominantes no  Facebook e na página Freis Franciscanos, onde as mulheres representam 54%, tendo  destaque a faixa etária de 25 a 34 anos, seguido de 35 a 44 anos representando 11%. Já  quanto ao gênero masculino, com 45% de fãs, as faixas etárias em destaque representam  13% e 8 % respectivamente e ambos os gêneros representam o percentual de 3% quanto  à faixa etária de 13 a 17 anos.   Já em relação aos horários mais acessados pelos seguidores da página, sem  qualquer diferença de gênero, faixa etária, modo de acesso, localização, idade entre  outras, verifica-se na figura 2, a seguir:     Através da figura 2, conclui-se que não há distinções entre os dados nacionais  Info (2013), que afirma os horários no qual os usuários acessam a internet, antes de  dormir, e após acordar, correspondem satisfatoriamente para possíveis publicações na  página.    Dessa forma, percebe-se que o acesso é elevado após às 07h. No turno  vespertino os horários predominantes de acesso giram em torno das 14h, mostrando  níveis elevados após as 19h findando no horário de pico, às 23h.   Assim, é recomendável analisar os horários das publicações da página, em  destaque os horários onde os índices estão altos, o que representa um número maior de  usuários na rede social e o que torna mais ampla a abrangência das curtidas,   Figura 1. Percentual de gênero masculino e feminino, de faixas etárias dos  seguidores da página Freis Franciscanos, no Facebook.   Figura 2. Horários acessados pelos seguidores do ‘Freis Franciscanos’ no Facebook.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     205   comentários, compartilhamento dos usuários, tendo como consequência maior  abrangência do carisma franciscano por parte dos seguidores e amigos que visualizarão  suas ações no Facebook, sendo os horários das 07h, 11h, 15h e das 22h compatíveis  com o quantitativo de acesso do público, visto que giram em torno dos horários de pico  ou crescentes nos turnos.   Corroborando com este estudo, vê-se na figura 3 a origem das curtidas na  página.  De acordo com a figura 3, observa-se que quando se trata de “curtidas”, as  publicações originárias da página são as menores, sendo superadas pelas “sugestões de  página”, por “suas publicações”, em seguida por “curtidas” originárias de celular. Com  isso, concorda-se com Brasil (2014) onde os usuários passam a utilizar as redes sociais  em smartphones e buscam ter dispositivos de tecnologia e fácil manuseio às mãos para  acessar as redes sociais.                           Assim, percebe-se que os amigos dos seguidores da página curtem as  publicações ou compartilham do material da mesma, e há um grande interesse por parte  de quem acessa a página em convidar seus amigos do Facebook para curtirem, fator  positivo para o objetivo que a página contém para a Província. Se destaca, conforme a  figura 3, o uso dos smartphones e celulares para curtir os conteúdos existentes na  página. Assim, deve-se aprofundar em publicações que sejam compatíveis com a  maioria dos celulares, com fontes grandes e pouca escrita, sendo realçado imagens e  cores de fácil definição.   CONCLUSÃO  A Igreja Católica reconhece as redes sociais e suas ramificações como ferramentas  auxiliares para a Evangelização, em um mundo onde os valores humanos devem ser  anunciados a todos de forma pacífica e com a maior proximidade possível levando à  Palavra de Deus e os projetos da Boa-Nova adiante.    A Província São Francisco de Assis do Brasil tem atingindo a bons passos a  realização do anúncio do carisma de São Francisco de Assis, além de acolher de bom  grado os usuários que desejam conhecer e experimentar a vida religiosa franciscana.    Diante do objetivo elaborado, percebe-se que a página Freis Franciscanos oscila  conforme o mercado nacional, nas variáveis destacadas, seguindo o caminho das redes  sociais.   Figura 3. Número de vezes que a página ‘Freis Franciscanos’ foi curtida e origem das  mesmas.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 199-206  Nov/2014     206   Portanto, este estudo tornou evidente a necessidade de apresentar os conteúdos  em horários específicos de pico, tendo em vista o acesso do público em prol de  acompanhar os trabalhos postados pela página Freis Franciscanos e assim obter maior  número de visualizações e adeptos ao carisma franciscano no Brasil e no mundo,  atingindo como consequências a expansão da página na rede social e o anúncio da  Palavra por meio dela.   REFERÊNCIAS  BRASIL, Marcus Vinícius. Invasões Bárbaras. Info, São Paulo, 338 ed., p. 63-66, fev.   2014.  CONECTADOS, Jovens. Coordenação da Pastoral Juvenil Nacional: diversidade na   unidade. Disponível em: <http://www.jovensconectados.org.br/coordenacao-nacio  nal-de-pastoral-juvenil-diversidade-na-unidade>. Acesso em: 26 de abril de 2014.   __________. Jovens Conectados. Disponível em: <www.facebook.com/jovensconecta  dos>. Acessado em: 02 de maio de 2014.   FRANCISCANOS, Freis. Ver informações. Disponível em: <https://www.facebook.  com/freisrs>. Acesso em: 03 de maio de 2014.   FRANCISCO, Papa. Mensagem para o 48º Dia Mundial das Comunicações Sociais.  Disponível em: <http://papa.cancaonova.com/mensagem-do-papa-para-48o-diamundial-das-comunicacoes/>. Acesso em: 20 de abril de 2014.    GIL, Antônio Carlos. Como elaborar projetos de pesquisa. 5 ed. São Paulo: Atlas, 2010.   INFO. A forte presença do smartphone. São Paulo, 336 ed., p. 32, dez. 2013.  INTERNET, Cartilha de Segurança para Internet. CERT.br, v. 4.0. São Paulo: Comitê   Gestor da Internet no Brasil, 2012.  IVO, Pedro. Invasões Bárbaras. Info, São Paulo, 338 ed., p. 54-61, fev. 2014.   MARQUEZI, Dagomir. O Facebook já cansou. Info, São Paulo, 326 ed., p.38, fev.  2013.   MENDONÇA, Andrey. Jesus Salva e Compartilha. Info, São Paulo, 336 ed., p. 80-85,  dez. 2013.   NEGROPONTE, Nicholas. A vida digital. São Paulo: Companhia das Letras, 1995.  POLINI, Gustavo. Uma década de curtição. Info, São Paulo, 338 ed., p. 54-61, fev.   2014.  PROVÍNCIA SÃO FRANCISCO DE ASSIS. Conspecto 2014. Porto Alegre: 2014.   RICHARDSON, Roberto Jarry. Pesquisa social: métodos e técnicas. 3 ed. São Paulo:  Atlas, 2010.   ROTHMAN, Paula. Jesus Salva e Compartilha. São Paulo, 336 ed., p. 80-85, dez. 2013.  SILVA, Frei Malone Rodrigues da. Mensagem recebida por <romulo.ferreirap@hot   mail.com> em 30 de abril de 2014.  TRISTÃO, Leonardo. Invasões Bárbaras. Info, São Paulo, 338 ed., p. 54-61, fev. 2014.        
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     207   O Algoritmo Genético Coevolucionário para Redução de  Subconjuntos de Casos de Teste da Análise de Mutantes   André Assis Lôbo de Oliveira1, Beatriz Proto Martins1, Celso G. Camilo-Junior1,  Auri M. Rizzo Vincenzi1     1Instituto de Informática – Universidade Federal de Goiás (UFG)  Caixa Postal 131 – 74.001-970 – Goiânia – GO – Brasil   1. {andreoliveira,beatrizmartins,celso,auri}@inf.ufg.br   Abstract. The Coevolutionary Genetic Algorithm (CGA), used in Mutation  Analysis, is responsible for selecting, concurrently, mutants programs and test  cases subsets with high mutation score and low cost. However, this algorithm  was not evaluated from the perspective of minimizing the selected subsets, a  factor that can reduce even more costs in Mutation Analysis. Thus, this  research aims to evaluate the AGC by applying test cases subsets  minimization. The AGC was compared with another minimization technique in  the literature on four benchmarks. The results shows that the AGC selects  minimized test cases subsets, or very close to this, on the analyzed scenarios.   Resumo. O Algoritmo Genético Coevolucionário (AGC), utilizado na Análise  de Mutantes, é responsável por selecionar, concomitantemente, subconjuntos  de programas mutantes e casos de teste com alto escore de mutação e baixo  custo. Todavia, tal algoritmo não foi avaliado sob a perspectiva de  minimização dos subconjuntos selecionados, fator que pode reduzir ainda  mais o custo da Análise de Mutantes. Tendo isso em vista, o presente trabalho  objetiva avaliar o AGC aplicando-se a minimização de subconjuntos de casos  de teste. O AGC foi comparado com outra técnica de minimização da  literatura sobre quatro benchmarks. Os resultados revelam que o AGC  seleciona subconjuntos de casos de teste mínimos, ou bem próximos, nos  cenários analisados.   1. Introdução  Durante o ciclo de vida de um software, uma grande parcela dos custos é gasta na fase  de testes. Com o objetivo de minimizá-los, surge a Search-Based Software Testing  (SBST) [McMinn 2011], uma abordagem que aplica metaheurísticas para otimizar  soluções de problemas em Teste de Software. Entre as metaheurísticas, destacam-se os  Algoritmos Genéticos (AGs), uma das técnicas mais eficientes em problemas de  otimização combinatória [De Jong 2006] com alta complexidade de busca.    Dentre as várias técnicas e critérios do Teste de Software, este trabalho aborda o  Teste de Mutação (TM), um critério de teste conhecido por sua grande eficácia em  detectar defeitos. No entanto, o alto custo computacional, proveniente da grande  quantidade de programas mutantes gerados, torna o TM pouco utilizado na prática.   Técnicas da SBST têm sido aplicadas para diminuir os custos do Teste de  Mutação. O Algoritmo Genético é uma das metaheurísticas mais utilizadas por ser  facilmente adaptado aos problemas e por gerar bons resultados. Uma de suas adaptações  é o Algoritmo Genético Coevolucionário (AGC) [Oliveira, Camilo-Junior e Vincenzi  2013-a], o qual utiliza coevolução para selecionar bons subconjuntos de casos de teste e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     208   mutantes, a fim de reduzir custos sem diminuir a eficácia. Todavia, o AGC não verifica  se a seleção empregada possui a capacidade de minimizar os subconjuntos selecionados.    Neste contexto, este trabalho visa avaliar o AGC sob a perspectiva do tamanho  dos subconjuntos de casos de teste selecionados. Para isso, o AGC é aplicado em 4  benchmarks conhecidos e a qualidade dos subconjuntos selecionados é comparada com  as seleções realizadas por outra técnica de minimização. Os resultados revelam que o  AGC possui a característica de selecionar subconjuntos reduzidos, o que encoraja a  continuação dos estudos sob tal perspectiva.   2. Revisão Bibliográfica   2.1 Teste de Mutação   A Análise de Mutantes ou Teste de Mutação (TM) no nível de unidade, surgiu na  década de 1970. DeMillo, Lipton, e Sayward (1978) apresentam a ideia da técnica que  está fundamentada na hipótese do programador competente e no efeito de acoplamento.  A hipótese do programador competente assume que programadores experientes  escrevem programas muitos próximos de estarem corretos. Assumindo a validade dessa  hipótese, pode-se dizer que os defeitos são introduzidos no programa por meio de  pequenos desvios sintáticos, que embora não causem erros sintáticos, alteram a  semântica do programa. O efeito de acoplamento, por sua vez, assume que defeitos  complexos estão relacionados a defeitos simples. Deste modo, a detecção de um defeito  simples pode levar a descoberta de defeitos complexos.    A partir de um programa original P, é criado um conjunto P' de programas  modificados (mutantes) com o objetivo de avaliar o quanto um conjunto de teste T é  adequado [DeMillo, Lipton e Sayward 1978]. Os casos de testes de T são executados  sobre o programa original e o mutante, caso as saídas sejam diferentes o mutante é dito  estar morto, dessa forma é possível que o programa em teste não contenha o defeito  representado pelo mutante. Um problema enfrentado em TM é a geração de uma grande  quantidade de mutantes traduzindo-se em um alto custo computacional para sua  realização. Outro problema, consiste na geração de mutantes equivalentes que são  sintaticamente diferentes do programa original, mas que são semanticamente iguais, não  sendo mortos por qualquer caso de teste. Verificar a equivalência entre dois programas  exige esforço humano por ser um problema indecidível [Jia and Harman 2011].    A métrica que define a adequabilidade de um conjunto de teste chama-se escore  de mutação. De acordo com DeMillo, Lipton, e Sayward (1978), o escore de mutação é  um número real que varia entre 0 e 1, calculado conforme a Equação 1. Quanto maior o  escore de mutação de um caso de teste, maior a sua capacidade em matar mutantes.          Onde:  - ms(P, T): escore de mutação do conjunto de testes T;  - DM (P, T): total de programas mutantes mortos por T;  - M(P): conjunto de mutantes do programa original P.  - EM (P): total de mutantes equivalentes.   2.2 Minimização de Conjuntos de Casos de Teste   Técnicas de minimização objetivam reduzir o tamanho do conjunto de teste pela     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     209   eliminação de casos de teste redudantes. A minimização pode também ser chamada de  “redução do conjunto de teste” (test suite reduction) [Yoo e Harman 2010].   Técnicas de minimização de subconjuntos de teste são desejáveis no Teste de  Regressão em que se objetiva estabelecer um subconjunto de casos de teste que seja  capaz de testar as diferentes versões de um programa. A ideia é garantir que as novas  características inseridas não influenciam no bom funcionamento das existentes. No  contexto do TM, as técnicas de minimização de conjuntos são desejáveis para  estabelecer um subconjunto pequeno que diminua o custo da execução dos casos de  teste sobre os mutantes, mas com alto escore de mutação.   Um critério de teste é satisfeito quando todos os requisitos de teste são satisfeitos  por quaisquer casos de teste. Para maximizar o efeito da minimização, , um  subconjunto de T, deve ser o conjunto mínimo. Todavia, atingir esse conjunto mínimo é  um problema NP-completo [Yoo e Harman 2010], uma vez que é similar ao problema  de cobertura do conjunto mínimo [Garey e Johnson 1979].    2.3 Trabalhos Correlatos   “A NP-completude do problema de minimização de subconjuntos encoraja a  aplicação de heurísticas” [Yoo e Harman 2010].  Vale citar as heurísticas GE e GRE  [Chen e Lau 1996]:    Heurística GE: a) seleciona todos os casos de teste essenciais do conjunto; b)  para os requisitos de teste remanescentes, usa um algoritmo guloso adicional que  seleciona o caso de teste que satisfaz o máximo de requisitos não satisfeitos;    Heurística GRE: a) remove todos os casos de teste redudantes no conjunto de  teste e partir disso forma o conjunto essencial de casos de teste; b) utiliza a  heurística GE para reduzir esse conjunto formado.   Metaheurísticas também são utilizadas nesse contexto de minimização.  Nachiyappan, Vimaladevi e SelvaLakshmi (2010), propuseram um algoritmo genético  que se baseia em informações de cobertura. Todavia, para construir o subconjunto, a  metaheurística considera informações de tempo de execução de aplicações anteriores  dos casos de teste, em um cenário de Teste de Regressão.    No contexto do Teste de Mutação, Polo, Piattini e García-Rodríguez (2008),  utilizam mutantes de segunda ordem para reduzir o custo da execução de mutantes. A  partir dessa classe de mutantes, forma-se o subconjunto mínimo de casos de teste por  meio do seguinte algoritmo guloso: a) coloca-se dentro de o caso de teste que mata o  maior número de mutantes; b) remove-se todos os mutantes já mortos por ; c)  seleciona-se o caso de teste seguinte que mata o maior número de mutantes; d) removese todos os mutantes já mortos por .  Esses passos são repetidos até que não haja  mutantes vivos. Obviamente, tais passos são realizados somente com os mutantes nãoequivalentes.   Polo et al. (2008) disponibilizaram todo o material da experimentação utilizado  na pequisa (programas e conjuntos de teste)4. Tal material pode servir como benchmark  para técnicas de minimização e seleção, uma vez que se pode comparar o subconjunto  selecionado com os subconjuntos ótimos ( mínimo com maior escore de mutação)  encontrados pela abordagem por eles proposta.                                                   4   Disponível em:  <http://www.inf-cr.uclm.es/www/mpolo/stvr/>     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     210    O AGC, proposto por Oliveira, Camilo-Junior e Vincenzi (2013-a), idem (2013b), aborda a coevolução de maneira competitiva para selecionar subconjuntos de casos  de teste e mutantes afim de reduzir custos sem diminuir a eficácia. Na seleção de casos  de teste, o AGC faz uso da Classificação Genética, o que provê alto escore de mutação  ao favorecer a seleção de genes efetivos, isto é, casos de testes que contribuem para o  subconjunto. Percebe-se que a Classificação Genética evita casos de teste redundantes  da mesma forma que as heurísticas para minimização de subconjuntos, portanto, pode  ser empregado para obter subconjuntos de casos de teste minimizados.   3. Abordagem Proposta  A abordagem proposta centra-se na aplicação do AGC para minimização de  subconjuntos de casos de teste. O objetivo consiste em verificar se o AGC consegue  selecionar subconjuntos de casos de teste mínimos com escore de mutação máximos,  por meio de sua busca coevolucionária entre casos de teste e programas mutantes.    Foi desenvolvida uma metodologia para proporcionar tal verificação, conforme  descrita na Figura 1.     Figura 1. Avaliação dos subconjuntos de casos de teste selecionados pelo AGC    A avaliação utiliza os benchmarks fornecidos por Polo et al (2008) pelo fato de  disponibilizarem os subconjuntos ótimos (T' com escore máximo e tamanho mínimo),  os quais servem como base de comparação. Os benchmarks são constituídos por quatro  elementos: a) programa original P; b) conjunto de mutantes P'; c) conjunto de casos de  teste T e; d) subconjunto ótimo de caso de teste T'.    O tamanho do subconjunto de casos de teste (tamanho do indivíduo no contexto  de algoritmo genético) é um parâmetro de entrada do AGC. A ideia é que ele receba o  parâmetro de tamanho de subconjunto e configure os indivíduos da população de casos  de teste. Ao final da busca coevolucionária ele deve fornecer um subconjunto de casos  de teste (indivíduo) com um tamanho menor do que o dado, ou seja, minimizado.     Dessa forma, o primeiro passo da abordagem de avaliação, consiste em fornecer  a entrada ao AGC, constituída pelos conjuntos P, P' e T. O segundo passo consiste na  busca evolucionária empregada pelo AGC para selecionar o melhor subconjunto  (melhor indivíduo) de casos de teste (Sub. AGC). O terceiro passo é a verificar se a  saída do AGC é igual ao subconjunto ótimo (Sub. Ótimo) do respectivo benchmark em  teste, ou seja, se o escore de mutação é igual e se os tamanhos dos subconjuntos são     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     211   iguais. O quarto, e último passo, consiste em armazenar a melhor seleção do AGC caso  ela seja ótima para extração de métricas estatísticas.   4. Estudos Experimentais   4.1 Programas Utilizados   São considerados os quatro seguintes benchmarks dos utilizados por Polo et al. (2008),  descritos, ainda, na Tabela 1:   1. Bubcorrecto (Bub): ordena um vetor através do método bubble-sort.  2. Fourballs: calcula o peso relativo de um corpo;  3. Mid: calcula o valor central a partir de três valores;  4. Trytip: realiza a classificação de triângulos, dadas as dimensões dos seus lados.   Tabela 1. Informações dos benchmarks utilizados   Nome Total Mutantes Total Equivalentes Total Casos de Teste    Bub 80 21 256   Fourballs 212 44 96   Mid 181 43 125   Trytip 309 70 216    De acordo com as informações da Tabela 2, foram realizados dois experimentos  com os tamanhos dos subconjuntos de casos de teste variados para cada benchmark,  sendo eles maiores do que os tamanhos mínimos possíveis. A intenção é verificar se o  melhor subconjunto selecionado pelo AGC é igual em escore e em tamanho em relação  ao tamanho ótimo do respectivo benchmark.   4.2 Parâmetros dos algoritmos   Para todos os algoritmos foram fixados os seguintes parâmetros: a) operador de seleção:  torneio, com 2 competidores; b) taxa de cruzamento: 95%; c) taxa de mutação: 5%; d)  elitismo: 1 indivíduo; e) tamanho das populações de casos de teste e de mutantes: 4; f)  quantidade de gerações: 50. O tamanho de indivíduo da população de mutantes foi  fixado em 2,5% do conjunto total mutantes, configurando um tamanho comum a todos  os benchmarks e pequeno em relação ao conjunto total de mutantes.   Tabela 2. Informações dos Experimentos   Nome Nº de casos de teste  (Conj. Reduzido)   Experimento 1: Tam. do Indivíduo  (sub. de casos de teste)   Experimento 2: Tam. do  Indivíduo (sub. de casos de teste)   Bub 1 2 3   Fourballs 5 10 15   Mid 5 10 15   Trytip 17 34 51   4.3 Discussão dos Resultados   Todos os resultados foram obtidos por meio de 30 execuções do AGC. A Tabela 3  apresenta os resultados dos experimentos.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     212      Tabela 3. Resultados experimentais   Experimento 1   Benchmark MAX MED MEDTAM TSMIN IMTAM   Bub 1 0.9897 1.53 1 99.40%   Fourballs 1 0.9998 4.97 5 94.83%   Mid 1 0.9961 6.07 5 95.15%   Trytip 1 0.9993 16.90 17 92.18%   Experimento 2   Benchmark MAX MED MEDTAM TSMIN IMTAM   Bub 1 0.9997 1.30 1 99.49%   Fourballs 1 1 5 5 94.79%   Mid 1 0.9976 5.70 5 95.44%   Trytip 1 0.9992 16.87 17 92.19%    Legendas da Tabela 3: a) MAX: escore máximo alcançado; b) MED: média dos  escores de mutação; c) MEDTAM: média dos tamanhos dos subconjuntos de casos de  teste selecionados; d) TSMIN: tamanho do subconjunto mínimo do benchmark e)  IMTAM: percentual de impacto da minimização no conjunto (percentual de redução em  relação ao conjunto total) [Yoo e Harman 2010], calculado conforme Equação 2.       (2)    Conforme Tabela 3, o AGC obtém bons escore de mutação. Além disso,  percebe-se que, em média, o AGC seleciona indivíduos com tamanhos muito próximos  ao do subconjunto ótimo do benchmark. O experimento 1 forma inicialmente indivíduos  menores do que no experimento 2. Todavia, para os benchmarks Bub e Trytip, o AGC  seleciona indivíduos maiores no experimento 1 do que no experimento 2, evidenciando  que esse aumento de tamanho não prejudicou a busca do AGC. Já para o benchmark  Fourballs obteve melhores resultados, em termos de escore de mutação e tamanho, no  experimento 2, alcançando a solução ótima nas 30 execuções. Da mesma forma, no  benchmark Mid, esse aumento também melhorou os resultados do AGC.   As Figuras 2 e 3, colocam em paralelo a quantidade de soluções ótimas  encontradas pelo AGC por benchmark, com a quantidade atingida de escores máximos e  de subconjuntos de tamanhos mínimos encontrados, para os experimentos 1 e 2,  respectivamente.    Conforme Figuras 1 e 2, encontrar soluções com escore de mutação máximo,  não significa encontrar subconjuntos com tamanhos reduzidos. Percebe-se também que  o aumento do tamanho do subconjunto de casos de teste não implicou em um aumento  do tamanho do subconjunto selecionado pelo AGC. Isso traz indícios de que, mesmo  com subconjuntos de tamanhos maiores, o AGC pode ser capaz de encontrar  subconjuntos de tamanho mínimo.        Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     213   Figura 2. Experimento 1: Quantitativo de soluções ótimas encontradas   Figura 3. Experimento 2: Quantitativo de soluções ótimas encontradas   5. Conclusões e Trabalhos Futuros  Nesta pesquisa o AGC foi avaliado sob a perspectiva de minimização de subconjuntos  de casos de teste aplicado a benchmarks reais. Os resultados revelam um bom  desempenho do AGC na obtenção dos subconjuntos de tamanhos reduzidos ao se  utilizar a Classificação Genética. Diante disso, acredita-se que o AGC constitui-se numa  abordagem promissora também no campo da minimização de subconjuntos de casos de  teste como contribução à redução de custos do Teste de Mutação.    Como trabalhos futuros, pretende-se: i) comparar com outras metaheurísticas e  técnicas de minimização para extrair maiores conclusões dessa abordagem; ii) aplicar o  AGC em número maior de benchmarks e iii) aprimorar o AGC para que ele seja capaz  de se auto-parametrizar para descobrir o melhor tamanho de subconjunto de casos de  teste para o programa que se está sendo testado.   Referências   P. McMinn (2011) “Search-Based Software Testing: past, present and future. In:  International Conference on Software Testing, Verication and Validation Workshops  (ICSTW) p. 153-163.   K. A. De Jong (2006) “Evolutionary Computation: a unified approach”, MIT Press.   A. Oliveira, C. Camilo-Junior and Vincenzi (2013-a) “A Coevolutionary Algorithm to     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 207-214  Nov/2014     214   Automatic Test Case Selection and Mutant in Mutation Testing”. In: IEEE Congress  on Evolutionary Computation (CEC) .   A. Oliveira, C. Camilo-Junior e A. Vincenzi (2013-b) “Um Algoritmo Genético  Coevolucionário com Classificação Genética Controlada aplicado ao Teste de  Mutação”. IV Workshop de Engenharia de Software Baseada em Busca (WESB),  2013, Brasília.   Chen TY, Lau MF. Dividing strategies for the optimization of a test suite. Information  Processing Letters, 60(3):135–141, 1996.   Garey MR, Johnson DS. Computers and Intractability: A Guide to the Theory of NPCompleteness. W.H. Freeman and Company: New York, NY, 1979.   M. Polo, M. Piattini and I. García-Rodríguez. Decreasing the Cost of Mutation Testing  with Second-Order Mutants,&rdquo, Software Testing, Verification, and Reliability,  vol. 19, no. 2, pp. 111-131, 2008.   S. Yoo an M. Harman. Regression testing minimization, selection and priorization: a  survey. Software Testing, Verification and Reability, 1(1): 121-141, March 2010.   S. Nachiyappan, A. Vimaladevi, C.B. SelvaLakshmi. An Evolutionary Algorithm for  Regression Test Suite Reduction, in proceedings of the International Conference on  Communication and Computational Intelligence, India.27-29 D ecember, 2010, pp.  503-508.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       215   Geração de Base de Dados para o Teste de Aplicações de  Banco de Dados pelo Emprego da Computação Evolucionária   Bruno Braz Silveira1, Plínio Sá Leitão-Júnior1, Mariana Soller Ramada1, Beatriz  Proto Martins1   1Instituto de Informática – Universidade Federal de Goiás (UFG)  Caixa Postal 131 – 74.001-970 – Goiânia – GO – Brazil   bbrazsilveira@gmail.com,{plinio,mariana,beatrizmartins}@inf.ufg.br   Abstract. This paper focuses on the problem of generating data for test  execution in SQL statements on the context of database applications. Given  the big amount of defects in SQL instructions of an application, it is necessary  to generate, within the domain of attributes in a database schema, tuples sets  with quality, which can help to detect the presence of most defects. For this, it  was applied the principles of Evolutionary Computation, through metaheuristic Genetic Algorithms, by evolving test data. In addition, it was used  Analysis of SQL Mutants for assessing the quality of the test data. In addition,  it was used Analysis of SQL Mutants for assessing the quality of the test data.   Resumo. Este artigo enfoca o problema da geração de dados para a execução  de testes em instruções SQL no contexto de aplicações de banco de dados.  Dado o grande número de defeitos em instruções SQL de uma aplicação, deve  ser gerado, dentro do domínio dos atributos de um esquema de banco de  dados, um conjunto de tuplas com qualidade, que consiga auxiliar na  detecção da maioria dos defeitos. Para isso, foram aplicados os princípios da  Computação Evolucionária, através da meta-heurística Algoritmos Genéticos,  ao evoluir os dados de teste. Além disso, foi utilizada a Análise de Mutantes  SQL para a avaliação da qualidade dos dados de teste.   1. Introdução   A Inteligência Computacional (IC) busca o desenvolvimento de sistemas inteligentes  que imitem aspectos do comportamento humano, tais como: aprendizado, percepção,  raciocínio, evolução e adaptação [Engelbrecht 2007]. Computação Evolucionária (CE) é  um paradigma de IC, que busca reproduzir processos naturais de evolução, onde é usado  o conceito de sobrevivência [Jong 2006]. Como os processos e os produtos de  engenharia de software são dependentes de decisões humanas, o uso de técnicas de CE  pode agregar qualidade à esses elementos.    A introdução de defeitos no software é inerente ao seu processo de  desenvolvimento. Desta forma, o programa ou sistema é executado durante a fase de  teste com a finalidade de encontrar defeitos, que passaram despercebidos durante a fase  de desenvolvimento [Myers 1979]. Entretanto, a própria atividade de teste possui  incertezas, como, por exemplo, o fato de somente um subconjunto de elementos do  domínio de entrada ser selecionado para o teste. Isso introduz uma taxa de incerteza por  não ser garantido que todos os defeitos serão revelados.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       216    O contexto desta pesquisa refere-se às incertezas inerentes ao teste de software,  especificamente durante o planejamento e a aplicação do teste, em atividades tais como  a seleção de dados de teste, execução do teste e a verificação dos resultados. É também  abordado o teste de software envolvendo persistência de dados através da Aplicação de  Banco de Dados (ABD). ABDs fazem uso de algum tipo de linguagem para acessar os  dados, onde se destaca a SQL (Structured Query Language).     O problema em questão refere-se em como gerar bases de dados para o teste de  aplicações de banco de dados a um baixo custo e com eficácia para a descoberta de  defeitos em instruções SQL. Os dados de teste para essa classe de aplicações constituem  bases de dados que serão lidas pelo software em teste, o que denota elevada  complexidade ao problema, devido às “infinitas” possibilidades para a geração dessas  bases de entrada [Tuya et al. 2009].    A geração de base de dados de entrada para o teste de ABD pode, em geral, ser  representado por um problema de otimização ou busca. Assim, é possível obter  resultados importantes para dados de teste aplicando-se a CE com um custo  computacional relativamente baixo.   1.1. Objetivos   O objetivo principal da pesquisa é testar ABDs, visando à descoberta de potenciais  defeitos em instruções em SQL. São aplicados conceitos da CE para a geração de bases  de entrada e, além disso, é utilizada a Análise de Mutantes para medir a qualidade do  conjunto de bases geradas.    Como a CE abrange uma grande quantidade de algoritmos, o objetivo principal  da pesquisa pode ser decomposto nos seguintes objetivos específicos: 1) Representar  base de dados como indivíduos que podem ser criados e evoluídos por meio da  aplicação de algoritmos da CE; 2) Desenvolver algoritmos e suporte computacional para  a aplicação da CE na geração de bases de teste de ABDs, segundo a meta-heurística  Algoritmos Genéticos (AG); 3) Empregar Análise de Mutantes em experimento para  avaliar e comparar bases de dados de teste geradas pelo uso de Algoritmos Genéticos  (AG) e aleatoriamente.   2. Fundamentação Teórica   2.1. Análise de Mutantes  Uma abordagem usada para aumentar a eficácia dos testes de instruções SQL é a  Análise de Mutantes [Derezinska 2007], que objetiva mensurar a qualidade de um  conjunto de bases de entrada. Para tal, são produzidas várias versões da instrução SQL,  denominadas mutantes, cada uma com uma pequena modificação na sintaxe da  instrução original. As bases de entrada são então aplicadas à instrução original e a todos  os seus mutantes.     Um conjunto de bases de entrada é promissor para revelar defeitos se o resultado  obtido pela execução da instrução original difere dos resultados dos seus mutantes. Ou  seja, o conjunto de bases de entrada foi capaz de detectar a diferença entre a instrução  original e os seus mutantes (nesse caso o mutante é “morto”). Essa técnica vem sendo     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       217   utilizada com resultados satisfatórios, como uma evidência de que os dados de teste são  reveladores de defeitos.   2.2. Algoritmos Genéticos   A meta-heurística Algoritmos Genéticos é um dos métodos mais utilizados para a  resolução de problemas de otimização. Utiliza conceitos da Genética, como população,  geração, reprodução e mutação. O funcionamento dessa meta-heurística se resume,  basicamente, no emprego de três operações genéticas: o cruzamento (crossover), no  qual as informações estruturais de duas soluções são cruzadas a fim de gerar novas  soluções; a mutação, processo pelo qual algumas alterações aleatórias podem ser  realizadas nas soluções geradas; e a seleção, que é responsável pela escolha dos  indivíduos que serão submetidos às operações genéticas. Após isso, as soluções atuais  são avaliadas para a determinação de quais sobreviverão para a próxima iteração  (geração) [Jong 2006].   2.3.  Trabalhos Relacionados  Gupta et al. (2010) trabalham a geração de dados de teste para matar mutantes SQL  considerando as mutações nas cláusulas JOIN e nos operadores relacionais. Shah, et al.  (2011), além dos JOINs e dos operadores relacionais, acrescentam a geração de dados  de teste para matar os mutantes dos comandos de agregação. Os resultados de ambos os  trabalhos foram considerados eficientes para as classes de mutantes envolvidas, porém  não utilizam meta-heurísticas nem evolução dos dados de testes.    Tuya, et. al (2009) apresentam uma estratégia de redução de um banco de dados  de produção para realização de teste, através de regras de cobertura de algumas  instruções SQL e usando a Análise de Mutantes como método de avaliação.     Nota-se que Gupta et al. (2010) e Shah et al. (2011) são trabalhos muito  semelhantes, que tratam sobre a geração de bancos de dados de teste, baseados em  mutantes de determinadas cláusulas SQL. Já em Tuya et al. (2009), considera-se um  banco de dados existente e trabalha-se com a sua redução.    Almeida et al. (2013) aplicaram Programação Evolucionária (PE) para  selecionar os dados a serem utilizados na avaliação de mutantes que podem ajudar a  detectar defeitos nas instruções SQL de uma determinada aplicação. Os resultados  foram obtidos a partir de experimentos que comparam Programação Evolucionária,  Geração Aleatória e Algoritmo Genético   4. Metodologia   A metodologia envolve as seguintes etapas: 1) Definição da representação  cromossômica dos dados de teste no contexto da Computação Evolucionária [Almeida  et al. 2013]; 2) Projeto e implementação de suporte computacional para o emprego e  avaliação da meta-heurística Algoritmos Genéticos no contexto de testes de ABDs; 3)  Execução dos algoritmos atribuídos à meta-heurística evolucionária; 4) Análise de  resultados, comparando com valores obtidos pelo Método Aleatório e pelo uso de  Algoritmos Genéticos.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       218    Um esquema de banco de dados foi utilizado na pesquisa, de modo que fosse  palco à realização dos experimentos e à obtenção de seus resultados. Foi usado o  Modelo Conceitual Empresa definido em Elmasri e Navathe (2012), muito difundido no  meio acadêmico. Em adição, um Banco de Dados de Referência (BDR) para o referido  esquema foi construído, utilizando-se as tuplas apresentadas no referido livro.    Um Banco de Dados de Domínios (BDD) foi construído, para armazenar  diversos valores pertinentes ao domínio de cada um dos atributos do Modelo Conceitual  Empresa. O BDD possui os valores que compõem o BDR, em adição a muitos outros  valores dos domínios dos atributos do modelo. A ideia foi usar o BDD para gerar  aleatoriamente Bases de Dados de Teste (BDTs).    Os experimentos foram elaborados para seguir as seguintes etapas: (E0)  entendimento dos possíveis defeitos em instruções SQL; (E1) seleção do conjunto S de  instruções SQL; (E2) geração de mutantes para as instruções contidas no conjunto S;  (E3) geração aleatória de bases de teste (BDTs), a partir dos valores presentes no banco  de dados de domínios (BDD); (E4) evolução da população P, buscando privilegiar a  sobrevivência de indivíduos que podem revelar a presença do maior número dos  potenciais defeitos nas instruções SQL do conjunto S.    Na etapa E0 foi alcançado o entendimento dos possíveis defeitos em instruções  SQL. Tal conhecimento é importante para entender o comportamento de instruções  SQL defeituosas, tal como posto em Silveira e Leitão-Júnior (2013). Na etapa E1 foram  selecionadas 50 instruções SQL de Elmasri e Navathe (2012). Na etapa E2 foi  empregada a ferramenta SQLMutation [Tuya et al. 2006] para a geração dos mutantes  para as instruções do conjunto S: 2559 mutantes foram gerados, com média aproximada  de 50 mutantes por instrução SQL. Na etapa E3, a intenção foi gerar a população inicial  de indivíduos. Um indivíduo é visto como uma base de dados para o teste das instruções  SQL. Assim, a população P de indivíduos é composta pelo BDR e pelos BDTs gerados  nesta etapa.    Os seguintes aspectos requerem realce na etapa evolucionária E4: 1) A  população possui 10 indivíduos enquanto que a população inicial foi constituída por 9  BDTs gerados aleatoriamente (a partir do BDD) e pelo BDR; 2) A operação de mutação  foi aplicada a 20% dos indivíduos da população a cada geração; a mutação consiste em  alterar indivíduos existentes, selecionados aleatoriamente; ocorre a mudança de valores  em algumas tuplas, substituindo por valores existentes no BDD; 3) A operação de  cruzamento também foi aplicada a 20% dos indivíduos da população a cada geração;  cada cruzamento ocorre da seguinte maneira: (i) selecionar 2 indivíduos, X e Y,  aleatoriamente; e (ii) gerar novo indivíduo Z, considerando somente os valores do  domínio dos indivíduos X e Y; 4) A seleção a cada geração envolveu a sobrevivência  dos melhores indivíduos, ou seja, aqueles indivíduos que possuem o melhor escore de  mutação:    Escore (indivíduo) = mutantes mortos / (mutantes - mutantes equivalentes)    As etapas E3 e E4 foram conduzidas utilizando suporte computacional, pela  aplicação da ferramenta, escrita em linguagem Java, desenvolvida para os fins desta  pesquisa.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       219   4. Resultados   Os resultados obtidos são apresentados na Tabela 1. A primeira coluna identifica a  geração, onde a Geração 0 refere-se ao estado inicial da população (antes da evolução).  A segunda coluna exibe o escore obtido com o indivíduo denominado BDR, o banco de  dados de referência extraído de Elmasri e Navathe (2012). A terceira e quarta colunas  apresentam, respectivamente, o escore do melhor indivíduo, dentre os nove indivíduos  restantes da população, e o escore médio desses indivíduos.   Tabela 1. Escores de mutação obtidos para todas as instruções SQL.    Deve ser ressaltado que o BDR serviu como referência aos outros BDTs (nove  indivíduos) da população, os quais foram gerados pelo método aleatório. Sobre os  resultados apresentados na Tabela 1, observa-se o seguinte: 1) O método aleatório  (indivíduos da Geração 0) foi o ponto de partida da população; os BDTs obtidos por  esse método são inferiores ao BDR; 2) Quatro gerações foram criadas durante o  processo de evolução da população; 3) O BDR possui escore superior a qualquer outro  indivíduo, incluindo os escores obtidos para as gerações mais evoluídas; 4) Houve  evolução positiva da população em geral durante o processo de evolução, pois o escore  médio inicial era 0,4093 e evoluiu até 0,4956; 5); O melhor indivíduo em cada geração  sempre foi bem superior a média da população.    Conclui-se que houve uma melhoria da população pela aplicação da metaheurística Algoritmos Genéticos. Os BDTs evoluíram a cada geração, tornando-se mais  eficazes para revelar a presença de possíveis defeitos em instruções SQL de consulta.  Duas instruções (SQL-01 e SQL-02) do conjunto original de 50 instruções são  apresentadas a seguir. As Tabelas 2 e 3 apresentam os resultados para as Instruções.     (SQL-01) SELECT Pnome, Unome FROM Funcionario      WHERE EXISTS (SELECT * FROM Dependente        WHERE Cpf=Fcpf)        AND EXISTS (SELECT *          FROM Departamento          WHERE Cpf=Cpf gerente)     (SQL-02) SELECT F.Unome AS Nome funcionario, S.Unome AS Nome supervisor      FROM Funcionario AS F, Funcionario AS S      WHERE F.Cpf supervisor=S.Cpf       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       220   Tabela 2.  Escores de mutação obtidos para a instrução SQL-01.   Tabela 3.  Escores de mutação obtidos para a instrução SQL-02.       Sobre os resultados apresentados nas Tabelas 2 e 3, é pertinente pontuar que em ambas  as instruções os escores obtidos foram superiores aos escores do BDR. Os escores são  distintos entre as instruções: SQL-01 obteve escores superiores em relação a SQL-02.  Além disso, houve uma tendência a estabilidade dos valores, com respeito aos escores  médio e do melhor indivíduo. A Instrução SQL-01 evoluiu os escores médio e de  melhor indivíduo na Geração 4, esse comportamento (evolução gradual do indivíduo) é  uma tendência observável nos dados da Tabela 1. Por fim, o escore de mutação pode ser  usado como uma medida para a complexidade de cada instrução no contexto da  atividade de teste.    Em síntese, há um grau de dificuldade para a obtenção de dados de teste para as  instruções SQL, tal que cada instrução possui um custo próprio de geração de dados de  teste. Através de uma análise dos resultados, foi identificado o fator da restritividade  nas cláusulas where como um dificultador para se matar mutantes SQL. A restritividade  é maior/menor quando há poucas/muitas tuplas na base de dados que atendem ao  predicado da cláusula where da instrução. Dessa forma, as instruções foram divididas  em dois conjuntos com relação ao BDR: instruções de Baixa Restritividade (BR) e de  Alta Restritividade (AR).    As Tabelas 4 e 5 apresentam os resultados para os comandos BR e AR,  respectivamente. Sobre os resultados apresentados em tais tabelas, observa-se que  houve uma melhor evolução dos BDTs para instruções de baixa restritividade; em  adição, os escores médio e do melhor indivíduo superaram o escore do BDR em todas  as gerações. Além disso, instruções de alta restritividade resultam em escores inferiores  (BDR e demais BDTs) em relação a instruções de baixa restritividade (ver as duas  últimas colunas de ambas as tabelas).              Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       221   Tabela 4.  Escores de mutação obtidos para as instruções BR.     Tabela 5.  Escores de mutação obtidos para as instruções AR.         Conclui-se que é mais difícil obter BDTs para revelar a presença de defeitos  para instruções SQL com alta restritividade, em relação a instruções SQL com baixa  restritividade.   5. Conclusões   Nesse trabalho, foi possível observar que a aplicação da Computação Evolucionária  aliada à Análise de Mutantes é promissora para resolver o problema da Geração de  Bases de Teste para a descoberta de defeitos em instruções SQL presentes em  Aplicações de Banco de Dados. Especificamente, a meta-heurística Algoritmos  Genéticos foi empregada no âmbito da evolução de indivíduos candidatos a dados de  entrada para o teste de instruções SQL.     A caracterização do problema e de variáveis para a construção de solução por  experimento, o desenvolvimento de ferramenta computacional para automatizar o  experimento e a obtenção de resultados preliminares promissores a partir de análise  empírica representam alguns dos aspectos importantes alcançados com esta pesquisa.    As conclusões ressaltadas foram que: 1) houve uma melhoria da população pela  aplicação da meta-heurística Algoritmos Genéticos; os BDTs evoluíram a cada geração,  tornando-se mais eficazes para revelar a presença de possíveis defeitos em instruções  SQL de consulta; 2) há um grau de dificuldade para a obtenção de dados de teste para as  instruções SQL, tal que cada instrução possui um custo próprio de geração de dados de  teste; 3) é mais difícil obter BDTs para revelar a presença de defeitos para instruções  SQL com alta restritividade, em relação a instruções SQL com baixa restritividade; 4) o  escore de mutação pode ser usado como uma medida para a complexidade de cada  instrução no contexto da atividade de teste.    Alguns desdobramentos futuros para a pesquisa são: 1) extensão da evolução  dos BDTs pelo aumento do número de gerações; 2) definição de outros operadores para     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 215-222  Nov/2014       222   mutação e cruzamento, que sejam específicos à solução do problema de geração de  dados de teste para ABDs; 3) utilização de novos parâmetros para a análise empírica,  tais como tamanho do indivíduo e emprego de medida de qualidade no conjunto da  população (em vez de cada indivíduo); 4) disponibilização da ferramenta em ambiente  Web; 5) expansão do escopo do problema, pelo tratamento da infactibilidade de  indivíduos; 6) aplicação de computação paralela, para alcançar melhor desempenho e  flexibilidade.   Referências   Derezinska, A. (2007) “An experimental case study to applying mutation analysis for  sql queries”, International Multiconference on Computer Science and Information  Technology.   Engelbrecht, A. P. (2007) “Computational Intelligence”. Willey, England.   Elmasri, R. and Navathe, S. B. (2012) “Sistemas de Banco de Dados”, 6a Edição,  Pearson.   Gupta, B. P., Vira, D., Sudarshan, S. (2010) “X-data: Generating test data for killing sql   mutants”. 26th International Conference on Data Engineering (ICDE).   Jong, K. A. D. (2006) “Evolutionary Computation A Unified Approach”. Massachusetts  Institute of Technology, Cambridge, MA.   Myers, G. J. (1979) “The Art of Software Testing”, John Wiley & Sons.   Shah, S., Sudarshan, S., Kajbaje, S., Patidar, S., Gupta, B., Vira, D. (2011) “Generating  test data for killing sql mutants: A constraint-based approach”, IEEE 27th  International Conference on Data Engineering (ICDE).   Silveira, B. B. and Leitão-Júnior, P. S. (2013) “Enumeração e Classificação de Defeitos  em Consultas SQL”, Congresso de Computação do Sul de Mato Grosso.   Tuya, J., Suárez-Cabal, M.J. and De Lariva, C. (2006) “SQLMutation: A tool to  generate mutants of SQL database queries”, 2nd Workshop on Mutation Analysis.   Tuya, J., Cabal, M. J. S., De Lariva, C. (2009) “Query-aware shrinking test databases”,  2nd International Workshop on Testing Database Systems, DBTest, Rhode Island,  USA.   Almeida, F., Leitão-Júnior, P. S., Vincenzi, A. M. R., Lucena, F. N. (2013) “Geração de  Bases de Dados de Teste pela Aplicação de Programação Evolucionária”. 7th  Brazilian Workshop on Systematic and Automated Software Testing (SAST), 2013.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       223   Aplicação WEB para Monitoramento Online de  Microgeração Elétrica via Modem WiFi utilizando Fontes   Renováveis de Energia     Fausto Sampaio1, Sandro C. S. Jucá1, Renata I. S. Pereira2   1 Departamento de Telemática – Instituto Federal de Educação, Ciência e Tecnologia do  Ceará (IFCE)   CEP 61939-140 – Maracanaú, CE – Brasil     2 Departamento de Engenharia Elétrica – Universidade Federal do Ceará (UFC)   Fortaleza, CE – Brasil     fausto.cefet@gmail.com, sandrojuca@ifce.edu.br, renata@dee.ufc.br  Abstract. The present paper describes the development of a WEB application  implemented with PHP and a WiFi acquisition system to send data to online  monitoring server using free software, applied in decentralized  microgeneration from renewable energy sources. The WiFi monitoring system  was prepared using the RN-XV Wifly modem coupled to a microcontrolled  based on SanUSB free tool. This online monitoring system was applied to a  photovoltaic (PV) water pumping plant without batteries. Furthermore, the  control system and communication with the online server is also autonomous  and powered by PV panel. The application allows to analyze the stored data  and charts via computational devices such as laptops, tablets and smartphones.   Resumo. O presente artigo descreve o desenvolvimento de uma aplicação  WEB implementada com PHP e um sistema de aquisição e envio de dados  WiFi para um servidor de monitoramento online utilizando software livre,  aplicada em microgeração descentralizada a partir de fontes renováveis de  energia. O sistema de monitoramento e envio de dados WiFi foi elaborado  utilizando o modem Wifly RN-XV acoplado a uma placa microcontrolada  baseada na ferramenta livre SanUSB. Este sistema de monitoramento online  foi aplicado em uma planta de bombeamento fotovoltaico (FV) sem baterias.  Além disso, o sistema de controle e comunicação com o servidor online  também é autônomo e alimentado por painel FV. A aplicação permite analisar  os dados armazenados e os gráficos através de dispositivos computacionais  como notebooks, tablets e smartphones.    1. Introdução  Com o surgimento da resolução normativa n. 482 da ANEEL (2012), que estabelece  condições gerais para a microgeração de energia elétrica conectada na rede de  distribuição por meio de unidades com potência instalada menor ou igual a 100 kW,  torna-se ainda mais relevante o desenvolvimento de sistemas de monitoramento online  para os processos de microgeração de energia elétrica baseados em fontes renováveis de  energia.   Na realidade brasileira, os sistemas de aquisição de dados e de monitoramento  online são encontrados principalmente em grandes centrais de geração elétrica, com  monitoramento complexo e com custos relativamente elevados, inviabilizando a  implantação em clientes domésticos e em outros clientes que se encontram dentro da     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       224   faixa de potência de microgeração estabelecida pela resolução da ANEEL (2012). Neste  contexto, o presente artigo visa desenvolver técnicas eficientes de monitoramento online  em software livre, sensoriamento e transmissão de dados via WiFi para auxiliar na  difusão e na instalação de sistemas de microgeração elétrica em locais de elevado  potencial de energia renovável no Brasil.   Em relação à comunicação com a Internet, Kurose e Ross (2003) lembram que  até a década de 90, era usada, como ferramenta de troca de arquivos, notícias e  mensagens eletrônicas por acadêmicos e universitários.  Após a década de 90 a WWW  (World Wide Web) entrou em cena, chamando a atenção dos usuários da rede e  alterando a forma como as pessoas interagem. A Web oferece uma interface gráfica de  fácil navegação. Os conteúdos da Web podem ser visualizados através de um browser,  que verifica os arquivos e exibe os conteúdos armazenados no servidor, como é o caso  da aplicação WEB para monitoramento online desenvolvida no presente projeto.   2. Envio de dados WiFi   O projeto proposto é baseado em uma placa de aquisição e envio de dados, com  conexão WiFi, como ilustrado na Figura 1, que envia os dados monitorados para um  servidor online programado em software livre e possibilita a depuração dos valores dos  sensores através da emulação serial virtual via USB.         Figura 3. Placa de aquisição de dados e modem WiFi    A placa de aquisição de dados utilizada no presente projeto é baseada em uma  ferramenta computacional de programação de microcontroladores via USB  desenvolvida em software livre, executável nos sistemas operacionais Linux, Mac OSX  e Windows® e disponível nos arquivos do Grupo SanUSB (2013). Esta ferramenta é  composta por um gerenciador pré-programado no microcontrolador e uma interface  gráfica utilizada no PC para gravar o novo firmware na memória de programa flash do  microcontrolador via USB. Por se tratar de uma ferramenta em hardware e software  livre e programada, diferentemente de outras ferramentas, em linguagem C padrão,  oferece muitas vezes melhor desempenho, incentiva a criatividade, permite aplicações  dedicadas e possibilita também localizar e corrigir erros de código mais rápido do que  em softwares proprietários [Paulson et al., 2004]. A Figura 2 mostra o processo de  programação da Ferramenta SanUSB.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       225        Figura 2. Processo de programação da Ferramenta SanUSB   3. Protocolo de comunicação via WiFi   O modem Wifly, ilustrado na Figura 3, integra o processo de monitoramento online via  WiFi. Este modem é baseado no módulo RN-171 que é responsável pela conexão às  redes sem fio. Utilizando este modem, são necessários apenas quatro pinos para  alimentação de tensão e conexão WiFi com o microcontrolador [WiFi Alliance, 2012].  Além disso, este dispositivo possui uma antena independente, que aumenta o raio de  ação e oferece sinais de transmissão mais fortes. Oferece também suporte aos  protocolos mais comuns de comunicação, entre os quais TCP, UDP e FTP.           Figura 3. Ilustração do processo de monitoramento online via modem WiFi   4. Configuração proposta de monitoramento online   Neste item é descrito o processo de monitoramento online e os princípios de aquisição  WiFi. No estudo de caso é utilizada uma planta de bombeamento FV sem baterias, em  que o sistema de controle e comunicação com o servidor online também é autônomo e  alimentado por painel FV. Neste caso, o envio de informações para o banco de dados  online foi configurado com acesso remoto via WiFi,  sem tarifação, diferentemente das  aplicações que utilizam o protocolo 3G/GPRS disponibilizado pelas operadoras de  telefonia móvel.     O banco de dados online pode ser consultado por qualquer dispositivo  computacional, conectado à internet, por meio de senha de acesso. As consultas podem  ser realizadas a qualquer momento com a atualização implementada a cada minuto. A  Figura 4 ilustra o monitoramento online desenvolvido em duas etapas:     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       226   • Sensoriamento, condicionamento e transmissão de dados.   • Armazenamento no banco de dados de um servidor online e apresentação  ao usuário.    A etapa 1 implementou a comunicação entre os sensores conectados à placa de  aquisição de dados. Já a etapa 2, ou seja, a camada de apresentação ao usuário, foi  desenvolvida em PHP com banco de dados em MySQL. Desta forma, é apresentada  uma alternativa totalmente livre de monitoramento online aplicado às fontes renováveis  de energia. A etapa 1, de sensoriamento, condicionamento e aquisição sem fio, lê os  dados dos sensores a cada minuto e os armazena em uma memória EEPROM interna.    A cada dez minutos, é calculada a média de cada sensor e enviada para a etapa 2.  É importante ressaltar que atuadores também podem ser conectados à placa permitindo  controle de cargas WiFi através do servidor.      Figura 4. Etapas do sistema de monitoramento em software livre    No servidor, foi desenvolvida uma interface de comunicação com o sistema de  aquisição, e outra, que funciona paralelamente para comunicação com o usuário. A  primeira interface é responsável por receber os dados via HTTP, armazená-los no banco  de dados e enviar uma confirmação à placa. Já a interface com o usuário fornece um  front-end amigável que possibilita a visualização dos dados na forma de lista ou gráfico.      5. Descrição da planta de microgeração fotovoltaica (FV)   A planta de microgeração utilizada no estudo de caso está instalada no Laboratório de  Energias Alternativas (LEA) da Universidade Federal do Ceará (UFC). Esta planta  consiste em um sistema de bombeamento de água acionado por painéis FV. A aplicação  WEB de monitoramento online e aquisição/envio de dados sem fio foi implementada no  intuito de armazenar os valores de tensão e corrente dos painéis FV, pressão e vazão do  conjunto motobomba (Figura 5), temperatura ambiente e radiação solar. Os dispositivos  eletrônicos foram acondicionados em caixas plásticas para evitar a influência da  variação térmica.        Figura 5. Motobomba CC     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       227    Em relação aos dados de tensão do painel FV, foi necessário desenvolver uma  placa com circuito de condicionamento por divisão de tensão para adquirir os dados,  pois os sinais ultrapassam o limite de tensão do conversor analógico-digital (AD) do  microcontrolador. No caso da leitura de tensão, o painel FV utilizado, para as condições  meteorológicas de Fortaleza-CE, em torno do meio dia, fornece um valor de tensão  máximo em torno de 19 V.   6. Software livre de monitoramento online   O Monitor WEB é uma aplicação desenvolvida em um servidor online com a linguagem  de programação PHP com as tecnologias HTML, Java Script e CSS em conjunto  com uma base de dados estruturada no SGBD (Sistema de Gerenciamento de Bancos de  Dados) MySQL no intuito de servir como visualização do monitoramento dos dados  (sinais de sensores) oriundos de fontes renováveis de energia, enviados através de uma  comunicação sem fio (GPRS ou WiFi). A Figura 6 mostra a tela de menu expandida,  onde é selecionado o tipo de monitoramento a ser visualizado.    Para acessar o sistema de monitoramento, é necessário digitar o endereço:  http://sanusb.site50.net/monitorWEB/index.php e em seguida é exibida a página de  autenticação do sistema. A página contém um formulário de autenticação (usuário e  senha) para que apenas os usuários previamente cadastrados tenham acesso ao sistema.     Figura 6. Tela de Menu expandida    Através do monitor WEB é possível consultar os dados armazenados no banco  online através de smartphones ou PCs. Considerando que o padrão Ethernet é a solução  mais utilizada atualmente em sistemas prioritários para interconectividade de redes, o  custo de sistemas de monitoramento para microgeração em rede wireless com software  livre tende a ser cada vez menor.    No item do menu “Monitoramento” (Figura 6) existem as aplicações a serem  visualizadas, e para cada aplicação existem  mais dois submenus: Gráfico e Logs,  conforme ilustrado na Figura 7. Ao clicar no submenu “Gráfico” será gerado um gráfico  com os valores dos sensores da aplicação que estão armazenados no banco de dados,  como mostra a Figura 8.                          Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       228        Figura 7. Gráfico utilizando a biblioteca Highcharts    Para geração dos gráficos foi utilizado o Highcharts (2014), que é uma  biblioteca de gráficos escrita em Java Script. O gráfico reinicia automaticamente a cada  30 segundos. Caso haja a necessidade de reiniciar o gráfico antes dos 30 segundos, é  preciso clicar no ícone de reiniciar destacado no gráfico da Figura 7.    Para exibir os valores dos sensores envolvidos na aplicação escolhida, de um  determinado dia, é necessário informar ou selecionar uma data válida e depois clicar no  ícone de uma lupa ao lado. Logo após, o gráfico será atualizado exibindo para cada  ponto do gráfico um valor representativo da média calculada sobre os valores dos  sensores em questão a cada 10 minutos.     No intuito de visualizar os logs correspondentes aos valores atuais exibidos no  gráfico, é necessário clicar no botão “logs” destacado na Figura 8.     O sistema também disponibiliza a opção de imprimir ou exportar (PNG, JPEG,  PDF e SVG) toda a estrutura do gráfico em exibição. Para isto é necessário clicar em  um dos ícones destacados também na parte superior direita da Figura 7.   6.1. Gráficos da Aplicação WEB   Neste tópico serão apresentados os gráficos obtidos da aplicação WEB para  monitoramento online referente aos dados de tensão, corrente e potência elétrica. O  formato do gráfico de tensão do painel FV, permanece estável nos dias de sol pleno,  apresentando um máximo de 19,3V ao meio dia e mantendo-se em torno de 19V de 06h  da manhã até às 17h.    A corrente na bomba FV tende a acompanhar a radiação solar, chegando a um  máximo de 3,7A às 12h, momento este em que há um pico de radiação. O gráfico de  potência elétrica é obtido multiplicando-se os valores de tensão e de corrente elétrica do  gerador FV.  A potência mantém em torno de 70W, ou seja, se a tensão gerada é de  19,29V e a corrente é de 3,64A, tem-se que a potência é aproximadamente 70W. Na  Figura 8 é possível visualizar os gráficos de tensão, corrente e potência elétrica em um  dia de monitoramento.   Filtrar por  dia   Exibir logs   Imprimir/Exportart ar   Atualizar     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       229     Figura 8. Gráfico de tensão, corrente e potência elétrica     A Figura 9 apresenta os valores de radiação solar e temperatura ambiente para  um dia típico de sol pleno em Fortaleza-CE. Às 11h35min, a radiação solar apresentou  uma medição de 607 W/m2 conforme mostrado na Figura 9.  Como esperado, a  radiação aumenta a partir de 6h, gradativamente, até o máximo ao meio dia e decresce  até as 17h, onde há pouca radiação solar sobre o painel FV.     Figura 9. Gráfico de temperatura e radiação solar ambiente     Quanto à temperatura ambiente, onde está instalado o sistema de bombeamento  FV, o valor de temperatura variou de 28ºC até o máximo de 35ºC às 17h30min.     A temperatura ambiente apresenta o valor máximo algumas horas após os  maiores índices de radiação, devido ao acúmulo de calor no ambiente.      7. Considerações finais   Como os recursos financeiros dos países em desenvolvimento são geralmente limitados,  as soluções dedicadas para monitoramento e identificação dos recursos energéticos  locais e para o monitoramento em tempo real de plantas descentralizadas que utilizam  fontes renováveis de energia podem contribuir para uma política de descentralização da  geração de energia elétrica nestes países.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 223 - 230  Nov/2014       230    O presente artigo apresentou uma proposta de sistema de aquisição de dados  sem fio, supervisão online aplicados à microgeração descentralizada de energia elétrica  a partir de fontes renováveis de energia.     O sistema desenvolvido de monitoramento WEB e aquisição de dados de uma  planta de microgeração mostrou-se eficaz devido à possibilidade de consulta online e  em tempo real da operação da planta de microgeração elétrica, apresentando um  comportamento de acordo com o projeto.    A utilização de ferramentas baseadas em softwares livres para sistemas de  monitoramento online, aplicadas em microgeração, permite maior interação e  acessibilidade aos usuários em geral.     O modelo WiFi de monitoramento online e aquisição/envio de dados proposto  pode ser expandido para registrar dados de outros tipos de sensores analógicos ou  digitais, bem como para outros tipos de aplicações utilizando fontes renováveis de  energia.      Referências   ANEEL (2012) “Resolução nº 482, de 17 de abril de 2012”, http://www.aneel.gov.br/ce  doc/ren2012482.pdf, Abril.   Grupo SanUSB (2013) “Ferramenta SanUSB”, http://www.tinyurl.com/SanUSB, Abril.   Paulson, J.W., Succi, G., Eberlein, A. (2004) “An empirical study of open-source and  closed-source software products”, IEEE Transactions on Software Engineering, 30,  246-256.   Kurose, J. and Ross, K. (2003) “Redes de computadores e a internet: uma nova  abordagem”, 1ª ed. São Paulo: Addison Wesley. 548 p.   WiFi Alliance (2012) “The How and Why of Wi-Fi”, https://www.wifi.org/knowledgecenter/articles/how-and-why-wi-fi, Outubro.   Highcharts (2014) “API Reference”, http://www.highcharts.com/products/highcharts,  Janeiro.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       231   Where am I? Desenvolvimento de um Objeto de  Aprendizagem para o auxílio de alunos iniciantes na língua   inglesa   Deivid Eive S. Silva¹, Vanessa O. Silva¹, Marialina Correa Sobrinho²   ¹ Curso de Sistemas de Informação – Centro Universitário Luterano de Santarém  (CEULS/ULBRA) Santarém – PA – Brasil – Acadêmico do trabalho Interdisciplinar   ² Curso de Sistemas de Informação – Centro Universitário Luterano de  Santarém – PA – Brasil – Orientadora do projeto   deivid.eive@gmail.com, vanessaperola19@gmail.com,  linasobrinho@gmail.com      Abstract This paper aims to teach prepositions in English making use of  Learning Objects – LO, because it has multimedia resource, it can generate  interest in the subject. The difficulty in understanding the prepositions is still  big, the produced object will mainly emphasize the place ones (Out, in, on,  under, behind, in front of, besides, between, the middle of). As part of the  methodology, the LO will be applied using web technology, enabling a more  recreational development. This application will allow students to visualize and  to understand the use of prepositions correctly. The object will serve, in this  sense, as an additional tool in the teaching of this language. This work is in  modeling phase.  Resumo Esse trabalho tem o objetivo de ensinar preposições em língua  inglesa fazendo uso dos Objetos de aprendizagem - OAs, pois como comporta  recurso multimídia, consegue gerar interesse pela disciplina. A dificuldade na  compreensão das preposições ainda é grande, o objeto produzido enfatizará  principalmente as de lugar (out, in, on, under, behind, in front of, besides,  between, a middle of). Como parte da metodologia, o OA será desenvolvido  usando tecnologias web, possibilitando um desenvolvimento mais lúdico. Essa  aplicação permitirá ao aluno visualizar e compreender o uso das preposições  corretamente.  O objeto servirá, nesse sentido, como uma ferramenta auxiliar  no ensino deste idioma. Este trabalho encontra-se em fase de modelagem.   1. Introdução  A tecnologia permite criar material didático cada vez mais interativo. Nesse processo,  surge um recurso digital conhecido como Objeto de Aprendizagem (OA) que deriva do  inglês “Learning Objects” - LO, com a finalidade de tornar as aulas mais dinâmicas.  Segundo Willey (2000), OA é qualquer recurso digital que pode ser reutilizado para  apoiar a aprendizagem.    Os docentes, nesse contexto, passam a ter uma ferramenta com a capacidade de  despertar o interesse pelo conteúdo, de reter a atenção dos seus alunos e inclusive de  gerar prazer nos processos de ensino e aprendizagem, além de servir para aulas  presenciais quanto a distância. Conforme Moran (1995) Uma mudança significativa,  que vem acentuando-se nos últimos anos, é a necessidade de comunicar-nos através de  sons, imagens e textos, integrando mensagens e tecnologias multimídia.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       232   A proposta deste trabalho é apresentar o desenvolvimento de um material  educativo baseado no conceito de Objeto de Aprendizagem para o ensino de  preposições em língua inglesa.  O Objeto a ser apresentado será desenvolvido com o  objetivo de ensinar este conteúdo com um OA que sirva para o cotidiano do aluno, onde  as aplicações aprendidas possam ser praticadas fora da sala de aula, assim, fortalecendo  o aprendizado adquirido, pois acredita-se que fazendo uso diariamente e tendo a noção  da aplicação no  meio será mais difícil de ser esquecida.   A metodologia a ser utilizada para a implementação do mesmo são ferramentas  web, aplicando um modelo de processo adaptado de engenharia software –P@PSEduc  (Processo Ágil para Sistemas Educativos). Onde o mesmo será detalhado na seção três.   O artigo está organizado em seções. A próxima seção trata sobre a importância  dos OAs na escola. Na seção três será apresentada a metodologia utilizada. Na quarta  seção contém a modelagem do produto e por fim a conclusão.   2. A Importância dos OAs na Escola  A inserção de recursos digitais no ambiente educacional se explica pelo fato de a atual  geração já nascer sob grande influência das tecnologias. Conforme Mendelsohn (1997),  “as crianças nascem em uma cultura em que se clica, e o dever dos professores é inserirse no universo de seus alunos". Segundo Vasconcelos (2014) em um “levantamento do  Ibope, 17% dos jovens das capitais e regiões metropolitanas têm tablet. Dos que usam  celular, 47% têm smartphone. Destes, 82% navegam na web pelo smartphone, enquanto  28% ficam com seus tablets”.    Com a proliferação das novas tecnologias, o espaço escolar é definitivamente  atingido pelas novas formas de informar e de se comunicar. Deste modo, o docente  passa a usar OAs como suporte no desenvolvimento de seu trabalho junto ao aluno.   Os objetos educacionais atuam como facilitadores nos processos de ensino e  aprendizagem, auxiliando professores em suas propostas pedagógicas. Para Nunes  (2004), “os objetos de aprendizagem são um recurso a mais. Em alguns casos eles não  são a melhor pedida. Em outros, são ideais. É o professor quem decide”.    A tecnologia construiu um caminho sem volta, precisa-se então procurar  conhecer meios que permitam atingir as expectativas da nova geração digital.   2.1. Agregando OAs na Disciplina de Língua Inglesa  O professor que desenvolve ou usa OAs, pode preparar a sua aula com mais   prazer e motivação, conseguindo maior facilidade em aumentar o desempenho e atingir  índices satisfatórios de seus alunos, utilizando sons, figuras e animações; pois, a  aplicação midiática passa ganhar à atenção de alguém para aquilo que é proposto  comunicar.   Tradicionalmente, nas aulas de inglês, usam-se livros, filmes, músicas, propõem  atividades com a finalidade de atingir uma melhor compreensão do conteúdo ministrado  na disciplina, tornando as aulas mais entretidas e agradáveis. Segundo Leffa (2006):   Durante muito tempo, essa unidade foi a palavra: dava-se ao aluno uma lista  de palavras da língua a ser aprendida [...]. Já em outro período, a unidade  operacional foi a frase: dividia-se a língua em frases padrão que deveriam ser  automatizadas pelo aluno. Houve também uma época em que se privilegiou o  evento comunicativo [...] ensinava-se ao aluno o que ele deveria dizer em     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       233   determinadas situações, tais como apresentar um amigo, registrar-se num  hotel, fazer um pedido no restaurante. [LEFFA 2006].   Pode-se notar que esses traços mencionados por Leffa ainda são vistos dentro da  sala de aula na ministração desta disciplina.   Os recursos midiáticos, nesse sentido, tem chamado a atenção dos pesquisadores  inclusive para o ensino de língua inglesa, pois, como visto anteriormente, o professor  busca elementos que sejam mais eficazes na consolidação do conhecimento e que  sirvam de apoio ao discente dentro quanto fora da sala de aula.   Para validar tal ideia um grupo de pesquisadores de uma cidade X aplicaram  Objetos de Aprendizagem desenvolvidos para alunos do 2° ao 4° ano de uma escola Y,  a fim de fazer uma retomada dos conhecimentos adquiridos em sala de aula.     As aplicações das atividades geraram valiosas informações, visto que os  comentários dos alunos, que posteriormente foram divididos em categorias,  tornaram-se instrumento fundamental para a percepção do auxílio desses  objetos de aprendizagem no processo de ensino infantil. Durante a aplicação,  foi possível ouvir comentários como: “Isso é bem melhor que ficar fazendo  os exercícios da apostila que nem as outras professoras de inglês nos  mandavam”, o que mostra o grau de satisfação e motivação dos alunos em ter  aulas lúdicas, que fogem do ensino tradicional. Também foi possível observar  a contribuição desse tipo de atividade para a aprendizagem, através de  comentários como: “Tia Fernanda, gostei desse jogo! Eu não lembrava como  era “olho” em inglês e no jogo tinha o desenho do olho e eu tinha que dizer  se era true ou false e eu marquei errado, mas agora eu sei que é eye porque  apareceu pra mim.”. (SAGGIOMO, BINSFELD e IRALA, 2010).    Outro grupo de pesquisadores de uma cidade A, adotaram um método em duas  turmas do 5° ano, equivalente a 63 alunos, para validar, seu material desenvolvido. No  primeiro momento, a professora de inglês ensinou os conteúdos normalmente, sem  conhecimento de OA, e ao final, aplicou uma prova de 10 questões referente aos  assuntos ministrados. No segundo momento, a mesma docente utilizou o laboratório de  informática para trabalhar a sua disciplina, mas desta vez, utilizando os OAs  disponíveis, após isso, aplicou uma nova avaliação também de 10 questões com o  mesmo grau de complexidade que a anterior. O resultado obtido foi que o teste usando o  material digital surtiu maior efeito. (Corrêa Sobrinho, Cardoso e Favero, 2006). A  figura 1 demonstra a comparação gráfica entre o antes e o depois deste processo.     Figura 1. Histograma dos resultados antes e depois do uso de Objetos de Aprendizagem.   Fonte: Correa Sobrinho, Cardoso e Favero, 2006.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       234   Então, sabendo do potencial desse material é de fundamental importância a sua  inserção nas disciplinas de língua inglesa, em razão de que estes artifícios podem ajudar  na aprendizagem da criança, podendo ser mais uma ferramenta para contribuir com o  ensino de idiomas.   3. Metodologia  Com o objetivo de cumprir exigências, optou-se por um Processo Ágil para  Desenvolvimento de Software Educativo – P@PSEduc, pois garante estabilidade no  desenvolvimento e possibilita organizar as atividades. (Geller, Corrêa Sobrinho e  Araújo, 2009).   A figura 2 mostra o diagrama de atividade do processo P@PSEduc.     Figura 2. Diagrama de atividades do P@PSeduc.                                            Fonte: Geller, Correa Sobrinho e Araújo, 2009.      Na primeira etapa do trabalho foi definido o tema. Em seguida, foram ouvidos 8  professores que lecionam língua inglesa nas escolas particulares da cidade de Santarém,  para definição do conteúdo a ser abordado. Foi identificado um grau de dificuldade  maior no aprendizado das preposições de lugar, elas serão o foco desse trabalho (out, in,  on, under, behind, in front of, besides, between, a middle of).    Em seguida, definiu-se o objetivo, o público alvo, como o objeto será usado e a  sua respectiva finalidade (com a ajuda de uma pedagoga foi possível ter uma visão mais  característica do aluno). Para a produção do OA foram identificados os recursos  disponíveis e o formato para o desenvolvimento. Além disso, foram pesquisados o uso  dos OAs e as formas existentes no ensino do idioma na web. Com base nisso, foi  possível definir o produto total, um objeto de aprendizagem que facilite o ensino de  preposições em língua inglesa de uma maneira interativa e agradável. O requisito a ser  priorizado é a tela de menu vista na figura 3 com intuito de apresentar o que será  proposto no OA.         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       235      Figura 3. Ilustração da tela de menu.                                         Fonte: Arquivo Pessoal.   4. Modelagem  O objeto será apresentado desta maneira: primeiro – tela de apresentação; segundo - tela  de menu.  Na última tela, o aluno precisará responder a seguinte pergunta: What do you  want to study now? (O que você deseja estudar agora?), precisando decidir por  preferência ou prioridade o que fará: (1) studying prepositions (estudando preposições),  (2) practicing (praticando). Deste modo, em apenas um clique o mesmo será  direcionado para a página solicitada.   Se o estudante (escolher 1), aparecerão as telas, uma de cada vez, explicando o  conteúdo de forma dinâmica, contendo animações que o aluno poderá visualizar e  compreender o uso das preposições corretamente, tendo a possibilidade de ouvir e ler.  Assim, reforçando o que o professor ministrou, ou não, em sala de aula. Se o estudante  (escolher 2), surgirá uma próxima tela com alguns ícones representando ambientes  distintos, em que o usuário poderá escolher para onde quer ser direcionado: bedroom  (quarto), kitchen (cozinha) ou classroom (sala de aula), com intuito de mostrar a  utilização, o contexto de uso  das preposições em sua rotina (em lugares onde o  estudante costuma frequentar), inserindo, então, o conteúdo no universo do  estudante,através de atividades propostas, como encaixe de termos visto na figuras 5 o  esquema do practcing.                     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       236   Figuras 5. Esquematização de telas referente a opção 2 da tela de menu e suas  respetivas atividades propostas nos ambientes escolhidos.    Fonte: Arquivo pessoal.     Além dessa, terá outra atividade em que o mesmo precisará deixar o lugar   escolhido organizado, (o aluno terá um tempo para visualizar os objetos, logo depois,  tudo sairá do lugar e o mesmo precisará colocar as coisas em ordem novamente, apenas  lendo e ouvindo as dicas dispostas, visto na figura 6).   Figura 6. Simulação de atividade do OA.                                   Fonte: Arquivo pessoal   Visando o público almejado e o contexto da aplicação proposta no estudo de  língua, foram identificados recursos midiáticos, interatividade, acessibilidade em  armazenamento e navegação. Com base nisso, foi selecionado o Framework Laravel,  que Segundo Imasters Box (2013) é “um framework PHP com uma sintaxe elegante e  expressiva, focado em trazer uma experiência de programação agradável, criativa e  reconfortante.”, levando em consideração o suporte oferecido para o desenvolvimento  do OA (produtividade e interatividade), por ser de código aberto e permitir alterações e  implementações necessárias na aplicação.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       237   Para que sejam feitas essas implementações precisas, se faz necessária a  instalação de ferramentas adicionais, que somadas darão todo o suporte ao Laravel.  Com base na pesquisa, foi encontrado o WampSever, um ambiente de desenvolvimento  web que quando instalado fornece as ferramentas que serão necessárias e utilizadas  neste processo, como: PHP, MySQL e Apache.    A ferramenta PHP é uma linguagem muito utilizada para o desenvolvimento de  aplicações web embutível dentro do HTML (Linguagem de Marcação de Hipertexto).  Como dito anteriormente, optou-se pelo MySQL para o desenvolvimento do banco de  dados com a função de armazenar as informações relevantes das atividades ocorridas no  objeto educacional.  O Apache, neste processo, como mencionado, será utilizado como  servidor. Outra ferramenta que também comportará no desenvolvimento do OA é o  software Audacity, um programa que permite editar, gravar, importar e exportar  diversos formatos diferentes de arquivos de áudio.    O objeto educacional, logo, terá base para ser desenvolvido com grande  ludicidade, favorecendo para um melhor rendimento e aproveitamento escolar.     4. Conclusão  Diante de todo o processo de pesquisa desenvolvida é possível dizer que a educação  baseada em multimídia aprimora em muito a educação tradicional, “criando uma  atmosfera de diversão e entusiasmo que permeia todos os aspectos da aprendizagem”,  [STARFALL 2002].   Neste processo, entende-se que os objetos de aprendizagem são recursos  tecnológicos que contribuem para uma melhor compreensão de conteúdos para uma  criança, por exemplo, em razão de que o aparato tecnológico pode influenciar  diretamente no aprendizado do mesmo, fazendo-o mais participativo e interessado,  principalmente para aqueles que apresentam déficit de atenção.    Eles são vistos, hoje, como peças chave na melhoria e no aumento da  aprendizagem. Então, é importante pensar, a partir desta pesquisa, em formas de ensinar  e aprender, de modo que os discentes possam ser também autores de sua própria  aprendizagem.   Este trabalho encontra-se em fase de modelagem. O teste de aceitação deste  produto será feito nos laboratórios de informática com as turmas dos professores de  língua inglesa entrevistados para produção deste projeto e que expressaram suas  dificuldades em fazer o aluno entender o conteúdo aqui apresentado - preposições.   Por conseguinte, o objeto descrito nesse artigo servirá como um fator relevante e  adicional no meio educacional para a disciplina de Língua Inglesa.   5. Referencias   Corrêa Sobrinho, M.; Cardoso, P. C. F.; Favero, E. L. (2006) “Objetos de   Aprendizagem no Ensino de Inglês”. Porto Alegre: UFRGS, vol. 4, n.2. 2006.  Disponível em: <http://seer.ufrgs.br/renote/article/view/14137>. Acesso em: 10 mar.  2014.   Geller, M. T. B; CorrêaSobrinho, M; Araújo, C. A. P. (2009) “Proposta de  Customização de um Processo para desenvolvimento de Software Educativo”.  Florianópolis: SBIE - Simpósio Brasileiro de Informática naEducação. Disponível     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 231-238  Nov/2014       238   em: <http://www.niee.ufrgs.br/eventos/SBIE/2009/artresumidos.html>. Acesso em:  10 ago. 2014.   Imaster Box: Laravel (2013). Disponível em:  <https://imasters.com.br/box/ferramenta/laravel/>. Acesso em: 23 mai. 2014.   Leffa, Vilson. (2006) “Nem tudo que balança cai: Objetos de Aprendizagem no Ensino  de Línguas”. Polifonia: Revista de Periódicos Científicos. Cuiabá: UFMT,vol. 12, n.  2.  Disponível em:  <http://www.periodicoscientificos.ufmt.br/ojs/index.php/polifonia/article/viewFile/1 069/841>. Acesso em: 10 jan. 2014.   Mendelsohn, Patrick. "suplemento de informática de L’Hebdo”. 1997, Extraído do  livro, Novas Competências para Ensinar, Philippe Perrenoud.   Moran, José Manuel. (1995) “Novas tecnologias e o reencantamento do mundo”.  Revista tecnologia educacional. Rio de Janeiro: UNICAMP, vol. 23, n. 126.  Disponível em:  <http://www.eca.usp.br/prof/moran/site/textos/tecnologias_eduacacao/novtec.pdf>.  Acesso em: 11 mai. 2014.   Nunes, César. (2004) “Objetos de aprendizagem a serviço do professor”. Microsoft  Educação. Entrevista publicada em: 19 nov. 2004. Disponível em:  <http://www.microsoft.com/brasil/educacao/parceiro/objeto_texto.mspx>. Acesso  em: 19 mai. 2014.   Saggiomo, F. L.; Binsfeld, A. F.; Irala, V. B. (2010) “Os Objetos de Aprendizagem no  Ensino de Língua Inglesa Para Crianças”. Unipampa: Anais do Salão Internacional  de Ensino, Pesquisa e Extensão. Disponível em:  <http://seer.unipampa.edu.br/index.php/siepe/article/view/4572>. Acesso em: 15  Out. 2014.   Starfall: "Objetos Educacionais” (2002). Disponível em: <www.starfall.com.br>.  Acesso em: 12 nov. 2013.   Vasconcelos, N. (2014) “Déficit de atenção? Eu?”. Brasil econômico. Disponível em:  <http://brasileconomico.ig.com.br/tecnologia/coluna-nelson/2014-07-22/deficit-deatencao-eu.html>. Acesso em: 16 Out. 2014.   Willey, David A. (2000) “Connecting learning objects to instructional design theory: a  definition, a metaphor, and a taxonomy. Utah StateUniversity”. Disponível em:  <http://reusability.org/read/chapters/wiley.doc>. Acesso em: 10 mar. 2014.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       239   Algoritmos Genéticos na obtenção de uma Grade de Horários  com Múltiplos Cursos para uma Instituição de Ensino   Alexandre Brasil da Silva1, Carlos Michel Betemps1, Milton Heinen1   1Universidade Federal do Pampa (UNIPAMPA) – Bagé – RS – Brasil  alexandre.brasil.eng.comp@gmail.com, {carlos.betemps,   miltonheinen}@unipampa.edu.br   Abstract. This article presents the application of a heuristic technique –  genetic algorithms – solving the problem in the class schedule for multiple  courses in an educational institution. The goal is to sweep the solution space  through a guided technique, so that the timetable concerning the resources  can be allocated efficiently and offer the possibility of real application. The  technique was shown to be applicable in practice through the use of bonus and  penalty criteria of the solutions, and was suitable for the hourly grids  generated results.    Resumo. Este artigo apresenta a aplicação de uma técnica heurística –  algoritmos genéticos – na resolução do problema da grade horária para  múltiplos cursos em uma instituição de ensino. O objetivo foi varrer o espaço  de solução através de uma técnica guiada, para que os recursos concernentes  à grade horária possam ser alocados de maneira eficiente e que ofereçam  possibilidade de aplicação real. A técnica mostrou-se aplicável na prática por  meio do uso de critérios de bonificação e penalização das soluções, sendo que  apresentou resultados adequados para as grades horárias geradas.   1. INTRODUÇÃO  O problema de confecção da grade horária é comum à grande maioria das instituições  de ensino [Ferreira e Corrêa 2010] e a sua solução é denotada na distribuição  sistemática de encontros entre docentes e discentes durante o período letivo [Gervásio  2012]. Essa distribuição deve levar em consideração alguns fatores/restrições como o de  professores ministrarem disciplinas com as quais possuem afinidades, docentes não  serem alocados em duas salas num mesmo horário concomitantemente, uma mesma sala  não ser ocupada por duas turmas com disciplinas diferentes num mesmo período  [Simonetti 2007], etc.   É visto que quanto maior o número de recursos (docentes, salas, disciplinas,  turmas), maior será o número de combinações que poderão ser feitas, tornando mais  fácil a ocorrência de erros e colisões de disciplinas e docentes. Se a solução for buscada  de forma manual acaba tornando-se inviável, necessitando de um fator computacional  como meio auxiliar nesta atividade [Lobo 2005].    Deste modo, este problema ainda pode possuir um conjunto de soluções que  satisfazem as restrições de seu escopo, formando um conjunto de respostas corretas. Ele  é um dos clássicos problemas da computação [De Oliveira 2000], cujos autores  denominam timetabling problem, e é classificado como pertencente à classe dos  problemas NP-Difíceis [Gervásio 2012].   A inteligência artificial, através de suas técnicas de busca, tem sido muito  empregada em problemas que possuem um elevado número de recursos que devem ser     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       240   combinados, alocados, e submetidos a determinadas restrições. Entre estas técnicas,  destacam-se os algoritmos genéticos, que muitas vezes apresentam resultados  extremamente satisfatórios para estes tipos de problemas [Lobo 2005].   Este tema já foi abordado em vários trabalhos, como em [Ferreira e Corrêa  2010], [Gervásio 2012], [Simonetti 2007], [Lobo 2005], [De Oliveira 2000]. O que os  difere é o método como os genes, os indivíduos e os operadores genéticos são  implementados. São utilizadas as mais diversas estruturas de dados e inúmeras  variações do fluxograma clássico de um algoritmo genético.     Neste artigo, as seções ficam divididas em: Seção 2 (Metodologia e  Desenvolvimento do Trabalho) que explana os componentes e como o problema foi  modelado para ser tratado pela técnica em questão. Seção 3 (Experimentos e  Resultados) mostra quais resultados foram obtidos a partir dos testes realizados e a  Seção 4 (Conclusões) expõe as conclusões obtidas até o presente momento.  2. METODOLOGIA E DESENVOLVIMENTO DO TRABALHO  Os algoritmos genéticos, dentro da inteligência artificial, são uma subárea dos  algoritmos evolucionários. Estes são altamente inspirados na teoria da seleção natural  de Charles Darwin, em que indivíduos mais aptos sobrevivem por maior tempo, e têm,  desta forma, maior chance de realizarem cruzamentos, fazendo com que eles possam  carregar seu material genético mais vezes às gerações futuras. Desta maneira, o  algoritmo pode direcionar sua pesquisa dentro do espaço de buscas através da realização  de um tipo de “refinamento da espécie”. Esta é uma técnica aleatório-guiada, em que  leva-se em consideração as iterações ocorridas para tornar mais eficiente sua passagem  pelo espaço de buscas (guiada), porém, sempre levando em consideração, informações  que estão dentro de um universo probabilístico (aleatório)[Linden 2012].   Conforme [De Oliveira 2000], [Linden 2012] e [Lobo 2005], a escolha dos  Algoritmos Genéticos para o problema em questão, deu-se, entre outros fatores,  principalmente por: poderem resolver problemas complexos de forma confiável; a  construção de um Algoritmo Genético e de seus modelos é algo geralmente simples de  ser implementado; são extensíveis a outros problemas; existe uma certa facilidade de  combinação com outros métodos de busca, principalmente no que se refere a questão de  otimização dos seus parâmetros de execução; existe a plena possibilidade de  implementação que tire vantagem de arquiteturas paralelas.   As informações sobre o problema, e como elas serão modeladas dentro dos  genes/indivíduos, não seguem uma regra, elas somente devem representar o problema  da melhor, e mais eficiente, forma possível [Linden 2012].    Enumeram-se abaixo os elementos necessários no AG implementado:  Gene: parcela indivisível de um indivíduo, implementado na forma de uma tupla com  as informações de disciplina, docente, sala, semestre e curso.   Indivíduo: é formado por um conjunto de genes e é uma das soluções candidatas à  resposta para o problema. Foi implementado na forma de uma lista de matrizes, onde  cada posição de suas matrizes é ocupada por um gene. Cada objeto desta lista refere-se  à grade horária de determinado semestre, e a matriz da grade do último semestre de  determinado curso é seguida pela matriz que possui a grade horária do primeiro  semestre do próximo curso selecionado para confecção dos horários.   Como pode ser observado na figura 2, as 4 primeiras linhas de cada matriz  representam os períodos da manhã e da tarde, e as duas últimas linhas representam os     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       241   períodos noturnos. A linha identificada por “Intervalo Turnos” (quinta linha) é o  período de intervalo entre os turnos (noturno/diurno) e pode ser usada como período  letivo. Cada linha nesta representação equivale a dois períodos consecutivos (forma  usual de alocação na UNIPAMPA Campus Bagé) onde cada gene terá na verdade, dois  períodos consecutivos de uma mesma disciplina.   População: conjunto de n indivíduos (parametrizado antes da execução do algoritmo)  coexistindo no período t de tempo. Na primeira geração (população inicial), este t é  zero.  População Inicial: Criada de forma aleatória, apenas combinando nos genes as  informações de disciplinas, docentes, salas, semestres e cursos, e distribuindo-os dentro  das matrizes dos indivíduos. Os únicos itens observados são os de não alocar disciplinas  à docentes que não possuem afinidade com a mesma, e de não alocar disciplinas em  semestres que são diferentes dos semestres/cursos nos quais são ofertadas.  Geração: variação dos indivíduos da população conforme as gerações (t) aumentam. É  um valor maior ou igual a 0; acrescido de 1 a cada iteração do algoritmo.  Função de Avaliação: função que calcula a aptidão (métrica) de um indivíduo em  relação à resposta esperada para o problema. Devem ser levadas em consideração,  restrições a serem obrigatoriamente atendidas: a não ocorrências de aulas concomitantes  para um mesmo docente em salas diferentes e não haver disciplinas diferentes alocadas  em uma mesma sala em um mesmo horário. Existem também restrições que  preferencialmente devem ser satisfeitas (mas caso não sejam satisfeitas, não invalidam a  resposta): alocação dos docentes conforme suas preferências de horários (indisponíveis,  disponíveis e preferenciais) e o controle da carga horária distribuída entre os docentes.    Cada gene alocado em uma matriz é um bônus para o indivíduo, assim como  quando um docente é alocado em um período em que o mesmo tem preferência por  ministrar suas aulas. Quando um docente é designado em um período em que é tido  como indisponível, quando é alocado em duas salas num mesmo período e quando  disciplinas diferentes são alocadas simultaneamente numa mesma sala, são  penalizações.   Também é tido como penalização, o resultado do cálculo do desvio padrão na  distribuição da carga horária entre os docentes. Indivíduos que possuem carga horária  distribuída de maneira mais igualitária (menor desvio padrão) são menos penalizados  nas suas avaliações do que indivíduos em que o desvio padrão é mais alto.     Figura 10. Indivíduo implementado, com suas matrizes.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       242    A equação 1 mostra a função que calcula a aptidão de um indivíduo.  f (x)=∑ bônus−∑ penalizações                 Equação (1)      Método de Seleção: É como os indivíduos são selecionados para que possam realizar  os cruzamentos entre si ou mutações originando novos indivíduos. Os métodos de  seleção abordados foram o elitismo e a roleta. O elitismo faz com que os m melhores  indivíduos da geração t sejam passados diretamente à próxima, e os indivíduos que  faltam (p indivíduos) para completar os n indivíduos da população da geração t+1 vêm  da seleção da roleta. A roleta seleciona p pares de indivíduos e os submete aos  operadores genéticos, que originam os (n - m) novos indivíduos para compor a  população. O tamanho da população de cada geração é dada pela equação 2.  n=m+ p                 Equação (2)     Operadores Genéticos: são as formas com que o material genético dos indivíduos são  trocados ou modificados no momento da reprodução. Os operadores utilizados foram o  cruzamento e a mutação. Baseado no parâmetro “probabilidade de cruzamento”, do  algoritmo genético, verifica-se se o mesmo é satisfeito. Caso positivo, ocorre o  cruzamento entre os pais selecionados pela roleta e o indivíduo resultante é adicionado à  população da próxima geração. Se o parâmetro não for satisfeito, um dos pais  selecionados é modificado pelo operador de mutação, criando um novo indivíduo, que  por sua vez é adicionado à população da próxima geração.    No cruzamento (figura 2), a composição do indivíduo “filho” é baseada em  sorteios (1 ou 0). Se o valor sorteado for 0, a matriz do filho resultante é originária do  pai 0, se o valor sorteado for 1, a matriz que fará parte do “filho” é oriunda do pai 1.   Na mutação (figura 3), é verificado cada gene do indivíduo em todas suas matrizes e,  conforme o parâmetro “probabilidade de mutação”, os genes podem ou não serem  trocados de lugar um com os outros de forma aleatória.     É importante observar que a distribuição dos genes dentro das matrizes não é  alterada pelo operador de cruzamento, e sim pelo operador de mutação. Se não fosse por  meio deste operador, a distribuição dos genes dentro das matrizes nunca seria alterada  desde a criação da população inicial até o término da execução do algoritmo. O  operador de mutação possibilita, desta forma, que a técnica consiga aumentar seu  espaço de busca, não previsto em sua primeira geração.  Critério de Parada: Foi utilizado como critério de parada o parâmetro número máximo  de gerações (tmáx). Quando este é alcançado, o que possuir a melhor avaliação e  pertencer à população da geração tmáx  e é tido como resposta para o problema.     Figura 11. Operadores genéticos: cruzamento entre pais     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       243   3. EXPERIMENTOS E RESULTADOS    Os experimentos foram realizados em uma plataforma Windows 8.1, com processador  Intel Core I7 e 8 Gb de memória RAM, sendo o algoritmo implementado de forma  sequencial na linguagem de programação JAVA.   Vários testes foram realizados na geração de uma grade horária. Foram  analisadas as informações da grade horária gerada, das parametrizações utilizadas e dos  resultados obtidos pelo algoritmo. Isto possibilitou verificar quais parâmetros deveriam  ser maximizados na função de avaliação e os cuidados a serem tomados para que  bonificações não amortizassem penalizações. Com isso, chegou-se a configuração de  parâmetros da função de avaliação para execução do algoritmo conforme mostra a  Tabela 1. A obtenção destes parâmetros ocorreu de forma empírica, sendo que a cada  execução do algoritmo, os resultados eram analisados com sua referida parametrização,  e comparados com novas execuções com parametrizações modificadas. Foi realizada a  observação de quanto as modificações destas variáveis implicariam na avaliação do  melhor indivíduo ao final de cada execução do algoritmo.  Tabela 4. Tabela dos parâmetros da função de avaliação.   Parâmetro Peso atribuído   Penalização por alocação de docente em período indisponível 120   Penalização sobre o cálculo do desvio padrão na distribuição de  disciplinas   2000   Penalização por ocorrência de colisão entre salas/horários dos  professores   700   Bônus por alocação de docente em período preferencial 30    Para simulação, foram importados da planilha de horários do semestre 2014/1 do  campus Bagé da UNIPAMPA (disponível em seu sítio da internet) os dados das  afinidades entre os docentes e as disciplinas, e as preferências dos dias e períodos que  estes possuem para ministrar suas aulas. Isto foi baseado nas alocações constantes na  referida planilha, de forma que se um docente foi alocado, por exemplo, na segundafeira, nos dois últimos períodos da noite e na terça-feira, nos dois primeiros períodos da  tarde, para efeito de simulação, estes são os seus períodos preferenciais e o mesmo  possui afinidade com a referida disciplina. Contabilizou-se um total de 638 períodos  preferenciais e foram adicionados aleatoriamente 24 períodos divididos entre 4  docentes, em que os mesmos estariam indisponíveis para ministrar suas disciplinas. O      Figura 12.Mutação de um indivíduo     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       244   quadro abaixo mostra o resumo de uma das melhores execuções da implementação:   Tamanho das populações: 1000  Número máximo de gerações: 3000  Percentual Elitismo: 10  Probabilidade de mutação: 0.5%  Probabilidade de Crossover: 65%  Avaliação melhor indivíduo: 30709  Total de colisões de salas: 0  Total de colisões de docentes: 0  Total de Disciplinas Alocadas: 248  Total de Períodos Alocados: 429  Desvio padrão na distribuição de disciplinas por docente: 1.91  Total de quebras de restrições de docentes em horários indisponíveis: 0  Total de alocações em horários preferenciais de docentes: 293  Tempo Total: 9402.4 segundos (~ 2 h e 30 min)   Observa-se que do total de períodos alocados, 68,3% foram em horários que os  docentes possuíam preferências por ministrarem suas aulas. Os outros 31,7% eram  indiferentes quanto aos períodos destinados a eles. Todos os períodos em que os  docentes encontravam-se indisponíveis foram preservados.   Restrições que invalidam a aplicação de uma grade horária, como a alocação de  uma sala para duas disciplinas diferentes concomitantemente e um professor ser alocado  para ministrar aulas em duas ou mais salas simultaneamente, foram satisfeitas.    Os testes foram realizados gerando as grades horárias para os semestres ímpares  de 10 cursos de graduação do campus Bagé da UNIPAMPA, totalizando 248 disciplinas  alocadas utilizando para isso 429 períodos disponíveis.   A curva que mostra a evolução das aptidões (avaliações) com a evolução das  gerações pode ser observada na figura 4. Nota-se o rápido crescimento da curva, isso  acontece por causa das colisões de salas e docentes, que por possuírem um dos maiores  valores na parametrização das penalizações, são tratadas primeiramente até serem  sanadas.       Posteriormente pode-se observar um declínio na taxa de crescimento dessa  curva, o que nos leva a perceber que o algoritmo faz com que passem a serem  exploradas as soluções que, após não possuírem mais colisões entre salas e docentes,  coíbem as alocações em que professores estariam indisponíveis para ministrarem suas  aulas. Em seguida, busca as soluções que contemplem também as alocações  preferenciais dos docentes, que é o parâmetro de bônus com menor peso.      Figura 13. Evolução das avaliações do indivíduos , limitado a mil gerações     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       245    Para confrontar esta informação, pode-se observar o gráfico da figura 5, onde  nota-se que tanto a curva das colisões de salas, quanto a curva das colisões de docentes  decaem de forma tão rápida quanto a curva da avaliação dos melhores indivíduos cresce  na figura 4. Sendo que ainda se observa na figura 5 a queda também acentuada do  número de alocações de docentes em períodos em que os mesmos estão indisponíveis.    Quando a curva do melhor indivíduo da figura 4 começa a diminuir sua taxa de  crescimento, acontece a busca do AG em alocar os docentes que ainda não estão seus  em seus horários preferenciais. Isto pode ser confirmado pela figura 6, que é gráfico que  mostra o crescimento do número de alocações dos docentes em horários de sua  preferência. Esta figura ainda mostra que no início da execução do algoritmo, as  primeiras gerações são passadas sem que o número da quantidade de alocações  preferenciais aumente de forma substancial. Este crescimento ocorre logo após este  pequeno período e prossegue até o final da execução do algoritmo.     4. CONCLUSÕES E TRABALHOS FUTUROS  A técnica de exploração de espaço de busca mostrou-se funcional em relação ao  problema proposto, sendo que grades horárias aplicáveis foram geradas com sucesso.  Grades que não poderiam ser aplicadas (com colisões de salas e horários de docentes)  também foram geradas, porém somente ocorreram casos isolados, com populações  pequenas, que limitavam muito o espaço de busca do AG.   Pode-se observar que tanto o tamanho da população quanto o número máximo  de gerações foram itens impactantes no desempenho do algoritmo, pois o tempo de  execução está diretamente relacionado com estes, principalmente por causa do número  de vezes com que as funções de cruzamento, mutação e avaliação são executadas.   Todavia, quanto maior o tamanho das populações, maior ser torna o espaço de  busca e a diversidade genética. Na maioria dos testes, um espaço de buscas grande     Figura 15. Quantidade de alocações preferenciais satisfeitas, limitado a mil   gerações     Figura 14. Quantidade de alocações de salas/docentes com colisão, e   quantidade de docentes alocados em períodos marcados como indisponíveis,  limitado a mil gerações     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 239-246  Nov/2014       246   encontrou soluções bem mais adequadas do que com populações pequenas. Algumas  simulações com populações de 300 indivíduos e número máximo de 300 gerações  apontaram para grades de horários que não possuíam colisões de docentes/salas e nem  ocorriam quebras de períodos em que os docentes estariam indisponíveis, porém poucos  períodos preferenciais foram alocados. Isto mostra que a partir de um certo número de  gerações o algoritmo busca algum tipo de “ajuste fino” para a sua solução, como pôde  ser observado nas figuras 4, 5 e 6.    Como trabalho futuro, observa-se a ideia de alocação e divisão dos discentes em  turmas, que não foi o foco deste trabalho. Essa divisão, possibilitará a alocação de  turmas de diferentes cursos numa mesma sala quando a disciplina entre ambos for igual,  e isto ajudaria tanto na alocação de salas, bem como, principalmente na melhor  distribuição da carga horária entre os docentes.   Seria interessante a execução desta técnica, de modo a explorar o potencial de  arquiteturas paralelas. Como acontece com a função de avaliação, que em uma  população de 3000 indivíduos, é executada 3000 vezes de forma sequencial somente  para uma única geração, ela poderia ser executada de forma paralela para mais de um  indivíduo simultaneamente, obtendo considerável otimização no tempo de execução.   6. REFERÊNCIAS  Linden, R. (2012) “Algoritmos Genéticos” 3ª Edição. Rio de Janeiro: Editora Ciência   Moderna Ltda.  Gervásio, Jairo de F. (2012) “Computação Evolutiva Aplicada ao Problema de Grade   Horária: o Caso do Curso de Análise e Desenvolvimento de Sistemas do IFTM”  Dissertação (Mestrado em Ciências), Universidade Federal do Triângulo Mineiro,  Uberlândia.   Lobo, Eduardo Luis Miranda (2005) “Uma Solução Do Problema De Horário Escolar  Via Algoritmo Genético Paralelo” Dissertação (Mestrado em Modelagem  Matemática e Computacional), Centro Federal de Educação Tecnológica de Minas  Gerais, Belo Horizonte.   Simonetti, Geraldo Bello (2007) “Abordagem do Problema de Programação de Grade  Horária Sujeito a Restrições Utilizando Coloração de Grafos” Dissertação (Mestrado  em Informática), Universidade Federal do Espírito Santo, Vitória.   Ferreira, Hélio de L. J.; Corrêa, Marcos V. (2010) “Implementação de uma Sistema de  Alocação de Professores e Disciplinas em Grades Horárias Utilizando Algoritmos  Genéticos” Trabalho de Conclusão de Curso (Bacharel em Ciências da Computação),  Universidade do Anhembi Morumbi, São Paulo.    De Oliveira, Osmar Braz Júnior (2000) “Otimização de Horários em Instituições de  Horários em Instituições de Ensino Superior Através de Algoritmos Genéticos”  Dissertação (Mestrado em Engenharia de Produção), UFSC, Florianópolis.    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       247   Estudo da Aplicabilidade do Projeto Unplugged com  Crianças Especiais   Rodrigo Erthal Wilson1, Savio Gurgel Ribas2   1Orientador – Docente - Instituto do Noroeste Fluminense de Educação Superior –  Universidade Federal Fluminense (UFF)   CEP 28470-000 – Santo Antônio de Pádua – RJ – Brasil            2Bolsista PIBID – Discente - Instituto do Noroeste Fluminense de Educação Superior  – Universidade Federal Fluminense (UFF)   CEP 28470-000 – Santo Antônio de Pádua – RJ – Brasil  erthal@infes.uff.br, savio_ribas@id.uff.br   Abstract. In this work, visits were made to an institution for teaching children  with special needs, monitoring day to day, and the implementation of some  activities in the book Unplugged, these activities have proposed a stimulus of  computational thinking, differentiating itself from other projects based on  "Unplugged" activities were performed according to the performance of each  student, since students who participated in the project had different  diagnoses, and from the implementation of the project could assess that  exceptional children can learn computing concepts and that these concepts  can help in the development of various both mental and social areas.    Resumo. Neste trabalho foram feitas visitas a uma instituição para ensino de  crianças com necessidades especiais, acompanhamento do dia a dia, e a  aplicação de algumas atividades presentes no livro Unplugged, essas  atividades propuseram um estímulo do pensamento computacional,  diferenciando-se de outros projetos baseados no “Unplugged” as atividades  foram realizadas de acordo com o desempenho de cada aluno, já que os  alunos que participaram do projeto possuíam diagnósticos diferentes, e a  partir da aplicação do projeto conseguimos avaliar que crianças  excepcionais podem aprender conceitos de computação, e que esses  conceitos podem ajudar no desenvolvimento de áreas tanto mentais quanto  sociais.     1. Introdução   Este artigo relata um trabalho aplicabilidade das atividades do livro Computer  Science Unplugged (Bell e Witten, 1995) com crianças com necessidades especiais,  neste trabalho foram aplicados os conceitos de informática sem a utilização do  computador através de atividades lúdicas e interativas e nele buscamos identificar metas  de usabilidade aplicáveis ao ensino de computação, voltado ao aprendizado de crianças  com necessidades especiais. Utilizando atividades sem o computador, mas com  conceitos voltados a ele como ferramenta de melhora de aprendizagem e dos recursos  educacionais propiciados pela interação Humano-Computador.    2. O Projeto Unplugged - O livro “Computer Science Unplugged”   Segundo (Bell e Witten, 1995) o livro “Computer Science Unplugged” consiste  em uma coleção de atividades desenvolvidas com o objetivo de ensinar os fundamentos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       248   da Ciência da Computação sem a necessidade de computadores. Uma grande vantagem  dessa abordagem reside na sua independência de recursos de hardware ou software.  Assim, as “atividades desplugadas” são passíveis de aplicação em localidades remotas  com acesso precário de infraestrutura (sem energia elétrica ou computadores  disponíveis) e podem até ser ministradas por não especialistas em computação. Os  conteúdos abordados nas atividades repousam sobre conceitos fundamentais da Ciência  da Computação, o que torna seu uso abrangente e evita a defasagem do conteúdo no  tempo. Tais atividades têm sido aplicadas e revisadas por diversos pesquisadores e  professores ao redor do mundo dentro de salas de aulas e fora delas. O site do projeto do  Unplugged (www.csunplugged.org) disponibiliza o livro gratuitamente em diversos  idiomas e provê atividades extras e vídeos demonstrativos.   Segundo Scaico et al (2012, p.4) com as atividades propostas é possível praticar  o Pensamento Computacional, que se refere ao uso de técnicas utilizadas na  Computação para a resolução de problemas, como é o caso da abstração de conceitos e  divisão e conquista. Os estudantes aprendem como os computadores fazem para  resolver problemas e aplicam técnicas, através de uma abordagem problematizadora e  orientada a desafios, para resolver situações do cotidiano.   O livro está estruturado em três partes: “Representando as Informações”,  “Algoritmos” e “Representando Procedimentos”. A primeira parte apresenta atividades  que ilustram as formas utilizadas pelos computadores na representação dos dados  tratando de temas como armazenamento e representação da informação (números  binários, texto e imagens) e compressão de dados. A parte sobre “Algoritmos” aborda  métodos computacionais de uso frequente no cotidiano tais como os algoritmos de  ordenação e de busca de informação. A última parte “Representação de Procedimentos”  apresenta conceitos mais avançados, a exemplo dos autômatos de estados finitos, grafos  e das linguagens de programação.     O livro abarca um rol importante de conceitos e respectivas atividades lúdicas  relativas à computação, a exemplo da representação da informação (números binários e  alfabetos), ordenação e busca de dados, autômatos de estados finitos, grafos e  ocorrência e situações de impasse (deadlocks). Tais atividades podem ser executadas  sem o uso do computador; algumas delas podem ser realizadas ao ar livre, o que  representa diferencial importante em relação aos processos de aprendizagem  convencionais.   Realizando pesquisas nós constatamos que não existe no Brasil nenhum projeto  voltado diretamente a crianças com necessidades especiais utilizando o as atividades  propostas do livro Unplugged, então decidimos realizar este estudo e verificamos que as  atividades são aplicáveis a crianças com necessidades especiais, ressaltando que haja  devida adaptação a cada caso de necessidade especial.  3.  Aplicação do Projeto   O presente trabalho foi realizado junto a uma turma com alunos que variavam a  idade entre 13 e 20 anos de ensino especial de uma Associação, a APAE (Associação  dos Pais e Amigos dos Excepcionais), localizada no município de Santo Antônio de  Pádua, a Associação possui em sua grade, o ensino de informática, cujas atividades  realizadas ainda focam somente o computador, softwares e acesso à internet o que  fornece uma visão bastante simplória e restrita dos fundamentos da computação,   Hodiernamente não são trabalhados fundamentos e abstrações dos conceitos  relacionados à computação, o entendimento predominante da sociedade sobre a  computação tem se limitado a utilização de softwares e equipamentos tecnológicos  (laptops e smartphones). Apesar de inicialmente darem uma boa impressão, esse tipo de  abordagem acarreta em limitações como a do pensamento errôneo de que a Computação     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       249   se restringe a capacitação de usos de bens tecnológicos e softwares. Portanto, torna-se  visível a necessidade da aplicação de novas metodologias que não se limitem a  conceitos superficiais quanto ao ensino de Informática.   Sousa et al afirma que o processo de aprendizagem corresponde à forma como  os indivíduos adquirem novos conhecimentos e desenvolvem competências provocando  uma mudança qualitativa na sua estrutura mental. A absorção de informações e  construção de novas estruturas cognitivas pode ser realizada através de técnicas de  ensino-aprendizagem ou a partir da aquisição de novos hábitos motivados pela inerente  e necessária vontade de aprender. Cognição é o ato ou processo de conhecer, o qual  envolve atenção, percepção, memória, raciocínio, juízo, imaginação, pensamento e  linguagem; E o estudo de tais conceitos poderia auxiliar o processo de aprendizagem,  ajudando as crianças com necessidades especiais a adquirirem novos conhecimentos da  mesma forma como aplicados a crianças consideradas normais.    Heidrich et al (2007)  O conhecimento das etapas do processo de alfabetização  torna possível detectar as necessidades educacionais e o processo cognitivo,  favorecendo a compatibilidade do objeto de aprendizagem em cada etapa da  alfabetização.    E iniciando o processo de observação com o dia letivo tendo início às sete horas  da manhã, com a instituição disponibilizando uma Van para transporte coletivo dos  alunos e um café da manhã para todos os alunos e professores; já em sala de aula aos  alunos eram propostas atividades de artesanato, jogos educativos, leitura, brincadeiras e  atividades físicas extra classe, as atividades se assemelhavam muito  a atividades que  são propostas a crianças de anos estudantis iniciais, foram observadas aulas e  atividades, dos alunos  com seus professores do dia a dia, para que fosse possível  conhecer melhor o cotidiano e a rotina das crianças dentro da Instituição, e sempre  sendo orientado pelos professores a  agir com calma, respeito e atenção aos alunos.                   Após o período de observação foram adaptadas e aplicadas as atividades  “Contando os Pontos, Colorindo com Números, A mágica de Virar Cartas, O mais Leve  e o mais pesado e Seja o mais rápido!”.  A experiência consistiu na aplicação das  atividades conceituadas oferecidas pelo livro Computer Science Unplugged (Bell e  Witten, 1995). Ainda com base nas observações feitas na instituição e dos alunos,  algumas atividades propostas pelo livro tiveram que ser adaptadas, sem perder seu foco  e seu conceito, para serem aplicadas a aproximadamente 20 alunos especiais e todos  eles conseguiram realizá-las.   No estudo foram realizadas cinco atividades baseadas no livro, com reuniões  semanais com duração média de uma hora e trinta minutos, Utilizando uma metodologia  de analogias com a vida real, ensino das regras, aplicação das atividades, observação  dos meios que os alunos acharam melhor para a realização das atividades, discussão de  como realizar as atividades devido às dificuldades apresentadas por alguns alunos e para  que não houvesse desmotivação destes, foram feitas modificações nas atividades  propostas no livro utilizando por vezes questões e métodos simplificados sempre com o  intuito de divertir as crianças e não deixá-las associar como uma atividade obrigatória e  competitiva.    4. Aplicação das Atividades   As atividades foram realizadas com os alunos em um período de quatro meses,  sendo realizadas as seguintes atividades “Contando os Pontos”, “Colorindo com  Números”, “Mágica de Virar Cartas”, “O mais Leve e o Mais pesado” e “Seja o Mais  Rápido!”, as atividades foram escolhidas pela diversidade de conceitos computacionais     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       250   e a realidade dos alunos.   Devido os diferentes diagnósticos dos alunos, alguns apresentaram uma  dificuldade mais acentuada nas atividades, fazendo com que a mesma atividade tivesse  que ser aplicada de maneira mais adaptativa a cada aluno.    4.1. Contando os Pontos – Número Binários   Esta atividade consiste em apresentar o conceito dos números binários utilizados  pelos computadores e sua relação com o sistema decimal utilizado hodiernamente. O  objetivo consiste em apreender como as palavras e números são representados no  computador somente através de zeros e uns. Nessa atividade segundo o livro  Unplugged, o aluno utiliza conceitos matemáticos tais como: operações de soma,  multiplicação, sequências numéricas e contagem.                          Para realizar a atividade, foi utilizada a lousa, para representar os cartões em   ordem crescente da direita para esquerda, tal como mostra a figura 1, foi perguntada aos  alunos a quantidade de pontos contidos nos cartões representados na lousa, afim de que  eles percebessem que a quantidade de pontos do cartão a esquerda representava o dobro  de pontos do cartão a direita, em seguida os alunos foram questionados de como deveria  ser representado se quisesse chegar ao valor de nove pontos (figura 2), quais cartões  deveriam exibir, e foram realizados questionamentos orais aos alunos de quais valores  se poderiam obter com quatro cartões.   Todos os alunos conseguiram desenvolver a atividade e posteriormente foi  pedido para que os alunos realizassem na lousa como se deveria representar o número  nove e sequencialmente outros valores, o resultado esperado era a representação de um  valor binário de quatro dígitos, no qual quando o cartão está desenhado mostrando  pontos, seu valor é um e quando está desenhando sem mostrar pontos nenhum, seu  valor é zero.         Figura 1. Representação dos Cartões com Valores (Bell et al,1995)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       251     Figura 2. Representação do valor binário questionado acima (Bell et al,1995)     4.2. Colorindo com Números – Representação de Imagens   Esta atividade visou dar o entendimento de como os computadores armazenam  desenhos, fotografias e outras imagens usando apenas números e de maneira divertida e  lúdica; Foi entrado em discussão com os alunos, como eles imaginavam que os  computadores armazenavam fotografias, os alunos responderam de maneira criativa o  entender deles sobre a indagação.   Em seguida foi explicado que as telas dos computadores são divididas em uma  grade de pequenos pontos chamados pixels (do inglês, pictures elements - elementos de  imagem) e que, por exemplo: Em uma foto preto e branco, cada pixel é preto ou é  branco.    Foi então pedido aos alunos que contassem quantos pixels pretos e brancos em  cada trecho de imagem passados na lousa, respeitando a ordem em que cada pixel  aparecia, sendo que a ordem era sempre primeiro branco e posteriormente preto e caso  começasse com preto, seria necessário escrever que começou com zero branco; Os  alunos apresentaram dificuldade em realizar a representação de imagens com números,  então foi utilizados trechos de imagens e então todos conseguiram desenvolver a  atividade “Colorindo os Pontos”.             4.3. A mágica de virar cartas – Detecção de erros   Esta atividade apresentou a maneira como os dados são armazenados em um  disco ou transmitidos de um computador para outro e que podem ocorrer problemas  com esses dados e eles podem ser alterados, e essa atividade buscou mostrar de maneira  divertida como detectar esses erros e segundo o livro CS Unplugged a atividade ajuda a  desenvolver habilidades de contagem e reconhecimento de números pares e ímpares.   Foi utilizada uma placa de poliestireno branca, e pequenas cartas de papéis  formando uma matriz 5x5 com posições aleatórias das cartas pretas e brancas, então foi  adicionado mais uma coluna e uma linha a matriz para ter uma paridade tornando-a 6x6,  certificado que o número de cartas brancas seja par, então foi pedido a outro aluno que  alterasse o valor de uma carta de preta para branca ou de branca para preta sem que a  pessoa que organizou a pudesse ver o valor alterado, então foi explicado aos alunos que  para descobrir o segredo eles precisariam observar que todas as linhas e colunas  precisam ter um número par cartas brancas, pois eles descobrindo a coluna e a linha  ímpares, eles descobririam exatamente o valor alterado e desenvolveram a atividade  entre eles mesmos.   Figura 3. Exemplo de como a atividade foi  realizado inicialmente (Bell et al,1995)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       252                                 4.4. O mais Leve e o mais Pesado – Algoritmos de Ordenação   Esta atividade apresentou aos alunos diferentes passos a passos que podemos ter  para ordenação de coisas com o intuito de discutir formas de organização eficiente dos  dados que um computador pode utilizar. Foi selecionado um grupo de alunos e cada  aluno do grupo recebeu um cartão com um número único, então foi pedido aos alunos  que restaram para encontrar no grupo selecionado o aluno que estivesse com menor  número, e nos indagamos a melhor maneira de fazer isso comparando apenas dois  alunos por vez. Em seguida, foi pedido aos alunos que ficaram fora do grupo  selecionado para colocar os alunos em ordem crescente utilizando a comparação de dois  alunos por vez. Findo esse passo, foi pedido aos alunos para verificarem se a ordenação  estava correta, comparando cada número dos alunos do grupo selecionado.   Em seguida, foi pedido aos alunos para modificar aleatoriamente a ordem dos  números atribuídos a eles e foi explicada a estratégia da ordenação por seleção, a qual se  fundamenta na seleção do menor número no conjunto a ser ordenado. Sendo que para  realizarem a atividade era preciso entender que primeiro deveríamos encontrar o aluno  com menor número e colocá-lo à parte e, depois deveríamos encontrar o aluno menor  número dentre os alunos restantes, separá-lo e colocá-lo ordenado com os alunos já  selecionados e, assim sucessivamente, até ordenar todo o grupo.                          Figura 5. Representação da Ordenação por Seleção presente no livro CS Unplugged; Com os  alunos da APAE foi realizada a adaptação, com os próprios alunos assumindo um número ao   invés de recipientes. (Bell et al,1995)   Figura 4. Representação da Atividade. (Bell et al,1995)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       253   4.5. Seja o mais rápido! – Redes de Ordenação  Esta atividade visou mostrar aos alunos que os computadores são extremamente   rápidos para a resolução de problemas, mas há um limite, e para ajudar a romper esses  limites para resolver mais problemas em menos tempo, poderiam ser utilizados vários  computadores e nessa atividade utilizamos o conceito de redes de ordenação para  efetuar várias comparações de ordenação ao mesmo tempo, utilizando os próprios  alunos como valores a serem utilizados nessa rede de ordenação.   Os alunos então foram levados até uma Quadra Poliesportiva, onde realizamos  no chão o desenho de vários tipos de redes de ordenação e então os alunos foram  divididos em equipes e cada membro foi atribuído um valor aleatório, então foi  realizado comparações de três tipos de redes de ordenação e qual delas foram realizadas  em menor tempo.                                            5. Observações realizadas   Durante a realização das atividades pode-se observar a evolução dos alunos no  entendimento  de  conteúdos  da computação,  alguns  alunos  apresentaram  ainda  uma maior facilidade na resolução de problemas lógicos, e que possivelmente   Figura 7. Alunos que realizaram as atividades do livro Computer Science Unplugged.   Figura 6. Exemplos de redes desenhadas no chão para atividade. (Bell et al,1995)     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 247-254  Nov/2014       254   aprenderiam muitos conceitos de programação utilizando uma linguagem  computacional; Observou- se que o planejamento, as adaptações e abstrações da  realidade foram fatores desencadeadores do entendimento das atividades propostas  pelo livro, e dentre as dificuldades encontradas ao longo da realização da atividade,  destaca-se a diversidade de diagnósticos dos alunos especiais, os recursos  disponíveis, a dispersão dos alunos, mobilidade dos alunos até a instituição a falta de  instrução dos professores da instituição em relação à informática.  No  final da realização do Projeto da aplicabilidade foi passado um questionário de  avaliação de resultados obtidos com os alunos. O questionário possuía oito questões  de   múltipla   escolha   (Nem   um   pouco,   Pouco,   Bastante   e   Demais)   sobre   o  comportamento do aluno após a realização das atividades e uma justificativa ao final  do questionário,  baseando  no  resultado  do  questionário  aplicado  as  duas   professoras, Raquel e Miliane que atuam diariamente em contato com os alunos que  participaram do projeto, pode-se  observar que dos dez alunos com mais frequência  nas atividades do projeto cinco melhoraram Bastante ou Demais nas atividades de  casa, seis melhoraram Bastante ou Demais o comportamento em atividades que  exigiam manutenção de esforço, cinco melhoraram Bastante ou Demais na capacidade  de resolver problemas matemáticos e de lógica, quatro melhoraram Bastante ou  Demais no comportamento com outros alunos, cinco melhoraram Bastante ou  Demais na capacidade linguística (escrita e falada), sete gostaram Bastante ou Demais  das atividades realizadas, e elas justificaram que o projeto foi muito bem  desenvolvido com os alunos e que o projeto foi muito importante pois despertou neles  o interesse no aprendizado, na curiosidade e no espirito competitivo. E de acordo com  os resultados do questionário, consideramos que o Projeto Unplugged é aplicável ao  ensino de alunos com necessidades especiais.     6. Bibliografia      Bell, T. C. G.; Witten, I. (1995). “Computer Science Unplugged: Capturing the interest        Of the uninterested”. Anais do NZ Computer Conference, Wellington, Nova Zelâdia.   Heidrich, Regina de O., Medina, Gueba, et al (2007). “Recomendações Ergonômicas  para Interfaces: Design Instrucional para Alfabetização de Crianças com  Necessidades Especiais”. Workshop em Informática na Educação (SBIE ).   Scaico, P. D.; Henrique, M. S.; Cunha, F. O. M.; Alencar, Y.M.; (2012). “Um Relato de  Experiências de Estagiários da Licenciatura em Computação com o Ensino de  Computação para Crianças”. CINTED-UFRGS,  Novas Tecnologias na Educação.    Sousa, R. V.; Barreto, L. P.; Andrade, A.; Abdalla, D. (2010). “Ensinando e  aprendendoconceitos sobre ciência da computação sem o uso do computador:  Computação Unplugged!!!”. Práticas em Informática Na Educação: Minicursos do  Congresso Brasileiro de Informática Na Educação, volume 1, número 1.                   
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 256-259 Nov/2014     256  Desenvolvimento de um Protótipo de um Sistema Inteligente  de Apoio à Decisão como Ferramenta de Business   Intelligence: um estudo de caso na Arbaza Alimentos     Maik Frizon, Sidnei Renato Silveira, Guilherme Bernardino da Cunha  mfrizon@fredon.com.br, sidneirenato.silveira@gmail.com, guilherme@ufsm.br     Universidade Federal de Santa Maria (UFSM) – Centro de Educação Superior Norte do   RS (CESNORS) – Frederico Westphalen  Departamento de Tecnologia da Informação – Curso de Bacharelado em Sistemas de   Informação     Resumo: Uma das principais necessidades de uma empresa é possuir o controle do fluxo  de informações que a mesma produz, para que essas informações possam auxiliar na  melhoria contínua dos processos da empresa, com a finalidade de agilizar o seu trabalho  e obter informações concretas no menor tempo possível. Neste contexto, este artigo  propõe a aplicação de técnicas de Inteligência Artificial no desenvolvimento de um  protótipo de ferramenta de Business Intelligence - um Sistema Inteligente de Apoio à  Decisão (SIAD), que será  implantado na empresa Arbaza Alimentos.  Abstract:  One of the main requirements of a company is to have control of the  information flow that it produces, so that this information can assist in the continuous  improvement of business processes, in order to streamline your work and get concrete  information in the shortest possible time . In this context, this paper proposes the  application of Artificial Intelligence techniques in the development of a prototype of  business intelligence tool. The proposal involves the implementation of an Intelligent  Decision Support System (IDSS), which will be deployed in the company Arbaza food.   1. Introdução  Este artigo apresenta uma proposta para desenvolvimento de um protótipo de Sistema  Inteligente de Apoio à tomada de Decisão (SIAD), no contexto de Business Intelligence  (BI), voltado para os gestores e gerentes das áreas logística e financeira da Empresa  Arbaza Alimentos Ltda, com o intuito de auxiliar os mesmos nas tomadas de decisões  com relação a custos de matéria prima e também com relação aos  lucros obtidos através  das vendas dos produtos.   A motivação para o desenvolvimento deste protótipo surgiu a partir do trabalho  desenvolvido no setor Comercial da empresa Arbaza Alimentos, contando com quase  três anos de experiência na gerência da área de Tecnologia da Informação (TI). A  vivência do dia a dia na empresa possibilita uma visão técnica e específica do  andamento do sistema como um todo. Tendo em vista que a TI interliga-se com os  demais setores, sentiu-se a necessidade de trazer novas idéias de aprimoramento e  precisão no controle gerencial para assim desenvolver o trabalho de compra e,  principalmente, de vendas de forma eficaz. A ferramenta proposta permitirá aos  gestores da empresa realizar um controle refinado sobre todo o processo de faturamento  da empresa possibilitando o gerenciamento efetivo e seguro para tomada de decisões.   2. Referencial Teórico  Dresner (2004 citado por SILVA, 2014, p.18) coloca que BI é “um conjunto de  conceitos, ferramentas e tecnologias para aperfeiçoar o processo de tomada de decisão     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 256-259 Nov/2014     257  em negócios, ou seja, é um processo de conseguir informações certas, no momento  oportuno, em uma forma utilizável pelos decisores, de modo que possa ser analisada  para implementar de imediato ações que tenham impacto positivo na condução dos  negócios”.   Os Sistemas de Apoio à Decisão (SAD) são sistemas de informação baseados  em computador que oferecem informações interativas a gerentes e profissionais de  negócios durante o processo decisório e fazem parte das ferramentas de BI (O´BRIEN,  2013). Segundo PRIMAK (2008), SADs são sistemas que permitem total acesso à base  de dados corporativa, modelagem de problemas, simulações e possuem uma interface  amigável. Além disso, auxiliam o executivo em todas as fases de tomada de decisão,  principalmente nas etapas de desenvolvimento, comparação e classificação de riscos,  além de fornecer subsídios para a escolha de uma boa alternativa (PRIMAK, 2008).    Os SIADs (Sistemas Inteligentes de Apoio à Decisão) são uma evolução dos  SADs e pretendem integrar automação de escritórios, Sistemas de Informações  Empresariais, SAD e Sistemas Especialistas em um único ambiente, fornecendo um  conjunto muito mais poderoso de ferramentas ao executivo. Sua interação com técnicas  de Inteligência Artificial permite sugestão de novas alternativas e o aconselhamento  sobre a melhor solução a ser adotada (PRIMAK, 2008).    3. Estado da Arte  Para apoiar o desenvolvimento do SIAD proposto foram estudados três sistemas  implementados como ferramentas de BI. O Sistema Especialista (SE) apresentado em  Dias (2004) – SEAP (Sistema Especialista de Ajuste de Previsão) propõe o ajuste de  previsão de vendas de uma franquia de uma multinacional do segmento de refrigerantes.  As regras de produção foram usadas para representar o conhecimento neste SE. O SE  foi implementado utilizando-se o Expert Sinta. Todas as informações foram obtidas em  entrevistas com as profissionais responsáveis pela previsão de demanda e pelo PCP  (Planejamento e Controle da Produção). O sistema fornece ao usuário a melhor previsão  e retorna dois valores mais otimistas que o valor ótimo e dois valores mais pessimistas.  Estes valores mais otimistas e pessimistas são variações percentuais do valor ótimo  (DIAS, 2004).   O trabalho apresentado por Luchtenberg (2000) é uma ferramenta que visa  auxiliar o processo de tomada de decisões da área comercial de uma empresa, através de  um SE, utilizando estudos de técnicas de vendas, aplicadas na ferramenta SPIRIT  (Simmetrical Probabilistic Intensional Reasoning Inference Transition). As ligações  lógicas são obtidas através de distribuições de probabilidade de ocorrência, por meio de  uma rede causal. A forma de representação do conhecimento no sistema SPIRIT é feita  através de regras de produção.    Pfeifer (2007) apresenta o SE Control-Ger, cujo objetivo é o estudo e a  implementação de módulos integrados a um sistema contábil, empregando técnicas de  IA para apoio e análise de seus lançamentos. O sistema possui um módulo especialista  para apoio e análise dos lançamentos e outro módulo para o usuário, que permite fazer  os lançamentos com os registros, acessando o módulo especialista para utilizar a base de  conhecimento, trazendo um resultado ao usuário. No módulo especialista foi  implementada a base de conhecimento, com uma máquina de inferência que possui uma  árvore de decisão (PFEIFER, 2007). Para o desenvolvimento do Sistema Especialista  foram utilizadas as tecnologias Microsoft .NET, com a linguagem de     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 256-259 Nov/2014     258  programaçãoVisual Basic.NET. Para armazenar a base de conhecimento utilizou-se o  SQL Server Express e, para gerar os relatórios, utilizou-se a ferramenta ReportViewer  para Visual Studio .NET.   4. Solução Proposta  O SIAD proposto será desenvolvido para atender uma necessidade da empresa Arbaza  Alimentos, permitindo um melhor acompanhamento sobre a vida da empresa, com  relação a resultados e metas a serem alcançados nas áreas de vendas e finanças da  empresa. Segundo a gerência de vendas, atualmente a empresa não tem como tomar  uma decisão em tempo hábil com relação as suas vendas, devido a não possuir uma  ferramenta para diagnosticar uma possível queda no volume de vendas em determinada  região, ou um grande desvio padrão de venda de seus principais representantes dentro  do mês vigente, entre outros aspectos, não podendo assim tomar uma medida corretiva  para evitar essas situações.    Atualmente as informações são analisadas por meio de relatórios do Sistema  ERP (Enterprise Resource Planning) empregado na empresa, a partir de um cruzamento  de dados realizado manualmente em planilhas utilizando o Microsoft Excel. Esta análise  e cruzamento demanda muito tempo dos diretores da área de vendas, que perdem o foco  do trabalho, que é o estudo do mercado, visando otimizar os processos de compras e  vendas. Além disso, este cruzamento manual não traz os resultados esperados. É neste  contexto que se justifica a implementação da ferramenta proposta.   Será desenvolvido um SIAD que apresentará inicialmente, por meio de uma  interface web, consultas e relatórios de dados empresariais relativos a toda parte  logística da empresa, envolvendo desde a compra até a venda, mostrando uma visão  atualizada do mercado, no que diz respeito à lucratividade e volume de vendas para os  gerentes comerciais e diretores. O segundo passo, será a visualização de sugestões de  decisões que poderão ser tomadas a partir dos dados analisados. Esta análise será  realizada pelo SIAD proposto, por meio da aplicação de técnicas de IA. Optou-se pela  implementação de um Sistema Especialista, baseado em regras de produção, como  técnica de IA para o SIAD. A aquisição do conhecimento, para construir a base de  conhecimento do SIAD proposto, foi realizada por meio de entrevistas com um  especialista do domínio, que trabalha na Arbaza Alimentos, ocupando o cargo de  Gerente no setor de Compra e Venda. O especialista possui experiência de 25 anos na  área de compra e venda de grãos.   A base de conhecimento do SIAD está estruturada da seguinte forma: toda regra  pertence a uma categoria previamente cadastrada (meta de vendas, faturamento, etc);  todas as variáveis que serão utilizadas nas regras precisam ser cadastradas previamente  (metas de vendas, meses, tipo de produto, etc); cada variável tem um código, nome, tipo  e diferentes valores possíveis (previamente cadastrados) e os seus diferentes valores  possíveis; as regras possuem um identificador,  nome, objetivo, a que categoria  pertencem e ação (a ação pode ser buscar outra regra ou mostrar um texto ao  especialista, indicando a ação que deve ser realizada). Para permitir a manutenção de  base de conhecimento, serão construídas interfaces para fazer o cadastro, alteração,  consulta e exclusão destas informações. A inferência será o algoritmo a ser criado para  buscar as regras e tomar as decisões (quais ações deverão ser mostradas). O SIAD será  implementado utilizando-se a linguagem de programação PHP e o Sistema Gerenciador  de Bancos de Dados (SGBD) Microsoft SQL Server. Após o desenvolvimento do     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 256-259 Nov/2014     259  protótipo de SIAD será realizada uma validação dos resultados apresentados pelo SIAD  com especialistas no assunto, neste caso, os gerentes e diretores da área de vendas da  empresa, após será implementado o sistema na empresa. A figura 1 apresenta uma  proposta de arquitetura para o SIAD.          Interface Web   (Consultas, Relatórios)                       Figura 1: Arquitetura do SIAD proposto   5. Considerações Finais  Até o momento, a aquisição do conhecimento foi uma das tarefas mais difíceis, pois a  comunicação entre o Engenheiro do Conhecimento e o especialista do domínio, apesar  de ser bastante facilitada pela proximidade e disposição do especialista, é dificultada no  que diz respeito à maneira de como o sistema irá se comportar, sendo difícil definir a  forma de representação do conhecimento que pudesse contemplar o raciocínio do  especialista. Atualmente, está sendo realizada a implementação do SIAD proposto, bem  como serão realizados os testes e a validação do mesmo. Também pretende-se realizar  um treinamento com os Diretores da empresa,  acompanhando os resultados, para  verificar se a ferramenta está sendo usada de forma adequada e se a mesma está  apresentando resultados positivos à empresa.   Referências   DIAS, A. S. Uso de Conhecimento Teórico e de Especialista  para previsão de demanda. São   Carlos, SP: Universidade Federal de São Carlos Centro de Ciências Exatas e Tecnologia,  2004-Curso de Pós Graduação em Engenharia da Produção.   LUCHTENBERG, J. Protótipo de Sistema Especialista para área Comercial utilizando a  ferramenta SPIRIT. Blumenau: Universidade Regional de Blumenau, 2000. Trabalho de  Conclusão de Curso – Curso de Bacharelado em Ciência da Computação.   O’BRIEN, J. A. Administração de Sistemas de Informação. Porto Alegre: AMGH, 2013.  PFEIFER, J. T. C. Emprego de técnicas de Inteligência Artificial para apoio e  análise de   lançamentos Contábeis. Porto Alegre: UniRittter, 2007. Trabalho de Conclusão de Curso –  Curso de Bacharelado em Sistemas de Informação.   PRIMAK, F. V. S. Decisões com BI (Business Intelligence). Rio de Janeiro: Ciência Moderna,  2008.   SILVA, C. A. V. Avaliação de uma ferramenta de Business Intelligence em uma indústria  aeronáutica.  Disponível em: < http://homes.dcc.ufba.br/~mauricio052/Topicos em  BD/Material Didático/Monografias/Avaliação de uma Ferramenta de Business intelligence  em uma Indústria Aeronáutica.pdf >. Acessado em: 24 de maio, 2014.         Base de  Conhecimento   Base de Dados  (Compras,  Logística,   SIAD – Sistema  Inteligente de Apoio à   Decisão    
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 260-263 Nov/2014     260  Estudo e Construção de um Protótipo de Framework de  Recomendação para Lojas Virtuais   Kelvin Salton do Prado1, Sidnei Renato Silveira2   1 Universidade Federal de Santa Maria (UFSM/CESNORS) – Curso de Bacharelado em  Sistemas de Informação – Frederico Westphalen – RS – Brasil    2 Departamento de Tecnologia da Informação – Universidade Federal de Santa Maria  (UFSM/CESNORS) - Frederico Westphalen – RS – Brasil    kelvinpfw@hotmail.com, sidneirenato.silveira@gmail.com    Resumo. Sistemas de recomendação permitem que sejam recomendados  produtos para cada cliente ou grupo de clientes em lojas virtuais, podendo ser  um fator muito relevante para a finalização ou não de uma compra. Neste  contexto, este artigo apresenta o estudo e construção de um protótipo de  framework de recomendação para lojas virtuais, com o objetivo principal de  proporcionar um framework funcional aos gestores e analistas de negócios,  para escolherem e configurarem de forma dinâmica o modo de oferta de  produtos específicos em suas lojas virtuais.   Palavras-chave: Framework; Sistemas de Recomendação; Lojas Virtuais.   Abstract. Recommender systems help web shops on the products  recommendation for each client or group of clients and can be very relevant  factor for the completion of a purchase or not. In this context, this paper  proposes the study and construction of a recommendation framework  prototype for web shops, with the main objective of provide a functional  framework for managers and business analysts choose and configure  dynamically the mode of offer of specific products in their web shops.   Keywords: Framework; Recommender Systems; Web Shops.   1. Introdução   Este trabalho tem seu objetivo motivado pelo constante crescimento do comércio  eletrônico no Brasil e no mundo. Segundo pesquisas realizadas pela E-bit (2014), a  previsão de crescimento do comércio eletrônico no Brasil em 2013 era de 25% em  relação a 2012, porém o crescimento nominal em 2013 foi de 28%, superando as  expectativas e fazendo com que o comércio eletrônico brasileiro faturasse mais de R$  28 bilhões. A estimativa para 2014 é que o comércio eletrônico brasileiro cresça 20%  em relação ao ano de 2013, faturando mais de R$ 34 bilhões.     Com este crescimento acabam surgindo alguns problemas, como por exemplo a  sobrecarga de informações sobre os usuários. Segundo Piroca (et. al., 2009) “a  quantidade de informação produzida e disponibilizada na web pode ocasionar uma  sobrecarga cognitiva sobre o usuário final”.  Com isto pode-se entender a necessidade de  um sistema que auxilie os usuários a encontrar produtos e informações que possam ser  de seu interesse. Acredita-se que fatores como este justifiquem o estudo e construção de  um framework de recomendação genérico para as lojas virtuais.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 260-263 Nov/2014     261  2. Referencial Teórico   De acordo com Ricci (et. al., 2011), sistemas de recomendação são ferramentas de  software e técnicas que fornecem sugestões de itens que podem ser úteis para um  usuário. Estas sugestões visam apoiar os usuários em tomadas de decisão, por exemplo,  a comprar algum item.    Pode-se citar como duas principais técnicas de filtragem em sistemas de  recomendação a Filtragem Baseada em Conteúdo e a Filtragem Colaborativa. De acordo  com Cardona e Silveira (2010), a filtragem baseada em conteúdo seleciona itens ou  produtos, que tenham uma correlação entre o conteúdo dos itens ou produtos e as  preferências dos usuários selecionados, enquanto a filtragem colaborativa seleciona os  itens ou produtos com base nas características semelhantes entre os clientes e as suas  preferências. Também pode-se citar aqui a filtragem hibrida que utiliza tanto técnicas da  filtragem baseada em conteúdo como da filtragem colaborativa.   3. Solução Proposta   Pretende-se desenvolver um protótipo de framework de sistemas de recomendação, que  possa ser integrado a qualquer loja virtual, diminuindo assim o esforço e o tempo dos  desenvolvedores, e implementando formas mais eficientes de recomendação de forma  dinâmica e parametrizável.    Com base nas informações existentes nos bancos de dados das lojas virtuais,  será preciso definir as ferramentas e técnicas que permitirão que sejam realizadas as  recomendações dos produtos, baseadas nos parâmetros pré-definidos pelos  administradores das lojas virtuais.    A recomendação dos produtos será realizada, inicialmente, por meio da  aplicação de métodos de filtragem baseada em conteúdo.  Dentro deste contexto de  recomendação, o administrador ou gerente da loja virtual poderá selecionar parâmetros  para gerar as recomendações de acordo com as suas necessidades, porém, estes  parâmetros poderão ou não estar disponíveis de acordo com os campos disponibilizados  pelo banco de dados da loja virtual.  A figura 1 apresenta o diagrama de Casos de Uso,  que auxilia na demonstração das ações dos atores dentro do sistema proposto. Este  diagrama foi desenvolvido utilizando-se da notação de Linguagem de Modelagem  Unificada (UML).    As parametrizações das recomendações serão disponibilizadas por meio de uma  interface gráfica, onde o administrador da loja virtual poderá selecionar os parâmetros  desejados. Poderão ser selecionados parâmetros como: recomendar produtos que estão a  mais tempo no estoque, recomendar produtos que estejam na mesma categoria de  produtos que o usuário já comprou, recomendar produtos que estão de acordo com datas  comemorativas ou estações do ano, entre outros. Dentro destes parâmetros poderá haver  sub-parâmetros, por exemplo, se o usuário selecionar a opção de recomendar produtos  de acordo com as datas comemorativas, ele deverá informar as datas/períodos desejados  para isto, para que possam ser geradas as recomendações de forma correta.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 260-263 Nov/2014     262  Figura 1: Diagrama de Casos de Uso (UML)   O protótipo de framework proposto será desenvolvido utilizando-se a linguagem  de programação PHP, pois é uma linguagem muito utilizada para o desenvolvimento  web e pode ser mesclada dentro de códigos HTML (Hypertext Markup Language). Um  dos motivos de se escolher a linguagem PHP é por ela ser interpretada no lado do  servidor, sendo assim relativamente segura para o desenvolvimento web (PHP.Net,  2014). O banco de dados utilizado para o desenvolvimento será o MySQL, por ser um  dos sistemas gerenciadores de bancos de dados (SGBDs) relacional mais populares e  difundidos hoje em dia, pois é um SGBD bastante rápido, de fácil utilização e que  atende bem as necessidades dos usuários (WELLING; THOMSON, 2005).     O protótipo de framework proposto será validado primeiramente para lojas  virtuais que utilizam banco de dados MySQL, por ser consideravelmente simples a sua  conexão com o PHP, e por ser um SGBD relacional bastante utilizado nos dias de hoje,  porém, a implementação e validação para outros bancos de dados podem ser  apresentadas como trabalhos futuros, com o intuito de deixar o framework o mais  genérico possível. Os testes e a validação do framework proposto por este trabalho serão  realizados a partir de um protótipo de loja virtual que será desenvolvido para estes fins.  Este protótipo de loja virtual contará com as principais tabelas utilizadas em um banco  de dados de uma loja virtual real, as quais serão utilizadas pelo framework para a  obtenção de dados. A partir disto serão criados usuários fictícios para a administração  da loja virtual e consequentemente do framework, os quais selecionarão os parâmetros e  sub-parâmetros para as recomendações.    Após esta etapa será solicitado a usuários reais que criem uma conta de cliente  no protótipo da loja virtual e realizem compras fictícias, para receberem as  recomendações e validarem se as recomendações são realmente de seu interesse ou  satisfaçam os parâmetros selecionados pelo administrador da loja virtual.  Posteriormente será solicitado que os usuários que realizaram os testes no protótipo da  loja virtual respondam um breve questionário relacionado às recomendações recebidas,  para a comprovação de que as recomendações foram realmente satisfatórias.      Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 260-263 Nov/2014     263  4. Considerações Parciais   Os estudos realizados na área de comércio eletrônico e sistemas de recomendação  comprovam o grande crescimento e consequentemente a grande demanda de serviços  nesta área. Através desta compreensão conclui-se que os estudos e desenvolvimento de  aplicações nestas áreas são de extrema importância para as lojas virtuais já existentes e  também para as que virão a existir.    Pelos estudos realizados até o momento, foram encontradas possíveis  dificuldades de implementação que deverão ser melhor estudadas para a implementação  do protótipo de framework. Entre as possíveis dificuldades encontradas citam-se: a  implementação e conexão com o banco de dados da loja virtual e a dificuldade de  implementação dos algoritmos de recomendação dos produtos através dos parâmetros.    O protótipo de framework será validado primeiramente para banco de dados  MySQL, podendo-se assim citar como trabalhos futuros a implementação e validação  para outros bancos de dados, tornando assim o framework o mais genérico possível.  Técnicas de filtragem colaborativa e hibrida podem aqui ser citadas também como  possíveis trabalhos futuros de implementação, visando uma melhor forma de  recomendação e aumentando o desempenho do framework.   Referências   Cardona, M.; Silveira, S. R. (2010). “SRISA – Desenvolvimento de um Sistema de  Recomendação para Instalação de Som Automotivo”. In: V WET Workshop de  Engenharia e Tecnologia - IV CCTEC Congresso de Ciência e Tecnologia do Vale  do Taquari, Lajeado. Workshop de Engenharia. Lajeado: UNIVATES.    E-BIT. (2014). “Relatório WebShoppers 2014”. 29. ed. Disponível em:  <http://img.ebit.com.br/webshoppers/pdf/WebShoppers2014.pdf>. Acesso em: 31 de  março de 2014.   PHP.Net. (2014). “PHP Documentation”. 1997-2014 the PHP Documentation Group.  Disponível em: <http://www.php.net/manual/pt_BR/>. Acesso em: 25 de março de  2014.   Piroca, V.; Zschornack, F.; Silveira, S. R. (2009). “Sistema de Recomendação para  Lojas Virtuais de Informática”. In: IV WET (Workshop de Engenharia e Tecnologia,   Lajeado, RS. Anais do 3º Congresso de Ciência e Tecnologia do Vale do Taquari.   Ricci, F.; Rokach; L.; Shapira, B.; Kantor, P. B. (2011). “Recommender Systems  Handbook”. Springer. Springer US.   Welling L.; Thomson, L. (2005) “PHP e MySQL: Desenvolvimento Web”. 3. ed. Rio de  Janeiro: Campus/Elsevier.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 264-268 Nov/2014     264  Biblioteca Virtual de Soluções Assistivas   Maria Helena Franciscatto1 Adriana Soares Pereira1 Roberto Franciscatto1 Liliana  Maria Passerino2   1Universidade Federal de Santa Maria (UFSM) – Colégio Agrícola de Frederico  Westphalen (CAFW) – Frederico Westphalen, RS   2Universidade Federal do Rio Grande do Sul (UFRGS) – CINTED (Centro  Interdisciplinar de Novas Tecnologias na Educação) – Porto Alegre, RS  m.h.franciscatto@hotmail.com, adriana.pereirah@gmail.com,   roberto@cafw.ufsm.br, liliana@cinted.ufrgs.br   Abstract. The present work aims to develop a virtual library of assistive  solutions (web and mobile) for accessibility solutions management. The  project is based on centralizing effective work practices that contribute to  accessibility solutions that can be adapted to a particular usual context. Given  the urgent need for social inclusion, the focus of the project turns to the  development of a system that can serve as a virtual library of assistive  solutions, containing information to be used by managers, employers and  disabled people.   Resumo. O presente trabalho tem como objetivo o desenvolvimento de uma  biblioteca virtual de soluções assistivas (web e mobile) para gerenciamento de  soluções de acessibilidade. O projeto tem como base centralizar práticas  laborais efetivas que contribuam para soluções de acessibilidade podendo  estas serem adaptadas para um determinado contexto usual. Diante da  necessidade de inclusão social, o enfoque do projeto volta-se para o  desenvolvimento de um sistema que possa servir como uma biblioteca virtual  de soluções assistivas, contendo informações a serem utilizadas por gestores,  empregadores ou pessoas portadoras de deficiência.   1. Introdução   Garantir acessibilidade aos portadores de necessidades especiais tornou-se uma tarefa  inadiável na atual sociedade brasileira. Segundo dados do IBGE (2010), 23,9% da  população apresenta algum tipo de deficiência. São milhões de pessoas portadoras de  deficiências físicas (motora, visual, auditiva) e intelectuais que necessitam de atenção e  soluções eficazes para que possam ser efetivamente inseridas na comunidade.   Diante de tal cenário, o presente trabalho propõe o desenvolvimento de uma  biblioteca virtual de soluções assistivas para gerenciamento de soluções de  acessibilidade contendo informações como recursos, estratégias e tecnologias adotadas  em diversos ambientes.    2. Bibliotecas Virtuais  As bibliotecas virtuais são portais que podem ser acessados remotamente por meio de  uma rede de computadores. Nestas bibliotecas ou portais, o acesso a dados é imediato,  facilitando a expansão da informação universalmente. Elas representam, de acordo com  LACRUZ (1998), informações e documentos “alojados na Web e sem local físico,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 264-268 Nov/2014     265  organizados e postos à disposição de usuários que vão acessá-los online, à distância  [...]”. As bibliotecas virtuais, entretanto, não excluem as tradicionais. Segundo  TARGINO (2010), considerando a enorme expansão de conhecimento em diversos  povos e culturas, as bibliotecas virtuais “subsistem ao lado de bibliotecas tradicionais,  em pleno século XXI”.    Ao analisar a abrangência do termo “bibliotecas virtuais”, percebe-se um  desconhecimento por parte de gestores de empresas e da população em geral a respeito  da potencialidade desses ambientes. Por permitirem acesso remoto imediato por  qualquer usuário, elas promovem, também a acessibilidade. Contudo, apesar da  tecnologia assistiva estar presente conceitualmente na Web, ela não é exposta em forma  de soluções de inclusão para pessoas portadoras de deficiência.     Diante desta realidade é importante que algumas questões sejam avaliadas: como  as soluções assistivas podem ser gerenciadas através de bibliotecas virtuais? De que  forma elas promovem a inclusão digital nos diversos ambientes sociais?   3. Soluções Assistivas  Soluções assistivas são ideias aplicáveis em qualquer ambiente e que possuem o intuito  de melhorar as condições sociais de pessoas com deficiência, aumentar sua autonomia e  facilitar o desenvolvimento de suas atividades diárias. Tais soluções contemplam  recursos, alternativas e estratégias para promover a acessibilidade e apresentam,  principalmente, inovações em aparelhos e dispositivos tecnológicos. Verifica-se,  contudo, uma carência de soluções assistivas por parte de empresas e demais ambientes  sociais, estimulada por falta de informação e suporte na implantação e no  gerenciamento destas tecnologias.    Dentro deste contexto, estuda-se a vantagem que as bibliotecas virtuais  apresentam na divulgação de informação e troca de experiências acerca das práticas  acessíveis, sendo abordados alguns exemplos no próximo tópico.    4. Trabalhos Relacionados  A proposta de criação de uma biblioteca virtual que gerencie soluções assistivas se dá a  partir da ideia de divulgar conhecimento nesta área. Confirma-se, não apenas no Brasil,  como também internacionalmente, a existência de inúmeros portais que exploram a  aplicação de soluções assistivas, porém, como catálogos de produtos, estímulos a  eventos e fóruns. Alguns exemplos destes portais, são especificados nos itens abaixo  (COUTINHO e PASSERINO, 2014):   4.1 EASTIN   O EASTIN (http://www.eastin.eu) é um motor de busca europeu que fornece acesso a  milhares de produtos de tecnologias acessíveis. Foi projetado para pessoas com  deficiência, profissionais de saúde, gestores, e demais interessados em sugestões que  possam auxiliar na resolução de problemas de autonomia na vida diária de pessoas com  deficiência.   4.2 Portal Nacional de Tecnologia Assistiva   Portal brasileiro mantido pelo Instituto de Tecnologia Social (ITS -  http://www.assistiva.org.br/). Apresenta material sobre inúmeros tipos de deficiência,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 264-268 Nov/2014     266  além de notícias, legislação e catálogo de produtos relacionados à acessibilidade.    4.3 SIVA   O SIVA (http://portale.siva.it/) é um portal italiano que apresenta orientações e  informações sobre tecnologia de acessibilidade, além de produtos que melhoram a  qualidade de vida de idosos e pessoas portadoras de deficiência. Faz parte da rede  EASTIN, citada anteriormente e é dedicado a qualquer pessoa interessada no assunto.   5. Desenvolvimento de uma Biblioteca Virtual de Soluções Assistivas  Como estágio inicial, foram analisados e identificados os requisitos básicos necessários  ao desenvolvimento da biblioteca virtual. A ideia de funcionamento geral é uma  biblioteca de soluções composta por contribuições dos usuários previamente  cadastrados no sistema, sejam eles pessoas físicas ou jurídicas. A partir da modelagem  de dados, então, verificou-se a necessidade do sistema apresentar interfaces para login  de usuário, busca de soluções e cadastro de pessoa física e/ou jurídica. Uma vez  realizado o cadastro, as informações do usuário armazenadas no banco de dados  permitirão uma personalização de seu perfil.    Ao se autenticar, o usuário tem acesso ao seu perfil, que contém suas  informações pessoais, as soluções cadastradas por ele e um formulário para contato com  o moderador do site, caso queira fazer sugestões ou modificar algum dado cadastral. Ao  realizar o cadastro no sistema, ainda, o usuário tem a oportunidade de cadastrar uma  solução, que posteriormente ficará visível a qualquer pessoa que acessar a biblioteca.   Na segunda etapa de desenvolvimento, foi implementada a busca de soluções,  subdividida em uma busca simples (por palavra chave digitada) e uma busca avançada  (o usuário procura solução por características específicas). Ao acessar qualquer solução,  são apresentadas em tela informações como contexto de uso, categoria em que se  enquadra, sua utilização, além de arquivos de mídia explicativos (vídeos, documentos  ou imagens) sobre a mesma. A figura 1 demonstra a arquitetura proposta para a  biblioteca virtual de soluções assistivas.     Figura 1. Arquitetura da biblioteca virtual de soluções assistivas   A primeira versão do sistema encontra-se disponível na Web através do endereço  http://www.ufrgs.br/teias/solassistv2/principal/index.php. Na atual fase do projeto,     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 264-268 Nov/2014     267  encontra-se em desenvolvimento o módulo administrativo da biblioteca, que irá conter  relatórios de buscas cadastradas, usuários cadastrados e filtragem de resultados. Ainda  em desenvolvimento encontra-se o protótipo para o Sistema Operacional Android, um  aplicativo para acesso e visualização de soluções cadastradas no sistema, acesso ao  perfil de usuário e informações gerais acerca do projeto.   A biblioteca virtual de soluções assistivas foi implementada de forma responsiva  com a utilização do banco de dados MySQL, linguagem de Programação PHP e  Javascript. Para o desenvolvimento das interfaces, foi utilizada a linguagem de  estruturação HTML5 e folhas de estilo em CSS3. Já o protótipo para Android encontrase em desenvolvimento no ambiente de desenvolvimento integrado (IDE) Eclipse, com  utilização da linguagem de programação Java.   O projeto de Biblioteca Virtual de Soluções Assistivas, denominado SolAssist, é  resultado de atividade de pesquisa em conjunto com a Universidade Federal do Rio  Grande do Sul (UFRGS).   5.1 Resultados Esperados e Trabalhos Futuros   Após a conclusão das atividades citadas acima, os resultados esperados são:    - Uma biblioteca virtual de soluções assistivas responsiva, acessível e segura,  disponível para usuários que queiram visualizar informações ou contribuir com uma  tecnologia de acessibilidade, a fim de promover a inclusão social;   - Versões móveis da biblioteca virtual desenvolvida para dispositivos móveis  baseados nos sistemas operacionais Android, iOS e Windows Phone, disponibilizadas  em forma de WebApp.   6. Conclusões   Por meio da pesquisa realizada neste trabalho, foi possível conhecer a necessidade de  implantar práticas de acessibilidade por meio da construção colaborativa. Visto que a  inclusão social é tarefa essencial e improrrogável em qualquer ambiente, foi exposto um  modelo de biblioteca virtual para soluções assistivas, a ser usado por gestores, pessoas  portadoras de deficiência e pela população em geral.    O estudo, por fim, permitiu um aprofundamento do tema, abrindo novas  possibilidades de desenvolvimento na área e trazendo o propósito de otimizar  funcionalidades já existentes no sistema desenvolvido, a fim de torná-lo eficaz na  disseminação de conhecimento acerca da acessibilidade e ações inclusivas.    Referências   COUTINHO, K. S., PASSERINO, L. M. (2014) Biblioteca Virtual de Soluções em  Tecnologia Assistiva: como começar? Universidade Federal do Rio Grande do Sul,  Porto Alegre – Rio Grande do Sul.   INSTITUTO BRASILEIRO DE GEOGRAFIA E ESTATÍSTICA (IBGE). Censo  Demográfico 2010: Características gerais da população, religião e pessoas com  deficiência. Disponível em:  <ftp://ftp.ibge.gov.br/Censos/Censo_Demografico_2010/Caracteristicas_Gerais_Reli giao_Deficiencia/caracteristicas_religiao_deficiencia.pdf>. Acesso em: 08 set. 2014.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 264-268 Nov/2014     268  LACRUZ, A. M. del C. (1998) Bibliotecas digitales y sociedade de la información.  Scire, Zaragoza, v. 4, n. 2, p. 47-62.   TARGINO, M. (2010) A Biblioteca do século XXI: novos paradigmas ou meras  expectativas? Informação & Sociedade: Estudos, João Pessoa, v. 20, n. 1, p. 39-48.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 269-272 Nov/2014     269  Computação de alto desempenho em R: paralelização e  técnicas de otimização   Angela Mazzonetto, Prof. Dr. Carlos Amaral Hölbig   Programa de Pós-Graduação em Computação Aplicada – PPGCA   Universidade de Passo Fundo (UPF) 99.001-970 - Passo Fundo – RS – Brasil   144981@upf.br, holbig@upf.br   Abstract. The processing and analysis of large amounts of data are present in  several areas such as biology, chemistry, physics, statistics, geography,  among others, a fact that can make the task computationally complex and  exhaustive. The R language is an efficient computational tool to perform these  kinds of tasks, allowing them to be performed in high-performance computing  environments, aiming its parallelization and consequently a better  computational performance. Because of this, this work aims at the study and  demonstration of implementations that demonstrate that the use of  R language  is a feasible alternative when working with large amounts of data and to  obtain efficient and quick responses when of the resolution of the most various  kinds of computational models and simulations.   Resumo. O processamento e análise de grande quantidade de dados estão  presentes nas mais diversas áreas como biologia, química, física, estatística,  geografia, entre outras, fato este que pode tornar a tarefa  computacionalmente complexa e exaustiva. A linguagem R é uma ferramenta  computacional eficiente para realizar estes tipos de tarefas, possibilitando,  ainda, que elas sejam realizadas em ambientes computacionais de alto  desempenho, objetivando sua paralelização e, consequentemente, um melhor  desempenho computacional. Por este motivo, este trabalho visa o estudo e a  demonstração de implementações que comprovam que a utilização da  linguagem R é uma alternativa viável quando da necessidade de se trabalhar  com grandes quantidades de dados e de se obter respostas eficientes e rápidas  quando da resolução dos mais diversos tipos de modelos e simulações  computacionais.   1. Introdução   Inúmeras organizações atualmente têm a necessidade de realizar o processamento e  análise de uma grande quantidade de dados em tempo computacional hábil. Por este  motivo a utilização de ferramentas computacionais torna-se indispensável para a  realização destas atividades.     Uma ferramenta que pode ser utilizada para suprir estas necessidades é a  linguagem R.  De acordo com Torgo (2009), o R é uma linguagem de programação  open source e um ambiente para computação estatística, modelação e visualização de  dados. Trata-se de uma linguagem de programação especializada em análise de dados.  Além disso, está disponível para uma vários sistemas operacionais, tais como Linux,  Unix, Windows e MacOS. Outra grande vantagem desta linguagem é a grande  disponibilidade de pacotes, ferramentas, bibliotecas e funções que possibilitam, entre     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 269-272 Nov/2014     270  várias funcionalidades, o processamento paralelo das aplicações nela desenvolvidas e a  otimização de seus programas por meio do uso de funções especiais e de códigos  compilados em outras linguagens de programação.    Este artigo visa apresentar algumas técnicas e ferramentas da linguagem R que  possibilitam o processamento de grandes quantidades de dados com mais eficiência e  em ambientes computacionais de alto desempenho.    2. Computação de alto desempenho na linguagem R   Na linguagem R foram desenvolvidos inúmeros pacotes que possibilitam a computação  de alto desempenho, pacotes voltados para os mais diversos ambientes computacionais  como, por exemplo, para grids de computadores (GridR), para clusters (RPVM, Rmpi,  snow, snowFT, snowfall, papply, taskPR, foreach, doMC, doSnow, doMPI  e Rdsm), para computadores multicore (fork e multicore) e para GPUs  (gputools, magma e HiPLARM). Além deles pode-se citar os pacotes parallel  (uma suíte de vários dos pacotes citados acima em um único pacote do R) e o RHadoop  (pacote do R que possibilita a sua integração com a ferramenta Apache Hadoop, que é  um framework que permite o processamento distribuído de grandes conjuntos de dados  em clusters de computadores, usando modelos de programação simples). Uma lista atual  destes pacotes poderá ser encontrada na página da CRAN Task View: HighPerformance and Parallel Computing with R5, que é a página da entidade que  disponibiliza o R e seus pacotes oficiais. Detalhes sobre estes pacotes podem ser obtidos  em Schmidberger (2009), Eugster (2011) e McCallum and Weston (2011).    Alternativas para se obter um melhor desempenho com a linguagem é o uso de  funções compiladas e de funções vetorizáveis. O código da linguagem R é interpretado  quando é executado, ao contrário de algumas outras linguagens de programação. Esta é  uma razão do porque as funções escritas em C são muitas vezes mais rápidas que as  funções escritas em R. Com o uso do pacote compiler é possível tornar as funções,  em alguns casos, mais rápidas. Para fazer o uso de funções compiladas em C em  programas em R é utilizada a função cmpfun(). Além das funções compiladas  acessadas pelo pacote compiler, o R possui o pacote chamado Rcpp, o qual  proporciona a integração de funções de R com rotinas escritas em programas em C++.     Além disso, em R existem algumas alternativas para a escrita de funções  “rápidas”. Estas alternativas abordam aspectos de vetorização de funções e o uso de  estrutura de dados mais simples. A vetorização no R é um recurso muito importante,  pois uma função vetorizada não funciona em apenas um valor, mas sim em todo um  vetor ao mesmo tempo, o que torna mais fácil a escrita do código. É natural o uso de  laços de repetição para a modificação de valores de um vetor, o que não é necessário  com o uso das funções vetorizadas no R. Um exemplo do uso da vetorização é a função  sum(), que retorna a soma dos valores de um vetor ou matriz evitando, assim, a  necessidade de usar um laço para todo o processo da soma. Grande parte das funções  em R são vetorizadas e geralmente são implementadas em C sendo, por isso, mais  rápidas do que o uso tradicionais com laços de repetição.                                                     5  http://cran.r-project.org/web/views/HighPerformanceComputing.html     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 269-272 Nov/2014     271  3. Testes e resultados   Com o intuito de validar a pesquisa realizada neste trabalho, alguns testes foram  desenvolvidos no grupo de pesquisa ComPaDi da Universidade de Passo Fundo. O  ambiente computacional foi composto por um computador com processador Intel Core  i7 920, que opera à frequência de 2.66 Ghz, com 8 MB de cache L2, 8 GB de memória  RAM, sistema operacional Ubuntu 14.04 64 bits e placa de vídeo GeForce GTS250  1GB DDR3 ECS. Os softwares utilizados foram a linguagem R (versão 3.1.1 de 64  bits), a IDE RStudio e o pacote foreach (1.4.1).    A Figura 1 apresenta um programa que realiza o cálculo sequencial da soma  entre duas matrizes de 2000 elementos cada. Na linha 10 a soma é realizada e esta  operação resultou em um tempo computacional de 0.011s. Posteriormente, utilizando a  função vetorizada sum (linha 23), o tempo de execução ficou em 0.005s. Este fato  demonstra a importância do uso das funções vetorizadas disponibilizadas pelo R.      1. ordem = 2000  2. S  = array(0, dim = c(ordem, ordem))  3. S1 = array(0, dim = c(ordem, ordem))  4.  for(i in 1:ordem)  5.  for(j in 1:ordem)  6.  {  7.  A[i,j] = round(runif(1)*10);  8.  B[i,j] = round(runif(1)*10);  9.  }  10. system.time(S<-A+B)  11. #  usuário   sistema decorrido   12. #    0.012     0.000     0.011  13.   14. system.time(  15. for(i in 1:ordem)  16. for(j in 1:ordem)  17. {  18. S1[i,j] <- A[i,j]+ B[i,j];  19. })  20. #  usuário   sistema decorrido   21. #    9.112     0.019     9.134   22.   23. system.time(s<-sum(A))  24. #  usuário   sistema decorrido   25. #    0.005     0.000     0.005    Figura 4. Programa em R com funções de otimização.       A Figura 2 apresenta um programa com aplicação do pacote foreach. Pode  ser observado que o tempo decorrido foi de 1.827s com o laço foreach (linha 14)  utilizando a opção %dopar% (execução em paralelo utilizando 8 processadores).  Posteriormente, com um laço for simples (linha 17) o tempo foi de 7.197s (execução  sequencial).         Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 269-272 Nov/2014     272  1. library(foreach)  2. require(doSNOW)  3. cl<-makeCluster(8) # numero de cores  4. registerDoSNOW(cl)l  5. # create a function to run in each itteration of the loop  6. check <-function(n) {  7. for(i in 1:1000)  8. {  9.  sme <- matrix(rnorm(100), 10,10)  10. solve(sme)  11. }  12. }  13. times <- 100     # times to run the loop  14. system.time(x <- foreach(j=1:times ) %dopar%   check(j))  15. #  usuário   sistema decorrido   16. #    0.091     0.008     1.827   17. system.time(for(j in 1:times ) x <- check(j))  18. #  usuário   sistema decorrido   19. #    7.185     0.011     7.197  20. stopCluster(cl)   Figura 2. Programa em R com uso do foreach.   4. Conclusão   Observa-se que o processamento e análise dos dados atualmente é algo imprescindível  para as organizações que possuem base de dados com grande quantidade de  informações. Por este motivo a linguagem R torna-se uma forte aliada para a criação de  modelos de simulação que realizem tarefas relacionadas aos estas informações. Porém,  inúmeras vezes, com apenas as funções básicas desta linguagem não é o suficiente para  que o processamento dos dados seja feito em um tempo computacional hábil.  Consequentemente surge a necessidade de buscar novos meios de proporcionar este  processamento ainda mais eficiente em termos de desempenho computacional. Neste  trabalho foram abordadas várias ferramentas para auxiliar o paralelismo em R. Também  se realizou alguns testes utilizando a função sum própria do R e o pacote foreach.  Estes testes demonstraram a viabilidade de sua utilização e o ganho em desempenho  obtido, concluindo, assim, que a paralelização e a otimização em R são opções viáveis e  eficientes quando da execução de aplicações reais de grande porte e com grande  quantidade de dados. Como trabalho futuro, esta pesquisa visa a execução paralela de  modelos de simulação de culturas e doenças de plantas implementados em R.   Referencias   Schmidberger, M. et al. (2009) "State of the Art in Parallel Computing with R", In:  Journal of Statistical Software., v.31, n.1, p. 1-27.   Eugster, M. J. A. et al. (2011) "Hands-on tutorial for parallel computing with R", In:  Computational Statistics, v. 26, n. 2, p. 219-239.   McCallum, Q.E. and Weston, S. (2011) “Parallel R”. O’Reilly Media, Inc.   Torgo, L. (2009) “A linguagem R: programação para a análise de dados.” Lisboa:  Escolar Editora, p. 203.      
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 273-276 Nov/2014     273  EAReq-Game: Um Jogo Educacional para o Ensino de  Elicitação e Análise de Requisitos   Natiel Cazarotto Chiavegatti, Giani Petri  Curso Superior de Tecnologia em Sistemas para Internet (TSI)   Universidade Federal de Santa Maria (UFSM)   {natiel.cazarotto, gianipetri}@gmail.com   Abstract. The requirements engineering objective to establish the understanding of the  problem and the needs of the customer. However, the process of teaching this  competence is not always satisfactory, as a theoretical content, many teachers use only  lectures, which ends up limiting student learning. Thus, the need to explore new  teaching methods arises. One of the educational resources available arethe  educational games that aim to contribute to practice by creating an environment that  will arouse the interest of students. The objective of this paper is to develop an  educational game in which the player acts as a requirements engineer, collecting,  organizing and prioritizing requirements in a simulated scenario, find progress in  stages of the game.    Resumo. A engenharia de requisitos objetiva estabelecer o entendimento do problema  e as necessidades do cliente. No entanto, o processo de ensino desta competência nem  sempre é satisfatório, por ser um conteúdo teórico, muitos professores utilizam  somente aulas expositivas, o que acaba limitando o aprendizado dos alunos. Assim,  surge a necessidade de explorar novos métodos de ensino. Um dos recursos  educacionais disponíveis são os jogos educativos, que objetivam contribuir com a  prática, criando um ambiente que desperte o interesse dos alunos. O objetivo deste  trabalho é desenvolver um jogo educativo no qual o jogador atuará como um  engenheiro de requisitos coletando, organizando e priorizando os requisitos em um  cenário simulado, buscando progredir nas fases do jogo.     1. Introdução   A engenharia de requisitos é umas das principais etapas dentro de um projeto de  desenvolvimento de software, e procura estabelecer o entendimento dos problemas e as  necessidades do cliente [Sommerville 2011]. No entanto, o ensino desta competência,  muitas vezes, deixa a desejar em cursos de graduação [Thiry, Zoucas e Gonçalves  2010], por ser um conteúdo muito teórico, muitos professores acabam ensinando  somente o conteúdo de modo teórico, com poucos exercícios, não utilizando estratégias  de ensino motivadoras, limitando assim o aprendizado dos alunos, causando  desinteresse dos acadêmicos em certas ocasiões.    A elicitação e análise de requisitos, uma das etapas da engenharia de requisitos,  está sendo notada como umas das principais causas de falhas em projetos de software  [Fernandes, Machado e Seidman 2009]. Isso pode ocorrer pelo fato de profissionais  recém formados entrarem no mercado de trabalho sem possuir uma experiência prática  de como exercer as atividades envolvidas na elicitação e análise de requisitos.    Diante disso, surge a necessidade de explorar novos métodos de ensino para  potencializar o real aprendizado e proporcionar um ambiente lúdico, interessante e  prazeroso para o aluno. Assim, um dos recursos educacionais disponíveis aos  professores são os jogos educativos, que objetivam contribuir no aprendizado dos     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 273-276 Nov/2014     274  alunos explorando a simulação de atividades práticas e criando um ambiente que  desperte o interesse dos alunos.   Desta forma, o objetivo deste trabalho é apresentar a proposta para o  desenvolvimento de um jogo educacional no qual o jogador atuará como um engenheiro  de requisitos coletando, organizando e priorizando os requisitos em um cenário  simulado, buscando progredir nas fases do jogo, que equivalem as fases envolvidas na  etapa de elicitação e análise de requisitos [Sommerville 2011].    2. Metodologia  A metodologia deste trabalho, quanto à natureza, classifica-se como pesquisa aplicada,  onde objetiva-se gerar um produto de software (jogo educacional digital). Inicialmente,  a pesquisa explorou artigos e livros publicados em bases acadêmicas, como objetivo de  identificar e analisar dados e estudos sobre engenharia de requisitos com um foco maior  sobre elicitação e análise de requisitos, quais seus métodos de ensino utilizando jogos  digitais, onde foram analisados alguns jogos que dentre eles, objetivou-se o  desenvolvimento de um jogo para auxiliar no ensino e aprendizagem de elicitação e  análise de requisitos.    O presente trabalho será desenvolvido seguindo as seguintes etapas: estudos,  pesquisas e análise de jogos digitais já existentes na área de engenharia de requisitos;  escolha de uma ferramenta para o desenvolvimento do jogo; estudo dos recursos  disponíveis no mesmo para desenvolvimento do trabalho e criação do jogo e suas fases;  seleção, planejamento e criação do jogo baseado em atividades de engenharia de  requisitos, mais especificamente em elicitação e análise de requisitos.       3. Fundamentação Teórica  3.1.  Jogos Educacionais  Os jogos educacionais estão cada vez mais contribuindo com o ensino e aprendizagem e  potencializando as práticas de atividades em instituições de ensino. Profissionais de  ensino tendem a buscar e explorar novas estratégias de ensino a seus acadêmicos para  alcançar seus objetivos de ensino e aprendizagem, tendo como foco a maior atenção  pelo conteúdo apresentado em teoria. Jogos educacionais são atividades baseadas em  regras e restrições que deverão ser cumpridas para se alcançar um determinado objetivo.  Estes recursos auxiliam no aprendizado do aluno, por mostrar na prática o que é  ensinado em teoria pelos docentes. Além de ser uma fonte de estímulo ao  desenvolvimento das atividades [Savi 2011].  3.2. Elicitação e Análise de requisitos  O processo de engenharia de requisitos é dividido em três estágios: elicitação e análise  de requisitos, validação de requisitos e o gerenciamento dos requisitos, sendo que as  atividades destes estágios estão organizadas em formato de espiral, neste modelo são  expostas camadas para abordagens que serão utilizadas no entendimento dos requisitos  em diversos níveis [Sommerville 2011].    A etapa de elicitação e análise de requisitos é composta pelas seguintes  atividades: descoberta de requisitos, classificação e organização de requisitos,  priorização e negociação de requisitos e especificação de requisitos [Sommerville  2011].    No processo de elicitação e análise de requisitos, os interessados, usuários finais  ou stakeholders trabalham juntos de forma colaborativa e organizada para identificar e     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 273-276 Nov/2014     275  resolver o problema na elaboração, negociação e especificação. Na atividade de  Descoberta de Requisitos, ocorre a interação com os stakeholders do sistema para  descobrir requisitos; na atividade de classificação e organização de requisitos, recebe os  requisitos de forma não estruturada, agrupa-os de forma relacionada e organiza em  grupos coerentes; já na atividade de priorização e negociação de requisitos, os  stakeholders se reúnem para decidir quais são os principais requisitos a serem  executados, assim entrando em um acordo sobre as prioridades dos requisitos do projeto  e; a atividade de especificação de requisitos, refere-se a documentação e inserção dos  requisitos no próximo ciclo do espiral, podem ser documentos formais ou informais  [Sommerville 2011].     4. EAReq-Game     Para ser um jogo educacional é necessário, além de jogabilidade, ter um objetivo  educacional bem definido [Savi 2011]. Assim, o objetivo do EAReq-Game é inserir o  aluno em um ambiente simulado para aplicar na prática as atividades do estágio de  elicitação e análise de requisitos, trabalhando na descoberta de requisitos, organização e  priorização de requisitos coletados em um cenário simulado, assumindo o papel de  engenheiro de requisitos.    No início do jogo, que está em fase de desenvolvimento, o aluno é instruído com  informações do cenário e de seus objetivos a serem cumpridos ao longo do jogo,  conforme apresenta a Figura 1.     Figura 1. Tela de apresentação do início do cenário e algumas explicações sobre  o jogo.   Após as informações iniciais, o avatar do jogador é direcionado para a primeira  fase do jogo. A primeira fase consiste em ingressar no colégio e dirigir-se até a  secretaria para descobrir os requisitos necessários, interagindo com outros avatares (que  representam os papéis de secretários e professores), livros, documentos, entre outros  objetos. Após descobrir o maior número de requisitos possíveis, o jogador deverá  organizá-los e agrupar os requisitos semelhantes para então, na sequência priorizá-los e  classificá-los em requisitos obrigatórios, desejáveis e fora do escopo. Essa classificação  irá gerar uma pontuação que irá para o ranking do jogo. Para avançar para a próxima  fase, o engenheiro de requisitos terá uma pontuação mínima a ser cumprida e, caso não  alcançá-la, deverá retornar às atividades de descoberta, classificação e priorização dos  requisitos do cenário anterior.    Na segunda fase o jogador irá para outro cenário do Colégio (a Direção,  conforme Figura 2) e novamente deverá interagir com os avatares e os objetos e então  aplicar as atividades de descoberta de requisitos, classificando-os e priorizando-os, onde  o resultado irá gerar uma pontuação que acumulará aos pontos do seu ranking.     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 273-276 Nov/2014     276       Figura 2. Apresenta a interação entre os avatares para coleta de requisitos em  uma sala de direção.   Ao longo do jogo o aluno, que terá o papel de engenheiro de requisitos, está  inserido em um cenário simulado de um Colégio aplicando na prática as atividades da  etapa de Elicitação e Análise de requisitos. Esta imersão no jogo potencializa o  aprendizado do aluno visualizando na prática os conceitos aprendidos em aulas teóricas,  além de estar utilizando um recurso educacional digital que estimula o aprendizado e o  interesse dos alunos.     5. Conclusões Parciais  Este trabalho tem por foco principal o desenvolvimento de um jogo que auxilie no  ensino e aprendizagem nos processos de elicitação e análise de requisitos. Nesta  oportunidade, são ressaltadas algumas etapas que foram, estão e serão utilizadas no  decorrer deste trabalho. Pretende-se que este jogo, que está em processo de  desenvolvimento, possa auxiliar os profissionais em colocar em prática boa parte do que  é apresentado aos acadêmicos em teoria, contribuindo assim para o aprendizado,  utilizando novas estratégias de ensino em um ambiente mais prazeroso.    O jogo está em fase inicial de concepção e projeto, utilizando para isso um  processo para o desenvolvimento de jogos educacionais existente na literatura. Após o  desenvolvimento do jogo, pretende-se avaliá-lo juntamente a uma turma de alunos,  identificando as reais potencialidades do jogo desenvolvido, utilizando para isso,  instrumentos de medição de jogos educacionais existentes na literatura.     6. Referências bibliográficas   Fernandes, M.; Machado, R.; Seidman, S. (2009). A Requirements Engineering and   Management Training Course for Software Development Professionals. 22th  Conference on Software Engineering Education and Training.    Thiry, M. Zoucas, A. Gonsalves, Q, R. (2010). Promovendo Aprendizagem de Engenharia  de Requisitos de Software Através de um Jogo Educativo. Universidade do Vale do  Itajaí (UNIVALI), São José - SC.   Savi, R. (2011). Avaliação de jogos voltados para a disseminação do conhecimento.  Universidade Federal de Santa Catarina (UFSC), 2011, tese (Doutorado) –  UFSC, Florianópolis.    Sommerville, I. (2011). Engenharia de software. 09 ed. São Paulo: Pearson Prentice  Hall.         
                               Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 277-280 Nov/2014     277  Jogos Educacionais no Ensino de Metodologias Ágeis: uma  revisão da literatura   Rogério Paulo Marcon Júnior, Giani Petri   Curso de Tecnologia em Sistemas para Internet (TSI)   Universidade Federal de Santa Maria (UFSM)  Caixa Postal 54 – 98.400-000 – Frederico Westphalen – RS – Brasil   rpjunior_1@hotmail.com, gpetri@inf.ufsm.br   Abstract.  The teaching and learning process subjects in the area of software  engineering, in particular the expertise of Agile Methodologies, does not have  the same result if the teacher does not provide a practical experience to  students. In this context, educational games contribute to learning, leveraging  experimentation of concepts in practice. However, there are few non  computerized educational games that explore the concepts involved in Agile  Methodologies.   Thus, the aim of this paper is to present a literature review of  non-computerized educational games used for teaching and learning Agile  Methodologies. Thus, helping teaching professionals in the insertion of new  instructional strategies in their classes.   Resumo.  O processo de ensino e aprendizagem das disciplinas da área de  Engenharia de Software, em especial à competência de Metodologias Ágeis,  não possui o mesmo resultado se o docente não proporcionar uma vivência  prática aos alunos. Neste contexto, os jogos educacionais contribuem na  aprendizagem, potencializando a experimentação dos conceitos na prática.  No entanto, há poucos jogos educativos não computadorizados que exploram  os conceitos envolvidos nas Metodologias Ágeis. Desta forma, o objetivo deste  trabalho é apresentar uma revisão da literatura dos jogos educacionais não  computadorizados utilizados para o ensino e o aprendizado de Metodologias  Ágeis. Assim, auxiliando profissionais docentes na inserção de novas  estratégias instrucionais em suas aulas.   1. Introdução   Em cursos da área de Ciência da Computação as disciplinas relacionadas à Engenharia  de Software são de grande importância para a formação profissional, em especial, as  metodologias ágeis de desenvolvimento de sistemas. Neste contexto, [Reif and Mitri  2005] destacam que o aprendizado dessas disciplinas não possui o mesmo efeito se o  aluno não tiver uma vivência prática com o conteúdo, por mais simples que seja. Desta  forma, cabe ao profissional docente inserir estratégias instrucionais diferenciadas em  suas aulas, tornando o ambiente agradável e que potencialize o processo de ensino e  aprendizagem.    Um dos recursos educacionais à disposição dos docentes atualmente são os  jogos educacionais. Os jogos educacionais contribuem na aprendizagem dos alunos,  potencializando a experimentação e visualização de conceitos, além de criar ambientes  que despertem a criatividade e o interesse dos alunos [Gramigma 1994]. Os jogos  educacionais são classificados em jogos digitais (computadorizados) e jogos não     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 277-280 Nov/2014     278  digitais (não computadorizados). Um jogo educacional digital objetiva aliar o  aprendizado com a diversão e são caracterizados por serem jogados através de um  dispositivo virtual (computador, tablet, etc.) e por oferecerem um ambiente interativo  [Mitamura et al. 2012]. Por outro lado, um jogo não computadorizado caracteriza-se por  explorar a interação entre um grupo de jogadores não individualizados, proporcionando  um momento lúdico e potencializando o convívio e a integração sem explorar o uso de  recursos digitais, o que muitas vezes pode ser um limitador na adoção de alguma  estratégia instrucional em ambientes acadêmicos.     Por estes motivos, este trabalho objetiva realizar uma revisão da literatura,  pesquisando estratégias instrucionais baseadas em jogos não computadorizados, que são  aplicadas para contribuir no processo de ensino e aprendizagem da competência de  Metodologias Ágeis.    Os resultados preliminares da revisão de literatura podem auxiliar os  profissionais docentes da área de Engenharia de Software a encontrar novas estratégias  instrucionais para inserir em suas aulas e assim, potencializar a capacitação e a  formação profissional de seus alunos na competência de Metodologias Ágeis.   2. Jogos Educacionais   Os jogos educacionais vêm contribuindo significantemente para o desenvolvimento de  habilidades, atitudes e conhecimentos para a formação de profissionais da área da  Ciência da Computação. Segundo [Prikladnicki and Wangenheim 2008], os jogos  educacionais têm a capacidade de auxiliar no desenvolvimento da criatividade,  explorando a visualização e experimentação de conceitos.    Dentro da área de Ciência da Computação, existem diversos jogos educacionais  que podem ser utilizados pelos professores em seus momentos pedagógicos. Em  especial, na Engenharia de Software, os jogos educacionais, digitais ou não, foram  desenvolvidos objetivando suprir as limitações no aprendizado dos alunos ao  participarem de aulas estritamente tradicionais, abordando somente a teoria das  competências.    3. Metodologia   A metodologia deste trabalho, quanto a natureza, classifica-se como uma pesquisa  básica qualitativa, que produz um conhecimento a ser utilizado em pesquisas aplicadas.  Quanto aos procedimentos, classifica-se como uma pesquisa bibliográfica, tendo como  finalidade conhecer os diferentes jogos educacionais não computadorizados utilizados  no ensino da Engenharia de Software, em especial a competência de Metodologias  Ágeis.    A pesquisa explorou bases acadêmicas, em especial a base Google Scholar,  objetivando encontrar materiais, como teses e artigos, que poderiam explicar melhor  como jogos educativos poderiam ser utilizados dentro de um ambiente acadêmico para o  ensino de Metodologias Ágeis. Na sequência, foi realizado um estudo e entendimento  dos jogos encontrados na literatura para identificar quais seriam os mais adequados para  estarem dentro de um ambiente acadêmico e que utilizavam somente recursos básicos,  acessíveis para quase todos os contextos educacionais.       Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 277-280 Nov/2014     279  4. Revisão da Literatura   Esta seção apresenta os resultados da revisão da literatura. Os dados dos jogos  educacionais não computadorizados encontrados na revisão estão apresentados na  Tabela 1.  A Tabela 1 está estrutura da seguinte forma: a primeira coluna refere-se  ao ID, que corresponde a um simples identificador do jogo educacional. A segunda  coluna da tabela apresenta o nome do jogo, a terceira coluna refere-se as referências e  trabalhos relacionados, na quarta coluna encontra-se uma breve descrição do jogo, a  quinta coluna apresenta a forma de utilização, como são divididas as equipes, na sexta  coluna, encontra-se o ambiente para aplicação do jogo e a sétima coluna, refere-se as  habilidades que os jogos procuram exercitar nos discentes.      Tabela 1. Jogos Educacionais não computadorizados para o Ensino de  Metodologias Ágeis   ID Jogo  Referência  s  Descrição   Forma de  utilização   Ambiente  de   execução   Habilidades  Desenvolvidas   1 Scrum  Game   [Cohn and  Wake 2007]      Os jogadores  simulam um projeto  envolvendo o  Scrum   O jogo é  jogado em  equipes   Jogo de  cartas e  tabuleiro   Trabalho em  equipe, tomada  de decisões   2 Agile  Ball  Point  Game   [Gloger,  2008]   [Petri,  Marcon  Júnior  2014a]  [Petri,  Marcon  Júnior  2014b]   Os jogadores  trabalharão em uma  equipe, estimando e  organizando o  processo para  alcançar as  estimativas   Todos os  jogadores  são uma  única  equipe.    Sala de aula  ou outro  ambiente  com espaço.  Utiliza-se  bolas de  tênis.   Trabalho em  equipe, tomada  de decisões,  senso de  liderança,  resolução de  conflitos e autoorganização   3 Scrum  With  Lego   [Krivitsky  2009]   As equipes  trabalharão juntas  para construir uma  cidade de lego   Os  jogadores  se dividem  em equipes,  porém,  todas  trabalham  juntas   Sala de aula  ou ambiente  com espaço   Trabalho em  equipe,  colaboração para  um sucesso  comum   4 Fábrica  de  barquinh os   [Zemuner  2011]   Cada equipe deverá  formar uma linha de  montagem, nesta  linha conterá quatro  membros com  características  distintas   As equipes  terão um  líder, um  preguiçoso,  um piadista  e um crítico   Sala de aula  ou ambiente  com espaço   Trabalho em  equipe, liderança,  comunicação,  lidar com pessoas  diferentes   5. Conclusões   A inserção de jogos educativos que visam explorar a prática de conteúdos, construindo  um ambiente de aprendizagem lúdico e que desperte o interesse dos educandos é uma  técnica que deve ser seguida pelos profissionais de educação, em especial os docentes     Anais do EATI - Encontro Anual de Tecnologia da Informação  e Semana Acadêmica de Tecnologia da Informação         Anais do EATI Frederico Westphalen - RS     Ano 4 n. 1 p. 277-280 Nov/2014     280  que trabalham com as disciplinas de Engenharia de Software, em cursos da área de  Ciência da Computação. De igual modo, as competências relacionadas às Metodologias  Ágeis devem ser vivenciadas na prática pelos educandos objetivando capacitar o  processo de ensino e aprendizagem.    Ao utilizar jogos educacionais em ambientes acadêmicos o professor pode  explorar mais dos alunos, podendo treiná-los para se tornarem bons líderes, para  tomarem decisões rápidas, e o mais importante, incentivá-los a trabalharem em conjunto  para um sucesso mútuo.    Desta forma, conclui-se que a revisão da literatura apresentada neste trabalho é  relevante, pois destaca algumas estratégias instrucionais eficientes para os docentes da  área de Engenharia de Software inseri-las em seus momentos pedagógicos e assim,  potencializar a aprendizagem de seus alunos em uma competência de grande  importância para os profissionais da área da Computação.   Referências   Cohn, M., Wake, M. (2007). Scrum Game. Disponível em:     http://www.mountaingoatsoftware.com/pages/28-the-scrum-game-a-fun-interactivetool-for-learning-scrum-amp-agile. Acesso em: 05 set. 2014.   Gramigma, M. R. M. (1994). Jogos de empresa. São Paulo: Makron Books, 1994.   Krivitsky, A. (2009). Scrum Simulation with LEGO Bricks. Disponível em:    https://www.scrumalliance.org/system/resource_files/0000/3689/Scrum-Simulationwith-LEGO-Bricks-v2.0.pdf. Acesso em: 05 set. 2014.   Mitamura, T., Suzuki, Y., and Oohori, T. (2012). Serious games for learning  programming languages. In Systems, Man, and Cybernetics (SMC), 2012 IEEE  International Conference on, pages 1812–1817.   Petri, G., Marcon Júnior, R.P. (2014a). Agile Ball Point Game: Um Jogo Educativo  Para o Ensino de Metodologias Ágeis. I Simpósio Internacional de Games, Mundos  Virtuais e Tecnologia na Educação. Santa Maria, RS.   Petri, G., Marcon Júnior, R.P. (2014b). Um Jogo Educacional Para o Ensino de  Metodologias Ágeis. FEES - Fórum de Educação em Engenharia de Software, evento  integrante do XXIII Simpósio Brasileiro de Engenharia de Software (SBES),  Maceió, Alagoas.   Prikladnicki, R,  and Wangenheim, C. G. (2008) O Uso de Jogos Educacionais para o  Ensino de Gerência de Projetos de Software. FEES - Fórum de Educação em  Engenharia de Software.   Reif, H. L., Mitri, M. (2005). How University Professors Teach Project Management for  Information Systems. Communications of the ACM, Vol. 48, N. 8, Ago/2005.   Zemuner, E. (2011). Fábrica de Barquinhos. Disponível em:  http://zemuner2.webnode.com.br/news/fabrica-de-barquinhos/. Acesso em: 05 set.  2014.        
